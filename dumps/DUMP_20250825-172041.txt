# ---- DUMP SCALP ----
time   : 2025-08-25 17:20:41
root   : /notebooks/scalp
output : /notebooks/scalp/dumps/DUMP_20250825-172041.txt


# ===== CHANGELOG.md ===== (13 lignes, modifié 2025-08-25 17:18:51)

# Changelog

## Unreleased

- Trigger trade entries via `strategy.generate_signal` with weighted scoring and
  signal levels.
- Dynamic risk management adapting `risk_pct` and leverage based on signal and
  user risk level.
- Notional and margin caps with available balance check to avoid Bitget error
  `40762`.
- Risk notifications with green/yellow/red indicators for terminal and
  Telegram.

# ===== INSTALL.txt ===== (41 lignes, modifié 2025-08-25 17:18:51)

# INSTALLATION — Projet scalp

Prérequis système
- Python 3.10+ (recommandé 3.11)
- Accès réseau sortant (Bitget API, Telegram)
- Espace persistant pour DATA_ROOT (ex: /notebooks/scalp_data)

1) Création d’environnement virtuel (recommandé)
   python -m venv .venv
   . .venv/bin/activate
   python -m pip install --upgrade pip

2) Installation des dépendances
   pip install -r requirements.txt

3) Configuration .env (dans /notebooks/.env)
   TELEGRAM_BOT_TOKEN=xxxx
   TELEGRAM_CHAT_ID=123456
   BITGET_ACCESS_KEY=xxxx
   BITGET_SECRET_KEY=xxxx
   BITGET_PASSPHRASE=xxxx
   DATA_ROOT=/notebooks/scalp_data
   LOG_LEVEL=INFO

4) Premier run (collecte market data simple)
   python bot.py
   → écrit /notebooks/scalp_data/data/live/logs/signals.csv

5) Mise à jour pairs + backfill
   python jobs/refresh_pairs.py --timeframe 5m --top 10 --backfill-tfs 1m,5m,15m,1h --limit 2000

6) Backtests + promotion stratégie
   python jobs/backtest.py --from-watchlist --tfs 1m,5m,15m,1h
   python jobs/promote.py --draft /notebooks/scalp_data/reports/strategies.yml.next

7) Lancement live (avec stratégies promues)
   python bot.py
   → écrit /notebooks/scalp_data/data/live/orders.csv (paper mode)

8) Dashboard (optionnel)
   streamlit run dash/app.py --server.port 8501 --server.headless true

# ===== PROMPT.md ===== (108 lignes, modifié 2025-08-25 17:18:51)

# Prompt de re-création du bot Scalp (version spot)

Ce fichier résume les modules et fonctions essentiels afin de recréer le bot de trading **spot** Bitget (paires USDT) à partir de zéro. Chaque fonction liste son rôle principal et les paramètres indispensables. Le fichier `.env` contenant les clés API se trouve dans le dossier parent du bot.

## Structure principale

### bot.py
- `_noop_event(*args, **kwargs)` : fonction vide pour le logging d'événements.
- `check_config()` : vérifie la présence des clés API Bitget et journalise un avertissement si elles manquent.
- `BitgetSpotClient` : sous-classe du client spot Bitget qui injecte `requests` et la fonction `log_event`.
- `find_trade_positions(client, pairs, interval="1m", ema_fast_n=None, ema_slow_n=None)` : applique la stratégie EMA sur une liste de paires et renvoie les signaux.
- `send_selected_pairs(client, top_n=40, tg_bot=None)` : sélectionne et notifie les paires les plus actives.
- `update(client, top_n=40, tg_bot=None)` : rafraîchit la liste des paires et renvoie la charge utile envoyée.
- `main(argv=None)` : initialise la configuration, le client, le `RiskManager`, le bot Telegram et exécute la boucle de trading.

### cli.py
- `run_parallel_optimization(pairs, timeframe, jobs)` : lance une optimisation paramétrique (exemple minimal).
- `run_walkforward_analysis(pair, timeframe, splits, train_ratio)` : exécute une analyse walk-forward.
- `run_live_pipeline(pairs, tfs)` : exécute la pipeline live asynchrone.
- `create_parser()` : construit l’analyseur d’arguments avec les sous-commandes `opt`, `walkforward`, `live` et `bump-version`.
- `main(argv=None)` : point d'entrée qui déclenche la commande choisie.

### init.py
- `install_packages(*args)` : installe des paquets via `pip`.
- `main()` : installe tous les fichiers `requirements*.txt` et `pytest`.

## Modules `scalp`

### bot_config.py
- `CONFIG` : dictionnaire global des paramètres (clés API, symbole, EMA, ATR, risques, etc.).

### metrics.py
- `calc_pnl_pct(entry_price, exit_price, side, fee_rate=0)` : pourcentage de PnL net des frais.
- `calc_rsi(prices, period=14)` : calcul du RSI (Wilder).
- `calc_atr(highs, lows, closes, period=14)` : ATR avec lissage de Wilder.
- `calc_macd(prices, fast=12, slow=26, signal=9)` : renvoie MACD, ligne signal et histogramme.
- `backtest_position(prices, entry_idx, exit_idx, side)` : valide qu’une position est cohérente avec le mouvement des prix.

### strategy.py
- `ema(series, window)` : moyenne mobile exponentielle.
- `vwap(highs, lows, closes, volumes)` : prix moyen pondéré par le volume.
- `obv(closes, volumes)` : série On Balance Volume.
- `cross(last_fast, last_slow, prev_fast, prev_slow)` : détecte les croisements EMA.
- `order_book_imbalance(bid_vol, ask_vol)` : mesure le déséquilibre du carnet d'ordres.
- `swing_levels(highs, lows, lookback)` : renvoie le dernier plus haut et plus bas.
- `Signal` : dataclass contenant `symbol`, `side`, `price`, `sl`, `tp1`, `tp2`, `qty`.
- `generate_signal(symbol, ohlcv, equity, risk_pct, ...)` : produit un `Signal` si toutes les conditions de stratégie sont réunies.
- `scan_pairs` et `select_active_pairs` sont re-exportés pour la sélection des paires.

### trade_utils.py
- `compute_position_size(equity_usdt, price, risk_pct, symbol=None)` : calcule la quantité à acheter/vendre en fonction du risque et du prix.
- `analyse_risque(open_positions, equity_usdt, price, risk_pct, symbol=None, side="long", risk_level=2)` : renvoie la taille de position conseillée selon l’exposition actuelle (sans effet de levier).
- `trailing_stop(side, current_price, atr, sl, mult=0.75)` : met à jour le stop loss en fonction de l'ATR.
- `break_even_stop(side, entry_price, current_price, atr, sl, mult=1.0)` : déplace le stop loss à break-even après un mouvement favorable.
- `should_scale_in(entry_price, current_price, last_entry, atr, side, distance_mult=0.5)` : indique si la position doit être renforcée.
- `timeout_exit(entry_time, now, entry_price, current_price, side, progress_min=15, timeout_min=30)` : ferme une position si aucune progression n’est constatée.
- `marketable_limit_price(side, best_bid, best_ask, slippage=0.001)` : calcule un prix limite pour une exécution quasi immédiate.

### risk
- `calc_risk_amount(equity, risk_pct)` : montant d'argent risqué sur un trade.
- `calc_position_size(equity, risk_pct, stop_distance)` : taille de position selon le stop.
- `adjust_risk_pct(risk_pct, win_streak, loss_streak, increase=0.12, decrease=0.25, min_pct=0.001, max_pct=0.05)` : ajuste le pourcentage de risque selon les séries de gains/pertes.
- `RiskManager` : classe gérant limites journalières, kill switch et ajustement de risque.
  - `reset_day()`, `register_trade(pnl_pct)`/`record_trade`, `dynamic_risk_pct(signal_quality, score)`, `apply_trailing(direction, price, sl, atr, params)`, `pause_duration()`, `can_open(current_positions)`.

### notifier.py
- `_pair_name(symbol)` : formatte le nom d’une paire.
- `_format_text(event, payload=None)` : construit un message lisible.
- `notify(event, payload=None)` : envoie des notifications via webhook HTTP et/ou Telegram.

### logging_utils.py
- `get_jsonl_logger(path, max_bytes=0, backup_count=0)` : renvoie une fonction de logging JSONL avec rotation optionnelle.
- `TradeLogger(csv_path, sqlite_path)` : enregistre chaque trade dans un CSV et une base SQLite (`log(data)`).

### bitget_client.py
- `BitgetSpotClient(access_key, secret_key, base_url, recv_window=30, paper_trade=True, requests_module=requests, log_event=None)` : client REST léger pour le marché spot.
  - `get_symbol_info(symbol=None)`, `get_kline(symbol, interval="1m", start=None, end=None)`, `get_ticker(symbol=None)`.
  - `_private_request(method, path, params=None, body=None)` : signe et exécute les requêtes privées.
  - `get_account()`, `get_open_orders(symbol=None)`.
  - `place_order(symbol, side, quantity, order_type, price=None, stop_loss=None, take_profit=None)`.
  - `cancel_order(symbol, order_id)`, `cancel_all(symbol)`.

### pairs.py
- `get_trade_pairs(client)` : récupère toutes les paires via `get_ticker`.
- `filter_trade_pairs(client, volume_min=5_000_000, max_spread_bps=5, top_n=40)` : filtre par volume/spread.
- `select_top_pairs(client, top_n=40, key="volume")` : trie par volume ou autre clé.
- `find_trade_positions(client, pairs, interval="1m", ema_fast_n=None, ema_slow_n=None, ema_func=ema, cross_func=cross)` : signaux EMA croisement.
- `send_selected_pairs(client, top_n=40, select_fn=select_top_pairs, notify_fn=notify)` : déduplique USD/USDT/USDC et notifie la liste.
- `heat_score(volatility, volume, news=False)` : score combinant volatilite et volume.
- `select_top_heat_pairs(pairs, top_n=3)` : sélection des paires les plus "chaudes".
- `decorrelate_pairs(pairs, corr, threshold=0.8, top_n=3)` : choisit des paires peu corrélées.

### telegram_bot.py
- `TelegramBot(token, chat_id, client, config, risk_mgr, requests_module=requests)` : mini bot Telegram.
  - `send_main_menu(session_pnl)`, `update_pairs()`, `send(text, keyboard=None)`, `answer_callback(cb_id)`,
  - `fetch_updates()`, `handle_updates(session_pnl)`, `handle_callback(data, session_pnl)`.
  - Helpers privés `_base_symbol`, `_build_stop_keyboard`, `_menu_text`.
- `init_telegram_bot(client, config, risk_mgr)` : instancie un `TelegramBot` si les variables d’environnement `TELEGRAM_BOT_TOKEN` et `TELEGRAM_CHAT_ID` sont définies.

## Utilisation
1. Définir les variables d’environnement (clés Bitget, token Telegram, etc.).
2. Exécuter `init.py` pour installer les dépendances.
3. Lancer `bot.py` pour démarrer le trading.
4. Utiliser `cli.py` pour les outils d’optimisation ou de tests.

Ce résumé fournit les éléments nécessaires à la reconstruction du bot et à la compréhension de chaque fonction essentielle.


# ===== README.md ===== (133 lignes, modifié 2025-08-25 17:18:51)

# Scalp

Bot de trading pour les futures USDT-M de Bitget. Ce projet est **expérimental** et fourni à des fins éducatives.

## Installation

Assurez-vous d'avoir Python 3.8 ou supérieur puis installez les dépendances :

```bash
pip install -r requirements.txt
```

Pour développer ou exécuter les tests :

```bash
pip install -r requirements-dev.txt
pytest  # ou make test
```

## Configuration

Le bot lit sa configuration via des variables d'environnement :

- `BITGET_ACCESS_KEY`, `BITGET_SECRET_KEY` : clés API Bitget (laisser les valeurs par défaut pour rester en mode papier).
- `PAPER_TRADE` (`true`/`false`) : par défaut `true`, n'envoie aucun ordre réel.
- `SYMBOL` : symbole du contrat futures (par défaut, `BTCUSDT`).
- `INTERVAL` : intervalle des chandeliers, ex. `1m`, `5m`.
- `EMA_FAST`, `EMA_SLOW` : périodes des EMA utilisées par la stratégie.
- `MACD_FAST`, `MACD_SLOW`, `MACD_SIGNAL` : paramètres du filtre de tendance MACD.
- `EMA_TREND_PERIOD` : période de l'EMA longue utilisée comme filtre de tendance général.
- `RISK_PCT_EQUITY`, `LEVERAGE`, `STOP_LOSS_PCT`, `TAKE_PROFIT_PCT` : paramètres de gestion du risque.
- `ATR_PERIOD`, `TRAIL_ATR_MULT`, `SCALE_IN_ATR_MULT`, `PROGRESS_MIN`, `TIMEOUT_MIN` : réglages pour l'ATR, l'ajout à la position, le trailing stop et la sortie par timeout.
- `MAX_DAILY_LOSS_PCT`, `MAX_DAILY_PROFIT_PCT`, `MAX_POSITIONS` (par défaut 3) : limites globales (kill switch après perte ou gain, nombre maximal de positions).
- `LOG_DIR` : dossier où seront écrits les fichiers de log.
- `ALLOWED_SYMBOLS` : liste de paires autorisées séparées par des virgules. Vide par défaut pour autoriser toutes les paires.

- `NOTIFY_URL` : URL d'un webhook HTTP pour recevoir les événements (optionnel, peut être utilisé en plus de Telegram).
- `TELEGRAM_BOT_TOKEN`, `TELEGRAM_CHAT_ID` : pour envoyer les notifications sur Telegram (optionnel, peut être combiné avec le webhook).

Pour éviter de versionner vos clés sensibles, vous pouvez créer un fichier
`.env` dans le dossier parent du dépôt (par exemple `Notebooks/.env` si le
code se trouve dans `Notebooks/scalp`).  Ce fichier est automatiquement chargé
au démarrage et toutes les variables qu'il contient seront disponibles pour le
bot.


Exemple :

```bash
export BITGET_ACCESS_KEY="votre_cle"
export BITGET_SECRET_KEY="votre_secret"
export PAPER_TRADE=true
export TELEGRAM_BOT_TOKEN="123456:ABCDEF..."
export TELEGRAM_CHAT_ID="123456789"
python bot.py
```

## Lancement

Après configuration, lancez simplement :

```bash
python bot.py
```

Le terminal reste silencieux au démarrage sauf en cas d'absence de variables critiques (`BITGET_ACCESS_KEY`, `BITGET_SECRET_KEY`). Les journaux sont écrits dans `logs/` et affichés sur la console. Le bot tourne jusqu'à `Ctrl+C`. Les ouvertures et fermetures de positions sont consignées dans `bot_events.jsonl`.

Lors du démarrage, deux notifications Telegram sont émises : la première affiche « Bot démarré » avec un logo, la seconde « Listing ok » sans détailler les paires sélectionnées.

Ensuite, un rappel du marché est envoyé chaque minute et l'interface Telegram propose un bouton « Fermer Bot » pour arrêter proprement l'exécution.


## Stratégie

Scalp cherche à capter de courts mouvements de tendance tout en coupant
rapidement les pertes.

Principes généraux :

- sélection de paires liquides au fort momentum ;
- trade uniquement dans le sens de la tendance dominante (MACD + EMA longue) ;
- confirmation multi‑indicateurs (VWAP, volume/OBV, RSI multi‑UT) ;
- stop‑loss et take‑profit dynamiques basés sur l’ATR avec taille de position
  calculée selon le risque ;
- limites quotidiennes pour protéger le capital.

Les règles détaillées et l’algorithme complet sont décrits dans
`STRATEGY.md`.

## Version

La version du bot est stockée dans le fichier `scalp/VERSION` et exposée dans
le code via la variable `scalp.__version__` :

```python
from scalp import __version__
print(__version__)
```

Pour incrémenter la version, utilisez `scalp.version.bump_version` avec

`"major"`, `"minor"` ou `"patch"` comme argument. La fonction
`scalp.version.bump_version_from_message` permet également de déterminer
automatiquement l'incrément à appliquer à partir d'un message de commit
suivant la convention [Conventional Commits](https://www.conventionalcommits.org).

Exemple d'incrément basé sur un message :

```python
from scalp.version import bump_version_from_message
bump_version_from_message("feat: add new strategy")
```

Exécuté en tant que script, `python -m scalp.version` lit le dernier
message de commit `git` et met à jour le fichier `VERSION` en
conséquence.

La même opération peut être déclenchée depuis la ligne de commande via
`cli.py` :

```bash
python cli.py bump-version
```


## Changelog

- Ajout d'un contrôle de marge disponible avant chaque ordre afin d'éviter l'erreur Bitget « The order amount exceeds the balance » (code 40762).

## Avertissement

© 2025 — Usage à vos risques. Ceci n'est pas un conseil financier.

# ===== STRATEGY.md ===== (43 lignes, modifié 2025-08-25 17:18:51)

# Stratégie de trading

Ce document décrit la logique de trading utilisée par le bot **Scalp**. Elle vise un scalping court terme sur les futures USDT‑M de Bitget.

## Principes généraux

- ne traiter que des actifs liquides à fort momentum ;
- suivre la tendance dominante et éviter les marchés plats ;
- utiliser des confirmations multi‑unités de temps pour limiter les faux signaux ;
- dimensionner chaque position selon un pourcentage fixe du capital ;
- couper rapidement les pertes et laisser courir les gains via un suivi dynamique.

## Sélection des paires

1. `scan_pairs` récupère les tickers Bitget et filtre ceux qui possèdent un volume quotidien suffisant et un spread réduit.
2. `select_active_pairs` affine la liste en conservant les paires présentant le plus de **momentum** :
   - croisement entre EMA20 et EMA50 ;
   - ATR élevé pour privilégier les actifs volatils.

## Génération du signal

`generate_signal` produit un signal d’entrée long ou court lorsque les conditions suivantes sont réunies :

- prix au‑dessus ou en dessous du **VWAP** et des EMA20/50 selon la direction recherchée ;
- **RSI(14)** traversant les niveaux 40/60 avec confirmation d’un **RSI 15 min** et de la pente de l’**EMA 1 h** ;
- **MACD** alignée avec la tendance et **EMA** longue en filtrage global ;
- hausse d’**OBV** ou volume supérieur à la moyenne ;
- cassure du dernier **swing high/low** ;
- éventuel filtre d’**order book imbalance** et de ratio de ticks.

Les distances de stop et de take profit sont calculées à partir de l’**ATR**, ce qui permet également de dimensionner la taille de position via `calc_position_size`.

## Gestion du risque

La classe `RiskManager` applique plusieurs garde‑fous :

- limite de perte quotidienne (`max_daily_loss_pct`) et optionnellement de gain (`max_daily_profit_pct`) déclenchant un *kill switch* ;
- suivi des séries de gains/pertes pour ajuster le pourcentage de risque par trade ;
- pause forcée en cas de pertes consécutives prolongées ;
- contrôle du nombre maximal de positions ouvertes.

Ces règles combinées visent à protéger le capital tout en conservant une exposition opportuniste au marché.

# ===== bot.py ===== (24 lignes, modifié 2025-08-25 17:18:51)

from __future__ import annotations
import sys, shutil
from pathlib import Path

ROOT = Path(__file__).resolve().parent
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

def _clean_py_caches(root: Path) -> None:
    for p in root.rglob("*.pyc"):
        try: p.unlink()
        except Exception: pass
    for d in root.rglob("__pycache__"):
        try: shutil.rmtree(d, ignore_errors=True)
        except Exception: pass

def main() -> int:
    _clean_py_caches(ROOT)
    from engine.app import run_app
    run_app()
    return 0

if __name__ == "__main__":
    raise SystemExit(main())

# ===== cli.py ===== (9 lignes, modifié 2025-08-25 17:18:51)

# cli.py  (à la racine du repo)
from __future__ import annotations
import argparse

def parse_cli() -> argparse.Namespace:
    ap = argparse.ArgumentParser(description="SCALP — launcher")
    ap.add_argument("--once", action="store_true", help="Exécuter une seule passe orchestrateur")
    ap.add_argument("--log-level", default="INFO", help="DEBUG/INFO/WARN/ERROR (défaut: INFO)")
    return ap.parse_args()

# ===== data/__init__.py ===== (6 lignes, modifié 2025-08-25 17:18:51)

"""Indicator computation helpers."""

from .indicators import compute_all

__all__ = ["compute_all"]

# ===== engine/__init__.py ===== (2 lignes, modifié 2025-08-25 17:18:51)

# Rend le dossier 'scalper' importable comme package.
__all__ = ["live", "signals", "core"]

# ===== engine/adapters/__init__.py ===== (0 lignes, modifié 2025-08-25 17:18:51)



# ===== engine/adapters/bitget.py ===== (218 lignes, modifié 2025-08-25 17:18:51)

# scalp/adapters/bitget.py
from __future__ import annotations
from typing import Any, Dict, List, Optional
import inspect, os
import requests

# Client bas-niveau fourni par le repo
from engine.bitget_client import BitgetFuturesClient as _Base


def _to_float(x, default: float = 0.0) -> float:
    try:
        return float(x)
    except Exception:
        return default


def _select_base_url() -> str:
    env = os.environ.get("BITGET_BASE_URL")
    if env:
        return env
    paper = os.environ.get("PAPER_TRADE", "true").lower() in ("1", "true", "yes", "on")
    return "https://api-testnet.bitget.com" if paper else "https://api.bitget.com"


class BitgetFuturesClient(_Base):
    """
    Adaptateur Bitget:
      - __init__ dynamique (passe seulement les kwargs que le client accepte)
      - Normalisations robustes: assets, ticker(s), positions, fills
    """

    # --------------------- INIT dynamique ---------------------
    def __init__(self, *args: Any, **kwargs: Any) -> None:
        """
        Accepte indifféremment:
          api_key/apiKey/access_key/accessKey/key
          api_secret/apiSecret/secret/secret_key/secretKey
          passphrase/password/api_passphrase/apiPassphrase
          base_url/baseUrl/host/endpoint (ou auto)
        On n'envoie au client de base que les noms présents dans sa signature.
        """
        user_kwargs = dict(kwargs)

        # Collecte des valeurs possibles (tous alias)
        incoming_key = (
            user_kwargs.pop("api_key", None)
            or user_kwargs.pop("apiKey", None)
            or user_kwargs.pop("access_key", None)
            or user_kwargs.pop("accessKey", None)
            or user_kwargs.pop("key", None)
            or user_kwargs.pop("API_KEY", None)
        )
        incoming_secret = (
            user_kwargs.pop("api_secret", None)
            or user_kwargs.pop("apiSecret", None)
            or user_kwargs.pop("secret_key", None)
            or user_kwargs.pop("secretKey", None)
            or user_kwargs.pop("secret", None)
            or user_kwargs.pop("API_SECRET", None)
        )
        incoming_pass = (
            user_kwargs.pop("passphrase", None)
            or user_kwargs.pop("password", None)
            or user_kwargs.pop("api_passphrase", None)
            or user_kwargs.pop("apiPassphrase", None)
        )
        incoming_base = (
            user_kwargs.pop("base_url", None)
            or user_kwargs.pop("baseUrl", None)
            or user_kwargs.pop("host", None)
            or user_kwargs.pop("endpoint", None)
            or _select_base_url()
        )

        # Signature réelle du client bas-niveau
        sig = inspect.signature(_Base.__init__)
        param_names = set(sig.parameters.keys())  # ex: {'self','access_key','secret_key','passphrase','base_url',...}

        def pick_name(cands: List[str]) -> Optional[str]:
            for c in cands:
                if c in param_names:
                    return c
            return None

        # Noms réellement supportés
        key_name = pick_name(["api_key", "apiKey", "access_key", "accessKey", "key"])
        sec_name = pick_name(["api_secret", "apiSecret", "secret_key", "secretKey", "secret"])
        pas_name = pick_name(["passphrase", "password", "api_passphrase", "apiPassphrase"])
        base_name = pick_name(["base_url", "baseUrl", "host", "endpoint"])
        req_mod_name = "requests_module" if "requests_module" in param_names else None

        # Construire kwargs à transmettre (une seule fois par nom)
        base_kwargs: Dict[str, Any] = {}
        if key_name and incoming_key is not None:
            base_kwargs[key_name] = incoming_key
        if sec_name and incoming_secret is not None:
            base_kwargs[sec_name] = incoming_secret
        if pas_name and incoming_pass is not None:
            base_kwargs[pas_name] = incoming_pass
        if base_name:
            base_kwargs[base_name] = incoming_base
        if req_mod_name:
            base_kwargs[req_mod_name] = requests

        # Ne transmettre aucun doublon : si user_kwargs contient un nom supporté
        # qui n'a pas été défini ci-dessus, on le relaie.
        for k, v in list(user_kwargs.items()):
            if k in param_names and k not in base_kwargs:
                base_kwargs[k] = v

        # Appel propre, 100% mots-clés (évite “missing positional arg” et “multiple values”)
        super().__init__(**base_kwargs)

    # --------------------- COMPTES / ASSETS ---------------------
    def get_assets(self) -> Dict[str, Any]:
        raw = super().get_assets()
        data = raw.get("data") or raw.get("result") or raw.get("assets") or []
        norm: List[Dict[str, Any]] = []
        for a in data:
            currency = a.get("currency") or a.get("marginCoin") or a.get("coin") or "USDT"
            equity = _to_float(a.get("equity", a.get("usdtEquity", a.get("totalEquity", 0))))
            available = _to_float(a.get("available", a.get("availableBalance", a.get("availableUSDT", 0))))
            norm.append({"currency": currency, "equity": equity, "available": available, **a})
        return {"success": True, "data": norm}

    # ------------------------ TICKER(S) -------------------------
    def get_ticker(self, symbol: Optional[str] = None) -> Dict[str, Any]:
        """
        Normalise vers liste d'objets: {symbol,lastPrice,bidPrice,askPrice,volume}
        Tolère top-level dict/list et items dict/list.
        """
        try:
            raw: Any = super().get_ticker(symbol) if symbol else super().get_tickers()
        except Exception as e:
            return {"success": False, "error": repr(e), "data": []}

        items: List[Any] = []
        if isinstance(raw, dict):
            d = raw.get("data")
            if symbol and isinstance(d, dict):
                items = [d]
            else:
                items = d or raw.get("result") or raw.get("tickers") or []
        elif isinstance(raw, (list, tuple)):
            items = list(raw)

        norm: List[Dict[str, Any]] = []
        for t in items:
            if isinstance(t, dict):
                s = (t.get("symbol") or t.get("instId") or t.get("instrumentId") or "").replace("_", "")
                last_ = t.get("lastPrice", t.get("last", t.get("close", t.get("markPrice", 0))))
                bid_ = t.get("bidPrice", t.get("bestBidPrice", t.get("bestBid", t.get("buyOne", last_))))
                ask_ = t.get("askPrice", t.get("bestAskPrice", t.get("bestAsk", t.get("sellOne", last_))))
                vol_usdt = t.get("usdtVolume", t.get("quoteVolume", t.get("turnover24h", None)))
                vol_base = t.get("baseVolume", t.get("volume", t.get("size24h", 0)))
                volume = _to_float(vol_usdt if vol_usdt is not None else vol_base)
                norm.append({
                    "symbol": s,
                    "lastPrice": _to_float(last_),
                    "bidPrice": _to_float(bid_),
                    "askPrice": _to_float(ask_),
                    "volume": volume
                })
            else:
                seq = list(t)
                if len(seq) >= 5:
                    first_ts = isinstance(seq[0], (int, float)) and seq[0] > 10**10
                    if first_ts:
                        close = _to_float(seq[4]); vol = _to_float(seq[5] if len(seq) > 5 else 0.0)
                    else:
                        close = _to_float(seq[3]); vol = _to_float(seq[4] if len(seq) > 4 else 0.0)
                else:
                    close = _to_float(seq[-1] if seq else 0.0); vol = 0.0
                s = (symbol or "").replace("_", "")
                norm.append({"symbol": s, "lastPrice": close, "bidPrice": close, "askPrice": close, "volume": vol})

        return {"success": True, "data": norm}

    # --------------- POSITIONS / ORDRES / FILLS -----------------
    def get_open_positions(self, symbol: Optional[str] = None) -> Dict[str, Any]:
        raw: Dict[str, Any] = super().get_positions() if hasattr(super(), "get_positions") else {}
        items = raw.get("data") or raw.get("result") or raw.get("positions") or []
        out: List[Dict[str, Any]] = []
        for p in items:
            s = (p.get("symbol") or p.get("instId") or "").replace("_", "")
            if symbol and s != symbol:
                continue
            side = (p.get("holdSide") or p.get("posSide") or p.get("side") or "").lower()
            qty = _to_float(p.get("size", p.get("holdAmount", p.get("total", 0))))
            avg = _to_float(p.get("avgOpenPrice", p.get("avgPrice", p.get("entryPrice", 0))))
            out.append({"symbol": s, "side": side, "qty": qty, "avgEntryPrice": avg})
        return {"success": True, "data": out}

    def get_fills(self, symbol: str, order_id: Optional[str] = None, limit: int = 100) -> Dict[str, Any]:
        raw: Dict[str, Any] = super().get_fills(symbol=symbol) if hasattr(super(), "get_fills") else {}
        items = raw.get("data") or raw.get("result") or []
        out: List[Dict[str, Any]] = []
        for f in items[:limit]:
            s = (f.get("symbol") or f.get("instId") or "").replace("_", "")
            if s != symbol:
                continue
            if order_id and str(f.get("orderId") or f.get("ordId") or "") != str(order_id):
                continue
            out.append({
                "orderId": str(f.get("orderId") or f.get("ordId") or ""),
                "tradeId": str(f.get("tradeId") or f.get("fillId") or f.get("execId") or ""),
                "price": _to_float(f.get("price", f.get("fillPx", 0))),
                "qty": _to_float(f.get("size", f.get("fillSz", 0))),
                "fee": _to_float(f.get("fee", f.get("fillFee", 0))),
                "ts": int(f.get("ts", f.get("time", 0))),
            })
        return {"success": True, "data": out}

    def cancel_order(self, symbol: str, order_id: str) -> Dict[str, Any]:
        raw = super().cancel_order(symbol=symbol, orderId=order_id) if hasattr(super(), "cancel_order") else {}
        ok = bool(raw.get("success", True)) if isinstance(raw, dict) else True
        return {"success": ok, "data": {"orderId": order_id}}

# ===== engine/adapters/bitget_fetch.py ===== (165 lignes, modifié 2025-08-25 17:18:51)

# scalper/adapters/bitget_fetch.py
from __future__ import annotations

import asyncio
import inspect
import os
from typing import Any, Optional

BT_DEBUG = int(os.getenv("BT_DEBUG", "0") or "0")

def _log(msg: str) -> None:
    if BT_DEBUG:
        print(f"[bt.debug] {msg}", flush=True)

_TF_TO_SECS = {
    "1m": 60, "3m": 180, "5m": 300, "15m": 900, "30m": 1800,
    "1h": 3600, "4h": 14400, "1d": 86400,
}
_TF_TO_MIX = {  # granularity pour mix (docs Bitget)
    "1m": "1min", "3m": "3min", "5m": "5min", "15m": "15min",
    "30m": "30min", "1h": "1h", "4h": "4h", "1d": "1day",
}
_TF_TO_SPOT = {  # period pour spot (docs Bitget)
    "1m": "1min", "3m": "3min", "5m": "5min", "15m": "15min",
    "30m": "30min", "1h": "1hour", "4h": "4hour", "1d": "1day",
}

def _await_if_needed(val: Any) -> Any:
    if inspect.isawaitable(val):
        try:
            asyncio.get_running_loop()
        except RuntimeError:
            return asyncio.run(val)
        else:
            fut = asyncio.run_coroutine_threadsafe(val, asyncio.get_running_loop())
            return fut.result()
    return val

class BitgetFetchAdapter:
    """
    Adaptateur qui fournit une méthode CCXT-like:
      fetch_ohlcv(symbol, timeframe='5m', since=None, limit=1000)
    au-dessus d'un client Bitget existant (sync ou async).
    """
    def __init__(self, client: Any, *, market_hint: str | None = None):
        self.client = client
        self.market_hint = (market_hint or "").lower() or None
        _log(f"BitgetFetchAdapter attaché sur {type(client).__name__} (market_hint={self.market_hint})")
        if hasattr(client, "fetch_ohlcv") and callable(getattr(client, "fetch_ohlcv")):
            _log("Client expose déjà fetch_ohlcv → adaptation inutile (utilisation directe).")

    @staticmethod
    def _possible_methods(client: Any) -> list[str]:
        names = dir(client)
        base = [
            "fetch_ohlcv",
            "get_candlesticks", "candlesticks", "get_candles", "candles",
            "klines", "get_klines", "kline",
            "mix_get_candles", "mix_candles",
            "spot_get_candles", "spot_candles",
            "market_candles", "public_candles",
        ]
        # + heuristique: tout ce qui contient candle/kline
        extra = [n for n in names if ("candle" in n.lower() or "kline" in n.lower()) and callable(getattr(client, n))]
        out = []
        for n in base + extra:
            if n in names and callable(getattr(client, n)) and n not in out:
                out.append(n)
        _log(f"Méthodes candidates détectées: {out or '(aucune)'}")
        return out

    @staticmethod
    def _sym_variants(sym: str) -> list[str]:
        s = sym.upper()
        out = [s]
        if not s.endswith("_UMCBL"):
            out.append(f"{s}_UMCBL")
        if not s.endswith("_SPBL"):
            out.append(f"{s}_SPBL")
        _log(f"Variantes symbole testées: {out}")
        return out

    @staticmethod
    def _param_variants(timeframe: str, market_hint: Optional[str]) -> list[dict]:
        secs = _TF_TO_SECS.get(timeframe, 300)
        mix = _TF_TO_MIX.get(timeframe, "5min")
        spot = _TF_TO_SPOT.get(timeframe, "5min")
        variants = []
        if market_hint == "mix":
            variants.append({"granularity": mix})
        if market_hint == "spot":
            variants.append({"period": spot})
        variants += [
            {"timeframe": timeframe},
            {"interval": timeframe},
            {"k": secs},
            {"granularity": mix},
            {"period": spot},
        ]
        _log(f"Variantes params testées pour tf={timeframe}: {variants}")
        return variants

    @staticmethod
    def _normalize_rows(raw: Any) -> list[list[float]]:
        import pandas as pd  # local import
        if raw is None:
            raise ValueError("OHLCV vide")
        if isinstance(raw, dict) and "data" in raw:
            raw = raw["data"]
        if isinstance(raw, (list, tuple)) and raw and isinstance(raw[0], (list, tuple)):
            out = []
            for r in raw:
                ts = int(str(r[0]))
                o, h, l, c, v = map(float, (r[1], r[2], r[3], r[4], r[5]))
                out.append([ts, o, h, l, c, v])
            return out
        if "pandas" in str(type(raw)):
            df = raw
            if "timestamp" in df.columns:
                df["timestamp"] = pd.to_datetime(df["timestamp"], utc=True, infer_datetime_format=True)
                df = df.set_index("timestamp").sort_index()
            df = df[["open", "high", "low", "close", "volume"]]
            return [[int(ts.value // 10**6), *map(float, row)] for ts, row in df.itertuples()]
        raise ValueError(f"Format OHLCV inattendu: {type(raw)}")

    def fetch_ohlcv(self, symbol: str, timeframe: str = "5m", since: Any | None = None, limit: int = 1000):
        methods = self._possible_methods(self.client)
        if not methods:
            raise AttributeError("Aucune méthode OHLCV trouvée sur le client Bitget")

        last_err: Exception | None = None
        for mname in methods:
            fn = getattr(self.client, mname)
            for sym in self._sym_variants(symbol):
                for par in self._param_variants(timeframe, self.market_hint):
                    kwargs = dict(par)
                    kwargs.setdefault("symbol", sym)
                    kwargs.setdefault("limit", limit)
                    if since is not None:
                        kwargs.setdefault("since", since)
                    try:
                        _log(f"→ Essai {mname}(kwargs={kwargs})")
                        res = _await_if_needed(fn(**kwargs))
                        rows = self._normalize_rows(res)
                        if rows:
                            unit = "ms" if rows and rows[0][0] > 10_000_000_000 else "s"
                            first = rows[0][0]; last = rows[-1][0]
                            _log(f"✓ OK via {mname} {sym} {par} | n={len(rows)} | "
                                 f"t0={first} {unit}, t1={last} {unit}")
                            return rows
                    except TypeError as e:
                        _log(f"TypeError {mname} {sym} {par}: {e}")
                        last_err = e
                    except Exception as e:
                        _log(f"Erreur {mname} {sym} {par}: {e}")
                        last_err = e
        raise last_err or RuntimeError("Impossible d'obtenir l'OHLCV via le client Bitget")

def ensure_bitget_fetch(exchange: Any, *, market_hint: str | None = None) -> Any:
    """Renvoie l'exchange si fetch_ohlcv existe, sinon un wrapper qui l’implémente. Log debug si BT_DEBUG=1."""
    if hasattr(exchange, "fetch_ohlcv") and callable(getattr(exchange, "fetch_ohlcv")):
        _log("exchange.fetch_ohlcv() déjà présent.")
        return exchange
    _log("exchange.fetch_ohlcv() absent → usage BitgetFetchAdapter.")
    return BitgetFetchAdapter(exchange, market_hint=market_hint)

# ===== engine/adapters/market_data.py ===== (77 lignes, modifié 2025-08-25 17:18:51)

# scalper/backtest/market_data.py
from __future__ import annotations

import os
from pathlib import Path
from typing import Any

import pandas as pd

BT_DEBUG = int(os.getenv("BT_DEBUG", "0") or "0")

def _log(msg: str) -> None:
    if BT_DEBUG:
        print(f"[bt.debug] {msg}", flush=True)

def _csv_path(data_dir: str | Path, symbol: str, timeframe: str) -> Path:
    root = Path(data_dir)
    root.mkdir(parents=True, exist_ok=True)
    tf = timeframe.replace(":", "")
    return root / f"{symbol}-{tf}.csv"

def _read_csv(path: Path) -> pd.DataFrame:
    _log(f"lecture CSV: {path}")
    df = pd.read_csv(path)
    ts_col = next((c for c in df.columns if c.lower() in ("ts", "timestamp", "time", "date")), None)
    if ts_col is None:
        raise ValueError("Colonne temps introuvable (timestamp/time/date)")
    df = df.rename(columns={ts_col: "timestamp"})
    df["timestamp"] = pd.to_datetime(df["timestamp"], utc=True, infer_datetime_format=True)
    df = df.set_index("timestamp").sort_index()
    _log(f"→ CSV ok, n={len(df)}, t0={df.index.min()}, t1={df.index.max()}")
    return df

def _write_csv(path: Path, df: pd.DataFrame) -> None:
    tmp = df.reset_index().rename(columns={"index": "timestamp"})
    if "timestamp" not in tmp.columns:
        tmp = tmp.rename(columns={"index": "timestamp"})
    tmp.to_csv(path, index=False)
    _log(f"écrit CSV: {path} (n={len(df)})")

def fetch_ohlcv_via_exchange(exchange: Any, symbol: str, timeframe: str, *, limit: int = 1000) -> pd.DataFrame:
    _log(f"fetch via exchange.fetch_ohlcv: symbol={symbol} tf={timeframe} limit={limit}")
    raw = exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=limit)  # peut être sync ou adapté
    # Normalisation minimaliste (liste de listes)
    rows = []
    for r in raw:
        ts = int(r[0])
        unit = "ms" if ts > 10_000_000_000 else "s"
        ts = pd.to_datetime(ts, unit=unit, utc=True)
        rows.append([ts, float(r[1]), float(r[2]), float(r[3]), float(r[4]), float(r[5])])
    df = pd.DataFrame(rows, columns=["timestamp", "open", "high", "low", "close", "volume"]).set_index("timestamp").sort_index()
    _log(f"→ exchange ok, n={len(df)}, t0={df.index.min()}, t1={df.index.max()}")
    return df

def hybrid_loader_from_exchange(exchange: Any, data_dir: str = "data", *, api_limit: int = 1000):
    """
    Loader hybride:
      1) lit data/<SYMBOL>-<TF>.csv si présent,
      2) sinon fetch via exchange.fetch_ohlcv, puis écrit le CSV en cache.
    """
    def load(symbol: str, timeframe: str, start: str | None, end: str | None) -> pd.DataFrame:
        path = _csv_path(data_dir, symbol, timeframe)
        if path.exists():
            df = _read_csv(path)
            src = "csv"
        else:
            df = fetch_ohlcv_via_exchange(exchange, symbol, timeframe, limit=api_limit)
            _write_csv(path, df)
            src = "exchange"
        if start:
            df = df.loc[pd.Timestamp(start, tz="UTC") :]
        if end:
            df = df.loc[: pd.Timestamp(end, tz="UTC")]
        _log(f"loader -> {symbol} {timeframe} (src={src}) n={len(df)} "
             f"range=[{df.index.min()} .. {df.index.max()}]")
        return df
    return load

# ===== engine/app.py ===== (21 lignes, modifié 2025-08-25 17:18:51)

from __future__ import annotations
import asyncio
import logging

from engine.bootstrap import bootstrap_environment, build_exchange

log = logging.getLogger("app")

async def _main_async() -> None:
    # import paresseux pour éviter toute boucle d'import
    from engine.live.orchestrator import Orchestrator, run_config_from_yaml

    bootstrap_environment()
    cfg = run_config_from_yaml()
    ex = build_exchange()

    orch = Orchestrator(cfg, ex)
    await orch.start()  # boucle infinie (scheduler interne)

def run_app() -> None:
    asyncio.run(_main_async())

# ===== engine/bitget_client.py ===== (658 lignes, modifié 2025-08-25 17:18:51)

import json
import logging
import time
import hmac
import hashlib
import base64
import uuid
from typing import Any, Dict, List, Optional

import requests


# Mapping of deprecated v1 product type identifiers to the new v2 names
_PRODUCT_TYPE_ALIASES = {
    "UMCBL": "USDT-FUTURES",
    "DMCBL": "USDC-FUTURES",
    "CMCBL": "COIN-FUTURES",
}

# Granularity aliases from v1 to v2 nomenclature
_GRANULARITY_ALIASES = {
    "MIN1": "1m",
    "MIN3": "3m",
    "MIN5": "5m",
    "MIN15": "15m",
    "MIN30": "30m",
    "HOUR1": "1H",
    "HOUR4": "4H",
    "HOUR12": "12H",
    "DAY1": "1D",
    "WEEK1": "1W",
}


# Default margin coin for each product type. Some authenticated endpoints
# require ``marginCoin`` in addition to ``productType``; supplying a sensible
# default avoids ``400 Bad Request`` responses when the caller does not provide
# it explicitly.
_DEFAULT_MARGIN_COIN = {
    "USDT-FUTURES": "USDT",
    "USDC-FUTURES": "USDC",
}


class BitgetFuturesClient:
    """Lightweight REST client for Bitget LAPI v2 futures endpoints."""

    def __init__(
        self,
        access_key: str,
        secret_key: str,
        base_url: str,
        *,
        product_type: str = "USDT-FUTURES",
        recv_window: int = 30,
        paper_trade: bool = True,
        requests_module: Any = requests,
        log_event: Optional[Any] = None,
        passphrase: Optional[str] = None,
    ) -> None:
        self.ak = access_key
        self.sk = secret_key
        self.base = base_url.rstrip("/")
        pt = product_type.upper()
        self.product_type = _PRODUCT_TYPE_ALIASES.get(pt, pt)
        self.recv_window = recv_window
        self.paper_trade = paper_trade
        self.requests = requests_module
        self.log_event = log_event or (lambda *a, **k: None)
        self.passphrase = passphrase
        if not self.ak or not self.sk or self.ak == "A_METTRE" or self.sk == "B_METTRE":
            logging.warning(
                "\u26a0\ufe0f Cl\u00e9s API non d\u00e9finies. Le mode r\u00e9el ne fonctionnera pas.",
            )
        # Cache for contract precision details to avoid repeated network calls
        self._contract_cache: Dict[str, Dict[str, Any]] = {}

    # ------------------------------------------------------------------
    # Helpers
    # ------------------------------------------------------------------
    @staticmethod
    def _ms() -> int:
        return int(time.time() * 1000)

    @staticmethod
    def _urlencode_sorted(params: Dict[str, Any]) -> str:
        if not params:
            return ""
        items = []
        for k in sorted(params.keys()):
            v = "" if params[k] is None else str(params[k])
            items.append(f"{k}={v}")
        return "&".join(items)

    def _sign(self, prehash: str) -> str:
        """Return a base64-encoded HMAC SHA256 signature."""
        digest = hmac.new(self.sk.encode(), prehash.encode(), hashlib.sha256).digest()
        return base64.b64encode(digest).decode()

    def _headers(self, signature: str, timestamp: int) -> Dict[str, str]:
        headers = {
            "ACCESS-KEY": self.ak,
            "ACCESS-SIGN": signature,
            "ACCESS-TIMESTAMP": str(timestamp),
            "ACCESS-RECV-WINDOW": str(self.recv_window),
            "Content-Type": "application/json",
        }
        if self.passphrase:
            headers["ACCESS-PASSPHRASE"] = self.passphrase
        return headers

    def _format_symbol(self, symbol: str) -> str:
        """Return ``symbol`` formatted for Bitget API.

        The v2 endpoints expect the trading pair without any product type
        suffix (``BTCUSDT``). Older configurations may provide symbols like
        ``BTC_USDT`` or ``BTCUSDT_UMCBL``; these are normalised by removing the
        separators and any trailing product type string (legacy or v2).
        """

        if not symbol:
            return symbol

        sym = symbol.replace("_", "").upper()
        # Strip product type suffix if present (e.g. BTCUSDTUMCBL)
        if sym.endswith(self.product_type):
            sym = sym[: -len(self.product_type)]
        else:
            for old in _PRODUCT_TYPE_ALIASES.keys():
                if sym.endswith(old):
                    sym = sym[: -len(old)]
                    break
        return sym

    def _product_type(self, pt: Optional[str] = None) -> str:
        """Normalise ``pt`` to a valid v2 product type identifier."""
        key = (pt or self.product_type or "").upper()
        return _PRODUCT_TYPE_ALIASES.get(key, key)

    # ------------------------------------------------------------------
    # Public endpoints
    # ------------------------------------------------------------------
    def get_contract_detail(self, symbol: Optional[str] = None) -> Dict[str, Any]:
        """Return futures contract information.

        The previous implementation queried ``/contract-detail`` which does not
        exist on Bitget's v2 API and resulted in a 404 error.  The correct
        endpoint is ``/contracts`` with the symbol supplied as a query
        parameter."""

        url = f"{self.base}/api/v2/mix/market/contracts"
        params: Dict[str, Any] = {"productType": self.product_type}
        if symbol:
            params["symbol"] = self._format_symbol(symbol)
        r = self.requests.get(url, params=params, timeout=15)
        if r.status_code == 404:  # pragma: no cover - depends on network
            logging.error("Contract detail introuvable pour %s", symbol)
            return {"success": False, "code": 404, "data": None}
        r.raise_for_status()
        return r.json()

    # ------------------------------------------------------------------
    def _get_contract_precision(self, symbol: str) -> tuple[int, int]:
        """Return price and volume precision for ``symbol``.

        Results are cached to minimise HTTP requests. If the contract
        information cannot be retrieved, ``(0, 0)`` is returned.
        """
        sym = self._format_symbol(symbol)
        info = self._contract_cache.get(sym)
        if info is None:
            detail = self.get_contract_detail(sym)
            try:
                data = detail.get("data", [])
                if isinstance(data, list) and data:
                    info = data[0]
                else:
                    info = {}
            except Exception:
                info = {}
            self._contract_cache[sym] = info
        price_place = int(info.get("pricePlace") or 0)
        volume_place = int(info.get("volumePlace") or 0)
        return price_place, volume_place

    def get_kline(
        self,
        symbol: str,
        interval: str = "1m",
        start: Optional[int] = None,
        end: Optional[int] = None,
    ) -> Dict[str, Any]:
        # Endpoint expects the trading pair in query parameters rather than
        # encoded in the path. Using ``/candles/{symbol}`` results in a 404
        # response from Bitget. See: https://api.bitget.com/api/v2/mix/market/candles
        url = f"{self.base}/api/v2/mix/market/candles"
        interval_norm = _GRANULARITY_ALIASES.get(interval.replace("_", "").upper(), interval)
        params: Dict[str, Any] = {
            "symbol": self._format_symbol(symbol),
            "productType": self.product_type,
            "granularity": interval_norm,
        }
        if start is not None:
            params["startTime"] = int(start)
        if end is not None:
            params["endTime"] = int(end)
        r = self.requests.get(url, params=params, timeout=15)
        r.raise_for_status()
        data = r.json()

        rows = data.get("data") if isinstance(data, dict) else None
        if isinstance(rows, list) and rows and isinstance(rows[0], list):
            cols = {"ts": [], "open": [], "high": [], "low": [], "close": [], "volume": [], "quoteVolume": []}
            for row in rows:
                if len(row) < 7:
                    continue
                try:
                    ts, op, hi, lo, cl, vol, qv = row[:7]
                    cols["ts"].append(int(ts))
                    cols["open"].append(float(op))
                    cols["high"].append(float(hi))
                    cols["low"].append(float(lo))
                    cols["close"].append(float(cl))
                    cols["volume"].append(float(vol))
                    cols["quoteVolume"].append(float(qv))
                except (TypeError, ValueError):
                    continue
            data["data"] = cols
        elif isinstance(rows, list):
            data["data"] = {"ts": [], "open": [], "high": [], "low": [], "close": [], "volume": [], "quoteVolume": []}
        return data

    def get_ticker(self, symbol: Optional[str] = None) -> Dict[str, Any]:
        if symbol:
            url = f"{self.base}/api/v2/mix/market/ticker"
            params = {
                "symbol": self._format_symbol(symbol),
                "productType": self.product_type,
            }
        else:
            url = f"{self.base}/api/v2/mix/market/tickers"
            params = {"productType": self.product_type}
        r = self.requests.get(url, params=params, timeout=15)
        r.raise_for_status()
        return r.json()

    # ------------------------------------------------------------------
    # Private endpoints
    # ------------------------------------------------------------------
    def _private_request(
        self,
        method: str,
        path: str,
        *,
        params: Optional[Dict[str, Any]] = None,
        body: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        method = method.upper()
        ts = self._ms()

        if method in ("GET", "DELETE"):
            qs = self._urlencode_sorted(params or {})
            req_path = path + (f"?{qs}" if qs else "")
            sig = self._sign(f"{ts}{method}{req_path}")
            headers = self._headers(sig, ts)
            url = f"{self.base}{req_path}"
            r = self.requests.request(method, url, headers=headers, timeout=20)
        elif method == "POST":
            qs = self._urlencode_sorted(params or {})
            req_path = path + (f"?{qs}" if qs else "")
            body_str = json.dumps(body or {}, separators=(",", ":"), ensure_ascii=False)
            sig = self._sign(f"{ts}{method}{req_path}{body_str}")
            headers = self._headers(sig, ts)
            url = f"{self.base}{req_path}"
            r = self.requests.post(
                url,
                data=body_str.encode("utf-8"),
                headers=headers,
                timeout=20,
            )
        else:
            raise ValueError("M\u00e9thode non support\u00e9e")

        resp_text = getattr(r, "text", "")
        try:
            data = r.json()
        except Exception:
            data = {
                "success": False,
                "error": resp_text,
                "status_code": getattr(r, "status_code", None),
            }

        status = getattr(r, "status_code", 0)
        if status >= 400:
            code = str(data.get("code")) if isinstance(data, dict) else ""
            if code == "22001":
                logging.info("Aucun ordre à annuler (%s %s)", method, path)
            else:
                try:
                    r.raise_for_status()
                except Exception as e:
                    if not resp_text:
                        resp_text = getattr(r, "text", "") or str(e)
                logging.error(
                    "Erreur HTTP/JSON %s %s -> %s %s",
                    method,
                    path,
                    status,
                    resp_text,
                )
                if isinstance(data, dict):
                    data.setdefault("success", False)
                    data.setdefault("status_code", status)
                    data.setdefault("error", resp_text)

        self.log_event(
            "http_private",
            {"method": method, "path": path, "params": params, "body": body, "response": data},
        )
        return data

    # Accounts & positions -------------------------------------------------
    def get_assets(self, margin_coin: Optional[str] = None) -> Dict[str, Any]:
        if self.paper_trade:
            return {
                "success": True,
                "code": 0,
                "data": [
                    {
                        "currency": "USDT",
                        "equity": 100.0,
                    }
                ],
            }

        params = {"productType": self.product_type}
        if margin_coin is None:
            margin_coin = _DEFAULT_MARGIN_COIN.get(self.product_type)
        if margin_coin:
            params["marginCoin"] = margin_coin
        data = self._private_request(
            "GET", "/api/v2/mix/account/accounts", params=params
        )
        if isinstance(data, dict):
            data.setdefault("success", str(data.get("code")) == "00000")
        try:
            for row in data.get("data", []):
                if "currency" not in row and row.get("marginCoin"):
                    row["currency"] = str(row["marginCoin"]).upper()
                chosen = None
                for key in ("available", "cashBalance", "equity", "usdtEquity"):
                    val = row.get(key)
                    if val is not None:
                        chosen = val
                        break
                if chosen is not None:
                    row["equity"] = chosen
                try:
                    row["equity"] = float(row["equity"])
                except Exception:
                    pass
        except Exception:  # pragma: no cover - best effort
            pass
        return data

    def get_positions(self, product_type: Optional[str] = None) -> Dict[str, Any]:
        if self.paper_trade:
            return {"success": True, "code": 0, "data": []}
        data = self._private_request(
            "GET",
            "/api/v2/mix/position/all-position",
            params={"productType": self._product_type(product_type)},
        )
        try:
            positions = data.get("data", [])
            filtered = []
            for pos in positions:
                vol = pos.get("vol")
                try:
                    if vol is not None and float(vol) > 0:
                        filtered.append(pos)
                except (TypeError, ValueError):
                    continue
            data["data"] = filtered
        except Exception:  # pragma: no cover - best effort
            pass
        return data

    def get_open_orders(self, symbol: Optional[str] = None) -> Dict[str, Any]:
        if self.paper_trade:
            return {"success": True, "code": 0, "data": []}
        params: Dict[str, Any] = {"productType": self.product_type}
        if symbol:
            params["symbol"] = self._format_symbol(symbol)
        return self._private_request("GET", "/api/v2/mix/order/orders-pending", params=params)

    # Account configuration -------------------------------------------------
    def set_position_mode_one_way(self, symbol: str, product_type: Optional[str] = None) -> Dict[str, Any]:
        body = {
            "productType": self._product_type(product_type),
            "symbol": self._format_symbol(symbol),
            "posMode": "one_way_mode",
        }
        return self._private_request("POST", "/api/v2/mix/account/set-position-mode", body=body)

    def set_leverage(
        self,
        symbol: str,
        product_type: Optional[str] = None,
        margin_coin: str = "USDT",
        leverage: int = 1,
    ) -> Dict[str, Any]:
        body = {
            "symbol": self._format_symbol(symbol),
            "productType": self._product_type(product_type),
            "marginCoin": margin_coin,
            "leverage": int(leverage),
        }
        return self._private_request(
            "POST", "/api/v2/mix/account/set-leverage", body=body
        )

    def place_market_order_one_way(
        self,
        symbol: str,
        side: str,
        size: float,
        product_type: Optional[str] = None,
        margin_coin: str = "USDT",
        *,
        time_in_force: str = "normal",
    ) -> Dict[str, Any]:
        side = side.lower()
        if side not in {"buy", "sell"}:
            raise ValueError("side must be 'buy' or 'sell'")
        body = {
            "symbol": self._format_symbol(symbol),
            "productType": self._product_type(product_type),
            "marginCoin": margin_coin,
            "marginMode": "crossed",
            "posMode": "one_way_mode",
            "orderType": "market",
            "side": side,
            "size": str(size),
            "timeInForceValue": time_in_force,
            "clientOid": str(uuid.uuid4())[:32],
        }
        return self._private_request(
            "POST", "/api/v2/mix/order/place-order", body=body
        )

    # Orders ---------------------------------------------------------------
    def place_order(
        self,
        symbol: str,
        side: int,
        vol: int,
        order_type: int,
        *,
        price: Optional[float] = None,
        open_type: int = 1,
        leverage: Optional[int] = None,
        position_id: Optional[int] = None,
        external_oid: Optional[str] = None,
        stop_loss: Optional[float] = None,
        take_profit: Optional[float] = None,
        position_mode: Optional[int] = None,
        margin_coin: Optional[str] = None,
        time_in_force: str = "normal",
    ) -> Dict[str, Any]:
        """Submit an order.

        This helper keeps backward compatibility with the older numeric
        parameters used by the bot while translating them to the string based
        fields required by Bitget's v2 API.
        """
        if self.paper_trade:
            logging.info(
                "PAPER_TRADE=True -> ordre simul\u00e9: side=%s vol=%s type=%s price=%s",
                side,
                vol,
                order_type,
                price,
            )
            return {
                "success": True,
                "paperTrade": True,
                "simulated": {
                    "symbol": symbol,
                    "side": side,
                    "vol": vol,
                    "type": order_type,
                    "price": price,
                    "openType": open_type,
                    "leverage": leverage,
                    "stopLossPrice": stop_loss,
                    "takeProfitPrice": take_profit,
                },
            }

        # ------------------------------------------------------------------
        # Parameter mapping
        # ------------------------------------------------------------------
        side_map = {
            1: ("buy", "long"),
            2: ("buy", "short"),
            3: ("sell", "short"),
            4: ("sell", "long"),
        }
        if isinstance(side, int):
            mapped = side_map.get(side)
            if not mapped:
                raise ValueError(f"Invalid side value: {side}")
            side_str, pos_side = mapped
        else:
            side_str = str(side)
            pos_side = None

        order_map = {1: "market", 2: "limit", 3: "post_only", 4: "fok", 5: "limit"}
        if isinstance(order_type, int):
            order_str = order_map.get(order_type)
            if order_str is None:
                order_str = "limit" if price is not None else "market"
        else:
            order_str = str(order_type)

        margin_mode = "crossed" if int(open_type) == 1 else "isolated"

        if margin_coin is None:
            margin_coin = _DEFAULT_MARGIN_COIN.get(self.product_type)

        # ------------------------------------------------------------------
        # Precision handling
        # ------------------------------------------------------------------
        try:
            price_place, volume_place = self._get_contract_precision(symbol)
        except Exception:  # pragma: no cover - best effort
            price_place = volume_place = 0
        if price is not None:
            price = round(float(price), price_place)
        if vol is not None:
            vol = round(float(vol), volume_place)

        body = {
            "symbol": self._format_symbol(symbol),
            "productType": self.product_type,
            "marginMode": margin_mode,
            "orderType": order_str,
            "side": side_str,
            "size": vol,
            "timeInForceValue": time_in_force,
        }
        if pos_side is not None:
            body["posSide"] = pos_side
        if margin_coin:
            body["marginCoin"] = margin_coin
        if price is not None:
            body["price"] = float(price)
        if leverage is not None:
            body["leverage"] = int(leverage)
        if position_id is not None:
            body["positionId"] = int(position_id)
        if external_oid:
            body["clientOid"] = str(external_oid)[:32]
        else:
            body["clientOid"] = str(uuid.uuid4())[:32]
        if stop_loss is not None:
            body["stopLossPrice"] = float(stop_loss)
        if take_profit is not None:
            body["takeProfitPrice"] = float(take_profit)
        if position_mode is not None:
            body["posMode"] = "one_way_mode" if int(position_mode) == 1 else "hedge_mode"
        elif pos_side is not None:
            body["posMode"] = "hedge_mode"

        return self._private_request("POST", "/api/v2/mix/order/place-order", body=body)

    def cancel_order(self, order_ids: List[int]) -> Dict[str, Any]:
        if self.paper_trade:
            logging.info(
                "PAPER_TRADE=True -> annulation simulée: order_ids=%s", order_ids
            )
            return {"success": True, "code": 0}
        return self._private_request(
            "POST", "/api/v2/mix/order/cancel-order", body={"orderIds": order_ids}
        )

    def cancel_all(
        self,
        symbol: Optional[str] = None,
        margin_coin: Optional[str] = None,
    ) -> Dict[str, Any]:
        if self.paper_trade:
            logging.info(
                "PAPER_TRADE=True -> annulation simulée de tous les ordres"
            )
            return {"success": True, "code": 0}
        body = {"productType": self.product_type}
        if symbol:
            body["symbol"] = self._format_symbol(symbol)
        if margin_coin is None:
            margin_coin = _DEFAULT_MARGIN_COIN.get(self.product_type)
        if margin_coin:
            body["marginCoin"] = margin_coin
        return self._private_request(
            "POST", "/api/v2/mix/order/cancel-all-orders", body=body
        )

    def close_position(
        self,
        symbol: str,
        size: Optional[int] = None,
        hold_side: Optional[str] = None,
    ) -> Dict[str, Any]:
        """Close an open position for ``symbol``.

        Parameters
        ----------
        symbol:
            Trading symbol to close.
        size:
            Optional number of contracts to close. If omitted the entire
            position is closed.
        hold_side:
            Optional side (``"long"``/``"short"``) to close when ``size`` is
            specified. If not provided the exchange will infer it.
        """

        if self.paper_trade:
            logging.info(
                "PAPER_TRADE=True -> fermeture simulée de la position %s", symbol
            )
            return {"success": True, "code": 0}

        body = {"symbol": self._format_symbol(symbol)}
        if size is not None:
            body["size"] = int(size)
        if hold_side:
            body["holdSide"] = hold_side

        body["productType"] = self.product_type
        return self._private_request(
            "POST", "/api/v2/mix/position/close-position", body=body
        )

    def close_all_positions(self, product_type: Optional[str] = None) -> Dict[str, Any]:
        """Close all open positions."""
        results = []
        try:
            for pos in self.get_positions(product_type).get("data", []):
                sym = pos.get("symbol")
                if sym:
                    results.append(self.close_position(sym))
        except Exception as exc:  # pragma: no cover - best effort
            logging.error("Erreur fermeture de toutes les positions: %s", exc)
        return {"success": True, "data": results}

# ===== engine/bootstrap.py ===== (142 lignes, modifié 2025-08-25 17:18:51)

# engine/bootstrap.py
from __future__ import annotations

import importlib
import logging
import subprocess
import sys
from pathlib import Path
from typing import Iterable, Optional

from engine.config.loader import load_config


log = logging.getLogger("bootstrap")


# ------------------------------------------------------------
# Dépendances minimales (légères) – on reste soft (pas de streamlit ici)
# ------------------------------------------------------------

_MIN_PKGS = [
    # pour la visu terminal (jobs/termboard ou health board)
    ("rich", "rich"),
    # utilitaires de base déjà utilisés dans le projet
    ("yaml", "pyyaml"),
    ("requests", "requests"),
]

def _is_installed(mod: str) -> bool:
    try:
        importlib.import_module(mod)
        return True
    except Exception:
        return False

def _pip_install(args: Iterable[str]) -> int:
    cmd = [sys.executable, "-m", "pip", "install", *list(args)]
    return subprocess.call(cmd)

def ensure_min_deps(extra: Optional[Iterable[str]] = None) -> None:
    """
    Installe en douceur les dépendances manquantes (rich, pyyaml, requests).
    Évite de planter le démarrage si pip échoue (on loggue seulement).
    """
    missing = []
    for mod, pip_name in _MIN_PKGS:
        if not _is_installed(mod):
            missing.append(pip_name)
    if extra:
        for name in extra:
            # si l'appelant veut forcer un paquet, on tente
            if not _is_installed(name):
                missing.append(name)

    if not missing:
        return

    try:
        log.info("[deps] installation manquante: %s", ", ".join(missing))
        _pip_install(missing)
    except Exception as e:
        log.warning("[deps] installation partielle: %s", e)


# ------------------------------------------------------------
# Chemins runtime (crée dossiers si absents)
# ------------------------------------------------------------

def ensure_paths() -> None:
    """
    Crée data_dir / reports_dir / logs_dir / tmp_dir si définis dans config.
    """
    cfg = load_config()
    rt = (cfg.get("runtime") or {})
    for key in ("data_dir", "reports_dir", "logs_dir", "tmp_dir"):
        p = Path(rt.get(key) or "").expanduser()
        if not p:
            continue
        try:
            p.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            log.warning("impossible de créer %s=%s: %s", key, p, e)


# ------------------------------------------------------------
# Exchange (Bitget REST) – tolérant aux signatures différentes
# ------------------------------------------------------------

def build_exchange():
    """
    Construit un client BitgetFuturesClient à partir de la conf.
    Supporte plusieurs signatures (paper/base optionnels) sans planter.
    """
    from engine.exchange.bitget_rest import BitgetFuturesClient  # existant dans ton repo

    cfg = load_config()
    ex_cfg = (cfg.get("exchange") or {}).get("bitget", {}) or {}
    trading = (cfg.get("trading") or {}) or {}

    ak = ex_cfg.get("access_key", "")
    sk = ex_cfg.get("secret_key", "")
    pp = ex_cfg.get("passphrase", "")
    base = ex_cfg.get("base", "https://api.bitget.com")
    paper = bool(trading.get("paper", True))

    # Essai 1: avec paper + base
    try:
        return BitgetFuturesClient(
            access_key=ak, secret_key=sk, passphrase=pp,
            paper=paper, base=base
        )
    except TypeError:
        pass
    # Essai 2: sans paper
    try:
        return BitgetFuturesClient(
            access_key=ak, secret_key=sk, passphrase=pp,
            base=base
        )
    except TypeError:
        pass
    # Essai 3: minimal
    try:
        return BitgetFuturesClient(
            access_key=ak, secret_key=sk, passphrase=pp
        )
    except TypeError as e:
        raise RuntimeError(f"BitgetFuturesClient incompatible avec la conf: {e}")


# ------------------------------------------------------------
# Entrée unique pour préparer l’environnement (appelée par app.run)
# ------------------------------------------------------------

def bootstrap_environment() -> None:
    """
    À appeler tôt au démarrage (depuis engine.app) :
      - installe les deps minimales (rich/pyyaml/requests) si besoin
      - prépare les dossiers runtime (data/reports/logs/tmp)
    """
    ensure_min_deps()
    ensure_paths()

# ===== engine/client.py ===== (100 lignes, modifié 2025-08-25 17:18:51)

import logging
from typing import Any, Dict, Optional

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry


class HTTPError(RuntimeError):
    """Raised when an HTTP request fails"""


class HttpClient:
    """Simple HTTP client with persistent session and retry logic.

    The client exposes a :py:meth:`close` method and implements the context
    manager protocol so it can be used with ``with`` statements to ensure
    that the underlying :class:`requests.Session` is properly closed.
    """

    def __init__(
        self,
        base_url: str,
        *,
        timeout: float = 10.0,
        max_retries: int = 3,
        backoff_factor: float = 0.3,
        status_forcelist: Optional[list[int]] = None,
    ) -> None:
        self.base_url = base_url.rstrip("/")
        self.timeout = timeout
        self.session = requests.Session()
        retry = Retry(
            total=max_retries,
            backoff_factor=backoff_factor,
            status_forcelist=status_forcelist or [429, 500, 502, 503, 504],
            allowed_methods=[
                "HEAD",
                "GET",
                "OPTIONS",
                "POST",
                "PUT",
                "DELETE",
                "PATCH",
            ],
        )
        adapter = HTTPAdapter(max_retries=retry)
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)

    def close(self) -> None:
        """Close the underlying :class:`requests.Session`."""
        self.session.close()

    # ------------------------------------------------------------------
    # Context manager support
    # ------------------------------------------------------------------
    def __enter__(self) -> "HttpClient":
        return self

    def __exit__(self, exc_type, exc, tb) -> None:  # type: ignore[override]
        self.close()

    def request(
        self,
        method: str,
        path: str,
        *,
        params: Optional[Dict[str, Any]] = None,
        json: Optional[Dict[str, Any]] = None,
        headers: Optional[Dict[str, str]] = None,
    ) -> Dict[str, Any]:
        """Perform an HTTP request and return JSON data.

        Errors during the request raise ``HTTPError``. If the response cannot
        be decoded as JSON, a dictionary describing the issue is returned.
        """
        url = f"{self.base_url}{path}"
        try:
            resp = self.session.request(
                method,
                url,
                params=params,
                json=json,
                headers=headers,
                timeout=self.timeout,
            )
            resp.raise_for_status()
        except requests.RequestException as exc:  # network or HTTP errors
            msg = f"HTTP error calling {url}: {exc}"
            logging.error(msg)
            raise HTTPError(msg) from exc

        try:
            return resp.json()
        except ValueError:  # invalid JSON
            msg = "Invalid JSON in response"
            logging.error("%s for %s: %s", msg, url, resp.text)
            return {"success": False, "error": msg, "text": resp.text}

# ===== engine/config/config.yaml ===== (56 lignes, modifié 2025-08-25 17:18:51)

# engine/config/config.yml
# ========================
# ⚙️ Configuration centrale (versionnée) – secrets (API keys) restent dans .env

runtime:
  data_dir: /notebooks/scalp_data/data
  reports_dir: /notebooks/scalp_data/reports
  logs_dir: /notebooks/scalp_data/logs
  tmp_dir: /notebooks/scalp_data/tmp

exchange:
  name: bitget
  base_url: https://api.bitget.com
  paper: true                 # false = réel, true = paper/sandbox si dispo
  rate_limit_ms: 200

watchlist:
  top: 10                     # nb de paires conservées
  score_tf: 5m               # TF pour scorer la watchlist (vol/volatilité)
  backfill_tfs: [1m, 5m, 15m]# TF à backfiller à chaque cycle
  backfill_limit: 1500       # nb max de bougies par appel

maintainer:
  interval_secs: 43200       # relance du cycle complet (12h)
  sleep_between_secs: 0.5    # pause entre backfills pour limiter le rate‑limit

  # Affichage "live" du tableau PAIR×TF dans le terminal
  live_table: true
  live_interval_secs: 2.0

  # Multiplicateur de durée de vie des stratégies (TTL = mult × TF)
  # ex: 1m × 240 = 240 minutes ≈ 4h
  ttl_mult:
    1m: 240
    5m: 240
    15m: 192
    1h: 168
    4h: 90
    1d: 60

strategies:
  # Valeurs par défaut pour la stratégie baseline (EMA/ATR)
  risk_default_pct: 1.0
  ema_fast: 9
  ema_slow: 21
  atr_period: 14
  trail_atr_mult: 2.0

notify:
  telegram: true
  console: true
  discord: false

dash:
  port: 8501
  auto_open_browser: false

# ===== engine/config/loader.py ===== (119 lignes, modifié 2025-08-25 17:18:51)

# engine/config/loader.py
from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict

# PyYAML est préférable (format YAML "humain"). On garde un fallback JSON.
try:
    import yaml  # type: ignore
except Exception:  # pragma: no cover
    yaml = None  # type: ignore

# ---------------------------------------------------------------------
# Emplacement du fichier de configuration versionné dans le repo
# ---------------------------------------------------------------------
_CFG_PATH = Path(__file__).resolve().parent / "config.yaml"

# Valeurs par défaut (si une clé manque dans config.yaml)
_DEFAULTS: Dict[str, Any] = {
    "runtime": {
        "timeframe": "1m",
        "refresh_secs": 5,
        "data_dir": "/notebooks/scalp_data/data",
        "reports_dir": "/notebooks/scalp_data/reports",
        "logs_dir": "/notebooks/scalp_data/logs",
    },
    "watchlist": {
        "top": 10,
        "score_tf": "5m",
        "backfill_tfs": ["1m", "5m", "15m"],
        "backfill_limit": 1500,
    },
    "maintainer": {
        "enable": True,
        "interval_secs": 43200,          # 12h
        "seed_tfs": ["1m"],
        "ttl_bars_experimental": 120,
    },
}

# Cache en mémoire pour éviter de relire le fichier à chaque appel
_CFG_CACHE: Dict[str, Any] | None = None


# ---------------------------------------------------------------------
# Utilitaires
# ---------------------------------------------------------------------
def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
    """Fusion récursive (override > base)."""
    out = dict(base)
    for k, v in (override or {}).items():
        if isinstance(v, dict) and isinstance(out.get(k), dict):
            out[k] = _deep_merge(out[k], v)  # type: ignore[index]
        else:
            out[k] = v
    return out


def _read_yaml_or_json(path: Path) -> Dict[str, Any]:
    """Lit config.yaml. Accepte YAML classique ou JSON 'lisible'."""
    if not path.exists():
        return {}
    txt = path.read_text(encoding="utf-8")
    # 1) tenter YAML si dispo
    if yaml is not None:
        try:
            doc = yaml.safe_load(txt) or {}
            if isinstance(doc, dict):
                return doc  # type: ignore[return-value]
        except Exception:
            pass
    # 2) fallback JSON
    try:
        doc = json.loads(txt) or {}
        if isinstance(doc, dict):
            return doc  # type: ignore[return-value]
    except Exception:
        pass
    return {}


# ---------------------------------------------------------------------
# API publique
# ---------------------------------------------------------------------
def cfg_path() -> Path:
    """Retourne le chemin du fichier de config dans le repo."""
    return _CFG_PATH


def load_config(reload: bool = False) -> Dict[str, Any]:
    """
    Charge la configuration fusionnée (defaults + engine/config/config.yaml).
    Utilise un cache en mémoire; passer reload=True pour forcer la relecture.
    """
    global _CFG_CACHE
    if _CFG_CACHE is not None and not reload:
        return _CFG_CACHE

    # Lire le document (vide si absent/illisible)
    doc = _read_yaml_or_json(_CFG_PATH)

    # Fusion récursive avec les defaults
    merged = _deep_merge(_DEFAULTS, doc)

    # Normalisations légères
    # - watchlist.backfill_tfs peut être une chaîne "1m,5m" -> liste
    wl = merged.get("watchlist", {})
    if isinstance(wl, dict):
        tfs = wl.get("backfill_tfs")
        if isinstance(tfs, str):
            wl["backfill_tfs"] = [t.strip() for t in tfs.split(",") if t.strip()]
        merged["watchlist"] = wl

    _CFG_CACHE = merged
    return merged


__all__ = ["load_config", "cfg_path"]

# ===== engine/config/strategies.py ===== (128 lignes, modifié 2025-08-25 17:18:51)

# engine/config/strategies.py
from __future__ import annotations
import json, os
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Any, Dict, Tuple

_STRAT_PATH = Path(__file__).resolve().parent / "strategies.yml"

_DEF_TTL_BARS = {  # fallback si meta absent
    "DEFAULT": 300,
    "LOW": 1000,
    "MEDIUM": 500,
    "HIGH": 250,
    "EXPERIMENTAL": 120,
}

def _parse_iso(s: str | None) -> datetime | None:
    if not s: return None
    try:
        if s.endswith("Z"): s = s[:-1] + "+00:00"
        return datetime.fromisoformat(s).astimezone(timezone.utc)
    except Exception:
        return None

def _pair_tf(key: str) -> Tuple[str, str]:
    # "BTCUSDT:1m" -> ("BTCUSDT","1m")
    if ":" in key:
        a, b = key.split(":", 1)
        return a.replace("_","").upper(), b
    return key.replace("_","").upper(), "1m"

def _tf_minutes(tf: str) -> float:
    tf = tf.strip().lower()
    if tf.endswith("m"): return float(tf[:-1] or 1)
    if tf.endswith("h"): return float(tf[:-1] or 1) * 60.0
    if tf.endswith("d"): return float(tf[:-1] or 1) * 60.0 * 24.0
    # défaut: 1m
    return 1.0

def _load_doc() -> Dict[str, Any]:
    if not _STRAT_PATH.exists(): return {"meta": {}, "strategies": {}}
    try:
        return json.loads(_STRAT_PATH.read_text(encoding="utf-8"))
    except Exception:
        return {"meta": {}, "strategies": {}}

def _policy_bars(meta: Dict[str, Any], risk_label: str) -> int:
    # 1) meta.ttl_policy_bars
    pol = meta.get("ttl_policy_bars") if isinstance(meta, dict) else None
    if not isinstance(pol, dict): pol = {}
    # 2) env overrides (STRAT_TTL_<RISK>=nb)
    env_key = f"STRAT_TTL_{risk_label.upper()}"
    if os.getenv(env_key):
        try:
            return max(1, int(float(os.getenv(env_key, "0"))))
        except Exception:
            pass
    # 3) table meta/par défaut
    return int(pol.get(risk_label.upper(), pol.get("DEFAULT", _DEF_TTL_BARS.get(risk_label.upper(), _DEF_TTL_BARS["DEFAULT"]))))

def _global_mult(meta: Dict[str, Any]) -> float:
    try:
        m = float(meta.get("ttl_global_multiplier", 1.0))
        env = os.getenv("STRAT_TTL_MULTIPLIER")
        if env is not None:
            m *= float(env)
        return max(0.01, m)
    except Exception:
        return 1.0

def load_strategies() -> Dict[str, Dict[str, Any]]:
    """
    Retourne {"PAIR:TF": { params..., 'expired': bool, 'executable': bool, 'ttl_hours': float }}
    TTL = (ttl_bars OU policy[risk]) * durée_barre(tf)
    """
    doc = _load_doc()
    meta = doc.get("meta") or {}
    src = doc.get("strategies") or {}
    mult = _global_mult(meta)

    now = datetime.now(timezone.utc)
    out: Dict[str, Dict[str, Any]] = {}

    for k, v in src.items():
        if not isinstance(v, dict): continue
        pair, tf = _pair_tf(k)
        tf_min = _tf_minutes(str(tf))
        risk = (v.get("risk_label") or "DEFAULT").upper()

        # nombre de barres de validité
        bars = int(v.get("ttl_bars")) if isinstance(v.get("ttl_bars"), (int, float, str)) and str(v.get("ttl_bars")).strip() else _policy_bars(meta, risk)
        bars = max(1, int(bars * mult))

        ttl_hours = (bars * tf_min) / 60.0
        last = _parse_iso(str(v.get("last_validated") or ""))

        expired = True
        if last is not None:
            expired = now > (last + timedelta(hours=ttl_hours))

        execute_flag = bool(v.get("execute", False))
        risk_label = (v.get("risk_label") or "").upper()
        # on ne décide pas ici pour EXPERIMENTAL; l'orchestrateur peut autoriser via env
        executable = execute_flag and not expired and risk_label != "EXPERIMENTAL"

        out[f"{pair}:{tf}"] = {
            **v,
            "pair": pair,
            "tf": tf,
            "risk_label": risk_label,
            "ttl_bars": bars,
            "ttl_hours": ttl_hours,
            "expired": expired,
            "executable": executable,
        }
    return out

def executable_keys(*, allow_experimental: bool = False) -> Dict[str, Dict[str, Any]]:
    all_ = load_strategies()
    out: Dict[str, Dict[str, Any]] = {}
    for k, s in all_.items():
        if s.get("expired"): continue
        if not s.get("execute"): continue
        if s.get("risk_label") == "EXPERIMENTAL" and not allow_experimental:
            continue
        out[k] = s
    return out

# ===== engine/config/strategies.yml ===== (16 lignes, modifié 2025-08-25 17:19:36)

{
  "strategies": {
    "BTCUSDT:1m": {
      "name": "BASE_UNTESTED",
      "risk_label": "EXPERIMENTAL",
      "execute": false,
      "ema_fast": 9,
      "ema_slow": 21,
      "atr_period": 14,
      "trail_atr_mult": 1.5,
      "risk_pct_equity": 0.005,
      "last_validated": "2025-08-25T08:30:00Z",
      "ttl_bars": 120
    }
  }
}

# ===== engine/config/watchlist.py ===== (35 lignes, modifié 2025-08-25 17:18:51)

# engine/config/watchlist.py
from __future__ import annotations
import json, os, time
from dataclasses import asdict
from pathlib import Path
from typing import Any, Dict, List

from engine.config.loader import load_config
from engine.pairs.selector import PairMetrics

def _watchlist_path() -> Path:
    # Fichier versionné ou non ? -> dans DATA_ROOT/reports (hors repo)
    cfg = load_config()
    p = Path(cfg["runtime"]["reports_dir"]) / "watchlist.yml"
    p.parent.mkdir(parents=True, exist_ok=True)
    return p

def save_watchlist(pairs: List[PairMetrics], *, timestamp: int | None = None) -> Path:
    path = _watchlist_path()
    doc = {
        "updated_at": int(timestamp or time.time()),
        "top": [asdict(p) for p in pairs],
    }
    # json lisible (compat .yml reader simple)
    path.write_text(json.dumps(doc, indent=2), encoding="utf-8")
    return path

def load_watchlist() -> Dict[str, Any]:
    p = _watchlist_path()
    if not p.exists():
        return {"updated_at": 0, "top": []}
    try:
        return json.loads(p.read_text(encoding="utf-8"))
    except Exception:
        return {"updated_at": 0, "top": []}

# ===== engine/core/indicators.py ===== (17 lignes, modifié 2025-08-25 17:18:51)

from __future__ import annotations
import pandas as pd

def ema(s: pd.Series, n: int) -> pd.Series:
    return s.ewm(span=max(1,int(n)), adjust=False).mean()

def macd(close: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9):
    macd_line = ema(close, fast) - ema(close, slow)
    signal_line = ema(macd_line, signal)
    hist = macd_line - signal_line
    return macd_line, signal_line, hist

def atr(df: pd.DataFrame, n: int = 14) -> pd.Series:
    high, low, close = df["high"], df["low"], df["close"]
    prev_close = close.shift(1)
    tr = (high - low).abs().combine((high - prev_close).abs(), max).combine((low - prev_close).abs(), max)
    return tr.rolling(max(1,int(n))).mean()

# ===== engine/core/signal.py ===== (19 lignes, modifié 2025-08-25 17:18:51)

from __future__ import annotations
import pandas as pd
from .indicators import ema, atr

def compute_signals(df: pd.DataFrame, params: dict) -> pd.DataFrame:
    fast = int(params.get("ema_fast", 20))
    slow = int(params.get("ema_slow", 50))
    atr_n = int(params.get("atr_period", 14))
    df = df.copy()
    df["ema_fast"] = ema(df["close"], fast)
    df["ema_slow"] = ema(df["close"], slow)
    df["atr"] = atr(df, atr_n)
    # signal = +1 si croisement haussier, -1 si baissier, 0 sinon
    cond_up = (df["ema_fast"] > df["ema_slow"]) & (df["ema_fast"].shift(1) <= df["ema_slow"].shift(1))
    cond_dn = (df["ema_fast"] < df["ema_slow"]) & (df["ema_fast"].shift(1) >= df["ema_slow"].shift(1))
    df["signal"] = 0
    df.loc[cond_up, "signal"] = 1
    df.loc[cond_dn, "signal"] = -1
    return df

# ===== engine/core/signals.py ===== (47 lignes, modifié 2025-08-25 17:18:51)

# engine/core/signals.py
from __future__ import annotations
import pandas as pd

def _ema(series: pd.Series, period: int) -> pd.Series:
    return series.ewm(span=period, adjust=False).mean()

def _atr(df: pd.DataFrame, period: int = 14) -> pd.Series:
    high, low, close = df["high"], df["low"], df["close"]
    prev_close = close.shift(1)
    tr = pd.concat([
        high - low,
        (high - prev_close).abs(),
        (low - prev_close).abs()
    ], axis=1).max(axis=1)
    return tr.rolling(period).mean()

def compute_signals(df: pd.DataFrame, params: dict[str, float]) -> pd.DataFrame:
    """
    Applique EMA crossover + ATR.
    Retourne DataFrame avec colonnes: ts, open, high, low, close, volume, ema_fast, ema_slow, atr, signal
    signal = +1 long / -1 short / 0 neutre
    """
    fast = int(params.get("ema_fast", 20))
    slow = int(params.get("ema_slow", 50))
    atr_period = int(params.get("atr_period", 14))

    out = df.copy()
    out["ema_fast"] = _ema(out["close"], fast)
    out["ema_slow"] = _ema(out["close"], slow)
    out["atr"] = _atr(out, atr_period)

    sig = 0
    signals = []
    for f, s in zip(out["ema_fast"], out["ema_slow"]):
        if pd.isna(f) or pd.isna(s):
            signals.append(0)
        elif f > s and sig <= 0:
            sig = 1
            signals.append(1)
        elif f < s and sig >= 0:
            sig = -1
            signals.append(-1)
        else:
            signals.append(sig)
    out["signal"] = signals
    return out

# ===== engine/exchange/bitget_ccxt.py ===== (22 lignes, modifié 2025-08-25 17:18:51)

from __future__ import annotations
import asyncio
from typing import Any, List, Sequence

class BitgetExchange:
    """Wrapper CCXT async. Installe `ccxt` pour l'utiliser, sinon bot tombera sur REST."""
    def __init__(self, api_key: str, secret: str, password: str, data_dir: str):
        try:
            import ccxt.async_support as ccxt  # type: ignore
        except Exception as e:  # ccxt non installé
            raise RuntimeError(f"ccxt non disponible: {e}")
        self._ccxt = ccxt.bitget({"apiKey": api_key, "secret": secret, "password": password})
        self.data_dir = data_dir

    async def fetch_ohlcv(self, symbol: str, timeframe: str, limit: int = 150) -> List[List[float]]:
        return await self._ccxt.fetch_ohlcv(symbol, timeframe=timeframe, limit=limit)

    async def close(self) -> None:
        try:
            await self._ccxt.close()
        except Exception:
            pass

# ===== engine/exchange/bitget_rest.py ===== (353 lignes, modifié 2025-08-25 17:18:51)

# engine/exchange/bitget_rest.py
from __future__ import annotations

import base64
import hashlib
import hmac
import json
import logging
import time
from dataclasses import dataclass
from typing import Any, Dict, Mapping, Optional

import requests

__all__ = ["BitgetFuturesClient", "ApiError"]

log = logging.getLogger("engine.exchange.bitget_rest")


# =============================================================================
# Exceptions
# =============================================================================
class ApiError(RuntimeError):
    """Erreur API Bitget (HTTP != 200, code != '00000', ou payload invalide)."""

    def __init__(self, message: str, *, http_status: int | None = None, body: Any | None = None):
        super().__init__(message)
        self.http_status = http_status
        self.body = body


# =============================================================================
# Helpers
# =============================================================================
def _now_ms() -> int:
    return int(time.time() * 1000)


def _canonical_json(obj: Mapping[str, Any] | None) -> str:
    if not obj:
        return ""
    # JSON compact, trié, ascii pour signature stable
    return json.dumps(obj, separators=(",", ":"), sort_keys=True, ensure_ascii=True)


# =============================================================================
# Client REST Futures (USDT-M)
# =============================================================================
@dataclass
class _Auth:
    access_key: str
    secret_key: str
    passphrase: str
    recv_window: int = 30_000  # ms


class BitgetFuturesClient:
    """
    Client REST léger pour les Futures USDT-M de Bitget.

    Points clés:
    - Public: get_ticker(symbol?), get_klines(symbol, interval, limit, start/end?)
    - Privé : get_account(), get_open_orders(symbol?), cancel_order(), cancel_all()
              place_market_order_one_way(), place_limit_order_one_way()
              set_position_mode_one_way(), set_leverage()
    - Safe: gestion d’erreurs centralisée, timeouts, session réutilisable.
    """

    def __init__(
        self,
        *,
        access_key: str = "",
        secret_key: str = "",
        passphrase: str = "",
        base_url: str = "https://api.bitget.com",
        paper_trade: bool = True,
        timeout: float = 10.0,
        session: Optional[requests.Session] = None,
    ) -> None:
        self.base_url = base_url.rstrip("/")
        self.auth = _Auth(access_key, secret_key, passphrase)
        self.paper = paper_trade
        self.timeout = float(timeout)
        self.sess = session or requests.Session()
        self.sess.headers.update({"Accept": "application/json"})
        log.info("BitgetFuturesClient ready (paper=%s base=%s)", self.paper, self.base_url)

    # -------------------------------------------------------------------------
    # Core HTTP
    # -------------------------------------------------------------------------
    def _sign(self, ts_ms: int, method: str, path: str, query: str, body: str) -> str:
        """
        Signature :
          sign = base64( HMAC_SHA256(secret, f"{ts}{method}{path}{query}{body}") )
        - method en MAJUSCULES
        - query inclut '?' si présent, sinon ""
        - body = chaîne JSON canonique (ou vide)
        """
        msg = f"{ts_ms}{method.upper()}{path}{query}{body}"
        return base64.b64encode(hmac.new(self.auth.secret_key.encode(), msg.encode(), hashlib.sha256).digest()).decode()

    def _request(
        self,
        method: str,
        path: str,
        *,
        params: Optional[Mapping[str, Any]] = None,
        body: Optional[Mapping[str, Any]] = None,
        signed: bool = False,
    ) -> Dict[str, Any]:
        url = f"{self.base_url}{path}"
        params = dict(params or {})
        body_json = _canonical_json(body)
        query = ""

        headers = {"Content-Type": "application/json"}
        if not signed:
            # Public
            resp = self.sess.request(
                method=method.upper(),
                url=url,
                params=params or None,
                timeout=self.timeout,
                headers=headers,
            )
        else:
            # Privé: timestamp + recvWindow
            ts = _now_ms()
            if "recvWindow" not in params:
                params["recvWindow"] = self.auth.recv_window
            # Construire la query string stable (requests la reformate si on passe 'params')
            if params:
                q_items = "&".join(f"{k}={params[k]}" for k in sorted(params))
                query = f"?{q_items}"
            signature = self._sign(ts, method, path, query, body_json)

            headers.update(
                {
                    "ACCESS-KEY": self.auth.access_key,
                    "ACCESS-SIGN": signature,
                    "ACCESS-TIMESTAMP": str(ts),
                    "ACCESS-PASSPHRASE": self.auth.passphrase,
                }
            )

            resp = self.sess.request(
                method=method.upper(),
                url=url,
                params=params or None,
                data=body_json if body_json else None,
                timeout=self.timeout,
                headers=headers,
            )

        # Gestion d’erreurs HTTP
        if resp.status_code != 200:
            raise ApiError(f"HTTP {resp.status_code} for {path}", http_status=resp.status_code, body=resp.text)

        # Décodage JSON
        try:
            data = resp.json()
        except Exception as exc:
            raise ApiError(f"Non-JSON response for {path}: {resp.text[:200]}") from exc

        # Protocole Bitget: code == '00000' attendu
        code = str(data.get("code", ""))
        if code and code != "00000":
            raise ApiError(f"Bitget API error code={code} for {path}", body=data)

        return data

    # -------------------------------------------------------------------------
    # PUBLIC
    # -------------------------------------------------------------------------
    def get_ticker(self, symbol: Optional[str] = None) -> Dict[str, Any]:
        """
        Ticker futures. Si `symbol` est fourni, retourne uniquement cette entrée.
        """
        params = {"productType": "USDT-FUTURES"}
        data = self._request("GET", "/api/v2/mix/market/tickers", params=params, signed=False)
        if not symbol:
            return data

        # Harmoniser: extraire l’entrée du symbole demandé
        items = data.get("data") or []
        sym = symbol.replace("_", "").upper()
        hit: Dict[str, Any] | None = None
        for it in items:
            if (it.get("symbol") or "").replace("_", "").upper() == sym:
                hit = it
                break
        return {"data": hit or {}}

    def get_klines(
        self,
        symbol: str,
        interval: str = "1m",
        limit: int = 100,
        start: Optional[int] = None,
        end: Optional[int] = None,
    ) -> Dict[str, Any]:
        """
        OHLCV Futures.
        interval: '1m', '5m', '15m', '1h', ...
        start/end: timestamps ms optionnels.
        """
        params: Dict[str, Any] = {
            "symbol": symbol.replace("_", "").upper(),
            "granularity": interval,
            "productType": "USDT-FUTURES",
            "limit": max(1, min(int(limit), 1000)),
        }
        if start is not None:
            params["startTime"] = int(start)
        if end is not None:
            params["endTime"] = int(end)

        return self._request("GET", "/api/v2/mix/market/candles", params=params, signed=False)

    # -------------------------------------------------------------------------
    # PRIVÉ (Futures One-Way par défaut)
    # -------------------------------------------------------------------------
    def get_account(self) -> Dict[str, Any]:
        """Infos compte futures (marges, balances)."""
        return self._request("GET", "/api/v2/mix/account/accounts", params={"productType": "USDT-FUTURES"}, signed=True)

    def get_open_orders(self, symbol: Optional[str] = None) -> Dict[str, Any]:
        params: Dict[str, Any] = {"productType": "USDT-FUTURES"}
        if symbol:
            params["symbol"] = symbol.replace("_", "").upper()
        return self._request("GET", "/api/v2/mix/order/open-orders", params=params, signed=True)

    def cancel_order(self, symbol: str, order_id: str) -> Dict[str, Any]:
        body = {
            "symbol": symbol.replace("_", "").upper(),
            "productType": "USDT-FUTURES",
            "orderId": order_id,
        }
        return self._request("POST", "/api/v2/mix/order/cancel-order", body=body, signed=True)

    def cancel_all(self, symbol: Optional[str] = None) -> Dict[str, Any]:
        body: Dict[str, Any] = {"productType": "USDT-FUTURES"}
        if symbol:
            body["symbol"] = symbol.replace("_", "").upper()
        return self._request("POST", "/api/v2/mix/order/cancel-batch-orders", body=body, signed=True)

    # -- Mode de position & levier ---------------------------------------------
    def set_position_mode_one_way(self, symbol: str, product_type: str = "USDT-FUTURES") -> Dict[str, Any]:
        """Passe le mode de position en One-Way (si nécessaire)."""
        body = {
            "productType": product_type,
            "symbol": symbol.replace("_", "").upper(),
            "holdMode": "one_way",
        }
        return self._request("POST", "/api/v2/mix/account/set-position-mode", body=body, signed=True)

    def set_leverage(
        self,
        symbol: str,
        product_type: str = "USDT-FUTURES",
        margin_coin: str = "USDT",
        leverage: int = 2,
        side: str = "long",
    ) -> Dict[str, Any]:
        """Règle l’effet de levier (par side 'long'/'short' ou global selon l’API)."""
        lev = max(1, int(leverage))
        body = {
            "symbol": symbol.replace("_", "").upper(),
            "productType": product_type,
            "marginCoin": margin_coin,
            "leverage": str(lev),
            "holdSide": side.lower(),  # 'long' ou 'short'
        }
        return self._request("POST", "/api/v2/mix/account/set-leverage", body=body, signed=True)

    # -- Placement d’ordres (One-Way) ------------------------------------------
    def place_market_order_one_way(
        self,
        symbol: str,
        side: str,
        size: float,
        product_type: str = "USDT-FUTURES",
        margin_coin: str = "USDT",
        client_oid: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Place un ordre MARKET en mode one-way.
        side: 'buy' ou 'sell'
        size: quantité de contrat (format arrondi côté serveur)
        """
        body: Dict[str, Any] = {
            "symbol": symbol.replace("_", "").upper(),
            "productType": product_type,
            "marginCoin": margin_coin,
            "size": f"{float(size):.6f}",
            "side": side.lower(),
            "orderType": "market",
        }
        if client_oid:
            body["clientOid"] = client_oid
        return self._request("POST", "/api/v2/mix/order/place-order", body=body, signed=True)

    def place_limit_order_one_way(
        self,
        symbol: str,
        side: str,
        size: float,
        price: float,
        product_type: str = "USDT-FUTURES",
        margin_coin: str = "USDT",
        tif: str = "GTC",
        client_oid: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Place un ordre LIMIT en mode one-way.
        tif: GTC/IOC/FOK suivant l’API.
        """
        body: Dict[str, Any] = {
            "symbol": symbol.replace("_", "").upper(),
            "productType": product_type,
            "marginCoin": margin_coin,
            "size": f"{float(size):.6f}",
            "price": f"{float(price):.8f}",
            "side": side.lower(),
            "orderType": "limit",
            "timeInForceValue": tif.upper(),
        }
        if client_oid:
            body["clientOid"] = client_oid
        return self._request("POST", "/api/v2/mix/order/place-order", body=body, signed=True)

    # -------------------------------------------------------------------------
    # Helpers d’accès
    # -------------------------------------------------------------------------
    def last_price(self, symbol: str) -> float:
        """Renvoie un prix last connu en tolérant plusieurs structures/clefs."""
        tick = self.get_ticker(symbol)
        data = tick.get("data")
        if isinstance(data, list) and data:
            data = data[0]
        if not isinstance(data, dict):
            return 0.0
        price_str = (
            data.get("lastPr")
            or data.get("lastPrice")
            or data.get("close")
            or data.get("price")
            or data.get("l")
        )
        try:
            return float(price_str)
        except Exception:
            return 0.0

# ===== engine/hooks/prewarm_cache.py ===== (22 lignes, modifié 2025-08-25 17:18:51)

# -*- coding: utf-8 -*-
"""
Pré-chauffe léger du cache OHLCV.

Objectif: ne PAS bloquer le lancement. On log juste un statut "warmup OK"
pour chaque symbole, et on s'assure que le dossier data existe.
Si tu veux rebrancher un vrai downloader plus tard, expose simplement une
fonction `prewarm_cache(cfg, symbols, timeframe, out_dir)` avec la même
signature.
"""
from __future__ import annotations
from pathlib import Path
from typing import Iterable


def prewarm_cache(cfg: dict, symbols: Iterable[str], timeframe: str, out_dir: str | Path) -> None:
    out = Path(out_dir)
    out.mkdir(parents=True, exist_ok=True)
    for sym in symbols:
        # Marqueur vide; permet à d’autres services de voir que le symbole est "préparé"
        (out / f"{sym}-{timeframe}.csv").touch(exist_ok=True)
        print(f"[cache] warmup OK for {sym}")

# ===== engine/live/__init__.py ===== (1 lignes, modifié 2025-08-25 17:18:51)

 

# ===== engine/live/commands.py ===== (60 lignes, modifié 2025-08-25 17:18:51)

# engine/live/commands.py
from __future__ import annotations
import asyncio
import logging
import os
from typing import Any, AsyncIterator, Dict, Optional

import requests

log = logging.getLogger("engine.live.commands")


async def telegram_command_stream(
    token: str,
    chat_id: str,
    *,
    poll_secs: int = 5,
    allowed_cmds: Optional[set[str]] = None,
) -> AsyncIterator[Dict[str, Any]]:
    """
    Flux de commandes Telegram via long‑polling.
    Émet des dicts {type: "tg", cmd: "status" | "reload" | "stop" | "help", raw: <update>}
    """
    allowed_cmds = allowed_cmds or {"status", "reload", "stop", "help", "watchlist"}
    url = f"https://api.telegram.org/bot{token}/getUpdates"
    offset = 0

    while True:
        try:
            r = requests.get(url, params={"timeout": poll_secs, "offset": offset + 1}, timeout=poll_secs + 3)
            data = r.json()
            for upd in data.get("result", []):
                offset = upd.get("update_id", offset)
                msg = upd.get("message") or upd.get("edited_message") or {}
                if str(msg.get("chat", {}).get("id")) != str(chat_id):
                    continue
                text = (msg.get("text") or "").strip()
                if not text.startswith("/"):
                    continue
                cmd = text.lstrip("/").split()[0].lower()
                if cmd in allowed_cmds:
                    yield {"type": "tg", "cmd": cmd, "raw": upd}
        except Exception:
            log.debug("poll telegram failed", exc_info=True)
        await asyncio.sleep(poll_secs)


def build_command_stream(cfg: Dict[str, Any] | None = None) -> Optional[AsyncIterator[Dict[str, Any]]]:
    """
    Construit un flux de commandes si TELEGRAM_* sont présents.
    Définir DISABLE_TG_COMMANDS=1 pour désactiver.
    """
    if os.getenv("DISABLE_TG_COMMANDS", "").lower() in {"1", "true", "yes"}:
        return None

    token = os.getenv("TELEGRAM_BOT_TOKEN") or (cfg or {}).get("secrets", {}).get("telegram", {}).get("token")
    chat_id = os.getenv("TELEGRAM_CHAT_ID") or (cfg or {}).get("secrets", {}).get("telegram", {}).get("chat_id")
    if token and chat_id:
        return telegram_command_stream(token, chat_id)
    return None

# ===== engine/live/health.py ===== (71 lignes, modifié 2025-08-25 17:18:51)

# engine/live/health.py
from __future__ import annotations
from typing import Dict, List, Tuple
import re

# codes ANSI simples
_COL = {"k":"\x1b[30m","r":"\x1b[31m","g":"\x1b[32m","o":"\x1b[33m","x":"\x1b[0m"}

def _short(sym: str) -> str:
    s = sym.upper().replace("_","")
    return s[:-4] if s.endswith("USDT") else s

def _center(t: str, w: int) -> str:
    pad = max(0, w-len(t)); return " "*(pad//2) + t + " "*(pad-pad//2)

class HealthBoard:
    """Affichage console: tableau PAIR × TF avec MIS/OLD/DAT/OK."""
    def __init__(self, state):
        self.state = state
        self._legend_once = False

    def banner(self) -> None:
        print("\x1b[2J\x1b[H", end="")
        print("=== ORCHESTRATOR ===")

    def _render_table(self) -> str:
        syms = self.state.symbols
        tfs  = self.state.tfs
        header = ["PAIR", *tfs]
        rows: List[List[str]] = []
        counts = {"k":0,"r":0,"o":0,"g":0}

        for s in syms:
            line = [_short(s)]
            for tf in tfs:
                lbl, col = self.state.grid.get((s, tf), ("MIS","k"))
                counts[col] = counts.get(col,0) + 1
                cell = f"{_COL[col]}{lbl}{_COL['x']}"
                line.append(cell)
            rows.append(line)

        # largeurs visibles (sans ANSI)
        def vislen(x: str) -> int:
            return len(re.sub(r"\x1b\[[0-9;]*m","",x))

        widths = [max(vislen(r[i]) for r in [header]+rows) for i in range(len(header))]

        def fmt(row: List[str]) -> str:
            out=[]
            for i,v in enumerate(row):
                w=widths[i]
                if "\x1b[" in v:
                    plain = re.sub(r"\x1b\[[0-9;]*m","",v)
                    v = v.replace(plain, _center(plain, w))
                else:
                    v = _center(v, w)
                out.append(v)
            return " | ".join(out)

        sep = ["-"*w for w in widths]
        table = "\n".join([fmt(header), fmt(sep), *[fmt(r) for r in rows]])
        legend = (f"{_COL['k']}MIS{_COL['x']}=no data • "
                  f"{_COL['r']}OLD{_COL['x']}=stale • "
                  f"{_COL['o']}DAT{_COL['x']}=data no strat • "
                  f"{_COL['g']}OK{_COL['x']}=ready")
        stats = f"stats • MIS={counts['k']} OLD={counts['r']} DAT={counts['o']} OK={counts['g']}"
        return f"{table}\n{legend}\n{stats}"

    def render(self) -> None:
        print("\x1b[2J\x1b[H", end="")
        print(self._render_table())

# ===== engine/live/notify.py ===== (35 lignes, modifié 2025-08-25 17:18:51)

# engine/live/notify.py
from __future__ import annotations
import asyncio
import logging
import os
from typing import Any

import requests

log = logging.getLogger("engine.live.notify")


class _NullNotifier:
    async def send(self, text: str) -> None:
        log.info("[NOTIFY] %s", text)


class TelegramNotifier:
    def __init__(self, token: str, chat_id: str, timeout: float = 5.0) -> None:
        self.token, self.chat_id, self.timeout = token, chat_id, timeout

    async def send(self, text: str) -> None:
        url = f"https://api.telegram.org/bot{self.token}/sendMessage"
        payload = {"chat_id": self.chat_id, "text": text}
        def _post() -> None:
            requests.post(url, json=payload, timeout=self.timeout)
        await asyncio.get_running_loop().run_in_executor(None, _post)


def build_notifier(cfg: dict | None = None) -> Any:
    token = os.getenv("TELEGRAM_BOT_TOKEN") or (cfg or {}).get("secrets", {}).get("telegram", {}).get("token")
    chat_id = os.getenv("TELEGRAM_CHAT_ID") or (cfg or {}).get("secrets", {}).get("telegram", {}).get("chat_id")
    if token and chat_id:
        return TelegramNotifier(token, chat_id)
    return _NullNotifier()

# ===== engine/live/orchestrator.py ===== (69 lignes, modifié 2025-08-25 17:18:51)

from __future__ import annotations
from dataclasses import dataclass
from typing import List

from engine.config.loader import load_config
from engine.config.watchlist import load_watchlist
from engine.live.scheduler import Scheduler
from engine.live.state import MarketState
from engine.live.health import HealthBoard

@dataclass
class RunConfig:
    symbols: List[str]
    timeframes: List[str]
    refresh_secs: int
    data_dir: str
    limit: int
    exec_enabled: bool = False
    auto: bool = True
    fresh_mult: float = 1.0
    cooldown_secs: int = 60

def run_config_from_yaml() -> RunConfig:
    cfg = load_config()
    rt = cfg.get("runtime", {}) or {}
    wl = cfg.get("watchlist", {}) or {}
    mt = cfg.get("maintainer", {}) or {}
    auto_cfg = cfg.get("auto") or {}

    wl_doc = load_watchlist()
    syms = [(d.get("symbol") or "").replace("_", "").upper()
            for d in (wl_doc.get("top") or []) if d.get("symbol")] or ["BTCUSDT","ETHUSDT","SOLUSDT"]
    tfs = [str(x) for x in (wl.get("backfill_tfs") or ["1m","5m","15m"])]

    return RunConfig(
        symbols=syms,
        timeframes=tfs,
        refresh_secs=int(mt.get("live_interval_secs", 5)),
        data_dir=str(rt.get("data_dir") or "/notebooks/scalp_data/data"),
        limit=int(wl.get("backfill_limit", 1500)),
        exec_enabled=bool((cfg.get("trading") or {}).get("exec_enabled", False)),
        auto=bool(auto_cfg.get("enabled", True)),
        fresh_mult=float(auto_cfg.get("fresh_mult", mt.get("fresh_mult", 1.0))),
        cooldown_secs=int(auto_cfg.get("cooldown_secs", 60)),
    )

class Orchestrator:
    def __init__(self, cfg: RunConfig, exchange):
        self.cfg = cfg
        self.exchange = exchange
        self.state = MarketState(cfg.symbols, cfg.timeframes, cfg.data_dir, cfg.fresh_mult)
        self.health = HealthBoard(self.state)
        self.sched = Scheduler(interval_sec=max(1, int(cfg.refresh_secs)))

    async def start(self) -> None:
        self.health.banner()
        async for _ in self.sched.ticks():       # boucle infinie
            await self._step()

    async def step_once(self) -> None:
        await self._step()

    async def _step(self) -> None:
        self.state.refresh()
        self.health.render()
        if self.cfg.auto:
            self.state.auto_actions(limit=self.cfg.limit, cooldown=self.cfg.cooldown_secs)
        for (s, tf) in self.state.ready_pairs():
            pass  # placeholder signaux

# ===== engine/live/scheduler.py ===== (15 lignes, modifié 2025-08-25 17:18:51)

from __future__ import annotations
import asyncio
from typing import AsyncIterator

class Scheduler:
    def __init__(self, interval_sec: int = 2):
        self.interval = max(1, int(interval_sec))

    async def ticks(self) -> AsyncIterator[int]:
        i = 0
        while True:
            yield i
            i += 1
            await asyncio.sleep(self.interval)
            

# ===== engine/live/state.py ===== (94 lignes, modifié 2025-08-25 17:18:51)

# engine/live/state.py
from __future__ import annotations
import time, subprocess
from dataclasses import dataclass
from typing import Dict, List, Tuple, Optional

from engine.backtest.loader_csv import load_csv_ohlcv
from engine.config.loader import load_config
from engine.config.strategies import load_strategies

_TF_MIN = {"1m":1,"5m":5,"15m":15,"1h":60,"4h":240,"1d":1440}

def _is_fresh(now_ms: int, last_ms: Optional[int], tf: str, mult: float) -> bool:
    if last_ms is None: return False
    return (now_ms - last_ms) <= (mult * _TF_MIN.get(tf,1) * 60_000)

@dataclass
class Cell:
    lbl: str  # MIS/OLD/DAT/OK
    col: str  # k/r/o/g

class MarketState:
    """Gère l’état (fraîcheur des CSV + présence/validité des stratégies) et actions AUTO."""
    def __init__(self, symbols: List[str], tfs: List[str], data_dir: str, fresh_mult: float = 1.0):
        self.symbols = symbols
        self.tfs = tfs
        self.data_dir = data_dir
        self.fresh_mult = fresh_mult
        self.grid: Dict[Tuple[str,str], Tuple[str,str]] = {}  # (lbl, col)
        self._cooldowns: Dict[str, float] = {}  # clé → epoch

    def _last_ts_ms(self, symbol: str, tf: str) -> Optional[int]:
        try:
            rows = load_csv_ohlcv(self.data_dir, symbol, tf, max_rows=1)
            return int(rows[-1][0]) if rows else None
        except Exception:
            return None

    def _status_cell(self, strategies: Dict[str, Dict], symbol: str, tf: str) -> Tuple[str,str]:
        now = int(time.time()*1000)
        last = self._last_ts_ms(symbol, tf)
        if last is None:
            return ("MIS","k")
        if not _is_fresh(now, last, tf, self.fresh_mult):
            return ("OLD","r")
        s = strategies.get(f"{symbol}:{tf}")
        if s and not s.get("expired"):
            return ("OK ","g")
        return ("DAT","o")

    def refresh(self, strategies: Optional[Dict[str, Dict]] = None) -> None:
        if strategies is None:
            strategies = load_strategies()
        new_grid: Dict[Tuple[str,str], Tuple[str,str]] = {}
        for s in self.symbols:
            for tf in self.tfs:
                new_grid[(s, tf)] = self._status_cell(strategies, s, tf)
        self.grid = new_grid

    def ready_pairs(self) -> List[Tuple[str,str]]:
        """Retourne (symbol, tf) dont la cellule est OK (verte)."""
        return [(s,tf) for (s,tf),(lbl,col) in self.grid.items() if col == "g"]

    # ---------- AUTO ----------
    def _cool(self, key: str, cooldown_secs: int) -> bool:
        now = time.time()
        t0 = self._cooldowns.get(key, 0.0)
        if (now - t0) >= cooldown_secs:
            self._cooldowns[key] = now
            return True
        return False

    def _run(self, args: List[str]) -> int:
        p = subprocess.run(args, capture_output=True, text=True)
        if p.stdout: print(p.stdout.strip())
        if p.stderr: print(p.stderr.strip())
        return p.returncode

    def auto_actions(self, limit: int, cooldown: int) -> None:
        """Déclenche automatiquement refresh/backtest/promote selon l’état."""
        # 1) refresh par TF si on voit MIS/OLD
        for tf in self.tfs:
            if any(self.grid.get((s,tf),("",""))[0] in ("MIS","OLD") for s in self.symbols):
                key = f"refresh:{tf}"
                if self._cool(key, cooldown):
                    print(f"[auto] refresh tf={tf}")
                    self._run(["python","-m","jobs.refresh_pairs","--timeframe",tf,"--top","0","--backfill-tfs",tf,"--limit",str(limit)])

        # 2) backtest + promote si on observe au moins un DAT
        if any(lbl == "DAT" for (lbl, _c) in self.grid.values()):
            if self._cool("backtest", cooldown):
                print("[auto] backtest + promote")
                self._run(["python","-m","jobs.backtest","--from-watchlist","--tfs",",".join(self.tfs)])
                self._run(["python","-m","jobs.promote","--backup"])

# ===== engine/live/trader.py ===== (96 lignes, modifié 2025-08-25 17:18:51)

# engine/live/trader.py
from __future__ import annotations
import math
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Optional, Sequence

@dataclass
class Position:
    symbol: str
    tf: str
    side: str = "flat"   # "long" | "flat"
    entry: float = 0.0
    size: float = 0.0
    trail: Optional[float] = None

class OrderLogger:
    def __init__(self, path: Path) -> None:
        self.path = path
        self.path.parent.mkdir(parents=True, exist_ok=True)
        if not self.path.exists():
            self._write(["ts","symbol","tf","action","price","size","reason"])

    def _write(self, row: Sequence[str | float | int]) -> None:
        with self.path.open("a", encoding="utf-8") as f:
            f.write(",".join(str(x).replace(",", " ") for x in row) + "\n")

    def log(self, **kw) -> None:
        self._write([kw.get("ts", int(time.time()*1000)), kw["symbol"], kw["tf"],
                     kw["action"], kw.get("price", 0.0), kw.get("size", 0.0),
                     kw.get("reason","")])

class Trader:
    """
    Gère un état de position très simple (one-way, long only) + logs, et passe
    aux ordres réels si paper_trade=False.
    """
    def __init__(self, *, paper_trade: bool, client: Any | None, order_logger: OrderLogger) -> None:
        self.paper = paper_trade
        self.client = client
        self.log = order_logger
        self.state: Dict[tuple[str,str], Position] = {}

    def _pos(self, symbol: str, tf: str) -> Position:
        key = (symbol, tf)
        if key not in self.state:
            self.state[key] = Position(symbol=symbol, tf=tf)
        return self.state[key]

    def _order_real_market(self, symbol: str, side: str, size: float) -> None:
        if not self.client:
            return
        try:
            self.client.place_market_order_one_way(symbol, side, size)
        except Exception:
            # on se contente de logguer; l'orchestrateur poursuit
            pass

    def compute_size(self, equity: float, price: float, atr: float, risk_pct: float) -> float:
        # risk par unité ~ ATR (garde-fou min)
        risk_per_unit = max(atr, price * 0.002)
        risk_cash = max(0.0, equity * risk_pct)
        units = risk_cash / risk_per_unit if risk_per_unit > 0 else 0.0
        return max(0.0, round(units, 6))

    def on_signal(self, *, symbol: str, tf: str, price: float, atr: float,
                  params: Dict[str, float], signal_now: int, signal_prev: int,
                  equity: float = 10_000.0, ts: int | None = None) -> None:
        ts = ts or int(time.time() * 1000)
        p = self._pos(symbol, tf)
        trail_mult = float(params.get("trail_atr_mult", 2.0))
        risk_pct = float(params.get("risk_pct_equity", 0.02))
        if p.side == "flat":
            if signal_prev <= 0 and signal_now > 0:
                size = self.compute_size(equity, price, atr, risk_pct)
                p.side = "long"; p.entry = price; p.size = size
                p.trail = price - trail_mult * atr if atr > 0 else None
                self.log.log(ts=ts, symbol=symbol, tf=tf, action="BUY", price=price, size=size, reason="ema_cross_up")
                if not self.paper and size > 0:
                    self._order_real_market(symbol, "buy", size)
        else:
            # update trailing stop
            new_trail = price - trail_mult * atr if atr > 0 else None
            if new_trail is not None and (p.trail is None or new_trail > p.trail):
                p.trail = new_trail
            # sortie par signal inverse ou par cassure du trail
            exit_by_signal = (signal_prev >= 0 and signal_now < 0)
            exit_by_trail = (p.trail is not None and price < p.trail)
            if exit_by_signal or exit_by_trail:
                self.log.log(ts=ts, symbol=symbol, tf=tf, action="SELL", price=price, size=p.size,
                             reason="ema_cross_down" if exit_by_signal else "trail_hit")
                if not self.paper and p.size > 0:
                    self._order_real_market(symbol, "sell", p.size)
                # flat
                self.state[(symbol, tf)] = Position(symbol=symbol, tf=tf)

# ===== engine/logging_utils.py ===== (167 lignes, modifié 2025-08-25 17:18:51)

"""Logging helpers for the Scalp bot."""

from __future__ import annotations

import atexit
import csv
import json
import os
import sqlite3
import time
from pathlib import Path
from typing import Any, Dict, List


def get_jsonl_logger(path: str, max_bytes: int = 0, backup_count: int = 0):
    """Return a callable that logs events as JSON lines.

    Parameters
    ----------
    path: str
        Target file path for JSON lines.
    max_bytes: int, optional
        If >0, rotate the file when its size exceeds this value.
    backup_count: int, optional
        Number of rotated files to keep when ``max_bytes`` is set.
    """
    os.makedirs(os.path.dirname(path), exist_ok=True)
    log_file = open(path, "a", encoding="utf-8")

    def _close_file() -> None:
        try:
            log_file.close()
        except Exception:
            pass

    atexit.register(_close_file)

    def _rotate() -> None:
        nonlocal log_file
        log_file.close()
        for i in range(backup_count - 1, 0, -1):
            src = f"{path}.{i}"
            dst = f"{path}.{i + 1}"
            if os.path.exists(src):
                os.replace(src, dst)
        os.replace(path, f"{path}.1")
        log_file = open(path, "a", encoding="utf-8")

    def _log(event: str, payload: Dict[str, Any]) -> None:
        nonlocal log_file
        payload = dict(payload or {})
        payload["event"] = event
        payload["ts"] = int(time.time() * 1000)
        line = json.dumps(payload, ensure_ascii=False)
        if max_bytes and backup_count > 0:
            if log_file.tell() + len(line) + 1 > max_bytes:
                _rotate()
        log_file.write(line + "\n")
        log_file.flush()

    return _log


class TradeLogger:
    """Helper writing trade information to CSV and SQLite files."""

    fields = [
        "pair",
        "tf",
        "dir",
        "entry",
        "sl",
        "tp",
        "score",
        "reasons",
        "pnl",
    ]

    def __init__(self, csv_path: str, sqlite_path: str) -> None:
        os.makedirs(os.path.dirname(csv_path), exist_ok=True)
        self.csv_path = csv_path
        self.sqlite_path = sqlite_path

        # Ensure CSV has header
        if not os.path.exists(csv_path):
            with open(csv_path, "w", newline="", encoding="utf-8") as f:
                writer = csv.DictWriter(f, fieldnames=self.fields)
                writer.writeheader()

        # Setup SQLite store
        self.conn = sqlite3.connect(sqlite_path)
        cur = self.conn.cursor()
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS trades (
                pair TEXT,
                tf TEXT,
                dir TEXT,
                entry REAL,
                sl REAL,
                tp REAL,
                score REAL,
                reasons TEXT,
                pnl REAL
            )
            """
        )
        self.conn.commit()
        atexit.register(self.conn.close)

    def log(self, data: Dict[str, Any]) -> None:
        row = {k: data.get(k) for k in self.fields}
        with open(self.csv_path, "a", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=self.fields)
            writer.writerow(row)
        cur = self.conn.cursor()
        cur.execute(
            "INSERT INTO trades (pair, tf, dir, entry, sl, tp, score, reasons, pnl) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)",
            (
                row["pair"],
                row["tf"],
                row["dir"],
                row["entry"],
                row["sl"],
                row["tp"],
                row["score"],
                row["reasons"],
                row["pnl"],
            ),
        )
        self.conn.commit()


BASE_DIR = Path(__file__).resolve().parents[2]


def _append_csv(path: Path, fields: List[str], row: Dict[str, Any]) -> None:
    """Append a row to ``path`` creating the file with ``fields`` if needed."""
    path.parent.mkdir(parents=True, exist_ok=True)
    file_exists = path.exists()
    with path.open("a", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=fields)
        if not file_exists:
            writer.writeheader()
        writer.writerow({k: row.get(k) for k in fields})


def log_position(data: Dict[str, Any]) -> None:
    """Log a closed position to ``../positions.csv``."""
    fields = [
        "timestamp",
        "pair",
        "direction",
        "entry",
        "exit",
        "pnl_pct",
        "fee_rate",
        "notes",
    ]
    _append_csv(BASE_DIR / "positions.csv", fields, data)


def log_operation_memo(data: Dict[str, Any]) -> None:
    """Log operation details to ``../operations_memo.csv``."""
    fields = ["timestamp", "pair", "details"]
    _append_csv(BASE_DIR / "operations_memo.csv", fields, data)

# ===== engine/metrics.py ===== (209 lignes, modifié 2025-08-25 17:18:51)

"""Utility metrics for trading calculations."""

from __future__ import annotations


from typing import Iterable

__all__ = ["calc_pnl_pct", "calc_rsi", "calc_atr", "calc_macd", "backtest_position"]


def calc_pnl_pct(
    entry_price: float, exit_price: float, side: int, fee_rate: float = 0.0
) -> float:
    """Return percentage PnL between entry and exit prices minus fees.


    Parameters
    ----------
    entry_price: float
        Trade entry price (>0).
    exit_price: float
        Trade exit price (>0).
    side: int
        +1 for long, -1 for short.
    fee_rate: float, optional
        Trading fee rate per operation (e.g., 0.0006 for 0.06%). The fee is
        applied twice (entry + exit).
    """
    if entry_price <= 0 or exit_price <= 0:
        raise ValueError("Prices must be positive")
    if side not in (1, -1):
        raise ValueError("side must be +1 (long) or -1 (short)")

    pnl = (exit_price - entry_price) / entry_price * 100.0 * side
    fee_pct = fee_rate * 2 * 100.0  # entrée + sortie
    return pnl - fee_pct


def calc_rsi(prices: Iterable[float], period: int = 14) -> float:
    """Compute the Relative Strength Index (RSI) using Wilder's smoothing.


    Parameters
    ----------
    prices:
        Ordered sequence of closing prices.
    period:
        Number of periods to use for the calculation. Must be positive and the
        length of ``prices`` must be at least ``period + 1``.
    """

    prices_list = [float(p) for p in prices]

    if period <= 0:
        raise ValueError("period must be positive")
    if len(prices_list) < period + 1:

        raise ValueError("len(prices) must be >= period + 1")

    gains: list[float] = []
    losses: list[float] = []
    for i in range(1, period + 1):

        diff = prices_list[i] - prices_list[i - 1]

        if diff >= 0:
            gains.append(diff)
            losses.append(0.0)
        else:
            gains.append(0.0)
            losses.append(-diff)

    avg_gain = sum(gains) / period
    avg_loss = sum(losses) / period

    for i in range(period + 1, len(prices_list)):
        diff = prices_list[i] - prices_list[i - 1]

        gain = max(diff, 0.0)
        loss = max(-diff, 0.0)
        avg_gain = (avg_gain * (period - 1) + gain) / period
        avg_loss = (avg_loss * (period - 1) + loss) / period

    if avg_gain == 0 and avg_loss == 0:
        return 50.0
    if avg_loss == 0:
        return 100.0
    if avg_gain == 0:
        return 0.0
    rs = avg_gain / avg_loss
    return 100.0 - (100.0 / (1.0 + rs))


def calc_atr(
    highs: Iterable[float],
    lows: Iterable[float],
    closes: Iterable[float],
    period: int = 14,
) -> float:
    """Compute the Average True Range (ATR) using Wilder's smoothing.


    Parameters
    ----------
    highs, lows, closes:
        Ordered sequences of high, low and close prices. All sequences must
        have the same length and contain at least ``period + 1`` elements.
    period:
        Number of periods to use for the calculation. Must be positive.
    """

    highs_list = [float(h) for h in highs]
    lows_list = [float(low) for low in lows]
    closes_list = [float(c) for c in closes]

    length = len(highs_list)
    if length != len(lows_list) or length != len(closes_list):

        raise ValueError("Input sequences must have the same length")
    if period <= 0:
        raise ValueError("period must be positive")
    if length < period + 1:
        raise ValueError("Input sequences must have at least period + 1 elements")

    trs: list[float] = []
    for i in range(1, len(highs_list)):
        tr = max(
            highs_list[i] - lows_list[i],
            abs(highs_list[i] - closes_list[i - 1]),
            abs(lows_list[i] - closes_list[i - 1]),
        )
        trs.append(tr)

    atr = sum(trs[:period]) / period
    for tr in trs[period:]:
        atr = (atr * (period - 1) + tr) / period
    return atr


def calc_macd(
    prices: Sequence[float],
    fast: int = 12,
    slow: int = 26,
    signal: int = 9,
) -> tuple[float, float, float]:
    """Return MACD, signal line and histogram values.

    The implementation computes exponential moving averages using Wilder's
    smoothing. ``prices`` must contain at least ``slow + signal`` elements.
    """

    prices_list = [float(p) for p in prices]
    if fast <= 0 or slow <= 0 or signal <= 0:
        raise ValueError("periods must be positive")
    min_len = max(fast, slow) + signal
    if len(prices_list) < min_len:
        raise ValueError("len(prices) must be >= slow + signal")

    def _ema_series(series: Sequence[float], window: int) -> list[float]:
        k = 2.0 / (window + 1.0)
        out = [float(series[0])]
        for x in series[1:]:
            out.append(float(x) * k + out[-1] * (1.0 - k))
        return out

    fast_ema = _ema_series(prices_list, fast)
    slow_ema = _ema_series(prices_list, slow)
    macd_series = [f - s for f, s in zip(fast_ema, slow_ema)]
    signal_series = _ema_series(macd_series, signal)
    macd_val = macd_series[-1]
    signal_val = signal_series[-1]
    hist = macd_val - signal_val
    return macd_val, signal_val, hist


def backtest_position(
    prices: list[float], entry_idx: int, exit_idx: int, side: int
) -> bool:
    """Run a basic backtest to verify a position's coherence.

    Parameters
    ----------
    prices: list[float]
        Sequential list of prices to evaluate.
    entry_idx: int
        Index in ``prices`` where the position is opened.
    exit_idx: int
        Index in ``prices`` where the position is closed (must be > ``entry_idx``).
    side: int
        +1 for long, -1 for short.

    Returns
    -------
    bool
        ``True`` if the resulting PnL is non-negative, meaning the position is
        coherent with the direction of price movement. ``False`` otherwise.
    """
    if side not in (1, -1):
        raise ValueError("side must be +1 (long) or -1 (short)")
    if not (0 <= entry_idx < exit_idx < len(prices)):
        raise ValueError(
            "entry_idx and exit_idx must be valid and entry_idx < exit_idx"
        )

    entry_price = float(prices[entry_idx])
    exit_price = float(prices[exit_idx])
    pnl = calc_pnl_pct(entry_price, exit_price, side)
    return pnl >= 0.0

# ===== engine/pairs.py ===== (277 lignes, modifié 2025-08-25 17:18:51)

"""Utilities to select trading pairs and detect signals."""
from __future__ import annotations
from typing import Any, Dict, List, Optional, Callable
from engine.strategy import Signal

from engine.bot_config import CONFIG
from engine.strategy import ema as default_ema, cross as default_cross
from engine.notifier import notify


def get_trade_pairs(client: Any) -> List[Dict[str, Any]]:
    """Return all trading pairs using the client's ``get_ticker`` method."""
    tick = client.get_ticker()
    data = tick.get("data") if isinstance(tick, dict) else []
    if not data:
        return []
    return data if isinstance(data, list) else [data]


def filter_trade_pairs(
    client: Any,
    *,
    volume_min: float = 5_000_000,
    max_spread_bps: float = 5.0,
    top_n: int = 40,
) -> List[Dict[str, Any]]:
    """Filter pairs by volume and spread."""
    pairs = get_trade_pairs(client)
    eligible: List[Dict[str, Any]] = []

    for info in pairs:
        sym = info.get("symbol")
        if not sym:
            continue
        try:
            vol = float(info.get("volume", 0))
        except (TypeError, ValueError):
            continue
        if vol < volume_min:
            continue
        try:
            bid = float(info.get("bidPrice", 0))
            ask = float(info.get("askPrice", 0))
        except (TypeError, ValueError):
            continue
        if bid <= 0 or ask <= 0:
            continue
        spread_bps = (ask - bid) / ((ask + bid) / 2) * 10_000
        if spread_bps >= max_spread_bps:
            continue
        eligible.append(info)

    eligible.sort(key=lambda row: float(row.get("volume", 0)), reverse=True)
    return eligible[:top_n]


def select_top_pairs(client: Any, top_n: int = 40, key: str = "volume") -> List[Dict[str, Any]]:
    """Return ``top_n`` pairs sorted by ``key``."""
    pairs = get_trade_pairs(client)

    def volume(row: Dict[str, Any]) -> float:
        try:
            return float(row.get(key, 0))
        except (TypeError, ValueError):
            return 0.0

    pairs.sort(key=volume, reverse=True)
    return pairs[:top_n]


def _ancienne_impl(
    client: Any,
    pairs: List[Dict[str, Any]],
    *,
    interval: str = "1m",
    ema_fast_n: Optional[int] = None,
    ema_slow_n: Optional[int] = None,
    ema_func=default_ema,
    cross_func=default_cross,
) -> List[Dict[str, Any]]:
    """Original implementation returning dicts."""
    ema_fast_n = ema_fast_n or CONFIG.get("EMA_FAST", 9)
    ema_slow_n = ema_slow_n or CONFIG.get("EMA_SLOW", 21)
    results: List[Dict[str, Any]] = []

    for info in pairs:
        symbol = info.get("symbol")
        if not symbol:
            continue
        k = client.get_kline(symbol, interval=interval)
        closes = k.get("data", {}).get("close", []) if isinstance(k, dict) else []
        if len(closes) < max(ema_fast_n, ema_slow_n) + 2:
            continue
        efull = ema_func(closes, ema_fast_n)
        eslow = ema_func(closes, ema_slow_n)
        signal = cross_func(efull[-1], eslow[-1], efull[-2], eslow[-2])
        if signal == 1:
            price_str = info.get("lastPr") or info.get("lastPrice") or 0.0
            results.append({"symbol": symbol, "signal": "long", "price": float(price_str)})
        elif signal == -1:
            price_str = info.get("lastPr") or info.get("lastPrice") or 0.0
            results.append({"symbol": symbol, "signal": "short", "price": float(price_str)})
    return results


def _to_signal(d: dict) -> Signal:
    side = 1 if d.get("signal") in ("long", "buy", 1, True) else -1
    return Signal(
        symbol=d.get("symbol"),
        side=side,
        entry=float(d.get("price", d.get("entry", 0))),
        sl=float(d.get("sl", 0)),
        tp1=float(d.get("tp1", 0)) or None,
        tp2=float(d.get("tp2", 0)) or None,
        score=d.get("score"),
        quality=d.get("quality"),
        reasons=d.get("reasons", []),
    )


def find_trade_positions(
    client: Any,
    pairs: List[Dict[str, Any]],
    *,
    interval: str = "1m",
    ema_fast_n: Optional[int] = None,
    ema_slow_n: Optional[int] = None,
    ema_func=default_ema,
    cross_func=default_cross,
) -> List[Signal]:
    raw = _ancienne_impl(
        client,
        pairs,
        interval=interval,
        ema_fast_n=ema_fast_n,
        ema_slow_n=ema_slow_n,
        ema_func=ema_func,
        cross_func=cross_func,
    )
    return [_to_signal(x) for x in raw]


def send_selected_pairs(
    client: Any,
    top_n: int = 40,
    *,
    select_fn: Callable[[Any, int], List[Dict[str, Any]]] = select_top_pairs,
    notify_fn: Callable[[str, Optional[Dict[str, Any]]], None] = notify,
) -> Dict[str, str]:
    """Fetch top pairs, drop USD/USDT/USDC duplicates and notify their list.

    Returns the payload sent to ``notify_fn``. The mapping contains the
    comma-separated symbols for each color group (``green``, ``orange`` and
    ``red``) or an empty dictionary when no pairs are available.
    """

    def split_symbol(sym: str) -> tuple[str, str]:
        if "_" in sym:
            left, right = sym.split("_", 1)
            # Legacy style: BTC_USDT
            if len(right) <= 4:
                return left, right
            # Bitget futures style: BTCUSDT_UMCBL
            main = left
            if main.endswith("USDT"):
                return main[:-4], "USDT"
            if main.endswith("USDC"):
                return main[:-4], "USDC"
            if main.endswith("USD"):
                return main[:-3], "USD"
            return main, ""
        if sym.endswith("USDT"):
            return sym[:-4], "USDT"
        if sym.endswith("USDC"):
            return sym[:-4], "USDC"
        if sym.endswith("USD"):
            return sym[:-3], "USD"
        return sym, ""

    pairs = select_fn(client, top_n=top_n * 3)
    allowed = {s.split("_")[0].upper() for s in CONFIG.get("ALLOWED_SYMBOLS", [])}
    by_base: Dict[str, Dict[str, Any]] = {}
    for info in pairs:
        sym = info.get("symbol")
        if not sym:
            continue
        norm_sym = sym.split("_")[0].upper()
        if allowed and norm_sym not in allowed:
            continue
        base, quote = split_symbol(sym)
        existing = by_base.get(base)
        priority = {"USDT": 3, "USDC": 2, "USD": 1}
        if existing is None or priority.get(quote, 0) > priority.get(existing["quote"], 0):
            by_base[base] = {"data": info, "quote": quote}

    unique = sorted(
        (v["data"] for v in by_base.values()),
        key=lambda row: float(row.get("volume", 0)),
        reverse=True,
    )
    symbols: list[str] = []
    for row in unique[:top_n]:
        sym = row.get("symbol")
        if not sym:
            continue
        base, _ = split_symbol(sym)
        symbols.append(base)
    if symbols:
        n = len(symbols)
        third = max(n // 3, 1)
        green = symbols[:third]
        orange = symbols[third : 2 * third]
        red = symbols[2 * third :]
        payload: Dict[str, str] = {}
        if green:
            payload["green"] = ", ".join(green)
        if orange:
            payload["orange"] = ", ".join(orange)
        if red:
            payload["red"] = ", ".join(red)
        notify_fn("pair_list", payload)
        return payload
    return {}


def heat_score(volatility: float, volume: float, news: bool = False) -> float:
    """Return a heat score combining volatility, volume and a news flag."""
    mult = 2.0 if news else 1.0
    return volatility * volume * mult


def select_top_heat_pairs(
    pairs: List[Dict[str, Any]], *, top_n: int = 3
) -> List[Dict[str, Any]]:
    """Return ``top_n`` pairs ranked by ``heat_score``."""

    scored: List[Dict[str, Any]] = []
    for info in pairs:
        try:
            vol = float(info.get("volatility", 0))
            volume = float(info.get("volume", 0))
        except (TypeError, ValueError):
            continue
        score = heat_score(vol, volume, bool(info.get("news")))
        row = dict(info)
        row["heat_score"] = score
        scored.append(row)

    scored.sort(key=lambda r: r["heat_score"], reverse=True)
    return scored[:top_n]


def decorrelate_pairs(
    pairs: List[Dict[str, Any]],
    corr: Dict[str, Dict[str, float]],
    *,
    threshold: float = 0.8,
    top_n: int = 3,
) -> List[Dict[str, Any]]:
    """Return top pairs while avoiding highly correlated symbols.

    ``corr`` is a mapping of pair symbol to correlation with other symbols.  Two
    pairs are considered too correlated when the absolute value of the
    correlation exceeds ``threshold``.
    """

    selected: List[Dict[str, Any]] = []
    for info in select_top_heat_pairs(pairs, top_n=len(pairs)):
        sym = info.get("symbol")
        if not sym:
            continue
        if all(abs(corr.get(sym, {}).get(p["symbol"], 0.0)) < threshold for p in selected):
            selected.append(info)
        if len(selected) >= top_n:
            break
    return selected

# ===== engine/pairs/__init__.py ===== (3 lignes, modifié 2025-08-25 17:18:51)

# engine/pairs/__init__.py
from .selector import PairMetrics, select_top_pairs  # re-export
__all__ = ["PairMetrics", "select_top_pairs"]

# ===== engine/pairs/selector.py ===== (94 lignes, modifié 2025-08-25 17:18:51)

# engine/pairs/selector.py
from __future__ import annotations
import math, statistics as stats, time
from dataclasses import dataclass
from typing import Any, Iterable, List, Dict, Tuple

@dataclass
class PairMetrics:
    symbol: str
    vol_usd_24h: float     # volume $ 24h (proxy)
    atr_pct_24h: float     # volatilité (ATR% sur close)
    score: float           # score combiné

def _ohlcv_to_atr_pct(rows: List[List[float]]) -> float:
    """rows: [ts,o,h,l,c,v]. Renvoie ATR% moyen ~ 24h (proxy simple)."""
    if not rows:
        return 0.0
    atr_vals: List[float] = []
    for i in range(1, len(rows)):
        o,h,l,c,_ = rows[i][1], rows[i][2], rows[i][3], rows[i][4], rows[i][5] if len(rows[i])>5 else 0.0
        pc = rows[i-1][4]
        tr = max(h-l, abs(h-pc), abs(l-pc))
        if c:
            atr_vals.append(tr / c)
    if not atr_vals:
        return 0.0
    return float(sum(atr_vals)/len(atr_vals))

def _norm(vals: List[float]) -> List[float]:
    if not vals: return []
    lo, hi = min(vals), max(vals)
    if hi <= 0 or hi == lo:
        return [0.0 for _ in vals]
    return [(v - lo)/(hi - lo) for v in vals]

def select_top_pairs(
    exchange: Any,
    *,
    universe: Iterable[str] | None = None,
    timeframe: str = "5m",
    lookback_candles: int = 300,   # ~ 24h en 5m
    top_n: int = 10,
    vol_weight: float = 0.6,
    volat_weight: float = 0.4,
) -> List[PairMetrics]:
    """
    Récupère OHLCV pour chaque symbole du 'universe' (sinon via tickers),
    calcule volume USD et ATR% 24h, puis score = 0.6*norm(volume) + 0.4*norm(volatilité).
    Retourne le Top N.
    """
    # 1) Construire l’univers
    symbols: List[str]
    if universe:
        symbols = list(dict.fromkeys([s.replace("_","").upper() for s in universe]))
    else:
        # essaie via exchange.get_ticker() (liste complète)
        try:
            data = exchange.get_ticker().get("data") or []
            symbols = [str(d.get("symbol","")).replace("_","").upper() for d in data if d.get("symbol")]
        except Exception:
            symbols = ["BTCUSDT","ETHUSDT","SOLUSDT","BNBUSDT","XRPUSDT","ADAUSDT","DOGEUSDT","LTCUSDT","LINKUSDT","MATICUSDT"]

    # 2) Collecte OHLCV + proxies volume
    metrics: List[Tuple[str, float, float]] = []  # (symbol, vol_usd, atr_pct)
    for sym in symbols:
        try:
            ohlcv = exchange.get_klines(sym, interval=timeframe, limit=lookback_candles).get("data") or []
            if len(ohlcv) < 50:
                continue
            atr_pct = _ohlcv_to_atr_pct(ohlcv)
            # proxy volume $ : somme(close*volume)
            vol_usd = 0.0
            for r in ohlcv[-288:]:  # ~ dernier jour
                close = float(r[4]); vol = float(r[5]) if len(r)>5 else 0.0
                vol_usd += close * vol
            metrics.append((sym, vol_usd, atr_pct))
        except Exception:
            continue

    if not metrics:
        return []

    vols = [m[1] for m in metrics]
    vols_norm = _norm(vols)
    atrs = [m[2] for m in metrics]
    atrs_norm = _norm(atrs)

    scored: List[PairMetrics] = []
    for (sym, vol_usd, atr_pct), nv, na in zip(metrics, vols_norm, atrs_norm):
        s = vol_weight*nv + volat_weight*na
        scored.append(PairMetrics(symbol=sym, vol_usd_24h=vol_usd, atr_pct_24h=atr_pct, score=s))

    scored.sort(key=lambda x: x.score, reverse=True)
    return scored[:top_n]

# ===== engine/positions/__init__.py ===== (0 lignes, modifié 2025-08-25 17:18:51)



# ===== engine/positions/state.py ===== (76 lignes, modifié 2025-08-25 17:18:51)

from __future__ import annotations
from dataclasses import dataclass, field
from enum import Enum, auto
from typing import List, Optional
import time

class PositionStatus(Enum):
    IDLE = auto()
    PENDING_ENTRY = auto()
    OPEN = auto()
    PENDING_EXIT = auto()
    CLOSED = auto()

class PositionSide(Enum):
    LONG = 1
    SHORT = -1

@dataclass
class Fill:
    order_id: str
    trade_id: str
    price: float
    qty: float
    fee: float
    ts: int

@dataclass
class PositionState:
    symbol: str
    side: PositionSide
    status: PositionStatus = PositionStatus.IDLE
    entry_order_id: Optional[str] = None
    exit_order_id: Optional[str] = None
    req_qty: float = 0.0
    filled_qty: float = 0.0
    avg_entry_price: float = 0.0
    avg_exit_price: float = 0.0
    sl: Optional[float] = None
    tp: Optional[float] = None
    realized_pnl: float = 0.0
    fees: float = 0.0
    opened_ts: Optional[int] = None
    closed_ts: Optional[int] = None
    fills: List[Fill] = field(default_factory=list)
    last_sync_ts: int = field(default_factory=lambda: int(time.time()*1000))

    def apply_fill_entry(self, f: Fill) -> None:
        self.fills.append(f)
        self.filled_qty += f.qty
        # moyenne pondérée
        notional = self.avg_entry_price * (self.filled_qty - f.qty) + f.price * f.qty
        self.avg_entry_price = notional / max(1e-12, self.filled_qty)
        self.fees += abs(f.fee)
        if self.opened_ts is None:
            self.opened_ts = f.ts
        if self.filled_qty > 1e-12:
            self.status = PositionStatus.OPEN

    def apply_fill_exit(self, f: Fill) -> None:
        self.fills.append(f)
        qty = min(self.filled_qty, f.qty)
        # realized pnl sur la quantité fermée
        if self.side == PositionSide.LONG:
            self.realized_pnl += (f.price - self.avg_entry_price) * qty
        else:
            self.realized_pnl += (self.avg_entry_price - f.price) * qty
        self.fees += abs(f.fee)
        self.filled_qty = max(0.0, self.filled_qty - qty)
        # moyenne de sortie indicative
        closed_q = (self.req_qty - self.filled_qty)
        self.avg_exit_price = ((self.avg_exit_price * (closed_q - qty)) + f.price * qty) / max(1e-12, closed_q)
        if self.filled_qty <= 1e-12:
            self.status = PositionStatus.CLOSED
            self.closed_ts = f.ts


# ===== engine/risk/__init__.py ===== (9 lignes, modifié 2025-08-25 17:18:51)

# scalp/risk/__init__.py
from .manager import (
    Caps,
    compute_size,
    calc_position_size,  # alias legacy
    RiskManager,         # shim legacy
)

__all__ = ["Caps", "compute_size", "calc_position_size", "RiskManager"]

# ===== engine/risk/manager.py ===== (70 lignes, modifié 2025-08-25 17:18:51)

# scalp/risk/manager.py
from __future__ import annotations
from dataclasses import dataclass
from typing import Optional, Dict, Any

@dataclass
class Caps:
    min_qty: float = 0.0
    min_notional: float = 0.0
    max_leverage: float = 20.0

def _get_caps(caps_by_symbol: Optional[Dict[str, Any]], symbol: str) -> Caps:
    if not caps_by_symbol:
        return Caps()
    c = caps_by_symbol.get(symbol, {})
    return Caps(
        min_qty=float(c.get("min_qty", 0.0) or 0.0),
        min_notional=float(c.get("min_notional", 0.0) or 0.0),
        max_leverage=float(c.get("max_leverage", 20.0) or 20.0),
    )

def compute_size(
    *,
    symbol: str,
    price: float,
    balance_cash: float,
    risk_pct: float = 0.5,
    caps_by_symbol: Optional[Dict[str, Any]] = None,
) -> float:
    """Sizing robuste avec gardes min_notional / min_qty."""
    price = max(1e-9, float(price))
    balance_cash = max(0.0, float(balance_cash))
    risk_pct = max(0.0, float(risk_pct))

    notionnel = balance_cash * risk_pct
    qty = notionnel / price

    caps = _get_caps(caps_by_symbol, symbol)
    if caps.min_notional > 0 and (qty * price) < caps.min_notional:
        qty = caps.min_notional / price
    if caps.min_qty > 0 and qty < caps.min_qty:
        qty = caps.min_qty
    return max(0.0, qty)

# --- Shims pour compatibilité ancienne API -----------------------------------

def calc_position_size(symbol: str, price: float, balance_cash: float,
                       risk_pct: float = 0.5,
                       caps_by_symbol: Optional[Dict[str, Any]] = None) -> float:
    """Alias legacy → compute_size."""
    return compute_size(
        symbol=symbol, price=price, balance_cash=balance_cash,
        risk_pct=risk_pct, caps_by_symbol=caps_by_symbol
    )

class RiskManager:
    """
    Shim minimal compatible avec l'ancien code:
      rm = RiskManager(risk_pct=0.5, caps_by_symbol={...})
      qty = rm.size(symbol, price, balance_cash)
    """
    def __init__(self, risk_pct: float = 0.5, caps_by_symbol: Optional[Dict[str, Any]] = None):
        self.risk_pct = float(risk_pct)
        self.caps_by_symbol = caps_by_symbol or {}

    def size(self, symbol: str, price: float, balance_cash: float) -> float:
        return compute_size(
            symbol=symbol, price=price, balance_cash=balance_cash,
            risk_pct=self.risk_pct, caps_by_symbol=self.caps_by_symbol
        )

# ===== engine/selection/__init__.py ===== (20 lignes, modifié 2025-08-25 17:18:51)

"""Pair selection helpers for the Scalp bot.

This package exposes two utilities used during the preparation phase of the
trading strategy:

``scan_pairs``
    Performs the first level market scan by filtering pairs based on volume,
    spread and hourly volatility.

``select_active_pairs``
    Refines a list of pairs by keeping only those showing an EMA20/EMA50
    crossover and a sufficiently high ATR.
"""

from .scanner import scan_pairs
from .momentum import select_active_pairs

__all__ = ["scan_pairs", "select_active_pairs"]


# ===== engine/selection/momentum.py ===== (99 lignes, modifié 2025-08-25 17:18:51)

"""Utilities to select pairs exhibiting strong momentum."""

from __future__ import annotations

from typing import Any, Dict, List, Sequence

from ..metrics import calc_atr


def ema(series: Sequence[float], window: int) -> List[float]:
    """Simple exponential moving average implementation."""

    if window <= 1 or not series:
        return list(series)
    k = 2.0 / (window + 1.0)
    out: List[float] = [float(series[0])]
    prev = out[0]
    for x in series[1:]:
        prev = float(x) * k + prev * (1.0 - k)
        out.append(prev)
    return out


def cross(last_fast: float, last_slow: float, prev_fast: float, prev_slow: float) -> int:
    """Return 1 if a bullish cross occurred, -1 for bearish, 0 otherwise."""

    if prev_fast <= prev_slow and last_fast > last_slow:
        return 1
    if prev_fast >= prev_slow and last_fast < last_slow:
        return -1
    return 0


def _quantile(values: Sequence[float], q: float) -> float:
    """Return the *q* quantile of *values* (0 <= q <= 1)."""

    if not values:
        return 0.0
    q = min(max(q, 0.0), 1.0)
    vals = sorted(values)
    idx = int((len(vals) - 1) * q)
    return vals[idx]


def select_active_pairs(
    client: Any,
    pairs: Sequence[Dict[str, Any]],
    *,
    interval: str = "Min5",
    ema_fast: int = 20,
    ema_slow: int = 50,
    atr_period: int = 14,
    atr_quantile: float = 0.5,
    top_n: int = 5,
) -> List[Dict[str, Any]]:
    """Return pairs with an EMA crossover and high ATR.

    Only pairs where ``EMA20`` crosses ``EMA50`` on the latest candle are kept.
    Among those candidates, the Average True Range is computed and only pairs
    whose ATR is above the provided quantile are returned.  The resulting
    dictionaries include an ``atr`` key for convenience.
    """

    candidates: List[Dict[str, Any]] = []
    atrs: List[float] = []

    for info in pairs:
        sym = info.get("symbol")
        if not sym:
            continue
        k = client.get_kline(sym, interval=interval)
        kdata = k.get("data") if isinstance(k, dict) else {}
        closes = kdata.get("close", [])
        highs = kdata.get("high", [])
        lows = kdata.get("low", [])
        if len(closes) < max(ema_slow, atr_period) + 2:
            continue
        efast = ema(closes, ema_fast)
        eslow = ema(closes, ema_slow)
        if cross(efast[-1], eslow[-1], efast[-2], eslow[-2]) == 0:
            continue
        atr_val = calc_atr(highs, lows, closes, atr_period)
        row = dict(info)
        row["atr"] = atr_val
        candidates.append(row)
        atrs.append(atr_val)

    if not candidates:
        return []

    threshold = _quantile(atrs, atr_quantile)
    selected = [row for row in candidates if row["atr"] >= threshold]
    selected.sort(key=lambda r: r["atr"], reverse=True)
    return selected[:top_n]


__all__ = ["select_active_pairs"]


# ===== engine/selection/scanner.py ===== (82 lignes, modifié 2025-08-25 17:18:51)

"""Utilities for scanning tradable pairs on the exchange."""

from __future__ import annotations

from typing import Any, Dict, List


def scan_pairs(
    client: Any,
    *,
    volume_min: float = 5_000_000,
    max_spread_bps: float = 5.0,
    min_hourly_vol: float = 0.0,
    top_n: int = 40,
) -> List[Dict[str, Any]]:
    """Return pairs satisfying basic liquidity and volatility filters.

    Parameters
    ----------
    client: Any
        Client instance exposing ``get_ticker`` and ``get_kline`` methods.
    volume_min: float, optional
        Minimum 24h volume required to keep a pair.
    max_spread_bps: float, optional
        Maximum allowed bid/ask spread expressed in basis points.
    min_hourly_vol: float, optional
        Minimum volatility over the last hour expressed as ``(high - low) /
        close``.  When set to ``0`` the filter is disabled.
    top_n: int, optional
        Limit the number of returned pairs.
    """

    tick = client.get_ticker()
    data = tick.get("data") if isinstance(tick, dict) else []
    if not isinstance(data, list):
        data = [data]

    eligible: List[Dict[str, Any]] = []

    for row in data:
        sym = row.get("symbol")
        if not sym:
            continue
        try:
            vol = float(row.get("volume", 0))
            bid = float(row.get("bidPrice", 0))
            ask = float(row.get("askPrice", 0))
        except (TypeError, ValueError):
            continue
        if vol < volume_min or bid <= 0 or ask <= 0:
            continue
        spread_bps = (ask - bid) / ((ask + bid) / 2.0) * 10_000
        if spread_bps >= max_spread_bps:
            continue

        if min_hourly_vol > 0:
            k = client.get_kline(sym, interval="Min60")
            kdata = k.get("data") if isinstance(k, dict) else {}
            highs = kdata.get("high", [])
            lows = kdata.get("low", [])
            closes = kdata.get("close", [])
            if not highs or not lows or not closes:
                continue
            try:
                h = float(highs[-1])
                l = float(lows[-1])
                c = float(closes[-1])
            except (TypeError, ValueError):
                continue
            hourly_vol = (h - l) / c if c else 0.0
            if hourly_vol < min_hourly_vol:
                continue

        eligible.append(row)

    eligible.sort(key=lambda r: float(r.get("volume", 0)), reverse=True)
    return eligible[:top_n]


__all__ = ["scan_pairs"]


# ===== engine/selfcheck.py ===== (117 lignes, modifié 2025-08-25 17:18:51)

# scalper/selfcheck.py
from __future__ import annotations
import os, sys, importlib, traceback
from pathlib import Path

NOTEBOOKS = Path("/notebooks")
REPO = (NOTEBOOKS / "scalp") if NOTEBOOKS.exists() else Path(__file__).resolve().parents[2]

def _mask(val: str) -> str:
    if not val: return ""
    return (val[:3] + "…" + val[-3:]) if len(val) > 6 else "********"

def _try_import(modname: str):
    try:
        m = importlib.import_module(modname)
        return True, m
    except Exception:
        return False, traceback.format_exc()

def preflight(verbose: bool = False) -> list[str]:
    """
    Retourne la liste des 'issues' trouvées (vide si tout est OK).
    Ne lève pas d'exception. N'écrit que de l'info lisible.
    """
    issues: list[str] = []
    # s'assurer que le repo est bien dans sys.path
    if str(REPO) not in sys.path:
        sys.path.insert(0, str(REPO))

    print("=== SCALPER PREFLIGHT ===")
    print(f"[i] Repo: {REPO}")
    print(f"[i] Python: {sys.version.split()[0]}")

    # backtest API
    ok, mod = _try_import("engine.backtest")
    if not ok:
        print("[✗] Import engine.backtest KO")
        if verbose: print(mod)  # ici 'mod' contient la trace
        issues.append("backtest import")
    else:
        has_single = hasattr(mod, "run_single")
        has_multi  = hasattr(mod, "run_multi")
        print(f"[✓] engine.backtest: run_single={has_single} run_multi={has_multi}")
        if not (has_single and has_multi):
            issues.append("backtest API incomplète")

    # trade_utils
    ok, mod = _try_import("engine.trade_utils")
    if not ok:
        print("[✗] Import engine.trade_utils KO")
        if verbose: print(mod)
        issues.append("trade_utils import")
    else:
        print(f"[✓] engine.trade_utils: compute_position_size={'compute_position_size' in dir(mod)}")

    # fees
    ok, mod = _try_import("engine.exchange.fees")
    if not ok:
        print("[✗] Import engine.exchange.fees KO")
        if verbose: print(mod)
        issues.append("fees import")
    else:
        need = {"get_fee", "load_bitget_fees"}
        miss = [n for n in need if not hasattr(mod, n)]
        if miss: issues.append("fees API manquante: " + ",".join(miss))
        print("[✓] engine.exchange.fees OK")

    # notify/commands/backtest_telegram/orchestrator
    for name, required in [
        ("engine.live.notify", ("build_notifier_and_stream",)),
        ("engine.live.commands", ("CommandHandler",)),
        ("engine.live.backtest_telegram", ("handle_backtest_command",)),
        ("engine.live.orchestrator", ("run_orchestrator", "Orchestrator")),
    ]:
        ok, mod = _try_import(name)
        if not ok:
            print(f"[✗] Import {name} KO")
            if verbose: print(mod)
            issues.append(f"{name} import")
        else:
            miss = [a for a in required if not hasattr(mod, a)]
            if miss: issues.append(f"{name} API manquante: {','.join(miss)}")
            print(f"[✓] {name} OK")

    # ENV (masqué)
    tg_t = os.getenv("TELEGRAM_BOT_TOKEN", "")
    tg_c = os.getenv("TELEGRAM_CHAT_ID", "")
    gu   = os.getenv("GIT_USER", "")
    gt   = os.getenv("GIT_TOKEN", "")
    print("\n-- ENV --")
    print(f"  TELEGRAM_BOT_TOKEN: {_mask(tg_t)} {'(ABSENT)' if not tg_t else ''}")
    print(f"  TELEGRAM_CHAT_ID  : {_mask(tg_c)} {'(ABSENT)' if not tg_c else ''}")
    print(f"  GIT_USER          : {gu or '(ABSENT)'}")
    print(f"  GIT_TOKEN         : {_mask(gt)} {'(ABSENT)' if not gt else ''}")

    # Data
    data_dir = (REPO / "data")
    print("\n-- DATA --")
    if data_dir.exists():
        csvs = list(data_dir.glob("*.csv"))
        print(f"  {len(csvs)} CSV trouvé(s) dans data/ (OK si tu backtestes via CSV)")
    else:
        print("  data/ absent (OK si loader API)")

    return issues

def preflight_or_die(verbose: bool = False) -> None:
    issues = preflight(verbose=verbose)
    if issues:
        print("\n[✗] Préflight a détecté des problèmes :")
        for it in issues: print("   -", it)
        print("\nConseils :")
        print(" - Vérifie les fichiers remplacés (backtest/__init__.py, trade_utils.py, exchange/fees.py).")
        print(" - Évite d'importer optimize/walkforward dans backtest/__init__.py.")
        print(" - Charge /notebooks/.env si TELEGRAM/GIT sont absents (source /notebooks/.env).")
        raise SystemExit(1)
    print("\n[✓] Préflight OK — démarrage du bot.")

# ===== engine/services/__init__.py ===== (0 lignes, modifié 2025-08-25 17:18:51)



# ===== engine/services/data_cache.py ===== (186 lignes, modifié 2025-08-25 17:18:51)

# scalper/services/data_cache.py
from __future__ import annotations

import asyncio
import csv
import os
import time
from typing import Iterable, List, Optional, Tuple, Dict

# ---------------------------------------------------------------------
# Réglages via env (valeurs sûres par défaut)
# ---------------------------------------------------------------------
DATA_DIR = os.getenv("DATA_DIR", "/notebooks/data")           # dossier PERSISTANT (hors-git)
CSV_MAX_AGE = int(os.getenv("CSV_MAX_AGE_SECONDS", "0"))      # 0 = auto (en fonction du TF)
CSV_MIN_ROWS = int(os.getenv("CSV_MIN_ROWS", "200"))          # minimum de lignes attendues
STALE_FACTOR = float(os.getenv("CSV_STALE_FACTOR", "6"))      # âge max = STALE_FACTOR * tf_sec
PREFETCH_CONC = int(os.getenv("CSV_PREFETCH_CONC", "4"))      # concurrence préchauffage

os.makedirs(DATA_DIR, exist_ok=True)


# ---------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------
def parse_timeframe_to_seconds(tf: str) -> int:
    tf = tf.strip().lower()
    unit = tf[-1]
    try:
        n = int(tf[:-1])
    except Exception as e:
        raise ValueError(f"timeframe invalide: {tf}") from e
    if unit == "m":
        return n * 60
    if unit == "h":
        return n * 3600
    if unit == "d":
        return n * 86400
    raise ValueError(f"timeframe invalide: {tf}")


def csv_path(symbol: str, timeframe: str) -> str:
    return os.path.join(DATA_DIR, f"{symbol}-{timeframe}.csv")


def read_csv_ohlcv(path: str) -> List[Tuple[int, float, float, float, float, float]]:
    rows: List[Tuple[int, float, float, float, float, float]] = []
    if not os.path.exists(path):
        return rows
    with open(path, "r", newline="") as f:
        r = csv.reader(f)
        header = next(r, None)  # accepte avec ou sans header
        for line in r:
            if not line:
                continue
            ts, o, h, l, c, v = line[:6]
            rows.append((int(ts), float(o), float(h), float(l), float(c), float(v)))
    return rows


def write_csv_ohlcv(path: str, data: Iterable[Tuple[int, float, float, float, float, float]]) -> None:
    first = not os.path.exists(path)
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "a", newline="") as f:
        w = csv.writer(f)
        if first:
            w.writerow(["timestamp", "open", "high", "low", "close", "volume"])
        for row in data:
            w.writerow(row)


def last_ts(rows: List[Tuple[int, float, float, float, float, float]]) -> Optional[int]:
    return rows[-1][0] if rows else None


# ---------------------------------------------------------------------
# Fetch CCXT paginé
# ---------------------------------------------------------------------
async def ccxt_fetch_ohlcv_all(
    exchange,
    symbol: str,
    timeframe: str,
    since_ms: Optional[int],
    limit: int = 1000,
) -> List[Tuple[int, float, float, float, float, float]]:
    """
    Récupère OHLCV par pages (limit 1000) depuis since_ms jusqu'à ~now.
    Retourne une liste triée/dédupliquée.
    """
    out: List[Tuple[int, float, float, float, float, float]] = []
    tf_ms = parse_timeframe_to_seconds(timeframe) * 1000
    now_ms = exchange.milliseconds() if hasattr(exchange, "milliseconds") else int(time.time() * 1000)

    cursor = since_ms or (now_ms - 200 * tf_ms)
    while True:
        batch = await exchange.fetch_ohlcv(symbol, timeframe=timeframe, since=cursor, limit=limit)
        if not batch:
            break
        for ts, o, h, l, c, v in batch:
            out.append((int(ts), float(o), float(h), float(l), float(c), float(v)))
        next_cursor = batch[-1][0] + tf_ms
        if next_cursor <= cursor:
            break
        cursor = next_cursor
        if cursor >= now_ms + (2 * tf_ms):
            break
        await asyncio.sleep(getattr(exchange, "rateLimit", 200) / 1000)

    out.sort(key=lambda x: x[0])
    dedup: List[Tuple[int, float, float, float, float, float]] = []
    seen = set()
    for row in out:
        if row[0] in seen:
            continue
        seen.add(row[0])
        dedup.append(row)
    return dedup


# ---------------------------------------------------------------------
# Cache manager
# ---------------------------------------------------------------------
async def ensure_symbol_csv_cache(
    exchange,
    symbol: str,
    timeframe: str,
    min_rows: int = CSV_MIN_ROWS,
) -> str:
    """
    Garantit qu'un CSV OHLCV récent existe pour (symbol, timeframe).
    Crée/append si nécessaire. Retourne le chemin.
    """
    path = csv_path(symbol, timeframe)
    rows = read_csv_ohlcv(path)
    tf_sec = parse_timeframe_to_seconds(timeframe)
    tf_ms = tf_sec * 1000
    now_ms = int(time.time() * 1000)

    # âge max
    max_age = CSV_MAX_AGE if CSV_MAX_AGE > 0 else int(tf_sec * STALE_FACTOR)

    need_full = False
    need_append = False

    if not rows:
        need_full = True
    else:
        last = last_ts(rows) or 0
        age_sec = max(0, (now_ms - last) // 1000)
        if age_sec > max_age or len(rows) < min_rows:
            need_append = True

    if need_full:
        since = now_ms - (tf_ms * 2000)  # ~2000 bougies
        fresh = await ccxt_fetch_ohlcv_all(exchange, symbol, timeframe, since_ms=since)
        if len(fresh) < min_rows:
            since = now_ms - (tf_ms * 5000)
            fresh = await ccxt_fetch_ohlcv_all(exchange, symbol, timeframe, since_ms=since)
        if os.path.exists(path):
            os.remove(path)
        write_csv_ohlcv(path, fresh)
        return path

    if need_append:
        since = (last_ts(rows) or now_ms - (tf_ms * 2000)) + tf_ms
        fresh = await ccxt_fetch_ohlcv_all(exchange, symbol, timeframe, since_ms=since)
        if fresh:
            write_csv_ohlcv(path, fresh)

    return path


async def prewarm_csv_cache(exchange, symbols: Iterable[str], timeframe: str) -> Dict[str, str]:
    """
    Prépare le cache pour plusieurs symboles (concurrence limitée).
    Retourne {symbol: path}.
    """
    sem = asyncio.Semaphore(PREFETCH_CONC)
    result: Dict[str, str] = {}

    async def _one(sym: str):
        async with sem:
            p = await ensure_symbol_csv_cache(exchange, sym, timeframe)
            result[sym] = p

    await asyncio.gather(*[_one(s) for s in symbols])
    return result

# ===== engine/services/order_service.py ===== (95 lignes, modifié 2025-08-25 17:18:51)

from __future__ import annotations
from dataclasses import dataclass
from typing import Any, Dict, Optional, Protocol
from engine.trade_utils import extract_available_balance


@dataclass
class OrderCaps:
    min_trade_usdt: float = 5.0
    leverage: float = 1.0


@dataclass
class OrderRequest:
    symbol: str
    side: str
    price: float
    sl: float
    tp: Optional[float]
    risk_pct: float


@dataclass
class OrderResult:
    accepted: bool
    reason: str = ""
    payload: Dict[str, Any] = None
    order_id: Optional[str] = None
    status: Optional[str] = None
    avg_price: Optional[float] = None
    filled_qty: Optional[float] = None


class Exchange(Protocol):
    def get_assets(self) -> Dict[str, Any]: ...
    def get_ticker(self, symbol: Optional[str] = None) -> Dict[str, Any]: ...
    def place_order(
        self,
        symbol: str,
        side: str,
        quantity: float,
        order_type: str,
        price: Optional[float] = None,
        stop_loss: Optional[float] = None,
        take_profit: Optional[float] = None,
    ) -> Dict[str, Any]: ...


class OrderService:
    def __init__(self, exchange: Exchange, caps: OrderCaps = OrderCaps()):
        self.exchange = exchange
        self.caps = caps

    @staticmethod
    def _abs(x: float) -> float:
        return -x if x < 0 else x

    def _calc_qty(self, equity_usdt: float, price: float, sl: float, risk_pct: float) -> float:
        dist = self._abs(price - sl)
        if dist <= 0:
            return 0.0
        risk_usdt = max(0.0, equity_usdt * risk_pct)
        return 0.0 if price <= 0 else (risk_usdt / dist)

    def prepare_and_place(self, equity_usdt: float, req: OrderRequest) -> OrderResult:
        qty = self._calc_qty(equity_usdt, req.price, req.sl, req.risk_pct)
        if qty <= 0:
            return OrderResult(False, "invalid_size")
        notional = qty * req.price
        if notional < self.caps.min_trade_usdt:
            return OrderResult(False, "under_min_notional")
        assets = self.exchange.get_assets()
        available = extract_available_balance(assets)
        required_margin = notional / max(1.0, self.caps.leverage)
        if available < required_margin:
            return OrderResult(False, "insufficient_margin")
        side = "BUY" if req.side == "long" else "SELL"
        out = self.exchange.place_order(
            symbol=req.symbol, side=side, quantity=qty,
            order_type="limit", price=req.price,
            stop_loss=req.sl, take_profit=req.tp
        )
        # extraire infos utiles
        oid = None; status = None; avg = None; filled = None
        try:
            data = out.get("data") if isinstance(out, dict) else out
            if isinstance(data, dict):
                oid = str(data.get("orderId") or data.get("ordId") or data.get("id") or "")
                status = (data.get("status") or data.get("state") or "new").lower()
                avg = float(data.get("avgPrice", data.get("avgPx", 0)) or 0)
                filled = float(data.get("filledQty", data.get("fillSz", 0)) or 0)
        except Exception:
            pass
        return OrderResult(True, "", out, oid, status, avg, filled)

# ===== engine/services/utils.py ===== (43 lignes, modifié 2025-08-25 17:18:51)

# scalper/services/utils.py
from __future__ import annotations
import asyncio
from typing import Callable, Any


class NullNotifier:
    async def send(self, _msg: str) -> None:
        return


async def heartbeat_task(running_getter: Callable[[], bool], notifier: Any, period: float = 30.0) -> None:
    if notifier is None:
        notifier = NullNotifier()
    try:
        while running_getter():
            await notifier.send("heartbeat alive")
            await asyncio.sleep(period)
    except asyncio.CancelledError:
        pass


async def log_stats_task(
    notifier: Any,
    ticks_getter: Callable[[], int],
    symbols_getter: Callable[[], list[str]],
    period: float = 30.0,
) -> None:
    if notifier is None:
        notifier = NullNotifier()
    last = 0
    try:
        while True:
            total = int(ticks_getter() or 0)
            delta = total - last
            last = total
            syms = symbols_getter() or []
            msg = f"[stats] ticks_total={total} (+{delta} /30s) | pairs=" + ",".join(syms)
            print(msg)
            await notifier.send(msg)
            await asyncio.sleep(period)
    except asyncio.CancelledError:
        pass

# ===== engine/signals/__init__.py ===== (1 lignes, modifié 2025-08-25 17:18:51)

__all__ = ["factory"]

# ===== engine/signals/current.py ===== (12 lignes, modifié 2025-08-25 17:18:51)

# scalper/signals/current.py
from __future__ import annotations

# Wrapper pour utiliser la stratégie live actuelle en mode "plugin"
from engine.strategy import generate_signal as _generate_signal

def generate_signal(**kwargs):
    """
    Expose la même signature que engine.strategy.generate_signal.
    Sert d’adaptateur pour la factory.
    """
    return _generate_signal(**kwargs)

# ===== engine/signals/factory.py ===== (72 lignes, modifié 2025-08-25 17:18:51)

# scalper/signals/factory.py
from __future__ import annotations
from typing import Callable, Dict, Any
import importlib
import os
import json

try:
    import yaml  # type: ignore
except Exception:
    yaml = None  # type: ignore

SignalFn = Callable[..., Any]

# IMPORTANT : on pointe par défaut sur TA stratégie actuelle dans scalper/strategy.py
_REGISTRY: Dict[str, str] = {
    "current": "engine.strategy:generate_signal",
    # Tu pourras ajouter d'autres stratégies ici, par ex :
    # "ema_cross": "engine.strategies.ema_cross:generate_signal",
}

def _load_callable(path: str) -> SignalFn:
    if ":" not in path:
        raise ValueError(f"Chemin callable invalide: {path}")
    module_name, attr = path.split(":", 1)
    mod = importlib.import_module(module_name)
    fn = getattr(mod, attr, None)
    if not callable(fn):
        raise ValueError(f"{attr} n'est pas callable dans {module_name}")
    return fn  # type: ignore

def load_signal(name: str) -> SignalFn:
    key = (name or "").strip().lower()
    if key not in _REGISTRY:
        raise KeyError(f"Stratégie inconnue: '{name}'. Registre: {list(_REGISTRY)}")
    return _load_callable(_REGISTRY[key])

def _read_yaml(path: str) -> dict:
    if yaml is None:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f) or {}

def load_strategies_cfg(path: str | None) -> dict:
    """
    Charge le mapping (symbole, timeframe) -> nom de stratégie.
    Si le fichier n'existe pas, retourne une config par défaut fonctionnelle.
    """
    default_cfg = {"default": "current", "by_timeframe": {}, "by_symbol": {}}
    if not path:
        return default_cfg
    if not os.path.isfile(path):
        # Pas de fichier ? On continue avec les valeurs par défaut.
        return default_cfg
    cfg = _read_yaml(path)
    cfg.setdefault("default", "current")
    cfg.setdefault("by_timeframe", {})
    cfg.setdefault("by_symbol", {})
    return cfg

def resolve_strategy_name(symbol: str, timeframe: str, cfg: dict) -> str:
    symbol = (symbol or "").upper()
    timeframe = (timeframe or "").lower()
    return (
        cfg.get("by_symbol", {}).get(symbol, {}).get(timeframe)
        or cfg.get("by_timeframe", {}).get(timeframe)
        or cfg.get("default", "current")
    )

def resolve_signal_fn(symbol: str, timeframe: str, cfg: dict) -> SignalFn:
    return load_signal(resolve_strategy_name(symbol, timeframe, cfg))

# ===== engine/signals/generator.py ===== (166 lignes, modifié 2025-08-25 17:18:51)

from __future__ import annotations

from typing import Any, Dict, List, Optional

import pandas as pd

from data.indicators import compute_all

__all__ = ["generate_signal"]


def _quality_from_score(score: float) -> str:
    if score >= 0.8:
        return "A"
    if score >= 0.5:
        return "B"
    return "C"


def generate_signal(
    df: pd.DataFrame,
    *,
    trend_tf: Optional[pd.DataFrame] = None,
    confirm_tf: Optional[pd.DataFrame] = None,
    atr_mult: float = 1.0,
    trailing: bool = False,
    **_: Any,
) -> Optional[Dict[str, Any]]:
    """Generate a trading signal with confluence scoring.

    Parameters
    ----------
    df: pd.DataFrame
        Primary timeframe OHLCV data.
    trend_tf: pd.DataFrame, optional
        Higher timeframe used for trend filtering.
    confirm_tf: pd.DataFrame, optional
        Lower timeframe used for confirmation.
    atr_mult: float, optional
        Multiplier applied to ATR for stop/target calculation.
    trailing: bool, optional
        When ``True`` include a ``trail`` distance (ATR * ``atr_mult``).

    Returns
    -------
    dict | None
        Dictionary describing the signal or ``None`` if no trade setup exists.
    """

    if df is None or len(df) < 2:
        return None

    df = compute_all(df)
    last = df.iloc[-1]

    conditions: List[bool] = []
    reasons: List[str] = []
    direction: Optional[str] = None

    # --- Basic trend via EMAs ----------------------------------------------
    if last["close"] > last["ema20"] > last["ema50"]:
        direction = "long"
        reasons.append("price_above_ema")
        conditions.append(True)
    elif last["close"] < last["ema20"] < last["ema50"]:
        direction = "short"
        reasons.append("price_below_ema")
        conditions.append(True)
    else:
        conditions.append(False)
        return None

    # --- RSI ---------------------------------------------------------------
    if direction == "long":
        cond = last["rsi"] > 55
        if cond:
            reasons.append("rsi_bullish")
        conditions.append(cond)
    else:
        cond = last["rsi"] < 45
        if cond:
            reasons.append("rsi_bearish")
        conditions.append(cond)

    # --- MACD --------------------------------------------------------------
    if direction == "long":
        cond = last["macd"] > last["macd_signal"]
        if cond:
            reasons.append("macd_bullish")
        conditions.append(cond)
    else:
        cond = last["macd"] < last["macd_signal"]
        if cond:
            reasons.append("macd_bearish")
        conditions.append(cond)

    # --- OBV momentum ------------------------------------------------------
    if len(df) >= 2:
        obv_up = df["obv"].iloc[-1] > df["obv"].iloc[-2]
        if obv_up:
            reasons.append("obv_trending")
        conditions.append(obv_up)

    # --- Trend timeframe filter -------------------------------------------
    if trend_tf is not None and len(trend_tf) >= 2:
        tdf = compute_all(trend_tf)
        ema50 = tdf["ema50"]
        slope = ema50.iloc[-1] - ema50.iloc[-2]
        if direction == "long":
            cond = slope > 0
            if cond:
                reasons.append("trend_up")
            conditions.append(cond)
        else:
            cond = slope < 0
            if cond:
                reasons.append("trend_down")
            conditions.append(cond)

    # --- Confirmation timeframe filter ------------------------------------
    if confirm_tf is not None and len(confirm_tf) > 0:
        cdf = compute_all(confirm_tf)
        rsi = cdf["rsi"].iloc[-1]
        if direction == "long":
            cond = rsi > 50
            if cond:
                reasons.append("confirm_rsi_bullish")
            conditions.append(cond)
        else:
            cond = rsi < 50
            if cond:
                reasons.append("confirm_rsi_bearish")
            conditions.append(cond)

    score = (
        sum(1 for c in conditions if c) / len(conditions) if conditions else 0.0
    )
    quality = _quality_from_score(score)

    atr = last.get("atr")
    if pd.isna(atr) or atr == 0:
        return None

    entry = float(last["close"])
    if direction == "long":
        sl = entry - atr * atr_mult
        tp = entry + atr * atr_mult * 2
    else:
        sl = entry + atr * atr_mult
        tp = entry - atr * atr_mult * 2

    result: Dict[str, Any] = {
        "direction": direction,
        "entry": entry,
        "sl": sl,
        "tp": tp,
        "score": round(score, 3),
        "reasons": reasons,
        "quality": quality,
    }

    if trailing:
        result["trail"] = atr * atr_mult

    return result

# ===== engine/strategy.py ===== (444 lignes, modifié 2025-08-25 17:18:51)

"""Core trading strategy components for scalping EMA/VWAP/RSI/ATR.

This module implements a minimal but functional version of the strategy
outlined in the project specification.  The focus is on pure Python
implementations so the logic can easily be unit tested without requiring
external services or heavy third‑party dependencies.

The strategy is deliberately stateless; functions operate on passed data and
return simple data structures.  This makes it easy to plug the logic into
real‑time trading loops or backtest engines.
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Sequence, List, Dict, Optional, Tuple, Any

from .metrics import calc_rsi, calc_atr, calc_pnl_pct, calc_macd
from .risk import calc_position_size

# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

def ema(series: Sequence[float], window: int) -> List[float]:
    """Return the exponential moving average of *series*.

    The first value is the raw input to remain consistent with most trading
    platforms.  ``window`` must be positive; when it equals ``1`` the input is
    returned unchanged.
    """

    if window <= 1 or not series:
        return list(series)
    k = 2.0 / (window + 1.0)
    out: List[float] = [float(series[0])]
    prev = out[0]
    for x in series[1:]:
        prev = float(x) * k + prev * (1.0 - k)
        out.append(prev)
    return out

def vwap(highs: Sequence[float], lows: Sequence[float],
         closes: Sequence[float], volumes: Sequence[float]) -> float:
    """Compute the volume weighted average price (VWAP).

    Parameters
    ----------
    highs, lows, closes, volumes: Sequence[float]
        Matching sequences for the period considered.
    """

    tp_vol = 0.0
    vol_sum = 0.0
    for h, low, c, v in zip(highs, lows, closes, volumes):
        tp = (h + low + c) / 3.0
        tp_vol += tp * v
        vol_sum += v
    return tp_vol / vol_sum if vol_sum else 0.0

def obv(closes: Sequence[float], volumes: Sequence[float]) -> List[float]:
    """Return the On Balance Volume (OBV) series."""

    if not closes:
        return []
    out: List[float] = [0.0]
    for i in range(1, len(closes)):
        if closes[i] > closes[i - 1]:
            out.append(out[-1] + volumes[i])
        elif closes[i] < closes[i - 1]:
            out.append(out[-1] - volumes[i])
        else:
            out.append(out[-1])
    return out


def cross(last_fast: float, last_slow: float, prev_fast: float, prev_slow: float) -> int:
    """Detect a crossing between two series.

    Returns ``1`` for a bullish crossover, ``-1`` for a bearish crossover and
    ``0`` otherwise.
    """

    if prev_fast <= prev_slow and last_fast > last_slow:
        return 1
    if prev_fast >= prev_slow and last_fast < last_slow:
        return -1
    return 0


def order_book_imbalance(bid_vol: float, ask_vol: float) -> float:
    """Compute order book imbalance.

    The value is normalised between ``-1`` and ``1`` where positive numbers
    indicate bid dominance.  ``0`` is returned when both volumes are zero.
    """

    total = bid_vol + ask_vol
    return (bid_vol - ask_vol) / total if total else 0.0


def swing_levels(
    highs: Sequence[float], lows: Sequence[float], lookback: int
) -> Tuple[float, float]:
    """Return the most recent swing high and swing low.

    ``lookback`` defines how many completed candles are inspected.  The current
    candle is excluded to avoid look‑ahead bias.
    """

    if len(highs) < lookback + 1 or len(lows) < lookback + 1:
        return highs[-1], lows[-1]
    high = max(highs[-lookback - 1 : -1])
    low = min(lows[-lookback - 1 : -1])
    return high, low

# ---------------------------------------------------------------------------
# Pair selection
# ---------------------------------------------------------------------------

# The first and second level pair selection helpers now live in
# :mod:`engine.selection`.  They are re-exported here for backward compatibility
# and to keep the public API unchanged.
from .selection.scanner import scan_pairs  # noqa: E402
from .selection.momentum import select_active_pairs  # noqa: E402

# ---------------------------------------------------------------------------
# Signal generation
# ---------------------------------------------------------------------------

@dataclass
class Signal:
    """Trading signal with risk parameters."""

    symbol: str
    side: int  # 1 for long, -1 for short
    entry: float
    sl: float
    tp1: float
    tp2: float
    qty: float = 0.0
    score: Optional[float] = None
    quality: Optional[float] = None
    reasons: Optional[List[str]] = None

    def __post_init__(self) -> None:  # pragma: no cover - simple coercion
        if isinstance(self.side, str):
            self.side = 1 if self.side.lower() in {"long", "buy", "1", "true"} else -1

    @property
    def price(self) -> float:
        return self.entry


def _generate_signal(
    symbol: str,
    ohlcv: Dict[str, Sequence[float]],
    *,
    equity: float,
    risk_pct: float,
    ohlcv_15m: Optional[Dict[str, Sequence[float]]] = None,
    ohlcv_1h: Optional[Dict[str, Sequence[float]]] = None,
    order_book: Optional[Dict[str, float]] = None,
    tick_ratio_buy: Optional[float] = None,
    atr_disable_pct: float = 0.2,
    atr_reduce_pct: float = 2.0,
    swing_lookback: int = 5,
    macd_fast: int = 12,
    macd_slow: int = 26,
    macd_signal: int = 9,
    trend_ema_period: int = 200,
) -> Optional[Signal]:
    """Return a trading :class:`Signal` if conditions are met.

    ``ohlcv`` must contain ``open``, ``high``, ``low``, ``close`` and ``volume``
    sequences ordered from oldest to newest.  The function checks the following
    rules:

    * price positioned relative to VWAP and EMA20/EMA50 trend
    * RSI(14) crossing key levels (40/60)
    * OBV rising or high short‑term volume
    * Multi time frame confirmation (H1 EMA50 slope, RSI15 >/< 50)
    * Micro‑structure breakout of last swing high/low
    * MACD trend filter
    * Long‑term trend via configurable EMA filter
    * Order book imbalance and tape filters
    * Dynamic ATR‑based stop‑loss and take‑profit
    * Position sizing via ``calc_position_size``
    """

    closes = [float(x) for x in ohlcv.get("close", [])]
    highs = [float(x) for x in ohlcv.get("high", [])]
    lows = [float(x) for x in ohlcv.get("low", [])]
    vols = [float(x) for x in ohlcv.get("volume", [])]
    if len(closes) < 60 or len(highs) != len(lows) or len(closes) != len(highs):
        return None

    price = closes[-1]
    ema20 = ema(closes, 20)
    ema50 = ema(closes, 50)
    ema_trend = ema(closes, trend_ema_period)
    v = vwap(highs, lows, closes, vols)
    obv_series = obv(closes, vols)
    obv_rising = obv_series[-1] > obv_series[-2]
    vol_last3 = sum(vols[-3:])
    vol_ma20 = sum(vols[-20:]) / 20.0
    vol_rising = vol_last3 > vol_ma20

    macd_val, macd_sig, _ = calc_macd(
        closes, fast=macd_fast, slow=macd_slow, signal=macd_signal
    )

    # Multi timeframe filters -------------------------------------------------
    trend_dir = 0  # 1 = long only, -1 = short only, 0 = neutral
    if ohlcv_1h:
        h_closes = [float(x) for x in ohlcv_1h.get("close", [])]
        if len(h_closes) >= 52:
            h_ema50 = ema(h_closes, 50)
            if len(h_ema50) >= 2:
                slope = h_ema50[-1] - h_ema50[-2]
                if slope > 0:
                    trend_dir = 1
                elif slope < 0:
                    trend_dir = -1

    rsi_15 = None
    if ohlcv_15m:
        m_closes = [float(x) for x in ohlcv_15m.get("close", [])]
        if len(m_closes) >= 15:
            rsi_15 = calc_rsi(m_closes, 14)

    # RSI crossing logic (5m)
    rsi_curr = calc_rsi(closes[-15:], 14)
    rsi_prev = calc_rsi(closes[-16:-1], 14)

    atr = calc_atr(highs, lows, closes, 14)
    atr_pct = atr / price * 100.0 if price else 0.0
    if atr_pct < atr_disable_pct:
        return None
    size_mult = 0.5 if atr_pct > atr_reduce_pct else 1.0

    sl_dist = 0.5 * atr
    tp1_dist = 1.0 * atr
    tp2_dist = 1.5 * atr

    swing_high, swing_low = swing_levels(highs, lows, swing_lookback)

    obi_ok_long = obi_ok_short = True
    if order_book is not None:
        bid = float(order_book.get("bid_vol_aggreg", 0))
        ask = float(order_book.get("ask_vol_aggreg", 0))
        obi = order_book_imbalance(bid, ask)
        obi_ok_long = obi > 0.1
        obi_ok_short = obi < -0.1

    tick_ok_long = tick_ratio_buy is None or tick_ratio_buy > 0.55
    tick_ok_short = tick_ratio_buy is None or tick_ratio_buy < 0.45

    def _size(dist: float) -> float:
        return calc_position_size(equity, risk_pct, dist) * size_mult
    weights = {
        "ema": 15.0,
        "macd": 15.0,
        "vwap": 15.0,
        "rsi": 15.0,
        "obv": 10.0,
        "swing": 10.0,
        "atr": 20.0,
    }

    atr_score = min(atr_pct / atr_reduce_pct, 1.0) * weights["atr"]

    long_score = atr_score
    long_reasons: List[str] = []
    if price > v:
        long_score += weights["vwap"]
        long_reasons.append("vwap")
    if ema20[-1] > ema50[-1]:
        long_score += weights["ema"]
        long_reasons.append("ema")
    if rsi_prev <= 40 < rsi_curr:
        long_score += weights["rsi"]
        long_reasons.append("rsi")
    if macd_val > macd_sig:
        long_score += weights["macd"]
        long_reasons.append("macd")
    if obv_rising or vol_rising:
        long_score += weights["obv"]
        long_reasons.append("obv")
    if price > swing_high:
        long_score += weights["swing"]
        long_reasons.append("swing")

    short_score = atr_score
    short_reasons: List[str] = []
    if price < v:
        short_score += weights["vwap"]
        short_reasons.append("vwap")
    if ema20[-1] < ema50[-1]:
        short_score += weights["ema"]
        short_reasons.append("ema")
    if rsi_prev >= 60 > rsi_curr:
        short_score += weights["rsi"]
        short_reasons.append("rsi")
    if macd_val < macd_sig:
        short_score += weights["macd"]
        short_reasons.append("macd")
    if obv_series[-1] < obv_series[-2] or vol_rising:
        short_score += weights["obv"]
        short_reasons.append("obv")
    if price < swing_low:
        short_score += weights["swing"]
        short_reasons.append("swing")

    side: Optional[str] = None
    score: float = 0.0
    reasons: List[str] = []
    if (
        long_score >= short_score
        and long_score > 0
        and macd_val > macd_sig
        and obi_ok_long
        and tick_ok_long
        and trend_dir >= 0
        and price > ema_trend[-1]
    ):
        side = "long"
        score = long_score
        reasons = long_reasons
        sl = price - sl_dist
        tp1 = price + tp1_dist
        tp2 = price + tp2_dist
    elif (
        short_score > long_score
        and short_score > 0
        and macd_val < macd_sig
        and obi_ok_short
        and tick_ok_short
        and trend_dir <= 0
        and price < ema_trend[-1]
    ):
        side = "short"
        score = short_score
        reasons = short_reasons
        sl = price + sl_dist
        tp1 = price - tp1_dist
        tp2 = price - tp2_dist
    else:
        return None

    qty = _size(sl_dist)
    return Signal(symbol, side, price, sl, tp1, tp2, qty, score, score, reasons)


def generate_signal(*args, **kwargs) -> Optional[Signal]:
    if "config" in kwargs:
        config = kwargs.pop("config")
        symbol = kwargs.pop("symbol", None)
        ohlcv = kwargs.pop("ohlcv", None)
        if ohlcv is None:
            raise TypeError("ohlcv argument required")
        return _generate_signal(
            symbol or ohlcv.get("symbol", ""),
            ohlcv,
            equity=kwargs.pop("equity", 0.0),
            risk_pct=getattr(config, "RISK_PCT", 0.0),
            **kwargs,
        )
    return _generate_signal(*args, **kwargs)

# ---------------------------------------------------------------------------
# Backtesting utilities
# ---------------------------------------------------------------------------

def max_drawdown(equity_curve: Sequence[float]) -> float:
    peak = equity_curve[0]
    mdd = 0.0
    for x in equity_curve:
        if x > peak:
            peak = x
        dd = (peak - x) / peak * 100.0
        if dd > mdd:
            mdd = dd
    return mdd

def backtest(
    trades: Sequence[Dict[str, Any]],
    *,
    equity_start: float = 1_000.0,
    fee_rate: float = 0.0,
) -> Dict[str, float]:
    """Evaluate a list of trade dictionaries.

    Each trade must provide ``symbol``, ``entry``, ``exit``, ``side`` and may
    optionally include ``duration`` in minutes.  Results are aggregated into
    common performance metrics to quickly evaluate the strategy.
    """

    equity = equity_start
    equity_curve = [equity]
    pnl_pct_list: List[float] = []
    wins = losses = 0
    win_sum = loss_sum = 0.0
    total_duration = 0.0

    for t in trades:
        pnl_pct = calc_pnl_pct(t["entry"], t["exit"], t["side"], fee_rate)
        pnl_pct_list.append(pnl_pct)
        if pnl_pct >= 0:
            wins += 1
            win_sum += pnl_pct
        else:
            losses += 1
            loss_sum += pnl_pct
        equity *= 1 + pnl_pct / 100.0
        equity_curve.append(equity)
        total_duration += float(t.get("duration", 0.0))

    pnl_pct_total = sum(pnl_pct_list)
    pnl_usdt = equity - equity_start
    profit_factor = (win_sum / abs(loss_sum)) if loss_sum else float("inf")
    winrate = wins / len(trades) * 100.0 if trades else 0.0
    mdd = max_drawdown(equity_curve)
    avg_trade_time = total_duration / len(trades) if trades else 0.0
    exposure = total_duration  # in minutes, callers can normalise if desired
    # Sharpe ratio based on per-trade returns
    if len(pnl_pct_list) > 1:
        mean = sum(pnl_pct_list) / len(pnl_pct_list)
        var = sum((r - mean) ** 2 for r in pnl_pct_list) / (len(pnl_pct_list) - 1)
        sharpe = mean / (var ** 0.5) if var > 0 else 0.0
    else:
        sharpe = 0.0

    return {
        "pnl_usdt": pnl_usdt,
        "pnl_pct": pnl_pct_total,
        "profit_factor": profit_factor,
        "winrate": winrate,
        "max_drawdown": mdd,
        "avg_trade_time": avg_trade_time,
        "exposure": exposure,
        "sharpe": sharpe,
    }

# ===== engine/strategy/factory.py ===== (1 lignes, modifié 2025-08-25 17:18:51)

annulé

# ===== engine/trade_utils.py ===== (29 lignes, modifié 2025-08-25 17:18:51)

# scalper/trade_utils.py
from __future__ import annotations

from typing import Optional


def compute_position_size(
    equity: float,
    price: float,
    risk_pct: float,
    *,
    symbol: Optional[str] = None,
    min_qty: float = 0.0,
    max_leverage: float = 1.0,
) -> float:
    """
    Sizing simple: position notionnelle = equity * risk_pct * max_leverage
    qty = notionnel / price
    - min_qty : borne basse éventuelle (0 pour ignorer)
    - max_leverage : si tu veux simuler un levier (1 par défaut)
    """
    equity = float(max(0.0, equity))
    price = float(max(1e-12, price))
    risk_pct = float(max(0.0, risk_pct))
    notionnel = equity * risk_pct * max_leverage
    qty = notionnel / price
    if min_qty > 0 and qty < min_qty:
        return 0.0
    return float(qty)

# ===== engine/utils/bootstrap.py ===== (73 lignes, modifié 2025-08-25 17:18:51)

# engine/utils/bootstrap.py
from __future__ import annotations
import importlib
import json
import os
import subprocess
import sys
from pathlib import Path
from typing import Dict, Tuple

_MARK_DIR = Path("/notebooks/.scalp")
_MARK_DIR.mkdir(parents=True, exist_ok=True)
STATE = _MARK_DIR / "DEPS.json"

# import_name -> pip_spec
CORE_REQS: Dict[str, str] = {
    "requests": "requests>=2.31",
    "pandas": "pandas>=2.1",
    "numpy": "numpy>=1.26",
    "yaml": "PyYAML>=6.0",
    "dotenv": "python-dotenv>=1.0",
}
DASH_REQS: Dict[str, str] = {"streamlit": "streamlit>=1.33"}
CCXT_REQS: Dict[str, str] = {"ccxt": "ccxt>=4.0.0"}


def _need(import_name: str) -> bool:
    try:
        importlib.import_module(import_name)
        return False
    except Exception:
        return True


def _pip(spec: str) -> Tuple[bool, str]:
    try:
        # upgrade pip une seule fois par session (léger)
        if not getattr(_pip, "_upgraded", False):
            subprocess.run([sys.executable, "-m", "pip", "install", "--upgrade", "pip"],
                           check=False, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            _pip._upgraded = True  # type: ignore[attr-defined]
        proc = subprocess.run([sys.executable, "-m", "pip", "install", spec],
                              capture_output=True, text=True, check=False)
        ok = (proc.returncode == 0)
        return ok, (proc.stdout + proc.stderr)[-3000:]
    except Exception as e:
        return False, f"pip failed: {e}"


def ensure_dependencies(*, with_dash: bool = True, with_ccxt: bool = True) -> Dict[str, str]:
    """
    Idempotent: installe seulement ce qui manque.
    Écrit l'état dans /notebooks/.scalp/DEPS.json
    """
    plan: Dict[str, str] = {}
    reqs = dict(CORE_REQS)
    if with_dash:
        reqs.update(DASH_REQS)
    if with_ccxt:
        reqs.update(CCXT_REQS)

    for import_name, spec in reqs.items():
        if _need(import_name):
            ok, log_tail = _pip(spec)
            plan[spec] = "installed" if ok else f"failed: {log_tail}"
        else:
            plan[spec] = "ok"

    try:
        STATE.write_text(json.dumps(plan, indent=2), encoding="utf-8")
    except Exception:
        pass
    return plan

# ===== engine/utils/ensure_deps.py ===== (68 lignes, modifié 2025-08-25 17:18:51)

# engine/utils/ensure_deps.py
from __future__ import annotations
import importlib, subprocess, sys
from pathlib import Path
from typing import Iterable

DEFAULT_PKGS = [
    # ce set couvre l'app + termboard + dash
    "pandas", "numpy", "pyyaml", "requests", "tqdm",
    "aiohttp", "websockets",
    "rich", "streamlit", "plotly", "matplotlib",
    "python-telegram-bot",
]

def _installed(mod: str) -> bool:
    try:
        importlib.import_module(mod)
        return True
    except Exception:
        return False

def _pip_install(args: list[str]) -> int:
    return subprocess.call([sys.executable, "-m", "pip", "install", *args])

def ensure_minimal(extra: Iterable[str] = ()) -> None:
    """Installe ce qui manque (module par module) sans planter le boot."""
    missing = []
    # mapping module->pip-name si différent
    name_map = {
        "python-telegram-bot": "python-telegram-bot",
        "pyyaml": "pyyaml",
        "matplotlib": "matplotlib",
        "streamlit": "streamlit",
        "plotly": "plotly",
        "rich": "rich",
        "tqdm": "tqdm",
        "aiohttp": "aiohttp",
        "websockets": "websockets",
        "pandas": "pandas",
        "numpy": "numpy",
        "requests": "requests",
    }
    modules = list(DEFAULT_PKGS) + list(extra or [])
    for pkg in modules:
        mod = pkg
        # pour certains noms pip = module
        if pkg == "python-telegram-bot":
            mod = "telegram"
        if pkg == "pyyaml":
            mod = "yaml"
        if not _installed(mod):
            missing.append(name_map.get(pkg, pkg))
    if missing:
        try:
            print(f"[deps] installation manquante: {', '.join(missing)}")
            _pip_install(missing)
        except Exception as e:
            print(f"[deps] avertissement: installation partielle: {e}")

def ensure_from_requirements() -> None:
    """Si requirements.txt existe, tente un install (idempotent)."""
    req = Path(__file__).resolve().parents[2] / "requirements.txt"
    if req.exists():
        try:
            print("[deps] pip install -r requirements.txt (auto)")
            _pip_install(["-r", str(req)])
        except Exception as e:
            print(f"[deps] échec install -r requirements.txt: {e}")

# ===== engine/version.py ===== (96 lignes, modifié 2025-08-25 17:18:51)

"""Utilities for managing the Scalp bot version."""

from __future__ import annotations

from pathlib import Path
import re

import subprocess


# Path to the VERSION file within the package
_VERSION_FILE = Path(__file__).resolve().parent / "VERSION"
_VERSION_RE = re.compile(r"^(\d+)\.(\d+)\.(\d+)$")


def get_version() -> str:
    """Return the current version of the bot.

    If the VERSION file does not exist the default version ``0.0.0`` is
    returned.
    """
    if not _VERSION_FILE.exists():
        return "0.0.0"
    return _VERSION_FILE.read_text().strip()


def _parse(version: str) -> tuple[int, int, int]:
    match = _VERSION_RE.match(version)
    if not match:
        raise ValueError(f"Invalid version: {version!r}")
    return tuple(int(x) for x in match.groups())


def bump_version(part: str = "patch") -> str:
    """Bump the version stored in the VERSION file.

    Parameters
    ----------
    part:
        Which component to increment. Accepted values are ``"major"``,
        ``"minor"`` and ``"patch"`` (default).
    """
    major, minor, patch = _parse(get_version())
    if part == "major":
        major += 1
        minor = 0
        patch = 0
    elif part == "minor":
        minor += 1
        patch = 0

    elif part == "patch":
        patch += 1
    else:
        raise ValueError(f"Unknown part: {part}")
    new_version = f"{major}.{minor}.{patch}"
    _VERSION_FILE.write_text(f"{new_version}\n")
    return new_version


def bump_version_from_message(message: str) -> str:
    """Bump the version according to a commit message.

    ``message`` is evaluated using a tiny subset of the Conventional
    Commits spec. Messages starting with ``feat`` bump the *minor*
    version, messages whose header ends with ``!`` or contain
    ``BREAKING CHANGE`` bump the *major* version. All other messages
    bump the *patch* component.
    """

    header = message.strip().splitlines()[0].lower()
    lower = message.lower()
    type_part = header.split(":")[0]
    if "!" in type_part or "breaking change" in lower:
        part = "major"
    elif type_part.startswith("feat"):
        part = "minor"
    else:
        part = "patch"
    return bump_version(part)


def bump_version_from_git() -> str:
    """Read the latest git commit message and bump the version accordingly."""
    try:
        message = subprocess.check_output(
            ["git", "log", "-1", "--pretty=%B"], text=True
        ).strip()
    except Exception:
        message = ""
    return bump_version_from_message(message)


if __name__ == "__main__":
    print(bump_version_from_git())

# ===== engine/ws.py ===== (71 lignes, modifié 2025-08-25 17:18:51)

"""Minimal websocket manager with heartbeat and auto-resubscribe.

This module provides a light-weight framework to maintain a realtime
connection to an exchange.  The actual network layer is expected to be
supplied by the caller via ``connect`` and ``subscribe`` callbacks.  The
manager handles retrying failed connections and periodically invoking the
``subscribe`` callback as a heartbeat.  This keeps the code fully testable
without opening real network sockets.
"""
from __future__ import annotations

import asyncio
import logging
from typing import Awaitable, Callable, Optional


class WebsocketManager:
    """Maintain a websocket connection with heartbeat and retry."""

    def __init__(
        self,
        connect: Callable[[], Awaitable[None]],
        subscribe: Callable[[], Awaitable[None]],
        *,
        heartbeat_interval: float = 30.0,
        max_retries: int = 3,
    ) -> None:
        self._connect = connect
        self._subscribe = subscribe
        self.heartbeat_interval = heartbeat_interval
        self.max_retries = max_retries
        self._heartbeat_task: Optional[asyncio.Task] = None

    async def run(self) -> None:
        """Open the connection retrying on failure."""
        retries = 0
        while True:
            try:
                await self._connect()
                await self._subscribe()
                self._heartbeat_task = asyncio.create_task(self._heartbeat())
                return
            except Exception as exc:  # pragma: no cover - network errors
                logging.error("websocket connect failed: %s", exc)
                retries += 1
                if retries > self.max_retries:
                    raise
                await asyncio.sleep(1)

    async def _heartbeat(self) -> None:
        """Send periodic heartbeats and resubscribe on failure."""
        while True:
            await asyncio.sleep(self.heartbeat_interval)
            try:
                await self._subscribe()
            except Exception as exc:  # pragma: no cover - network errors
                logging.warning("websocket heartbeat failed: %s", exc)
                await self.run()
                break

    async def stop(self) -> None:
        """Cancel the heartbeat task if it is running."""
        task = self._heartbeat_task
        if task and not task.done():
            task.cancel()
            try:
                await task
            except BaseException:  # pragma: no cover - cancellation
                pass
        self._heartbeat_task = None

# ===== init.py ===== (37 lignes, modifié 2025-08-25 17:18:51)

#!/usr/bin/env python3
"""Install all project dependencies.

Run this script once to install every ``requirements*.txt`` file found in the
repository as well as the packages needed for the test suite.  All subsequent
invocations of the bot or its submodules will then share the same Python
environment with the required dependencies available.
"""

from __future__ import annotations

import subprocess
import sys
from pathlib import Path


def install_packages(*args: str) -> None:
    """Install packages using pip for the current Python interpreter."""
    cmd = [sys.executable, "-m", "pip", "install", *args]
    subprocess.check_call(cmd)


def main() -> None:
    repo_root = Path(__file__).resolve().parent

    # Install from any requirements*.txt file across the repository so that
    # sub-packages with their own dependency lists are also covered.
    for req in sorted(repo_root.rglob("requirements*.txt")):
        install_packages("-r", str(req))

    # Ensure test dependencies are available
    install_packages("pytest")


if __name__ == "__main__":
    main()

# ===== jobs/__init__.py ===== (1 lignes, modifié 2025-08-25 17:18:51)

 

# ===== jobs/backfill.py ===== (37 lignes, modifié 2025-08-25 17:18:51)

from __future__ import annotations
import argparse, os
from pathlib import Path
from engine.config.loader import load_config
from engine.exchange.bitget_rest import BitgetFuturesClient
from engine.backtest.loader_csv import write_csv_ohlcv

def main() -> int:
    ap = argparse.ArgumentParser(description="Backfill OHLCV -> DATA_ROOT/data")
    ap.add_argument("--symbols", required=True, help="BTCUSDT,ETHUSDT")
    ap.add_argument("--tfs", required=True, help="1m,5m,15m,1h")
    ap.add_argument("--limit", type=int, default=5000)
    args = ap.parse_args()

    cfg = load_config()
    out_dir = Path(cfg["runtime"]["data_dir"]).resolve()
    out_dir.mkdir(parents=True, exist_ok=True)

    client = BitgetFuturesClient(
        access_key=cfg["secrets"]["bitget"]["access"],
        secret_key=cfg["secrets"]["bitget"]["secret"],
        passphrase=cfg["secrets"]["bitget"]["passphrase"],
        base_url=os.getenv("BITGET_BASE_URL","https://api.bitget.com"),
    )

    symbols = [s.strip() for s in args.symbols.split(",") if s.strip()]
    tfs = [t.strip() for t in args.tfs.split(",") if t.strip()]
    for sym in symbols:
        for tf in tfs:
            resp = client.get_klines(sym, interval=tf, limit=args.limit)
            rows = resp.get("data") or []
            write_csv_ohlcv(out_dir, sym, tf, rows)
            print(f"[✓] {sym} {tf} -> {out_dir}")
    return 0

if __name__ == "__main__":
    raise SystemExit(main())

# ===== jobs/backtest.py ===== (60 lignes, modifié 2025-08-25 17:18:51)

#!/usr/bin/env python3
from __future__ import annotations
import argparse, json
from pathlib import Path
from typing import Any, Dict, List
from engine.config.loader import load_config
from engine.config.watchlist import load_watchlist
from engine.backtest.loader_csv import load_csv_ohlcv
from engine.backtest.engine import run_backtest_once, compute_metrics, grid_params

def main() -> int:
    ap = argparse.ArgumentParser(description="Backtests grid -> DATA_ROOT/reports")
    ap.add_argument("--symbols", default="", help="Liste explicite (sinon watchlist)")
    ap.add_argument("--from-watchlist", action="store_true", help="Utiliser la watchlist (top N)")
    ap.add_argument("--tfs", required=True, help="1m,5m,15m,1h")
    ap.add_argument("--out", default=None)
    args = ap.parse_args()

    cfg = load_config()
    data_dir = Path(cfg["runtime"]["data_dir"])
    reports_dir = Path(args.out or cfg["runtime"]["reports_dir"])
    reports_dir.mkdir(parents=True, exist_ok=True)

    if args.from_watchlist:
        wl = load_watchlist()
        symbols = [d["symbol"] for d in wl.get("top", [])]
    else:
        symbols = [s.strip() for s in args.symbols.split(",") if s.strip()]
    tfs = [t.strip() for t in args.tfs.split(",") if t.strip()]

    summary: List[Dict[str, Any]] = []
    best: Dict[str, Dict[str, Any]] = {}

    for sym in symbols:
        for tf in tfs:
            csv_path = data_dir / f"{sym.replace('/','').replace('_','')}-{tf}.csv"
            if not csv_path.exists():
                print(f"[!] CSV manquant: {csv_path} — fais d'abord jobs/refresh_pairs.py")
                continue
            df = load_csv_ohlcv(csv_path)
            best_score = None
            best_params = None
            for p in grid_params():
                res = run_backtest_once(sym, tf, df, params=p)
                m = res["metrics"]
                summary.append({"symbol": sym, "tf": tf, **p, **m})
                sc = float(m["score"])
                if (best_score is None) or (sc > best_score):
                    best_score, best_params = sc, p
            if best_params:
                best[f"{sym}:{tf}"] = best_params

    (reports_dir / "summary.json").write_text(json.dumps(summary, indent=2), encoding="utf-8")
    (reports_dir / "strategies.yml.next").write_text(json.dumps({"strategies": best}, indent=2), encoding="utf-8")
    print(f"[✓] Résumé -> {reports_dir/'summary.json'}")
    print(f"[✓] Brouillon stratégie -> {reports_dir/'strategies.yml.next'}")
    return 0

if __name__ == "__main__":
    raise SystemExit(main())

# ===== jobs/boot_live.py ===== (57 lignes, modifié 2025-08-25 17:18:51)

#!/usr/bin/env python3
# jobs/boot_live.py
from __future__ import annotations

import argparse
import subprocess
import sys
from pathlib import Path

from engine.config.loader import load_config

ROOT = Path(__file__).resolve().parents[1]

def run(cmd: list[str]) -> int:
    print("+", " ".join(cmd))
    return subprocess.run(cmd, cwd=str(ROOT)).returncode

def main(argv=None) -> int:
    ap = argparse.ArgumentParser()
    ap.add_argument("--top", type=int, default=None)
    ap.add_argument("--timeframe", type=str, default=None)
    ap.add_argument("--backfill-tfs", type=str, default=None)
    ap.add_argument("--limit", type=int, default=None)
    ap.add_argument("--seed-tfs", type=str, default=None)
    ap.add_argument("--ttl-bars-exp", type=int, default=None)
    ap.add_argument("--no-seed", action="store_true")
    ap.add_argument("--just-run", action="store_true")
    ns = ap.parse_args(argv)

    cfg = load_config()
    wl = cfg.get("watchlist", {})
    mt = cfg.get("maintainer", {})

    top = ns.top or int(wl.get("top", 10))
    timeframe = ns.timeframe or str(wl.get("score_tf", "5m"))
    backfill_tfs = ns.backfill_tfs or ",".join(wl.get("backfill_tfs", ["1m","5m","15m"]))
    limit = ns.limit or int(wl.get("backfill_limit", 1500))
    seed_tfs = ns.seed_tfs or ",".join(mt.get("seed_tfs", ["1m"]))
    ttl_bars_exp = ns.ttl_bars_exp or int(mt.get("ttl_bars_experimental", 120))

    if not ns.just_run:
        rc = run([sys.executable, "-m", "jobs.refresh_pairs",
                  "--timeframe", timeframe, "--top", str(top),
                  "--backfill-tfs", backfill_tfs, "--limit", str(limit)])
        if rc != 0:
            print(f"[boot] refresh_pairs RC={rc} (continue)")

        if not ns.no_seed:
            rc = run([sys.executable, "-m", "jobs.seed_strategies",
                      "--tfs", seed_tfs, "--ttl-bars-exp", str(ttl_bars_exp)])
            if rc != 0:
                print(f"[boot] seed_strategies RC={rc} (continue)")

    return run([sys.executable, "bot.py"])

if __name__ == "__main__":
    raise SystemExit(main())

# ===== jobs/dash.py ===== (38 lignes, modifié 2025-08-25 17:18:51)

#!/usr/bin/env python3
"""
jobs/dash.py — Lance le dashboard Streamlit du projet scalp
Usage:
    python jobs/dash.py
Options:
    --port 8501       Port HTTP (défaut 8501)
    --headless true   Mode headless (recommandé en remote)
"""

import argparse
import subprocess
import sys
from pathlib import Path

def main(argv=None):
    ap = argparse.ArgumentParser()
    ap.add_argument("--port", type=int, default=8501, help="Port HTTP (défaut 8501)")
    ap.add_argument("--headless", action="store_true", help="Force mode headless")
    args = ap.parse_args(argv)

    app_path = Path(__file__).resolve().parents[1] / "dash" / "app.py"
    if not app_path.exists():
        sys.exit(f"Dashboard introuvable: {app_path}")

    cmd = [
        sys.executable, "-m", "streamlit", "run", str(app_path),
        "--server.port", str(args.port),
    ]
    if args.headless:
        cmd += ["--server.headless", "true"]

    print(f"[i] Lancement du dashboard Streamlit sur port {args.port} ...")
    print(" ".join(cmd))
    subprocess.run(cmd)

if __name__ == "__main__":
    main()

# ===== jobs/maintainer.py ===== (399 lignes, modifié 2025-08-25 17:18:51)

#!/usr/bin/env python3
# jobs/maintainer.py
from __future__ import annotations

import argparse
import logging
from logging.handlers import RotatingFileHandler
import subprocess
import sys
import time
from pathlib import Path
from typing import Dict, List, Set, Tuple

from engine.config.loader import load_config
from engine.config.watchlist import load_watchlist
from engine.config.strategies import load_strategies
from engine.backtest.loader_csv import load_csv_ohlcv, find_csv_path  # pour vérifier la fraicheur des données

ROOT = Path(__file__).resolve().parents[1]
log = logging.getLogger("maintainer")

# --------- couleurs / rendu ----------
COLORS = {
    "black": "\x1b[30m",
    "red": "\x1b[31m",
    "green": "\x1b[32m",
    "orange": "\x1b[33m",
    "reset": "\x1b[0m",
}

_TF_MIN = {"1m":1, "5m":5, "15m":15, "1h":60, "4h":240, "1d":1440}

def _tf_minutes(tf: str) -> int:
    return _TF_MIN.get(str(tf), 1)

def _ttl_mult_cfg() -> Dict[str, int]:
    try:
        cfg = load_config()
        mt = cfg.get("maintainer", {}) or {}
        return {str(k): int(v) for k, v in (mt.get("ttl_mult") or {}).items()}
    except Exception:
        return {}

def _short_sym(s: str) -> str:
    s = s.upper().replace("_", "")
    return s[:-4] if s.endswith("USDT") else s

def _color_block(color: str, text: str) -> str:
    c = COLORS.get(color, "")
    r = COLORS["reset"]
    return f"{c}{text}{r}"

def _center(text: str, width: int) -> str:
    pad = max(0, width - len(text))
    left = pad // 2
    right = pad - left
    return " " * left + text + " " * right

# ------------------------ logging ------------------------

def _setup_logging() -> None:
    if log.handlers:
        return
    cfg = load_config()
    rt = cfg.get("runtime", {})
    logs_dir = Path(rt.get("logs_dir") or "/notebooks/scalp_data/logs")
    logs_dir.mkdir(parents=True, exist_ok=True)
    fh = RotatingFileHandler(str(logs_dir / "maintainer.log"),
                             maxBytes=10 * 1024 * 1024, backupCount=5)
    fh.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(message)s"))
    ch = logging.StreamHandler()
    ch.setFormatter(logging.Formatter("[maintainer] %(levelname)s: %(message)s"))
    log.setLevel(logging.INFO)
    fh.setLevel(logging.INFO); ch.setLevel(logging.INFO)
    log.addHandler(fh); log.addHandler(ch)
    log.info("Logger prêt • fichier=%s", logs_dir / "maintainer.log")

# ------------------------ helpers conf/fs ------------------------

def run_cmd(args: List[str]) -> tuple[int, str, str]:
    """Lance une commande en capturant stdout/stderr. Retourne (rc, out, err)."""
    p = subprocess.run(args, cwd=str(ROOT), capture_output=True, text=True)
    out = (p.stdout or "").strip()
    err = (p.stderr or "").strip()
    if out: log.info("stdout: %s", out)
    if err: log.warning("stderr: %s", err)
    return p.returncode, out, err

def _symbols_top(top: int | None) -> List[str]:
    wl = load_watchlist()
    syms = [(d.get("symbol") or "").replace("_", "").upper()
            for d in (wl.get("top") or []) if d.get("symbol")]
    return syms if not top else syms[:top]

# ------------------------ statut data/strat ------------------------

_MIS_REPORTED = set()

def _last_bar_ts_ms(data_dir: str, symbol: str, tf: str) -> int | None:
    """
    Dernier timestamp (ms) ; trace 1 fois un warning si fichier introuvable
    pour aider au diagnostic.
    """
    rows = load_csv_ohlcv(data_dir, symbol, tf, max_rows=1)
    if rows:
        return int(rows[-1][0])

    key = (symbol, tf)
    if key not in _MIS_REPORTED:
        _MIS_REPORTED.add(key)
        guessed = find_csv_path(data_dir, symbol, tf)
        msg = f"CSV introuvable pour {symbol}:{tf}"
        if guessed:
            msg += f" (dernier essai: {guessed})"
        else:
            msg += " (aucun chemin candidat trouvé)"
        log.warning(msg)
    return None

def _data_is_fresh(now_ms: int, last_ms: int | None, tf: str) -> bool:
    """Data 'fraîche' si la dernière bougie ≤ 2×TF."""
    if last_ms is None:
        return False
    tf_ms = _tf_minutes(tf) * 60_000
    return (now_ms - last_ms) <= (2 * tf_ms)

def _strat_is_valid(strategies: Dict[str, Dict], symbol: str, tf: str) -> bool:
    k = f"{symbol}:{tf}"
    s = strategies.get(k)
    return bool(s) and not bool(s.get("expired"))

def _status_cell(symbol: str, tf: str, strategies: Dict[str, Dict], data_dir: str, ttl_mult: Dict[str,int]) -> tuple[str,str]:
    """
    Renvoie (label, color) :
      ⬛ ('MIS','black')   = données manquantes
      🟥 ('OLD','red')    = données présentes mais trop vieilles
      🟧 ('DAT','orange') = données ok, stratégie absente/expirée
      🟩 ('OK ','green')  = données + stratégie valides
    """
    now = int(time.time() * 1000)
    last_ms = _last_bar_ts_ms(data_dir, symbol, tf)
    has_data = last_ms is not None
    fresh = _data_is_fresh(now, last_ms, tf)

    if not has_data:
        return ("MIS","black")
    if not fresh:
        return ("OLD","red")
    if _strat_is_valid(strategies, symbol, tf):
        return ("OK ","green")
    return ("DAT","orange")

# ------------------------ rendering tableau ------------------------

def _render_status_table(symbols: List[str], tfs: List[str],
                         strategies: dict, data_dir: str) -> str:
    header = ["PAIR"] + tfs
    rows: List[List[str]] = []

    for s in symbols:
        line = [_short_sym(s)]
        for tf in tfs:
            lbl, color = _status_cell(s, tf, strategies, data_dir, _ttl_mult_cfg())
            cell = _color_block(color, lbl)
            line.append(cell)
        rows.append(line)

    # largeur visible (ignore codes ANSI)
    def visible_len(x: str) -> int:
        import re
        return len(re.sub(r"\x1b\[[0-9;]*m", "", x))

    widths = [max(visible_len(r[i]) for r in ([header] + rows)) for i in range(len(header))]

    def fmt(row: List[str]) -> str:
        out = []
        import re
        for i, v in enumerate(row):
            w = widths[i]
            if "\x1b[" in v:
                plain = re.sub(r"\x1b\[[0-9;]*m", "", v)
                pad = _center(plain, w)
                # reconstruire: couleur + texte centré + reset (le libellé coloré est toujours de la forme <color>TXT<reset>)
                start = v[:v.find(plain)] if plain in v else ""
                v = f"{start}{pad}{COLORS['reset']}"
            else:
                v = _center(v, w)
            out.append(v)
        return " | ".join(out)

    bar = [ "-" * w for w in widths ]
    table = [fmt(header), fmt(bar), *[fmt(r) for r in rows]]
    return "\n".join(table)

def _paint_live_table(symbols: List[str], tfs: List[str]) -> None:
    """Affichage 'live' (stdout) sans passer par le logger."""
    try:
        cfg = load_config()
        data_dir = str((cfg.get("runtime") or {}).get("data_dir") or "/notebooks/scalp_data/data")
        strategies = load_strategies()
        table = _render_status_table(symbols, tfs, strategies, data_dir)
        sys.stdout.write("\x1b[2J\x1b[H")  # clear + home
        sys.stdout.write("[maintainer] État (PAIR×TF)\n")
        sys.stdout.write(table + "\n")
        sys.stdout.flush()
    except Exception:
        pass

# ------------------------ calcul expirés/manquants ------------------------

def _expired_pairs(tfs: List[str]) -> List[Tuple[str, str]]:
    """
    (symbol, tf) expirés/à créer par rapport à strategies.yml et watchlist.
    NB: ce calcul ne sert plus au rendu (qui lit les CSV), mais reste utile pour
    prioriser l'ordre de backfill si besoin.
    """
    all_ = load_strategies()
    need: List[Tuple[str, str]] = []
    present = {(k.split(":")[0], k.split(":")[1]) for k in all_.keys()}

    for k, v in all_.items():
        s, tf = k.split(":")
        if v.get("expired"):
            need.append((s, tf))

    wl_syms = set(_symbols_top(None))
    for s in wl_syms:
        for tf in tfs:
            if (s, tf) not in present:
                need.append((s, tf))

    out, seen = [], set()
    for x in need:
        if x not in seen:
            out.append(x); seen.add(x)
    return out

# ------------------------ actions ------------------------

def refresh_watchlist(top: int, score_tf: str, backfill_tfs: List[str], limit: int) -> None:
    rc, _, _ = run_cmd([
        sys.executable, "-m", "jobs.refresh_pairs",
        "--timeframe", score_tf,
        "--top", str(top),
        "--backfill-tfs", ",".join(backfill_tfs),
        "--limit", str(limit),
    ])
    if rc != 0:
        log.warning("refresh_pairs RC=%s (continue)", rc)

def backfill_symbol_tf(symbol: str, tf: str, limit: int) -> bool:
    rc, _, _ = run_cmd([
        sys.executable, "-m", "jobs.refresh_pairs",
        "--timeframe", tf,
        "--top", "0",
        "--backfill-tfs", tf,
        "--limit", str(limit),
    ])
    ok = (rc == 0)
    if ok:  log.info("backfill OK: %s:%s", symbol, tf)
    else:   log.warning("backfill FAIL: %s:%s (rc=%s)", symbol, tf, rc)
    return ok

def backtest_and_promote() -> None:
    rc, _, _ = run_cmd([sys.executable, "-m", "jobs.backtest",
                        "--from-watchlist", "--tfs", "1m,5m,15m,1h"])
    if rc != 0:
        log.warning("backtest RC=%s", rc)
    draft = "/notebooks/scalp_data/reports/strategies.yml.next"
    rc, _, _ = run_cmd([sys.executable, "-m", "jobs.promote", "--draft", draft])
    if rc != 0:
        log.warning("promote RC=%s", rc)
    _summary_strategies()

def _summary_strategies() -> None:
    try:
        strat: Dict[str, Dict] = load_strategies()
        total = len(strat)
        expired = sum(1 for v in strat.values() if v.get("expired"))
        by_tf: Dict[str, int] = {}
        for k in strat.keys():
            try: _, tf = k.split(":")
            except ValueError: tf = "?"
            by_tf[tf] = by_tf.get(tf, 0) + 1
        tf_str = ", ".join(f"{tf}:{n}" for tf, n in sorted(by_tf.items()))
        log.info("STRATEGIES • total=%d • expirées=%d • par_tf=(%s)", total, expired, tf_str)
    except Exception as e:
        log.warning("summary strategies impossible: %s", e)

# ------------------------ pipeline ------------------------

def run_once(top: int, score_tf: str, tfs: List[str], limit: int,
             sleep_between_secs: float,
             live_table: bool,
             live_interval: float) -> None:
    log.info("=== RUN ONCE === top=%s score_tf=%s tfs=%s limit=%s", top, score_tf, tfs, limit)

    # 1) refresh + backfill global rapide
    refresh_watchlist(top=top, score_tf=score_tf, backfill_tfs=tfs, limit=limit)

    # 2) lecture watchlist + premier rendu
    syms = _symbols_top(top)
    if not syms:
        log.warning("Watchlist vide — stop.")
        return

    cfg = load_config()
    data_dir = str((cfg.get("runtime") or {}).get("data_dir") or "/notebooks/scalp_data/data")
    try:
        strat = load_strategies()
        table = _render_status_table(syms, tfs, strat, data_dir)
        log.info("\n%s", table)
    except Exception:
        pass
    if live_table:
        _paint_live_table(syms, tfs)

    # 3) backfill séquentiel 1→N et TF croisés
    touched = False
    last_live = time.time()
    for s in syms:
        for tf in tfs:
            ok = backfill_symbol_tf(s, tf, limit=limit)
            touched = touched or ok
            if live_table and (time.time() - last_live) >= live_interval:
                _paint_live_table(syms, tfs)
                last_live = time.time()
            time.sleep(max(0.0, sleep_between_secs))

    if live_table:
        _paint_live_table(syms, tfs)

    # 4) backtest + promote si on a touché des données
    if touched:
        log.info("backtest → promote…")
        backtest_and_promote()
    else:
        log.info("rien de nouveau — skip backtest.")
        _summary_strategies()

# ------------------------ CLI ------------------------

def _cfg_vals():
    cfg = load_config()
    wl = cfg.get("watchlist", {})
    mt = cfg.get("maintainer", {})
    return {
        "top": int(wl.get("top", 10)),
        "score_tf": str(wl.get("score_tf", "5m")),
        "tfs": [str(x) for x in (wl.get("backfill_tfs") or ["1m", "5m", "15m"])],
        "limit": int(wl.get("backfill_limit", 1500)),
        "interval": int(mt.get("interval_secs", 43200)),
        "sleep_between": float(mt.get("sleep_between_secs", 0.5)),
        "live": bool(mt.get("live_table", True)),
        "live_interval": float(mt.get("live_interval_secs", 2.0)),
    }

def main(argv=None) -> int:
    _setup_logging()
    ap = argparse.ArgumentParser(description="Mainteneur TOP‑N watchlist + backfill + backtest/promotion (tableau live)")
    ap.add_argument("--top", type=int, default=None)
    ap.add_argument("--score-tf", type=str, default=None)
    ap.add_argument("--tfs", type=str, default=None)
    ap.add_argument("--limit", type=int, default=None)
    ap.add_argument("--interval", type=int, default=None, help="intervalle boucle (sec)")
    ap.add_argument("--once", action="store_true", help="exécute une seule passe et sort")
    ap.add_argument("--sleep-between", type=float, default=None, help="pause entre backfills (sec)")
    ap.add_argument("--live-table", action="store_true", help="active le tableau live (sinon lecture config)")
    ap.add_argument("--no-live-table", action="store_true", help="force la désactivation du live")
    ap.add_argument("--live-interval", type=float, default=None, help="rafraîchissement du live (sec)")

    ns = ap.parse_args(argv)

    base = _cfg_vals()
    top = ns.top if ns.top is not None else base["top"]
    score_tf = ns.score_tf if ns.score_tf is not None else base["score_tf"]
    tfs = [t.strip() for t in (ns.tfs or ",".join(base["tfs"])).split(",") if t.strip()]
    limit = ns.limit if ns.limit is not None else base["limit"]
    interval = ns.interval if ns.interval is not None else base["interval"]
    sleep_between = ns.sleep_between if ns.sleep_between is not None else base["sleep_between"]

    if ns.live_table: live = True
    elif ns.no_live_table: live = False
    else: live = base["live"]
    live_interval = ns.live_interval if ns.live_interval is not None else base["live_interval"]

    if ns.once:
        run_once(top, score_tf, tfs, limit, sleep_between, live, live_interval)
        return 0

    while True:
        try:
            run_once(top, score_tf, tfs, limit, sleep_between, live, live_interval)
        except Exception:
            log.exception("erreur maintainer")
        time.sleep(max(300, interval))

if __name__ == "__main__":
    raise SystemExit(main())

# ===== jobs/promote.py ===== (177 lignes, modifié 2025-08-25 17:18:51)

#!/usr/bin/env python3
# jobs/promote.py
from __future__ import annotations

import argparse
import json
import shutil
import sys
import time
from pathlib import Path
from typing import Dict, Tuple

from engine.config.loader import load_config

# ---------- utils paths ----------

def _paths() -> Tuple[Path, Path, Path]:
    cfg = load_config()
    rt = cfg.get("runtime", {})
    reports_dir = Path(rt.get("reports_dir") or "/notebooks/scalp_data/reports")
    draft = reports_dir / "strategies.yml.next"
    final = Path(__file__).resolve().parents[1] / "engine" / "config" / "strategies.yml"
    backups = reports_dir / "backups"
    backups.mkdir(parents=True, exist_ok=True)
    return draft, final, backups

def _read_json(path: Path) -> Dict:
    if not path.exists():
        return {}
    try:
        return json.loads(path.read_text(encoding="utf-8") or "{}")
    except Exception:
        return {}

def _write_json_atomic(path: Path, doc: Dict) -> None:
    tmp = path.with_suffix(path.suffix + ".tmp")
    tmp.write_text(json.dumps(doc, indent=2), encoding="utf-8")
    tmp.replace(path)

# ---------- TTL helpers ----------

# mapping TF -> minutes
_TF_MIN = {"1m": 1, "5m": 5, "15m": 15, "1h": 60, "4h": 240, "1d": 1440}

def _tf_minutes(tf: str) -> int:
    return _TF_MIN.get(str(tf), 1)

def _default_ttl_mult(tf: str) -> int:
    """
    Multiplicateur de TTL par TF.
    Ajuste si tu veux être plus/moins strict.
    """
    if tf == "1m":   return 240     # 4h
    if tf == "5m":   return 240     # 20h
    if tf == "15m":  return 192     # 2j
    if tf == "1h":   return 168     # 1 semaine
    return 240

def _is_expired(created_at_ms: int, tf: str, ttl_mult: int | None = None) -> bool:
    now_ms = int(time.time() * 1000)
    mult = _default_ttl_mult(tf) if ttl_mult is None else int(ttl_mult)
    ttl_min = mult * _tf_minutes(tf)
    return now_ms - int(created_at_ms or 0) > ttl_min * 60_000

# ---------- merge/promotion ----------

def _promote(draft_doc: Dict, current_doc: Dict, ttl_mult_cfg: Dict[str, int]) -> Tuple[Dict, Dict]:
    """
    Retourne (merged, summary)
    - merged: nouveau document final {"strategies": {...}}
    - summary: stats de promotion
    """
    merged: Dict[str, Dict] = {"strategies": {}}
    cur = (current_doc.get("strategies") or {})
    new = (draft_doc.get("strategies") or {})

    added = updated = kept = expired = 0
    now_ms = int(time.time() * 1000)

    # 1) intégrer toutes les entrées actuelles
    for key, val in cur.items():
        merged["strategies"][key] = dict(val)
        kept += 1

    # 2) injecter / écraser avec le draft
    for key, val in new.items():
        # key format "SYMBOL:TF"
        tf = key.split(":")[1] if ":" in key else "1m"
        # TTL bars (optionnel) -> converti en created_at/expired
        created = int(val.get("created_at") or now_ms)
        ttl_mult = ttl_mult_cfg.get(tf)
        is_old = _is_expired(created, tf, ttl_mult=ttl_mult)
        val2 = dict(val)
        val2["created_at"] = created
        val2["expired"] = bool(is_old)

        if key in merged["strategies"]:
            merged["strategies"][key].update(val2)
            updated += 1
        else:
            merged["strategies"][key] = val2
            added += 1
        if is_old:
            expired += 1

    summary = {
        "added": added,
        "updated": updated,
        "kept": kept,
        "expired": expired,
        "total": len(merged["strategies"]),
    }
    return merged, summary

def _ttl_cfg_from_config() -> Dict[str, int]:
    """
    Permet de surcharger le multiplicateur TTL par TF via config.yaml:
      maintainer:
        ttl_mult:
          1m: 240
          5m: 240
          15m: 192
          1h: 168
    """
    try:
        cfg = load_config()
        mt = cfg.get("maintainer", {}) or {}
        ttl = mt.get("ttl_mult") or {}
        return {str(k): int(v) for k, v in ttl.items()}
    except Exception:
        return {}

# ---------- CLI ----------

def main(argv=None) -> int:
    ap = argparse.ArgumentParser(description="Promote strategies.yml.next -> strategies.yml (merge + TTL)")
    ap.add_argument("--draft", type=str, default=None,
                    help="Chemin du draft (par défaut: reports/strategies.yml.next)")
    ap.add_argument("--final", type=str, default=None,
                    help="Chemin du fichier final (par défaut: engine/config/strategies.yml)")
    ap.add_argument("--backup", action="store_true", help="Sauvegarde du fichier final avant écrasement")
    ns = ap.parse_args(argv)

    draft_def, final_def, backups_dir = _paths()
    draft_path = Path(ns.draft or draft_def)
    final_path = Path(ns.final or final_def)

    if not draft_path.exists():
        print(f"[promote] draft introuvable: {draft_path}")
        return 1

    draft_doc = _read_json(draft_path)
    current_doc = _read_json(final_path)

    # sauvegarde
    if ns.backup and final_path.exists():
        ts = time.strftime("%Y%m%d-%H%M%S")
        bkp = backups_dir / f"strategies.{ts}.json"
        shutil.copy2(final_path, bkp)
        print(f"[promote] backup -> {bkp}")

    ttl_cfg = _ttl_cfg_from_config()
    merged, summary = _promote(draft_doc, current_doc, ttl_cfg)

    # écriture atomique
    final_path.parent.mkdir(parents=True, exist_ok=True)
    _write_json_atomic(final_path, merged)

    # trace humaine
    add, upd, kept, expd, tot = (summary[k] for k in ("added","updated","kept","expired","total"))
    print(f"[promote] OK • added={add} • updated={upd} • kept={kept} • expired={expd} • total={tot}")
    print(f"[promote] => {final_path}")

    return 0

if __name__ == "__main__":
    raise SystemExit(main())

# ===== jobs/refresh_pairs.py ===== (227 lignes, modifié 2025-08-25 17:18:51)

#!/usr/bin/env python3
# jobs/refresh_pairs.py
from __future__ import annotations

import argparse
import csv
import json
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Iterable, List

from engine.config.loader import load_config

# Exchange: CCXT si dispo sinon REST Bitget
from engine.exchange.bitget_rest import BitgetFuturesClient as BitgetRESTClient
try:
    from engine.exchange.bitget_ccxt import CCXTFuturesClient as BitgetCCXTClient  # type: ignore
    _HAS_CCXT = True
except Exception:
    _HAS_CCXT = False


# ---------- utils FS ----------

def _ensure_dir(p: Path) -> Path:
    p.mkdir(parents=True, exist_ok=True)
    return p

def _ohlcv_path(data_dir: str, symbol: str, tf: str) -> Path:
    return _ensure_dir(Path(data_dir) / "ohlcv" / symbol) / f"{tf}.csv"

def _write_csv_ohlcv(path: Path, rows: Iterable[List[float]]) -> None:
    write_header = not path.exists()
    with path.open("a", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        if write_header:
            w.writerow(["ts", "open", "high", "low", "close", "volume"])
        for r in rows:
            try:
                ts = int(r[0])
                o, h, l, c = float(r[1]), float(r[2]), float(r[3]), float(r[4])
                v = float(r[5]) if len(r) > 5 else 0.0
                w.writerow([ts, o, h, l, c, v])
            except Exception:
                continue


# ---------- exchange helpers ----------

def _fetch_ohlcv_any(ex, symbol: str, timeframe: str, limit: int = 1000) -> List[List[float]]:
    # 1) CCXT sync si dispo
    fetch = getattr(ex, "fetch_ohlcv", None)
    if callable(fetch):
        try:
            data = fetch(symbol, timeframe, limit=limit)
            return list(data or [])
        except Exception:
            pass
    # 2) REST Bitget (wrapper)
    get_klines = getattr(ex, "get_klines", None)
    if callable(get_klines):
        try:
            resp = get_klines(symbol, interval=timeframe, limit=int(limit))
            rows = resp.get("data") or []
            out: List[List[float]] = []
            for r in rows:
                try:
                    out.append([
                        int(r[0]), float(r[1]), float(r[2]), float(r[3]),
                        float(r[4]), float(r[5]) if len(r) > 5 else 0.0
                    ])
                except Exception:
                    continue
            out.sort(key=lambda x: x[0])
            return out
        except Exception:
            pass
    return []

def _list_usdt_perps_any(ex) -> List[str]:
    # CCXT: via load_markets()
    load_markets = getattr(ex, "load_markets", None)
    if callable(load_markets):
        try:
            markets = load_markets() or {}
            syms: List[str] = []
            for m in markets.values():
                sym = str(m.get("symbol") or "")
                typ = str(m.get("type") or "")
                if "USDT" in sym and typ in {"swap", "future", "perpetual"}:
                    syms.append(sym.replace("_", "").upper())
            if syms:
                return sorted(set(syms))
        except Exception:
            pass
    # REST wrapper: méthode custom facultative
    list_symbols = getattr(ex, "list_symbols", None)
    if callable(list_symbols):
        try:
            items = list_symbols() or []
            out = [str(s).replace("_", "").upper() for s in items if "USDT" in str(s).upper()]
            if out:
                return sorted(set(out))
        except Exception:
            pass
    # Fallback statique
    return ["BTCUSDT","ETHUSDT","SOLUSDT","BNBUSDT","XRPUSDT",
            "ADAUSDT","DOGEUSDT","LTCUSDT","MATICUSDT","LINKUSDT"]

def _build_exchange():
    if _HAS_CCXT:
        try:
            return BitgetCCXTClient(paper=True)  # si ton wrapper supporte paper
        except Exception:
            pass
    return BitgetRESTClient()


# ---------- scoring ----------

@dataclass
class PairScore:
    symbol: str
    vol_usd_24h: float
    atr_pct_24h: float
    score: float

def _atr_pct_estimate(ohlcv: List[List[float]]) -> float:
    if len(ohlcv) < 50:
        return 0.0
    rng = [(r[2] - r[3]) for r in ohlcv[-200:]]
    atr = sum(abs(x) for x in rng) / max(1, len(rng))
    close = float(ohlcv[-1][4])
    return (atr / close) if close > 0 else 0.0

def _score_pairs(ex, symbols: List[str], timeframe: str, limit: int) -> List[PairScore]:
    out: List[PairScore] = []
    for s in symbols:
        ohlcv = _fetch_ohlcv_any(ex, s, timeframe, limit=min(1000, limit))
        if not ohlcv:
            continue
        vol_usd = 0.0
        for r in ohlcv[-500:]:
            try:
                vol_usd += float(r[4]) * float(r[5])
            except Exception:
                pass
        atr_pct = _atr_pct_estimate(ohlcv)
        score = vol_usd * (1.0 + 10.0 * atr_pct)
        out.append(PairScore(symbol=s, vol_usd_24h=vol_usd, atr_pct_24h=atr_pct, score=score))
        time.sleep(0.03)  # anti rate‑limit léger
    out.sort(key=lambda x: x.score, reverse=True)
    return out


# ---------- watchlist IO ----------

def _save_watchlist(path: Path, scores: List[PairScore], top: int) -> None:
    selected = scores[:top] if top > 0 else scores
    doc = {
        "generated_at": int(time.time() * 1000),
        "top": [
            {
                "symbol": s.symbol,
                "vol_usd_24h": s.vol_usd_24h,
                "atr_pct_24h": s.atr_pct_24h,
                "score": s.score,
            }
            for s in selected
        ],
    }
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(json.dumps(doc, indent=2), encoding="utf-8")


# ---------- main ----------

def main(argv=None) -> int:
    ap = argparse.ArgumentParser(description="Rafraîchit watchlist + backfill OHLCV")
    ap.add_argument("--timeframe", type=str, default="5m", help="TF utilisé pour scorer la watchlist")
    ap.add_argument("--top", type=int, default=10, help="Garder les N meilleures paires (0=toutes)")
    ap.add_argument("--backfill-tfs", type=str, default="1m,5m,15m", help="TFs à backfiller")
    ap.add_argument("--limit", type=int, default=1500, help="Nombre de bougies à récupérer par TF")
    ns = ap.parse_args(argv)

    cfg = load_config()
    rt = cfg.get("runtime", {})
    data_dir = str(rt.get("data_dir") or "/notebooks/scalp_data/data")
    reports_dir = str(rt.get("reports_dir") or "/notebooks/scalp_data/reports")

    ex = _build_exchange()

    # 1) universe
    symbols = _list_usdt_perps_any(ex)
    if not symbols:
        print("[refresh] aucun symbole listé — abandon.")
        return 2

    # 2) scoring
    scores = _score_pairs(ex, symbols, ns.timeframe, ns.limit)
    if not scores:
        print("[refresh] aucun score — abandon.")
        return 3

    # 3) write watchlist
    _save_watchlist(Path(reports_dir) / "watchlist.yml", scores, ns.top)
    selected = [s.symbol for s in (scores[:ns.top] if ns.top > 0 else scores)]
    print(f"[refresh] watchlist top={ns.top}: {', '.join(selected)}")

    # 4) backfill
    tfs = [t.strip() for t in ns.backfill_tfs.split(",") if t.strip()]
    for tf in tfs:
        for sym in selected:
            ohlcv = _fetch_ohlcv_any(ex, sym, tf, limit=ns.limit)
            if not ohlcv:
                print(f"[refresh] pas de données pour {sym}:{tf}")
                continue
            _write_csv_ohlcv(_ohlcv_path(data_dir, sym, tf), ohlcv)
            time.sleep(0.02)  # anti rate‑limit

    print("[refresh] terminé.")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())

# ===== jobs/seeds_strategies.py ===== (148 lignes, modifié 2025-08-25 17:18:51)

#!/usr/bin/env python3
# jobs/seed_strategies.py
"""
Génère/actualise engine/config/strategies.yml à partir de la watchlist.

- Crée pour chaque symbole de la watchlist une stratégie EXPERIMENTAL
  (execute=false => observe-only) sur les TF demandés.
- TTL basé sur un nombre de barres (ttl_policy_bars) par niveau de risque.
- Merge non destructif par défaut (garde les entrées déjà présentes, sauf --overwrite).

Exemples:
  # seed pour 1m seulement, observe-only
  python jobs/seed_strategies.py --tfs 1m

  # seed 1m,5m pour les 15 1ers symboles de la watchlist
  python jobs/seed_strategies.py --tfs 1m,5m --top 15

  # forcer overwrite complet du fichier (remplace tout)
  python jobs/seed_strategies.py --tfs 1m,5m --overwrite
"""
from __future__ import annotations

import argparse
import json
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List

from engine.config.loader import load_config

# --- bootstrap chemin + sitecustomize ---
from pathlib import Path
import sys

ROOT = Path(__file__).resolve().parents[1]   # racine du repo
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))
try:
    import sitecustomize  # charge .env + deps + paths (si présent)
except Exception:
    pass
# --- fin bootstrap ---

# ---------- chemins ----------
def _paths() -> Dict[str, Path]:
    cfg = load_config()
    rt = cfg.get("runtime", {})
    reports_dir = Path(rt.get("reports_dir") or "/notebooks/scalp_data/reports")
    watchlist = reports_dir / "watchlist.yml"  # JSON lisible
    strat_yml = Path(__file__).resolve().parents[1] / "engine" / "config" / "strategies.yml"
    return {"watchlist": watchlist, "strategies": strat_yml}

# ---------- IO ----------
def _read_json(path: Path) -> Dict:
    if not path.exists():
        return {}
    try:
        return json.loads(path.read_text(encoding="utf-8"))
    except Exception:
        return {}

def _write_json(path: Path, doc: Dict) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(json.dumps(doc, indent=2), encoding="utf-8")

# ---------- core ----------
def _now_iso() -> str:
    return datetime.now(timezone.utc).isoformat()

def _normalize_symbol(s: str) -> str:
    return (s or "").replace("_", "").upper()

def seed_from_watchlist(tfs: List[str], top: int | None, overwrite: bool, ttl_bars_exp:int) -> int:
    P = _paths()
    wl = _read_json(P["watchlist"])
    if not wl:
        print(f"[seed] Watchlist introuvable ou vide: {P['watchlist']}")
        return 2

    symbols = [_normalize_symbol(d.get("symbol","")) for d in (wl.get("top") or []) if d.get("symbol")]
    if top:
        symbols = symbols[:top]
    if not symbols:
        print("[seed] Aucun symbole valide dans la watchlist.")
        return 3

    # doc courant (merge) ou nouveau
    if overwrite or not P["strategies"].exists():
        doc = {
            "meta": {
                "generated_at": _now_iso(),
                "note": "EXPERIMENTAL: observe-only (execute=false). TTL en nb de barres.",
                "ttl_policy_bars": {
                    "DEFAULT": 300, "LOW": 1000, "MEDIUM": 500, "HIGH": 250, "EXPERIMENTAL": ttl_bars_exp
                },
                "ttl_global_multiplier": 1.0
            },
            "strategies": {}
        }
    else:
        doc = _read_json(P["strategies"]) or {"meta": {}, "strategies": {}}
        doc.setdefault("meta", {}).setdefault("ttl_policy_bars", {"DEFAULT": 300, "EXPERIMENTAL": ttl_bars_exp})
        doc["meta"]["generated_at"] = _now_iso()
        doc["meta"].setdefault("ttl_global_multiplier", 1.0)

    strategies = doc.setdefault("strategies", {})

    created = 0
    for sym in symbols:
        for tf in tfs:
            key = f"{sym}:{tf}"
            # on n’écrase pas les entrées existantes sauf --overwrite
            if not overwrite and key in strategies:
                continue
            strategies[key] = {
                "name": "BASE_UNTESTED",
                "risk_label": "EXPERIMENTAL",
                "execute": False,                 # observe-only
                "ema_fast": 9,
                "ema_slow": 21,
                "atr_period": 14,
                "trail_atr_mult": 1.5,
                "risk_pct_equity": 0.005,
                "last_validated": _now_iso(),     # marquage initial
                # facultatif : forcer un TTL spécifique pour EXPERIMENTAL
                "ttl_bars": ttl_bars_exp
            }
            created += 1

    _write_json(P["strategies"], doc)
    print(f"[seed] OK • {created} entrées écrites • fichier: {P['strategies']}")
    return 0

# ---------- main ----------
def main(argv=None) -> int:
    ap = argparse.ArgumentParser(description="Seed strategies.yml depuis la watchlist")
    ap.add_argument("--tfs", type=str, default="1m", help="Liste de TF séparés par des virgules (ex: 1m,5m,15m)")
    ap.add_argument("--top", type=int, default=0, help="Limiter aux N premiers de la watchlist (0=illimité)")
    ap.add_argument("--overwrite", action="store_true", help="Remplace entièrement les entrées existantes")
    ap.add_argument("--ttl-bars-exp", type=int, default=120, help="TTL (nb de barres) pour EXPERIMENTAL")
    ns = ap.parse_args(argv)

    tfs = [t.strip() for t in ns.tfs.split(",") if t.strip()]
    top = int(ns.top) if ns.top and ns.top > 0 else None
    return seed_from_watchlist(tfs=tfs, top=top, overwrite=ns.overwrite, ttl_bars_exp=int(ns.ttl_bars_exp))

if __name__ == "__main__":
    raise SystemExit(main())

# ===== jobs/termboard.py ===== (152 lignes, modifié 2025-08-25 17:18:51)

#!/usr/bin/env python3
# jobs/termboard.py
from __future__ import annotations

import argparse
import json
import os
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List

# --- dépendance légère pour l'affichage terminal ---
# (si "rich" n'est pas dispo, fais:  pip install rich)
from rich.console import Console
from rich.live import Live
from rich.table import Table
from rich.panel import Panel
from rich import box


# ---------- chemins / config ----------
def _paths() -> Dict[str, Path]:
    """
    Récupère data_dir, reports_dir depuis la config si possible.
    Fallback sur /notebooks/scalp_data/.
    """
    try:
        from engine.config.loader import load_config
        cfg = load_config()
        rt = cfg.get("runtime", {}) or {}
        data = Path(rt.get("data_dir") or "/notebooks/scalp_data/data")
        reports = Path(rt.get("reports_dir") or "/notebooks/scalp_data/reports")
    except Exception:
        root = Path("/notebooks/scalp_data")
        data, reports = root / "data", root / "reports"

    strat = Path(__file__).resolve().parents[1] / "engine" / "config" / "strategies.yml"
    return {"DATA": data, "REPORTS": reports, "STRAT": strat}


def _csv_path(sym: str, tf: str, data_dir: Path) -> Path:
    return data_dir / "ohlcv" / f"{sym}USDT" / f"{tf}.csv"


def _load_strats(strat_yml: Path) -> Dict[str, Dict]:
    """
    strategies.yml stocké en JSON lisible (extension .yml).
    Retourne un dict: { "PAIR:TF": { ... } }.
    """
    try:
        return (json.loads(strat_yml.read_text(encoding="utf-8"))).get("strategies", {})  # type: ignore
    except Exception:
        return {}


# ---------- statut cellule ----------
@dataclass
class Cell:
    text: str
    color: str  # code rich (ex: 'red', 'green3', ...)


def _status(sym: str, tf: str, data_dir: Path, strats: Dict[str, Dict], age_mult: int) -> Cell:
    """
    Codes:
      MIS (gris) : CSV manquant
      OLD (rouge): CSV trop ancien
      DAT (jaune): CSV ok mais stratégie absente
      OK  (vert) : CSV ok + stratégie promue (non expirée)
    """
    p = _csv_path(sym, tf, data_dir)
    if not p.exists():
        return Cell("MIS", "grey50")

    # fraicheur: seuil = age_mult × TF
    tf_sec = {
        "1m": 60, "3m": 180, "5m": 300, "15m": 900,
        "30m": 1800, "1h": 3600, "4h": 14400
    }.get(tf, 300)
    max_age = age_mult * tf_sec
    age = time.time() - p.stat().st_mtime
    if age > max_age:
        return Cell("OLD", "red")

    key = f"{sym}USDT:{tf}"
    s = strats.get(key)
    if s and not s.get("expired"):
        return Cell("OK", "green3")

    return Cell("DAT", "yellow3")


# ---------- tableau ----------
def _build_table(symbols: List[str], tfs: List[str], data_dir: Path,
                 strats: Dict[str, Dict], age_mult: int) -> Table:
    tbl = Table(box=box.SIMPLE_HEAVY, expand=False)
    tbl.add_column("PAIR", justify="left")
    for tf in tfs:
        tbl.add_column(tf, justify="center")

    stats = {"MIS": 0, "OLD": 0, "DAT": 0, "OK": 0}
    for s in symbols:
        row = [s]
        for tf in tfs:
            c = _status(s, tf, data_dir, strats, age_mult)
            stats[c.text] += 1
            row.append(f"[{c.color}]{c.text}[/{c.color}]")
        tbl.add_row(*row)

    legend = "[grey50]MIS[/]=no data • [red]OLD[/]=stale • [yellow3]DAT[/]=data no strat • [green3]OK[/]=ready"
    tbl.caption = f"{legend}\n" \
                  f"stats • MIS={stats['MIS']} OLD={stats['OLD']} DAT={stats['DAT']} OK={stats['OK']}"
    return tbl


# ---------- main ----------
def main() -> int:
    ap = argparse.ArgumentParser(description="Termboard: état pairs×TF (console)")
    ap.add_argument("--symbols", default="ETH,BTC,SOL,XRP,LINK,ADA,DOGE,BNB,LTC",
                    help="Liste de tickers (sans USDT), ex: ETH,BTC,SOL")
    ap.add_argument("--tfs", default="1m,5m,15m", help="Timeframes séparés par des virgules")
    ap.add_argument("--refresh", type=float, default=2.0, help="Période de rafraîchissement (s)")
    ap.add_argument("--age-mult", type=int, default=5, help="Multiple de TF accepté avant OLD")
    args = ap.parse_args()

    syms = [s.strip().upper() for s in args.symbols.split(",") if s.strip()]
    tfs = [t.strip() for t in args.tfs.split(",") if t.strip()]

    P = _paths()
    DATA, STRAT = P["DATA"], P["STRAT"]

    console = Console()
    # calcul raisonnable pour Live.refresh_per_second
    rps = max(1, int(1 / max(0.2, args.refresh)))

    with Live(console=console, refresh_per_second=rps):
        while True:
            strats = _load_strats(STRAT)
            title = (
                f"=== ORCHESTRATOR (TUI) ===\n"
                f"DATA_DIR={DATA}\n"
                f"refresh={args.refresh}s  tfs={','.join(tfs)}  age_mult×TF={args.age_mult}"
            )
            table = _build_table(syms, tfs, DATA, strats, args.age_mult)
            console.clear()
            console.print(Panel(table, title=title, border_style="cyan"))
            time.sleep(args.refresh)


if __name__ == "__main__":
    raise SystemExit(main())

# ===== jobs/viewer.py ===== (163 lignes, modifié 2025-08-25 17:18:51)

#!/usr/bin/env python3
# jobs/viewer.py
from __future__ import annotations

import argparse
import json
import os
from pathlib import Path
from typing import Any, Dict, Iterable, List, Sequence

from engine.config.loader import load_config

# ---------- utils paths ----------

def _data_root_cfg() -> Dict[str, str]:
    cfg = load_config()
    rt = cfg.get("runtime", {})
    return {
        "data_dir": rt.get("data_dir") or "/notebooks/scalp_data/data",
        "reports_dir": rt.get("reports_dir") or "/notebooks/scalp_data/reports",
    }

def _live_dir() -> Path:
    return Path(_data_root_cfg()["data_dir"]) / "live"

def _orders_csv() -> Path:
    return _live_dir() / "orders.csv"

def _signals_csv() -> Path:
    return _live_dir() / "logs" / "signals.csv"

def _watchlist_yml() -> Path:
    return Path(_data_root_cfg()["reports_dir"]) / "watchlist.yml"

def _strategies_yml() -> Path:
    # stocké en JSON lisible (extension .yml)
    return Path(__file__).resolve().parents[1] / "engine" / "config" / "strategies.yml"

# ---------- pretty helpers ----------

def _print_table(rows: Sequence[Sequence[Any]], headers: Sequence[str] | None = None) -> None:
    if headers:
        rows = [headers, ["-"*len(h) for h in headers], *rows]
    widths = [max(len(str(r[i])) for r in rows) for i in range(len(rows[0]))] if rows else []
    for r in rows:
        line = " | ".join(str(v).ljust(widths[i]) for i, v in enumerate(r))
        print(line)

def _tail(path: Path, n: int = 20) -> List[str]:
    if not path.exists():
        return []
    try:
        # simple tail sans dépendances
        with path.open("r", encoding="utf-8", errors="ignore") as f:
            lines = f.readlines()[-n:]
        return [l.rstrip("\n") for l in lines]
    except Exception:
        return []

# ---------- viewers ----------

def cmd_watchlist(_: argparse.Namespace) -> int:
    p = _watchlist_yml()
    if not p.exists():
        print(f"(watchlist introuvable) {p}")
        return 1
    try:
        doc = json.loads(p.read_text(encoding="utf-8"))
    except Exception:
        print(f"(format non lisible) {p}")
        return 1
    top = doc.get("top") or []
    rows = []
    for d in top:
        rows.append([d.get("symbol",""), f"{float(d.get('vol_usd_24h',0.0)):.0f}", f"{float(d.get('atr_pct_24h',0.0))*100:.2f}%", f"{float(d.get('score',0.0)):.3f}"])
    _print_table(rows, headers=["SYMBOL","VOL_USD_24H","ATR% (approx)","SCORE"])
    return 0

def cmd_strategies(_: argparse.Namespace) -> int:
    p = _strategies_yml()
    if not p.exists():
        print(f"(strategies.yml introuvable) {p}")
        return 1
    try:
        doc = json.loads(p.read_text(encoding="utf-8"))
    except Exception:
        print(f"(format non lisible) {p}")
        return 1
    strat = doc.get("strategies") or {}
    rows = []
    for k, v in strat.items():
        rows.append([
            k,
            v.get("ema_fast",""),
            v.get("ema_slow",""),
            v.get("atr_period",""),
            v.get("trail_atr_mult",""),
            v.get("risk_pct_equity",""),
        ])
    rows.sort(key=lambda r: r[0])
    _print_table(rows, headers=["PAIR:TF","ema_fast","ema_slow","atr_period","trail_mult","risk_pct"])
    return 0

def cmd_tail_orders(ns: argparse.Namespace) -> int:
    p = _orders_csv()
    lines = _tail(p, ns.lines)
    if not lines:
        print(f"(pas de contenu) {p}")
        return 0
    print(f"# {p}")
    for ln in lines:
        print(ln)
    return 0

def cmd_tail_signals(ns: argparse.Namespace) -> int:
    p = _signals_csv()
    lines = _tail(p, ns.lines)
    if not lines:
        print(f"(pas de contenu) {p}")
        return 0
    print(f"# {p}")
    for ln in lines:
        print(ln)
    return 0

def cmd_status(_: argparse.Namespace) -> int:
    dr = _data_root_cfg()
    print("=== STATUS ===")
    print("DATA_DIR    :", dr["data_dir"])
    print("REPORTS_DIR :", dr["reports_dir"])
    wl = _watchlist_yml()
    st = _strategies_yml()
    od = _orders_csv()
    sg = _signals_csv()
    print("watchlist   :", wl, "(ok)" if wl.exists() else "(absent)")
    print("strategies  :", st, "(ok)" if st.exists() else "(absent)")
    print("orders.csv  :", od, f"(tail {len(_tail(od,1)) and 'non-vide' or 'vide'})")
    print("signals.csv :", sg, f"(tail {len(_tail(sg,1)) and 'non-vide' or 'vide'})")
    return 0

# ---------- main ----------

def main(argv: Iterable[str] | None = None) -> int:
    ap = argparse.ArgumentParser(description="Mini viewer scalp")
    sub = ap.add_subparsers(dest="cmd", required=True)

    sub.add_parser("status", help="Résumé chemins + présence des fichiers").set_defaults(func=cmd_status)
    sub.add_parser("watchlist", help="Affiche la watchlist top N").set_defaults(func=cmd_watchlist)
    sub.add_parser("strategies", help="Affiche les stratégies promues").set_defaults(func=cmd_strategies)

    p1 = sub.add_parser("orders", help="Tail des ordres (paper ou réel)")
    p1.add_argument("--lines", type=int, default=30)
    p1.set_defaults(func=cmd_tail_orders)

    p2 = sub.add_parser("signals", help="Tail des signaux prix live")
    p2.add_argument("--lines", type=int, default=30)
    p2.set_defaults(func=cmd_tail_signals)

    ns = ap.parse_args(argv)
    return int(ns.func(ns))

if __name__ == "__main__":
    raise SystemExit(main())

# ===== pytest.ini ===== (3 lignes, modifié 2025-08-25 17:18:51)

[pytest]
addopts = -q

# ===== requirements-dev.txt ===== (2 lignes, modifié 2025-08-25 17:18:51)

annulé

# ===== requirements.txt ===== (23 lignes, modifié 2025-08-25 17:18:51)

# --- Core ---
pandas>=2.0
numpy>=1.24
pyyaml>=6.0
requests>=2.31
tqdm>=4.66

# --- Async / IO ---
aiohttp>=3.9
websockets>=11.0

# --- Console / UI ---
rich>=13.7
streamlit>=1.36
plotly>=5.20
matplotlib>=3.8

# --- Notifications (si Telegram) ---
python-telegram-bot>=20.3

# --- Optionnel (laisse commenté si REST-only) ---
# ccxt>=4.0
# uvloop>=0.19 ; platform_system == "Linux"

# ===== run-dash.sh ===== (6 lignes, modifié 2025-08-25 17:18:51)

#!/bin/bash
cd "$(dirname "$0")"
echo "[*] Lancement du dashboard Streamlit..."
# tente python -m pip install -r si jamais le bootstrap n'a pas tourné
python -m pip install -r requirements.txt >/dev/null 2>&1 || true
streamlit run dash/app.py --server.port 8501 --server.headless true

# ===== scalper/config/__init__.py ===== (3 lignes, modifié 2025-08-25 17:18:51)

from .loader import load_settings
__all__ = ['load_settings']

# ===== scalper/config/loader.py ===== (136 lignes, modifié 2025-08-25 17:18:51)

# scalp/config/loader.py
from __future__ import annotations
import os, json
from typing import Any, Dict, Tuple

# YAML est recommandé, mais on fallback proprement si PyYAML n'est pas installé
try:
    import yaml  # type: ignore
except Exception:
    yaml = None  # fallback JSON si besoin

# dotenv (facultatif) pour charger un .env automatiquement
try:
    from dotenv import load_dotenv  # type: ignore
except Exception:
    load_dotenv = None

# ---------------- Utils ----------------

def _parse_bool(x: Any, default: bool = False) -> bool:
    if isinstance(x, bool): return x
    s = str(x).strip().lower()
    if s in ("1","true","yes","y","on"): return True
    if s in ("0","false","no","n","off",""): return False
    return default

def _parse_float(x: Any, default: float | None = None) -> float | None:
    try: return float(x)
    except Exception: return default

def _parse_int(x: Any, default: int | None = None) -> int | None:
    try: return int(str(x).strip())
    except Exception: return default

def _parse_csv(x: Any) -> list[str]:
    if x is None: return []
    if isinstance(x, (list, tuple)): return [str(v).strip() for v in x if str(v).strip()]
    return [t.strip() for t in str(x).replace(" ", "").split(",") if t.strip()]

def _read_yaml(path: str) -> Dict[str, Any]:
    if not os.path.exists(path): return {}
    with open(path, "r", encoding="utf-8") as f:
        if yaml:
            return yaml.safe_load(f) or {}
        # fallback JSON si quelqu’un met du JSON dans config.yml (rare mais safe)
        try:
            return json.load(f)
        except Exception:
            raise RuntimeError(f"Impossible de lire {path}: installe PyYAML (`pip install pyyaml`) ou fournis du JSON valide.")

def _merge_dict(a: Dict[str, Any], b: Dict[str, Any]) -> Dict[str, Any]:
    # shallow merge suffisant ici (structure plate)
    out = dict(a)
    out.update({k: v for k, v in b.items() if v is not None})
    return out

# ---------------- Public API ----------------

def load_settings(
    config_path: str = "config.yml",
    config_local_path: str = "config.local.yml",
) -> Tuple[Dict[str, Any], Dict[str, Any]]:
    """
    Retourne (config_runtime, secrets) :
      - config_runtime : paramètres de stratégie / exécution (OK pour versionner)
      - secrets        : clés API & tokens (NE PAS versionner)
    Priorité : config.yml < config.local.yml < ENV (non sensibles)
    Secrets proviennent EXCLUSIVEMENT de l'ENV (.env)
    """
    # 1) .env (pour secrets & env non sensibles). Faculatif.
    if load_dotenv is not None:
        load_dotenv(override=False)

    # 2) Charge YAML (config.yml + override local)
    base = _read_yaml(config_path)
    local = _read_yaml(config_local_path)
    cfg = _merge_dict(base, local)

    # 3) Overlay ENV **non sensibles** (permet de surcharger sans toucher au YAML)
    env_overlay: Dict[str, Any] = {}
    # Verbosité
    env_overlay["QUIET"] = _parse_bool(os.getenv("QUIET", cfg.get("QUIET", 0)), bool(cfg.get("QUIET", 0)))
    env_overlay["PRINT_OHLCV_SAMPLE"] = _parse_bool(os.getenv("PRINT_OHLCV_SAMPLE", cfg.get("PRINT_OHLCV_SAMPLE", 0)),
                                                    bool(cfg.get("PRINT_OHLCV_SAMPLE", 0)))
    # Runtime / Stratégie
    env_overlay["TIMEFRAME"] = os.getenv("TIMEFRAME", cfg.get("TIMEFRAME", "5m"))
    env_overlay["CASH"] = _parse_float(os.getenv("CASH", cfg.get("CASH", 10000)), cfg.get("CASH", 10000))
    env_overlay["RISK_PCT"] = _parse_float(os.getenv("RISK_PCT", cfg.get("RISK_PCT", 0.5)), cfg.get("RISK_PCT", 0.5))
    env_overlay["SLIPPAGE_BPS"] = _parse_float(os.getenv("SLIPPAGE_BPS", cfg.get("SLIPPAGE_BPS", 0)), cfg.get("SLIPPAGE_BPS", 0))
    # Watchlist
    env_overlay["WATCHLIST_MODE"] = os.getenv("WATCHLIST_MODE", cfg.get("WATCHLIST_MODE", "static"))
    env_overlay["WATCHLIST_LOCAL_CONC"] = _parse_int(
        os.getenv("WATCHLIST_LOCAL_CONC", cfg.get("WATCHLIST_LOCAL_CONC", 4)), cfg.get("WATCHLIST_LOCAL_CONC", 4)
    )
    env_overlay["TOP_SYMBOLS"] = _parse_csv(os.getenv("TOP_SYMBOLS", cfg.get("TOP_SYMBOLS")))
    env_overlay["TOP_CANDIDATES"] = _parse_csv(os.getenv("TOP_CANDIDATES", cfg.get("TOP_CANDIDATES")))
    # Caps (optionnel) : on accepte YAML (dict) ou ENV JSON
    caps_env = os.getenv("CAPS_JSON")
    if caps_env:
        try:
            env_overlay["CAPS"] = json.loads(caps_env)
        except Exception:
            env_overlay["CAPS"] = cfg.get("CAPS", {})
    else:
        env_overlay["CAPS"] = cfg.get("CAPS", {})

    # 4) Secrets UNIQUEMENT via ENV (jamais via YAML)
    secrets = {
        "BITGET_API_KEY": os.getenv("BITGET_API_KEY", ""),
        "BITGET_API_SECRET": os.getenv("BITGET_API_SECRET", ""),
        "BITGET_API_PASSWORD": os.getenv("BITGET_API_PASSWORD", ""),
        "BITGET_USE_TESTNET": _parse_bool(os.getenv("BITGET_USE_TESTNET", os.getenv("BITGET_TESTNET", "1")), True),
        "BITGET_PRODUCT": os.getenv("BITGET_PRODUCT", "umcbl"),
        "TELEGRAM_BOT_TOKEN": os.getenv("TELEGRAM_BOT_TOKEN", ""),
        "TELEGRAM_CHAT_ID": os.getenv("TELEGRAM_CHAT_ID", ""),
    }

    # 5) Runtime normalisé pour l’orchestrateur
    runtime = {
        "quiet": bool(env_overlay["QUIET"]),
        "print_sample": bool(env_overlay["PRINT_OHLCV_SAMPLE"]),
        "timeframe": str(env_overlay["TIMEFRAME"]),
        "cash": float(env_overlay["CASH"]),
        "risk_pct": float(env_overlay["RISK_PCT"]),
        "slippage_bps": float(env_overlay["SLIPPAGE_BPS"]),
        "watchlist_mode": str(env_overlay["WATCHLIST_MODE"]),
        "watchlist_local_conc": int(env_overlay["WATCHLIST_LOCAL_CONC"]),
        "top_symbols": env_overlay["TOP_SYMBOLS"],          # list[str]
        "top_candidates": env_overlay["TOP_CANDIDATES"],    # list[str]
        "caps": env_overlay["CAPS"],                        # dict
        # rempli au boot par les frais Bitget
        "fees_by_symbol": {}, 
    }

    return runtime, secrets
    

# ===== scalper/config/strategies.yml ===== (14 lignes, modifié 2025-08-25 17:18:51)

# scalper/config/strategies.yml
default: current
by_timeframe:
  "1m": current
  "5m": current
  "15m": current
  "1h": current
by_symbol:
  BTCUSDT:
    "1m": current
    "5m": current
  ETHUSDT:
    "5m": current

# ===== scalper/exchange/__init__.py ===== (2 lignes, modifié 2025-08-25 17:18:51)

# Rend le sous-package exchanges importable
__all__ = ["bitget"]

# ===== scalper/exchange/bitget.py ===== (107 lignes, modifié 2025-08-25 17:18:51)

# scalper/exchange/bitget.py
from __future__ import annotations
import os
import requests
from typing import List, Dict, Any

BASE_URL = "https://api.bitget.com"

# Spot: period strings
_SPOT_PERIOD = {
    "1m": "1min", "3m": "3min", "5m": "5min", "15m": "15min", "30m": "30min",
    "1h": "1hour", "4h": "4hour", "6h": "6hour", "12h": "12hour",
    "1d": "1day", "3d": "3day", "1w": "1week",
}
# Mix: granularity seconds
_MIX_GRAN = {
    "1m": 60, "3m": 180, "5m": 300, "15m": 900, "30m": 1800,
    "1h": 3600, "4h": 14400, "6h": 21600, "12h": 43200,
    "1d": 86400, "3d": 259200, "1w": 604800,
}

def _market_from_symbol(symbol: str) -> str:
    s = symbol.upper()
    if s.endswith("_SPBL"):
        return "spot"
    if s.endswith("_UMCBL"):
        return "umcbl"
    if s.endswith("_DMCBL"):
        return "dmcbl"
    if s.endswith("_CMCBL"):
        return "cmcbl"
    # fallback env / défaut umcbl
    return os.getenv("BITGET_MARKET", "umcbl").lower()

def _product_type(market: str) -> str:
    # valeur attendue par les endpoints mix (umcbl/dmcbl/cmcbl)
    if market in ("umcbl", "dmcbl", "cmcbl"):
        return market
    return "umcbl"

class BitgetExchange:
    """
    Wrapper simple: get_ohlcv(symbol, timeframe, limit) -> [[ts, o, h, l, c, v], ...]
    symbol spot ex: BTCUSDT_SPBL
    symbol perp ex: BTCUSDT_UMCBL / BTCUSD_DMCBL / BTCUSD_CMCBL
    """
    def __init__(self, api_key: str = "", api_secret: str = "", api_passphrase: str = "", timeout: int = 20) -> None:
        self.session = requests.Session()
        self.session.headers.update({"User-Agent": "scalp-bot/1.0"})
        self.timeout = timeout

    def _get(self, path: str, params: Dict[str, Any]) -> Dict[str, Any]:
        url = BASE_URL + path
        r = self.session.get(url, params=params, timeout=self.timeout)
        r.raise_for_status()
        data = r.json()
        # Bitget: {"code":"00000","msg":"success","requestTime":..., "data":[...]}
        if not isinstance(data, dict) or str(data.get("code")) not in ("00000", "0", "200"):
            raise RuntimeError(f"Bitget error payload: {data}")
        return data

    def get_ohlcv(self, symbol: str, timeframe: str = "5m", limit: int = 500) -> List[List[float]]:
        timeframe = timeframe.lower()
        mkt = _market_from_symbol(symbol)

        if mkt == "spot":
            period = _SPOT_PERIOD.get(timeframe)
            if not period:
                raise ValueError(f"timeframe spot non supporté: {timeframe}")
            # Bitget spot: limit max souvent 1000
            lim = max(1, min(int(limit), 1000))
            params = {"symbol": symbol, "period": period, "limit": lim}
            data = self._get("/api/spot/v1/market/candles", params=params)
            rows = data.get("data") or []
            out: List[List[float]] = []
            # Bitget renvoie décroissant -> on inverse
            for r in reversed(rows):
                ts = int(r[0]); o, h, l, c = map(float, r[1:5]); v = float(r[5])
                out.append([ts, o, h, l, c, v])
            return out

        # MIX (umcbl/dmcbl/cmcbl)
        gran = _MIX_GRAN.get(timeframe)
        if not gran:
            raise ValueError(f"timeframe mix non supporté: {timeframe}")

        # Bitget mix: limit max souvent 200, granularity en secondes, productType parfois requis
        lim = max(1, min(int(limit), 200))
        params = {
            "symbol": symbol,
            "granularity": int(gran),
            "limit": lim,
            "productType": _product_type(mkt),
        }

        # essais: candles -> history-candles (certaines régions)
        try:
            data = self._get("/api/mix/v1/market/candles", params=params)
        except requests.HTTPError:
            data = self._get("/api/mix/v1/market/history-candles", params=params)

        rows = data.get("data") or []
        out: List[List[float]] = []
        for r in reversed(rows):
            ts = int(r[0]); o, h, l, c = map(float, r[1:5]); v = float(r[5])
            out.append([ts, o, h, l, c, v])
        return out

# ===== scalper/exchange/bitget_ccxt.py ===== (177 lignes, modifié 2025-08-25 17:18:51)

# scalper/exchange/bitget_ccxt.py
from __future__ import annotations

import asyncio
import csv
import os
import time
from typing import Any, List, Optional

# CCXT async
try:
    import ccxt.async_support as ccxt
except Exception as e:  # noqa: BLE001
    raise RuntimeError("CCXT n'est pas installé. Fais `pip install ccxt`.") from e


def _now_ms() -> int:
    return int(time.time() * 1000)


class BitgetExchange:
    """
    Échange Bitget via CCXT (async) avec cache CSV local.
    - Orienté SPOT pour simplifier (BTCUSDT, ETHUSDT, ...).
    - fetch_ohlcv(symbol, timeframe, limit) -> list[list] façon CCXT:
        [[ts, open, high, low, close, volume], ...]
    """

    def __init__(
        self,
        *,
        api_key: Optional[str] = None,
        secret: Optional[str] = None,
        password: Optional[str] = None,  # Bitget a souvent "password" (API passphrase)
        data_dir: str = "/notebooks/data",
        use_cache: bool = True,
        min_fresh_seconds: int = 0,  # fraicheur minimale requise (0 = on accepte tout)
        spot: bool = True,           # True = SPOT (recommandé ici)
    ) -> None:
        self.data_dir = data_dir
        self.use_cache = use_cache
        self.min_fresh = int(min_fresh_seconds)
        self.spot = spot

        os.makedirs(self.data_dir, exist_ok=True)

        # Instance CCXT (async)
        self.ex = ccxt.bitget({
            "apiKey": api_key or "",
            "secret": secret or "",
            "password": password or "",
            "enableRateLimit": True,
            # CCXT timeframe natif (pas besoin de rajouter des headers…)
        })

        # Pré‑charge les marchés SPOT pour résoudre correctement symboles
        self._markets_task: Optional[asyncio.Task[Any]] = None

    async def _ensure_markets(self) -> None:
        if self._markets_task is None:
            self._markets_task = asyncio.create_task(self.ex.load_markets())
        await self._markets_task

    # ---------- CSV cache ----------
    def _csv_path(self, symbol: str, timeframe: str) -> str:
        safe = symbol.replace("/", "").replace(":", "")
        return os.path.join(self.data_dir, f"{safe}-{timeframe}.csv")

    def _read_cache(self, path: str) -> List[List[float]]:
        if not os.path.exists(path):
            return []
        rows: List[List[float]] = []
        try:
            with open(path, "r", newline="") as f:
                rd = csv.reader(f)
                for r in rd:
                    if not r:
                        continue
                    # ts, o, h, l, c, v
                    try:
                        rows.append([
                            int(r[0]),
                            float(r[1]),
                            float(r[2]),
                            float(r[3]),
                            float(r[4]),
                            float(r[5]),
                        ])
                    except Exception:
                        # on ignore les lignes corrompues
                        continue
        except Exception:
            return []
        return rows

    def _write_cache(self, path: str, data: List[List[float]]) -> None:
        # On ré‑écrit intégralement (simple et sûr)
        tmp = path + ".tmp"
        with open(tmp, "w", newline="") as f:
            wr = csv.writer(f)
            wr.writerows(data)
        os.replace(tmp, path)

    # ---------- API publique pour orchestrateur ----------
    async def fetch_ohlcv(
        self, symbol: str, timeframe: str, limit: int, since: Optional[int] = None
    ) -> List[List[float]]:
        """
        Conformité orchestrateur : signature (symbol, timeframe, limit).
        Retour CCXT OHLCV. Utilise cache si dispo/assez frais, sinon CCXT.
        """
        await self._ensure_markets()

        # Bitget (spot) symbol format CCXT: "BTC/USDT"
        ccxt_symbol = symbol.replace("USDT", "/USDT")
        cache_path = self._csv_path(symbol, timeframe)

        # 1) Cache
        if self.use_cache:
            cached = self._read_cache(cache_path)
            if cached:
                # fraicheur = diff entre maintenant et ts dernière bougie
                last_ts = int(cached[-1][0])
                if self.min_fresh == 0 or (_now_ms() - last_ts) <= self.min_fresh * 1000:
                    # suffisant => on retourne la fin
                    if len(cached) >= limit:
                        return cached[-limit:]
                    # pas assez, on essaiera de compléter via CCXT plus bas
                # sinon: on tentera de rafraîchir plus loin

        # 2) Remote via CCXT
        # CCXT fetch_ohlcv: since=None, limit=…  (since en ms)
        # On demande 'limit' bougies; si cache partiel, on pourra fusionner ensuite.
        params: dict[str, Any] = {}
        if self.spot is True:
            params["type"] = "spot"  # ccxt bitget accepte 'type' pour certain endpoints

        try:
            ohlcv = await self.ex.fetch_ohlcv(ccxt_symbol, timeframe, since=since, limit=limit, params=params)
        except Exception as e:  # noqa: BLE001
            # En cas d’échec remote: si on a du cache, on le renvoie quand même
            cached = self._read_cache(cache_path) if self.use_cache else []
            if cached:
                return cached[-limit:]
            raise RuntimeError(f"Bitget CCXT fetch_ohlcv failed for {symbol} {timeframe}: {e}") from e

        # 3) Merge simple cache + remote et ré‑écrit (sans doublons sur ts)
        if self.use_cache:
            base = self._read_cache(cache_path)
            merged = _merge_ohlcv(base, ohlcv)
            self._write_cache(cache_path, merged)
            # retourne la fin
            return merged[-limit:]

        return ohlcv[-limit:]

    async def close(self) -> None:
        try:
            await self.ex.close()
        except Exception:
            pass


def _merge_ohlcv(a: List[List[float]], b: List[List[float]]) -> List[List[float]]:
    """
    Fusionne deux listes OHLCV par timestamp, en écrasant a par b sur collision.
    """
    if not a:
        return list(b)
    if not b:
        return list(a)

    # index rapide par ts
    by_ts: dict[int, List[float]] = {int(row[0]): row for row in a}
    for row in b:
        by_ts[int(row[0])] = row
    return [by_ts[k] for k in sorted(by_ts)]

# ===== scalper/exchange/fees.py ===== (58 lignes, modifié 2025-08-25 17:18:51)

# scalper/exchange/fees.py
from __future__ import annotations

from typing import Dict, Iterable

# Valeurs par défaut (Bitget spot/futures ~ ordre de grandeur ; sera écrasé quand on charge les frais)
DEFAULT_TAKER_BPS = 6    # 0.06%
DEFAULT_MAKER_BPS = 2    # 0.02%

# Cache local: symbol -> {"taker_bps": int, "maker_bps": int}
_FEES_BY_SYMBOL: Dict[str, Dict[str, float]] = {}


def get_fee(symbol: str, kind: str = "taker") -> float:
    """
    Retourne le fee rate (fraction, ex 0.0006) pour 'symbol' et 'kind' ("taker" ou "maker").
    Utilise le cache alimenté par load_bitget_fees(), sinon valeurs par défaut.
    """
    rec = _FEES_BY_SYMBOL.get(symbol, {"taker_bps": DEFAULT_TAKER_BPS, "maker_bps": DEFAULT_MAKER_BPS})
    bps = rec["taker_bps"] if kind == "taker" else rec["maker_bps"]
    return float(bps) / 10_000.0


async def load_bitget_fees(exchange, symbols: Iterable[str]) -> Dict[str, Dict[str, float]]:
    """
    Tente de charger les frais auprès de l'exchange (type ccxt):
      - fetch_trading_fees(symbols) si dispo
      - sinon fetch_trading_fee(symbol) pour chaque symbole
    Remplit le cache _FEES_BY_SYMBOL avec des BPS (entiers).
    """
    symbols = list(symbols)
    fees: Dict[str, Dict[str, float]] = {}

    try:
        if hasattr(exchange, "fetch_trading_fees"):
            data = await exchange.fetch_trading_fees(symbols)
            for s in symbols:
                d = (data or {}).get(s, {}) or {}
                taker = float(d.get("taker", DEFAULT_TAKER_BPS / 10_000))
                maker = float(d.get("maker", DEFAULT_MAKER_BPS / 10_000))
                fees[s] = {"taker_bps": round(taker * 10_000), "maker_bps": round(maker * 10_000)}
        else:
            for s in symbols:
                try:
                    d = await exchange.fetch_trading_fee(s)
                except Exception:
                    d = {}
                taker = float(d.get("taker", DEFAULT_TAKER_BPS / 10_000))
                maker = float(d.get("maker", DEFAULT_MAKER_BPS / 10_000))
                fees[s] = {"taker_bps": round(taker * 10_000), "maker_bps": round(maker * 10_000)}
    except Exception:
        # fallback: défauts
        for s in symbols:
            fees[s] = {"taker_bps": DEFAULT_TAKER_BPS, "maker_bps": DEFAULT_MAKER_BPS}

    # maj du cache
    _FEES_BY_SYMBOL.update(fees)
    return fees

# ===== scalper/live/__init__.py ===== (1 lignes, modifié 2025-08-25 17:18:51)

__all__ = ["orchestrator", "fetcher", "runner"]

# ===== scalper/live/backtest_telegram.py ===== (57 lignes, modifié 2025-08-25 17:18:51)

# scalper/live/backtest_telegram.py
from __future__ import annotations

import asyncio
import os
from typing import List

from engine.backtest import BTCfg, run_multi
from engine.services.utils import safe_call

# Exchange CCXT asynchrone pour OHLCV publics (Bitget)
async def _get_exchange():
    try:
        import ccxt.async_support as ccxt  # type: ignore
    except Exception:
        raise RuntimeError("CCXT n'est pas installé. Lance: pip install ccxt")
    return ccxt.bitget()

def _parse_symbols(defaults: List[str]) -> List[str]:
    env = os.getenv("BACKTEST_SYMBOLS", "")
    if env.strip():
        return [s.strip().upper() for s in env.split(",") if s.strip()]
    return defaults

async def handle_backtest_command(notifier, defaults: List[str], timeframe: str = "5m") -> None:
    """Lancé par l'orchestrateur quand l'utilisateur tape /backtest sur Telegram."""
    symbols = _parse_symbols(defaults)
    cash = float(os.getenv("BT_CASH", "10000"))
    risk = float(os.getenv("BT_RISK_PCT", "0.05"))
    slip = float(os.getenv("BT_SLIPPAGE_BPS", "0.0"))
    limit = int(os.getenv("BT_LIMIT", "1500"))

    await notifier.send(
        "🧪 Backtest en cours...\n"
        f"• Symbols: {', '.join(symbols)}\n"
        f"• TF: {timeframe}\n"
        f"• Cash: {cash:,.0f}  • Risk: {risk:0.4f}  • Slippage: {slip:0.1f} bps\n"
        f"• Source: exchange.fetch_ohlcv (adapté) + cache CSV"
    )

    async def _run():
        exchange = await _get_exchange()
        try:
            cfg = BTCfg(symbols=symbols, timeframe=timeframe, cash=cash,
                        risk_pct=risk, slippage_bps=slip, limit=limit)
            res = await run_multi(cfg, exchange)
            await notifier.send(f"✅ Backtest terminé. Résultats: `{res['out_dir']}`")
        finally:
            try:
                await exchange.close()
            except Exception:
                pass

    try:
        await safe_call(_run, label="backtest", max_retry=1)  # 1 tir = si fail on avertit
    except Exception as e:
        await notifier.send(f"⚠️ Backtest : erreur inattendue: {e}")

# ===== scalper/live/commands.py ===== (89 lignes, modifié 2025-08-25 17:18:51)

# scalper/live/commands.py
from __future__ import annotations

import asyncio
from typing import Awaitable, Callable


class CommandHandler:
    """
    Gère les commandes reçues d'un CommandStream (Telegram ou Null).
    Chaque commande est routée vers un callback approprié.
    Les erreurs de callbacks sont capturées pour ne pas tuer l'orchestrateur.
    """

    def __init__(self, notifier, command_stream, status_getter, status_sender):
        self.notifier = notifier
        self.stream = command_stream
        self.status_getter = status_getter
        self.status_sender = status_sender

    async def _safe_call(self, coro: Awaitable[None], err_msg: str) -> None:
        try:
            await coro
        except Exception as e:
            try:
                await self.notifier.send(f"⚠️ {err_msg}: {e}")
            except Exception:
                pass  # on ne propage jamais

    async def run(
        self,
        on_pause: Callable[[], None],
        on_resume: Callable[[], None],
        on_stop: Callable[[], Awaitable[None]] | None,
        on_setup_apply: Callable[[dict], None],
        on_backtest: Callable[[str], Awaitable[None]] | None = None,
    ):
        """
        Boucle asynchrone qui lit les lignes du CommandStream
        et exécute le callback approprié.
        TOUTE exception de callback est absorbée pour ne pas terminer cette task.
        """
        async for line in self.stream:
            txt = (line or "").strip()
            if not txt:
                continue

            try:
                if txt.startswith("/pause"):
                    on_pause()
                    await self.notifier.send("⏸️ Pause.")

                elif txt.startswith("/resume"):
                    on_resume()
                    await self.notifier.send("▶️ Resume.")

                elif txt.startswith("/stop"):
                    if on_stop:
                        await self._safe_call(on_stop(), "Arrêt échoué")

                elif txt.startswith("/status"):
                    snap = self.status_getter()
                    await self.notifier.send(f"ℹ️ {snap}")

                elif txt.startswith("/setup"):
                    await self.notifier.send("🧩 Setup wizard à compléter.")

                elif txt.startswith("/backtest"):
                    if on_backtest:
                        tail = txt[len("/backtest"):].strip()
                        # IMPORTANT : on ne bloque PAS la boucle de commandes.
                        asyncio.create_task(self._safe_call(
                            on_backtest(tail), "Backtest échoué"
                        ))
                        await self.notifier.send("🧪 Backtest lancé en tâche de fond.")
                    else:
                        await self.notifier.send("⚠️ Backtest non disponible.")

                else:
                    await self.notifier.send(
                        "❓ Commandes: /status /pause /resume /stop /setup /backtest"
                    )

            except Exception as e:
                # On protège la boucle quoi qu'il arrive
                try:
                    await self.notifier.send(f"⚠️ Erreur commande: {e}")
                except Exception:
                    pass

# ===== scalper/live/data_utils.py ===== (51 lignes, modifié 2025-08-25 17:18:51)

# scalper/live/data_utils.py
from __future__ import annotations
from typing import Dict, List, Sequence

Cols = ("timestamp", "open", "high", "low", "close", "volume")

def ohlcv_rows_to_dict(rows: Sequence[Sequence[float]]) -> Dict[str, List[float]]:
    """
    Convertit [[ts,o,h,l,c,v], ...] -> dict de listes.
    Tolère float|int|str numériques.
    """
    out: Dict[str, List[float]] = {k: [] for k in Cols}
    for r in rows:
        if len(r) < 6:
            raise ValueError("Ligne OHLCV invalide (6 colonnes attendues).")
        out["timestamp"].append(float(r[0]))
        out["open"].append(float(r[1]))
        out["high"].append(float(r[2]))
        out["low"].append(float(r[3]))
        out["close"].append(float(r[4]))
        out["volume"].append(float(r[5]))
    return out

def ohlcv_df_or_dict_to_dict(obj) -> Dict[str, List[float]]:
    """
    Accepte:
      - pandas.DataFrame avec colonnes Cols
      - dict de listes
    """
    if hasattr(obj, "columns"):
        missing = [c for c in Cols if c not in obj.columns]
        if missing:
            raise ValueError(f"Colonnes OHLCV manquantes: {missing}")
        return {k: [float(x) for x in obj[k].tolist()] for k in Cols}
    if isinstance(obj, dict):
        missing = [c for c in Cols if c not in obj]
        if missing:
            raise ValueError(f"Clés OHLCV manquantes: {missing}")
        return {k: [float(x) for x in obj[k]] for k in Cols}
    raise TypeError("Format OHLCV non supporté (DataFrame ou dict attendu).")

def map_index_secondary(ts_main: float, ts_arr: List[float]) -> int:
    """
    Retourne l'index i du timestamp secondaire le plus proche
    inférieur/égal à ts_main. Recherche linéaire suffisante en live.
    """
    j = 0
    n = len(ts_arr)
    while j + 1 < n and ts_arr[j + 1] <= ts_main:
        j += 1
    return j

# ===== scalper/live/fetcher.py ===== (56 lignes, modifié 2025-08-25 17:18:51)

# scalper/live/fetcher.py
from __future__ import annotations
from typing import Dict, List, Optional, Any

class DataFetcher:
    """
    Récupération OHLCV depuis un client d'exchange.
    Compatible:
      - Wrapper custom: client.get_ohlcv(symbol, timeframe, limit)
      - ccxt direct:    client.fetch_ohlcv(symbol, timeframe=..., limit=...)
    Retour standardisé: dict[str, list[float]] avec clés:
      timestamp, open, high, low, close, volume
    """
    def __init__(self, client: Any) -> None:
        self.client = client
        # Détection des méthodes disponibles
        self._has_get = hasattr(client, "get_ohlcv")
        self._has_fetch = hasattr(client, "fetch_ohlcv")

        if not (self._has_get or self._has_fetch):
            raise AttributeError(
                "Le client exchange doit exposer get_ohlcv(...) ou fetch_ohlcv(...). "
                "Ex: wrapper custom ou objet ccxt.bitget."
            )

    @staticmethod
    def _to_dict(rows: List[List[float]]) -> Dict[str, List[float]]:
        cols = ("timestamp", "open", "high", "low", "close", "volume")
        out = {k: [] for k in cols}
        for r in rows:
            # rows: [ts, open, high, low, close, volume]
            out["timestamp"].append(float(r[0]))
            out["open"].append(float(r[1]))
            out["high"].append(float(r[2]))
            out["low"].append(float(r[3]))
            out["close"].append(float(r[4]))
            out["volume"].append(float(r[5]))
        return out

    def fetch(self, symbol: str, timeframe: str, limit: int = 1500) -> Dict[str, List[float]]:
        if self._has_get:
            rows = self.client.get_ohlcv(symbol=symbol, timeframe=timeframe, limit=limit)
        else:
            # ccxt: fetch_ohlcv(symbol, timeframe=..., limit=...)
            rows = self.client.fetch_ohlcv(symbol, timeframe=timeframe, limit=limit)
        return self._to_dict(rows)

    def try_fetch_1h(self, symbol: str, limit: int = 1500) -> Optional[Dict[str, List[float]]]:
        try:
            if self._has_get:
                rows = self.client.get_ohlcv(symbol=symbol, timeframe="1h", limit=limit)
            else:
                rows = self.client.fetch_ohlcv(symbol, timeframe="1h", limit=limit)
            return self._to_dict(rows)
        except Exception:
            return None

# ===== scalper/live/journal.py ===== (20 lignes, modifié 2025-08-25 17:18:51)

from __future__ import annotations
import os, csv
from typing import Any, Dict, List

class LogWriter:
    """Gestion simple des CSV (création à la volée + append)."""
    def __init__(self, dirpath: str) -> None:
        self.dir = dirpath
        os.makedirs(self.dir, exist_ok=True)

    def init(self, fname: str, headers: List[str]) -> None:
        p = os.path.join(self.dir, fname)
        if not os.path.exists(p):
            with open(p, "w", newline="", encoding="utf-8") as f:
                csv.DictWriter(f, fieldnames=headers).writeheader()

    def row(self, fname: str, row: Dict[str, Any]) -> None:
        p = os.path.join(self.dir, fname)
        with open(p, "a", newline="", encoding="utf-8") as f:
            csv.DictWriter(f, fieldnames=list(row.keys())).writerow(row)

# ===== scalper/live/logs.py ===== (22 lignes, modifié 2025-08-25 17:18:51)

# scalp/live/logs.py
from __future__ import annotations
import os, csv
from typing import Any, List, Dict

class CsvLog:
    def __init__(self, path: str, headers: List[str]):
        self.path = path
        self.headers = headers
        self._ensure_header()

    def _ensure_header(self):
        must_write = not os.path.exists(self.path) or os.path.getsize(self.path) == 0
        os.makedirs(os.path.dirname(self.path), exist_ok=True)
        if must_write:
            with open(self.path, "w", newline="") as f:
                csv.writer(f).writerow(self.headers)

    def write_row(self, row: Dict[str, Any]):
        with open(self.path, "a", newline="") as f:
            w = csv.DictWriter(f, fieldnames=self.headers)
            w.writerow({k: row.get(k, "") for k in self.headers})

# ===== scalper/live/loops/trade.py ===== (138 lignes, modifié 2025-08-25 17:18:51)

# scalp/live/loops/trade.py
from __future__ import annotations
import asyncio, os
from dataclasses import dataclass, field
from typing import Any, Dict, List, Callable

from ...services.utils import safe_call
from ...risk.manager import compute_size

QUIET = int(os.getenv("QUIET", "0") or "0")
PRINT_OHLCV_SAMPLE = int(os.getenv("PRINT_OHLCV_SAMPLE", "0") or "0")

class PositionFSM:
    def __init__(self):
        self.state = "FLAT"
        self.side = "flat"
        self.entry = 0.0
        self.qty = 0.0
    def can_open(self): return self.state == "FLAT"
    def on_open(self, side, entry, qty): self.state, self.side, self.entry, self.qty = "OPEN", side, entry, qty
    def can_close(self): return self.state == "OPEN"
    def on_close(self): self.state, self.side, self.entry, self.qty = "FLAT", "flat", 0.0, 0.0

@dataclass
class SymbolContext:
    symbol: str
    timeframe: str
    ohlcv: List[List[float]] = field(default_factory=list)
    ticks: int = 0
    fsm: PositionFSM = field(default_factory=PositionFSM)

class TradeLoop:
    """
    Boucle par symbole, indépendante de l'orchestrateur.
    """
    def __init__(
        self,
        symbol: str,
        timeframe: str,
        ohlcv_fetch: Callable[..., Any],           # async fn(symbol, timeframe, limit) -> ohlcv
        order_market: Callable[..., Any],          # async fn(symbol, side, qty) -> order dict
        generate_signal: Callable[[List[List[float]], Dict[str, Any]], Dict[str, Any]],
        config: Dict[str, Any],
        mode_getter: Callable[[], str],
        log_signals, log_orders, log_fills,
        tick_counter_add: Callable[[int], None],
    ):
        self.symbol = symbol
        self.timeframe = timeframe
        self.fetch = ohlcv_fetch
        self.order_market = order_market
        self.generate_signal = generate_signal
        self.config = config
        self.get_mode = mode_getter
        self.log_signals = log_signals
        self.log_orders = log_orders
        self.log_fills = log_fills
        self.ctx = SymbolContext(symbol, timeframe)
        self._tick_add = tick_counter_add

        # Risk/frais
        self.risk_pct = float(self.config.get("risk_pct", 0.5))
        self.caps_by_symbol = self.config.get("caps", {})  # dict optionnel
        self.fees_map = self.config.get("fees_by_symbol", {})  # {sym: {"maker_bps":..., "taker_bps":...}}
        self.slippage_bps = float(self.config.get("slippage_bps", 0.0))

    def _bps_for(self, order_type: str = "market") -> float:
        # market -> taker; limit post-only -> maker
        per = self.fees_map.get(self.symbol, {})
        if order_type == "limit":
            return float(per.get("maker_bps", 0.0))
        return float(per.get("taker_bps", 0.0))

    async def run(self, running: Callable[[], bool]):
        lookback = 200
        while running():
            if self.get_mode() != "RUNNING":
                await asyncio.sleep(0.5); continue

            async def _fetch():
                return await self.fetch(self.symbol, timeframe=self.timeframe, limit=lookback+2)
            ohlcv = await safe_call(_fetch, label=f"fetch_ohlcv:{self.symbol}")
            if not ohlcv or len(ohlcv) < lookback+1:
                await asyncio.sleep(1.0); continue

            self.ctx.ohlcv = ohlcv
            self.ctx.ticks += 1
            self._tick_add(1)

            window = ohlcv[-(lookback+1):]
            ts, _o, _h, _l, c, _v = window[-1]

            try:
                sig = self.generate_signal(window, self.config) or {}
            except Exception as e:
                if not QUIET:
                    print(f"[trade:{self.symbol}] generate_signal error: {e}", flush=True)
                await asyncio.sleep(0.5); continue

            side = sig.get("side","flat"); entry = float(sig.get("entry", c)); sl = sig.get("sl"); tp = sig.get("tp")
            self.log_signals.write_row({"ts": ts, "symbol": self.symbol, "side": side, "entry": entry, "sl": sl, "tp": tp, "last": c})

            # --- Entrée (market -> taker)
            if self.ctx.fsm.state == "FLAT" and side in ("long","short"):
                balance = float(self.config.get("cash", 10_000.0))
                qty = compute_size(
                    symbol=self.symbol, price=entry or c, balance_cash=balance,
                    risk_pct=self.risk_pct, caps_by_symbol=self.caps_by_symbol
                )
                if qty > 0:
                    async def _place():
                        return await self.order_market(self.symbol, side, qty)
                    order = await safe_call(_place, label=f"order:{self.symbol}")
                    self.ctx.fsm.on_open(side, entry or c, qty)
                    self.log_orders.write_row({"ts": ts, "symbol": self.symbol, "side": side, "qty": qty,
                                               "status": "placed", "order_id": (order or {}).get("id",""), "note": f"entry taker={self._bps_for('market')}bps"})

            # --- Sortie (market -> taker)
            elif self.ctx.fsm.state == "OPEN" and (side == "flat" or (side in ("long","short") and side != self.ctx.fsm.side)):
                qty = self.ctx.fsm.qty
                exit_side = "sell" if self.ctx.fsm.side == "long" else "buy"
                async def _close():
                    return await self.order_market(self.symbol, exit_side, qty)
                order = await safe_call(_close, label=f"close:{self.symbol}")

                # fill avec slippage + frais (taker)
                price_fill = float(c)
                price_fill *= (1 + (self.slippage_bps/10000.0)) if exit_side == "buy" else (1 - (self.slippage_bps/10000.0))
                self.log_orders.write_row({"ts": ts, "symbol": self.symbol, "side": exit_side, "qty": qty,
                                           "status": "placed", "order_id": (order or {}).get("id",""), "note": f"exit taker={self._bps_for('market')}bps"})
                self.log_fills.write_row({"ts": ts, "symbol": self.symbol, "side": exit_side, "price": price_fill, "qty": qty,
                                          "order_id": (order or {}).get("id","")})
                self.ctx.fsm.on_close()

            if PRINT_OHLCV_SAMPLE and (self.ctx.ticks % 20 == 0) and not QUIET:
                print(f"[{self.symbol}] last={c} ticks={self.ctx.ticks}", flush=True)

            await asyncio.sleep(0.1 if QUIET else 0.01)

# ===== scalper/live/notify.py ===== (73 lignes, modifié 2025-08-25 17:18:51)

# -*- coding: utf-8 -*-
from __future__ import annotations
import os
import asyncio
from dataclasses import dataclass
from typing import AsyncIterator, Optional


@dataclass
class BaseNotifier:
    async def send(self, text: str) -> None:  # pragma: no cover
        print(text)


class NullNotifier(BaseNotifier):
    pass


class TelegramNotifier(BaseNotifier):
    def __init__(self, token: str, chat_id: str, session: Optional[asyncio.AbstractEventLoop]=None):
        import aiohttp  # lazy
        self._token = token
        self._chat = chat_id
        self._session: aiohttp.ClientSession | None = None

    async def _ensure(self):
        import aiohttp
        if self._session is None or self._session.closed:
            self._session = aiohttp.ClientSession()

    async def send(self, text: str) -> None:
        import aiohttp
        await self._ensure()
        # pas de markdown pour éviter les erreurs 400 de parsing
        url = f"https://api.telegram.org/bot{self._token}/sendMessage"
        payload = {"chat_id": self._chat, "text": text, "disable_web_page_preview": True}
        try:
            async with self._session.post(url, json=payload, timeout=20) as r:
                await r.text()  # on ignore la réponse pour rester simple
        except Exception:
            # on fait un fallback silencieux pour ne pas casser le bot
            print("[notify:telegram] send fail (ignored)")

    async def close(self):
        if self._session and not self._session.closed:
            await self._session.close()


class _NullCommands:
    """Itérateur async vide utilisé quand Telegram n'est pas configuré."""
    def __aiter__(self) -> AsyncIterator[str]:
        return self
    async def __anext__(self) -> str:
        await asyncio.sleep(3600)  # jamais
        raise StopAsyncIteration


async def build_notifier_and_commands(config: dict) -> tuple[BaseNotifier, AsyncIterator[str]]:
    """
    Retourne (notifier, command_stream).

    - Si TELEGRAM_BOT_TOKEN et TELEGRAM_CHAT_ID sont présents: TelegramNotifier,
      et un flux (vide) – l’orchestreur n’en a besoin que si on implémente des
      commandes interactives plus tard.
    - Sinon: NullNotifier + flux vide.
    """
    token = os.getenv("TELEGRAM_BOT_TOKEN")
    chat = os.getenv("TELEGRAM_CHAT_ID")
    if token and chat:
        print("[notify] TELEGRAM configured.")
        return TelegramNotifier(token, chat), _NullCommands()
    print("[notify] TELEGRAM not configured -> Null notifier will be used.")
    return NullNotifier(), _NullCommands()

# ===== scalper/live/ohlcv_service.py ===== (91 lignes, modifié 2025-08-25 17:18:51)

from __future__ import annotations
import time
from typing import Any, Dict, List, Optional

try:
    from engine.adapters.market_data import MarketData
except Exception:
    MarketData = None  # type: ignore

class OhlcvService:
    """Lecture/normalisation OHLCV avec fallback agressifs."""
    def __init__(self, exchange) -> None:
        self.exchange = exchange
        self.md = MarketData(exchange) if MarketData is not None else None

    @staticmethod
    def normalize_rows(rows: Any) -> List[Dict[str, float]]:
        out: List[Dict[str, float]] = []
        if not rows: return out
        for r in rows:
            if isinstance(r, dict):
                ts = int(r.get("ts") or r.get("time") or r.get("timestamp") or 0)
                o = float(r.get("open", 0.0)); h = float(r.get("high", o)); l = float(r.get("low", o)); c = float(r.get("close", o))
                v = float(r.get("volume", r.get("vol", 0.0)))
            else:
                rr = list(r)
                if len(rr) >= 6 and isinstance(rr[0], (int, float)) and rr[0] > 10**10:
                    ts, o, h, l, c = int(rr[0]), float(rr[1]), float(rr[2]), float(rr[3]), float(rr[4]); v = float(rr[5])
                else:
                    o = float(rr[0]) if len(rr) > 0 else 0.0
                    h = float(rr[1]) if len(rr) > 1 else o
                    l = float(rr[2]) if len(rr) > 2 else o
                    c = float(rr[3]) if len(rr) > 3 else o
                    v = float(rr[4]) if len(rr) > 4 else 0.0
                    ts = int(rr[5]) if len(rr) > 5 else 0
            out.append({"ts": ts, "open": o, "high": h, "low": l, "close": c, "volume": v})
        return out

    async def fetch_once(self, symbol: str, interval: str = "1m", limit: int = 100) -> List[Dict[str, float]]:
        # 1) MarketData (si dispo)
        if self.md is not None:
            try:
                d = self.md.get_ohlcv(symbol, interval, limit)
                if isinstance(d, dict) and d.get("success") and d.get("data"):
                    return self.normalize_rows(d["data"])
            except Exception:
                pass

        # 2) Exchange natif
        rows: List[Any] = []
        try:
            data = self.exchange.get_kline(symbol, interval=interval)
        except Exception:
            data = None

        if isinstance(data, dict):
            rows = (
                data.get("data") or data.get("result") or data.get("records") or
                data.get("list") or data.get("items") or data.get("candles") or []
            )
            guard = 0
            while isinstance(rows, dict) and guard < 3:
                rows = (
                    rows.get("data") or rows.get("result") or rows.get("records") or
                    rows.get("list") or rows.get("items") or rows.get("candles") or rows.get("klines") or rows.get("bars") or []
                )
                guard += 1
        elif isinstance(data, (list, tuple)):
            rows = list(data)

        out = self.normalize_rows(rows)[-limit:]
        if out: return out

        # 3) Fallback strict via ticker -> bougie synthétique
        try:
            tkr = self.exchange.get_ticker(symbol)
            items = []
            if isinstance(tkr, dict): items = tkr.get("data") or tkr.get("result") or tkr.get("tickers") or []
            elif isinstance(tkr, (list, tuple)): items = list(tkr)
            if items:
                last = items[0]
                if isinstance(last, dict):
                    p = float(last.get("lastPrice", last.get("close", last.get("markPrice", 0.0))))
                    v = float(last.get("volume", last.get("usdtVolume", last.get("quoteVolume", 0.0))))
                else:
                    seq = list(last); p = float(seq[3] if len(seq) > 3 else seq[-2]); v = float(seq[4] if len(seq) > 4 else seq[-1])
                ts = int(time.time()*1000)
                return [{"ts": ts, "open": p, "high": p, "low": p, "close": p, "volume": v}]
        except Exception:
            pass
        return []

# ===== scalper/live/orchestrator.py ===== (46 lignes, modifié 2025-08-25 17:18:51)

# scalper/live/orchestrator.py
from __future__ import annotations
import time
from typing import List, Tuple, Dict, Any
from engine.live.fetcher import DataFetcher
from engine.live.runner import JobRunner

class Orchestrator:
    def __init__(
        self,
        *,
        exchange_client: Any,
        strategies_cfg: Dict[str, Any],
        jobs: List[Tuple[str, str]],   # [(symbol, timeframe)]
        interval_sec: int = 60,
        equity: float = 1000.0,
        risk_pct: float = 0.01,
    ) -> None:
        self.fetcher = DataFetcher(exchange_client)
        self.runner = JobRunner(strategies_cfg, equity, risk_pct)
        self.jobs = [(s.upper(), tf) for s, tf in jobs]
        self.interval = max(5, int(interval_sec))

    def _tick(self) -> None:
        for symbol, tf in self.jobs:
            try:
                data = self.fetcher.fetch(symbol, tf)
                data_1h = self.fetcher.try_fetch_1h(symbol)
                sig = self.runner.run_once(symbol=symbol, timeframe=tf, ohlcv=data, ohlcv_1h=data_1h)
                if sig is None:
                    print(f"[{symbol}/{tf}] Aucun signal.")
                else:
                    d = sig.as_dict()
                    print(f"[{symbol}/{tf}] side={d['side']} entry={d['entry']:.6f} "
                          f"sl={d['sl']:.6f} tp1={d['tp1']:.6f} tp2={d['tp2']:.6f} "
                          f"score={d['score']} q={d['quality']:.2f} :: {d.get('reasons','')}")
            except Exception as e:
                print(f"[{symbol}/{tf}] ERREUR: {e}")

    def loop(self) -> None:
        print(f"[Orchestrator] jobs={self.jobs} interval={self.interval}s")
        while True:
            t0 = time.time()
            self._tick()
            dt = time.time() - t0
            time.sleep(max(0.0, self.interval - dt))

# ===== scalper/live/orders.py ===== (101 lignes, modifié 2025-08-25 17:18:51)

# live/orders.py
from __future__ import annotations
from dataclasses import dataclass
from typing import Any, Optional

from engine.services.order_service import OrderService, OrderRequest

@dataclass
class OrderResult:
    accepted: bool
    order_id: str | None = None
    status: str | None = None
    reason: str | None = None

class OrderExecutor:
    """
    Fine couche autour d'OrderService + exchange :
      - calcule l'équité USDT
      - place une entrée (risk_pct)
      - récupère les fills (normalisés)
    L'orchestrateur n’appelle plus OrderService directement.
    """

    def __init__(self, order_service: OrderService, exchange: Any, config: Any) -> None:
        self.order_service = order_service
        self.exchange = exchange
        self.config = config

    # ---------- Equity ----------
    def get_equity_usdt(self) -> float:
        equity = 0.0
        try:
            assets = self.exchange.get_assets()
            if isinstance(assets, dict):
                for a in (assets.get("data") or []):
                    if str(a.get("currency")).upper() == "USDT":
                        equity = float(a.get("equity", 0.0))
                        break
        except Exception:
            pass
        return equity

    # ---------- Entrée ----------
    def place_entry(self, *, symbol: str, side: str, price: float,
                    sl: float | None, tp: float | None, risk_pct: float) -> OrderResult:
        """
        side: 'long' | 'short'
        Retourne OrderResult(accepted, order_id, status, reason)
        """
        equity = self.get_equity_usdt()
        req = OrderRequest(symbol=symbol, side=side, price=float(price),
                           sl=(float(sl) if sl else None), tp=(float(tp) if tp else None),
                           risk_pct=float(risk_pct))
        try:
            res = self.order_service.prepare_and_place(equity, req)
            return OrderResult(accepted=bool(getattr(res, "accepted", False)),
                               order_id=getattr(res, "order_id", None),
                               status=getattr(res, "status", None),
                               reason=getattr(res, "reason", None))
        except Exception as e:
            return OrderResult(accepted=False, reason=str(e))

    # ---------- Fills ----------
    def fetch_fills(self, symbol: str, order_id: str | None, limit: int = 50) -> list[dict]:
        """
        Normalise le format en liste de dicts {orderId, tradeId, price, qty, fee}
        """
        try:
            raw = self.exchange.get_fills(symbol, order_id, limit)
        except Exception:
            return []

        items: list = []
        if isinstance(raw, dict):
            items = raw.get("data") or raw.get("result") or raw.get("fills") or []
        elif isinstance(raw, (list, tuple)):
            items = list(raw)

        out: list[dict] = []
        for f in items:
            if isinstance(f, dict):
                out.append({
                    "orderId": f.get("orderId") or f.get("order_id") or "",
                    "tradeId": f.get("tradeId") or f.get("trade_id") or "",
                    "price": float(f.get("price", f.get("fillPrice", 0.0)) or 0.0),
                    "qty": float(f.get("qty", f.get("size", f.get("fillQty", 0.0))) or 0.0),
                    "fee": float(f.get("fee", f.get("fillFee", 0.0)) or 0.0),
                })
            else:
                try:
                    seq = list(f)
                    out.append({
                        "orderId": str(seq[0]) if seq else "",
                        "tradeId": str(seq[1]) if len(seq) > 1 else "",
                        "price": float(seq[2]) if len(seq) > 2 else 0.0,
                        "qty": float(seq[3]) if len(seq) > 3 else 0.0,
                        "fee": float(seq[4]) if len(seq) > 4 else 0.0,
                    })
                except Exception:
                    continue
        return out

# ===== scalper/live/position_fsm.py ===== (108 lignes, modifié 2025-08-25 17:18:51)

# live/position_fsm.py
from __future__ import annotations
from dataclasses import dataclass
from typing import Optional, Dict, Any, List


STATE_FLAT = "FLAT"
STATE_PENDING_ENTRY = "PENDING_ENTRY"
STATE_OPEN = "OPEN"
STATE_PENDING_EXIT = "PENDING_EXIT"


@dataclass
class PositionState:
    symbol: str
    state: str = STATE_FLAT
    order_id: Optional[str] = None
    side: Optional[str] = None   # "long" | "short"
    qty: float = 0.0
    entry: float = 0.0


class PositionFSM:
    """
    FSM ultra-simple par symbole.
    - set_pending_entry(order_id, side)
    - reconcile(open_positions, fills) -> met à jour l'état à partir des données Bitget
    """

    def __init__(self, symbols: List[str]) -> None:
        self._by_symbol: Dict[str, PositionState] = {s: PositionState(s) for s in symbols}

    # -------- API utilisateur --------
    def ensure_symbol(self, symbol: str) -> None:
        if symbol not in self._by_symbol:
            self._by_symbol[symbol] = PositionState(symbol)

    def set_pending_entry(self, symbol: str, order_id: str, side: str) -> None:
        self.ensure_symbol(symbol)
        st = self._by_symbol[symbol]
        st.state = STATE_PENDING_ENTRY
        st.order_id = order_id
        st.side = side

    def mark_pending_exit(self, symbol: str) -> None:
        self.ensure_symbol(symbol)
        st = self._by_symbol[symbol]
        st.state = STATE_PENDING_EXIT

    def force_flat(self, symbol: str) -> None:
        self._by_symbol[symbol] = PositionState(symbol)

    # -------- Lecture --------
    def get(self, symbol: str) -> PositionState:
        self.ensure_symbol(symbol)
        return self._by_symbol[symbol]

    def all(self) -> Dict[str, PositionState]:
        return self._by_symbol

    # -------- Réconciliation --------
    def reconcile(self, open_positions: List[Dict[str, Any]], fills: Dict[str, List[Dict[str, Any]]]) -> None:
        """
        open_positions: liste [{symbol, side, qty, avgEntryPrice}]
        fills: dict symbol -> liste de fills [{orderId, price, qty, ...}]
        """
        # indexer positions ouvertes
        idx_open = {p["symbol"]: p for p in open_positions if float(p.get("qty", 0.0)) > 0.0}

        for sym, st in self._by_symbol.items():
            p = idx_open.get(sym)

            if st.state == STATE_PENDING_ENTRY:
                # si on voit des fills de l'ordre en attente -> OPEN
                f_list = fills.get(sym) or []
                qty_filled = sum(float(f.get("qty", 0.0)) for f in f_list if not st.order_id or str(f.get("orderId")) == str(st.order_id))
                if qty_filled > 0.0 or p:
                    st.state = STATE_OPEN
                    st.qty = float(p.get("qty", qty_filled)) if p else qty_filled
                    st.entry = float(p.get("avgEntryPrice", f_list[0].get("price", 0.0) if f_list else 0.0)) if p else \
                               float(f_list[0].get("price", 0.0)) if f_list else 0.0
            elif st.state == STATE_OPEN:
                # si plus de position ouverte -> FLAT
                if not p:
                    st.state = STATE_FLAT
                    st.order_id = None
                    st.side = None
                    st.qty = 0.0
                    st.entry = 0.0
                else:
                    st.qty = float(p.get("qty", st.qty))
                    st.entry = float(p.get("avgEntryPrice", st.entry))
            elif st.state == STATE_PENDING_EXIT:
                # si plus de position -> FLAT ; sinon reste OPEN
                if not p:
                    st.state = STATE_FLAT
                    st.order_id = None
                    st.side = None
                    st.qty = 0.0
                    st.entry = 0.0
                else:
                    st.state = STATE_OPEN  # pas encore clos
            else:
                # FLAT: si une position apparaît (cas reboot) -> OPEN
                if p:
                    st.state = STATE_OPEN
                    st.qty = float(p.get("qty", 0.0))
                    st.entry = float(p.get("avgEntryPrice", 0.0))

# ===== scalper/live/runner.py ===== (21 lignes, modifié 2025-08-25 17:18:51)

# scalper/live/runner.py
from __future__ import annotations
from typing import Dict, List, Optional
from engine.signals.factory import resolve_signal_fn

class JobRunner:
    def __init__(self, strategies_cfg: dict, equity: float, risk_pct: float) -> None:
        self.cfg = strategies_cfg
        self.equity = float(equity)
        self.risk = float(risk_pct)

    def run_once(
        self, *, symbol: str, timeframe: str,
        ohlcv: Dict[str, List[float]],
        ohlcv_1h: Optional[Dict[str, List[float]]] = None
    ):
        fn = resolve_signal_fn(symbol, timeframe, self.cfg)
        return fn(
            symbol=symbol, timeframe=timeframe, ohlcv=ohlcv,
            equity=self.equity, risk_pct=self.risk, ohlcv_1h=ohlcv_1h
        )

# ===== scalper/live/setup_wizard.py ===== (103 lignes, modifié 2025-08-25 17:18:51)

from __future__ import annotations
import asyncio, os
from dataclasses import dataclass
from typing import List, Dict, Optional, Callable
from ..signals.factory import load_signal
from ..backtest.runner import BacktestRunner
from .notify import Notifier, CommandStream

@dataclass
class SetupResult:
    strategy: str
    symbols: List[str]
    timeframes: List[str]
    risk_pct: float
    accepted: bool
    summary_path: str

class SetupWizard:
    """
    Wizard interactif Telegram avant lancement des trades.
    Utilise Notifier (send/send_menu) + CommandStream (async iterator).
    """
    def __init__(self, notifier: Notifier, cmd_stream: CommandStream,
                 ohlcv_loader_sync: Callable, out_dir: str = "out_bt_setup",
                 admin_chat_id: Optional[int]=None):
        self.notifier = notifier
        self.cmd_stream = cmd_stream
        self.loader = ohlcv_loader_sync
        self.out_dir = out_dir
        self.admin_chat_id = admin_chat_id

    async def _ask_list(self, prompt: str, choices: List[str], allow_multi=True) -> List[str]:
        await self.notifier.send_menu(prompt, choices)
        async for msg in self.cmd_stream:
            txt = msg.strip()
            if allow_multi and ("," in txt or " " in txt):
                sel = [t.strip() for t in txt.replace(" ", "").split(",") if t.strip()]
                return sel
            if txt.isdigit():
                i = int(txt)-1
                if 0 <= i < len(choices):
                    return [choices[i]]
            if txt in choices:
                return [txt]
            await self.notifier.send("Entrée invalide. Réessaie.")

    async def _ask_value(self, prompt: str, cast: Callable, default):
        await self.notifier.send(f"{prompt} (défaut: {default})")
        async for msg in self.cmd_stream:
            txt = msg.strip()
            if txt == "" or txt.lower() in ("d","defaut","default"):
                return default
            try:
                return cast(txt)
            except Exception:
                await self.notifier.send("Entrée invalide. Réessaie.")

    async def run(self, default_symbols: List[str], default_timeframes: List[str],
                  default_strategy: str="current") -> SetupResult:
        await self.notifier.send("🧪 Validation avant trading : choix strat/symbols/TF → backtest → validation.")
        # 1) stratégie
        strategies = ["current","ema_cross","vwap_break"]
        [strategy] = await self._ask_list("Choisis la stratégie :", strategies, allow_multi=False)

        # 2) symboles
        symbols = await self._ask_list("Sélectionne les symboles :", default_symbols, allow_multi=True)

        # 3) timeframes
        timeframes = await self._ask_list("Sélectionne les timeframes :", default_timeframes, allow_multi=True)

        # 4) risk %
        risk_pct = await self._ask_value("Risk % du solde (ex: 0.5 = 50%)", float, 0.5)

        # 5) période backtest
        start = await self._ask_value("Date de début (YYYY-MM-DD)", str, "2024-01-01")
        end   = await self._ask_value("Date de fin   (YYYY-MM-DD)", str, "2025-08-01")

        # 6) run backtest
        from ..backtest.cli import parse_ts
        start_ms, end_ms = parse_ts(start), parse_ts(end)
        runner = BacktestRunner(self.loader, self.out_dir, strategy,
                                cfg={}, cash=10_000.0, risk_pct=risk_pct, max_conc=6)
        res = await runner.run_all(symbols, timeframes, start_ms, end_ms)

        # 7) résumé
        sum_path = os.path.join(self.out_dir, "metrics.json")
        prop = res["proposal"]
        lines = ["**Proposition** :"]
        for sym, best in prop["per_symbol_best"].items():
            lines.append(f"• {sym}: {best['timeframe']}  score={best['score']:.3f}  PF={best['pf']:.2f}  WR={best['winrate']:.1%}  DD={best['maxdd']:.1%}")
        await self.notifier.send("\n".join(lines) + f"\nFichier: {sum_path}\n✅ Tape **ACCEPTER** pour lancer\n🔁 **MODIFIER** pour relancer\n❌ **ANNULER** pour quitter.")

        # 8) décision
        async for msg in self.cmd_stream:
            t = msg.strip().lower()
            if t in ("accepter","accept","ok","go","start"):
                await self.notifier.send("✅ Validation reçue — passage en RUNNING.")
                return SetupResult(strategy, symbols, timeframes, risk_pct, True, sum_path)
            if t in ("modifier","again","repeat"):
                return await self.run(default_symbols, default_timeframes, default_strategy=strategy)
            if t in ("annuler","cancel","stop"):
                await self.notifier.send("❌ Annulé.")
                return SetupResult(strategy, symbols, timeframes, risk_pct, False, sum_path)

# ===== scalper/live/state_store.py ===== (48 lignes, modifié 2025-08-25 17:18:51)

# live/state_store.py
from __future__ import annotations
import json, os, time, asyncio
from typing import Callable, Dict, Any

class StateStore:
    """
    Persistance légère de l'état (FSM + horodatages) dans un JSON.
    - save_state(snapshot: dict) -> écrit sur disque
    - load_state() -> dict
    - task_autosave(get_snapshot: callable) -> boucle d’auto‑save
    """

    def __init__(self, filepath: str, period_s: float = 10.0) -> None:
        self.filepath = filepath
        self.period_s = period_s
        os.makedirs(os.path.dirname(self.filepath), exist_ok=True)
        self._running = False

    # -------- I/O --------
    def save_state(self, snapshot: Dict[str, Any]) -> None:
        tmp = self.filepath + ".tmp"
        with open(tmp, "w", encoding="utf-8") as f:
            json.dump(snapshot, f, ensure_ascii=False, indent=2)
        os.replace(tmp, self.filepath)

    def load_state(self) -> Dict[str, Any]:
        if not os.path.exists(self.filepath):
            return {}
        try:
            with open(self.filepath, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}

    # -------- Autosave --------
    async def task_autosave(self, get_snapshot: Callable[[], Dict[str, Any]]):
        self._running = True
        while self._running:
            try:
                snap = get_snapshot()
                snap["saved_at"] = int(time.time() * 1000)
                self.save_state(snap)
            except Exception:
                pass
            await asyncio.sleep(self.period_s)

    def stop(self): self._running = False

# ===== scalper/live/telegram_async.py ===== (68 lignes, modifié 2025-08-25 17:18:51)

from __future__ import annotations
import time
import requests
import asyncio
from typing import Optional, Dict, Any, List


class TelegramAsync:
    """
    Client Telegram simple basé sur requests, utilisé de manière non bloquante via asyncio.to_thread.
    Sans nouvelle dépendance.
    """
    def __init__(self, token: Optional[str], chat_id: Optional[str]) -> None:
        self.token = token
        self.chat_id = chat_id
        self.base = f"https://api.telegram.org/bot{token}" if token else None
        self._offset = 0
        self._enabled = bool(token and chat_id)

    def enabled(self) -> bool:
        return self._enabled

    # ---------- sync I/O (appelées via to_thread) ----------
    def _send_message_sync(self, text: str) -> Dict[str, Any]:
        if not self._enabled:
            return {"ok": False, "reason": "disabled"}
        url = f"{self.base}/sendMessage"
        payload = {"chat_id": self.chat_id, "text": text}
        try:
            r = requests.post(url, json=payload, timeout=10)
            return r.json()
        except Exception as e:
            return {"ok": False, "error": repr(e)}

    def _get_updates_sync(self, timeout_s: int = 30) -> Dict[str, Any]:
        if not self._enabled:
            return {"ok": True, "result": []}
        url = f"{self.base}/getUpdates"
        params = {"timeout": timeout_s, "offset": self._offset}
        try:
            r = requests.get(url, params=params, timeout=timeout_s + 5)
            return r.json()
        except Exception as e:
            return {"ok": False, "error": repr(e), "result": []}

    # ---------- async wrappers ----------
    async def send_message(self, text: str) -> None:
        await asyncio.to_thread(self._send_message_sync, text)

    async def poll_commands(self, timeout_s: int = 30) -> List[Dict[str, Any]]:
        data = await asyncio.to_thread(self._get_updates_sync, timeout_s)
        if not data.get("ok"):
            return []
        out = []
        for upd in data.get("result", []):
            self._offset = max(self._offset, int(upd.get("update_id", 0)) + 1)
            msg = upd.get("message") or {}
            text = (msg.get("text") or "").strip()
            if not text:
                continue
            out.append({
                "date": msg.get("date"),
                "chat": str((msg.get("chat") or {}).get("id")),
                "text": text,
                "from": (msg.get("from") or {}).get("username") or (msg.get("from") or {}).get("first_name") or "unknown",
            })
        return out

# ===== scalper/live/watchlist.py ===== (18 lignes, modifié 2025-08-25 17:18:51)

# -*- coding: utf-8 -*-
from __future__ import annotations
from dataclasses import dataclass
from typing import List


@dataclass
class WatchlistManager:
    symbols: List[str]

    @classmethod
    def from_env_or_default(cls) -> "WatchlistManager":
        # Tu peux lire une variable d'env ici si tu veux surcharger
        default = [
            "BTCUSDT","ETHUSDT","SOLUSDT","BNBUSDT","XRPUSDT",
            "DOGEUSDT","ADAUSDT","LTCUSDT","AVAXUSDT","LINKUSDT"
        ]
        return cls(default)

# ===== sitecustomize.py ===== (24 lignes, modifié 2025-08-25 17:18:51)

# sitecustomize.py
from __future__ import annotations
import os
from pathlib import Path

# S'assurer que 'scalp' (racine du repo) est dans sys.path via import direct
# (en général déjà fait par bot.py, mais au cas où)
try:
    import sys
    ROOT = Path(__file__).resolve().parent
    if str(ROOT) not in sys.path:
        sys.path.insert(0, str(ROOT))
except Exception:
    pass

# Installer automatiquement les dépendances manquantes
try:
    from engine.utils.ensure_deps import ensure_minimal, ensure_from_requirements
    # d'abord requirements (idempotent), puis vérif minimale (streamlit, rich, etc.)
    ensure_from_requirements()
    ensure_minimal()
    print("[bootstrap] dépendances ok")
except Exception as e:
    print(f"[bootstrap] dépendances partielles: {e}")

# ===== tg_diag.py ===== (23 lignes, modifié 2025-08-25 17:18:51)

# tg_diag.py
import asyncio, os, aiohttp

TOKEN = os.getenv("TELEGRAM_TOKEN", "")
CHAT  = os.getenv("TELEGRAM_CHAT_ID", "")

async def main():
    if not TOKEN or not CHAT:
        print("❌ Manque TELEGRAM_TOKEN ou TELEGRAM_CHAT_ID dans l'env.")
        return
    url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
    payload = {"chat_id": CHAT, "text": "🔎 Test Telegram OK ?"}
    try:
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=15)) as s:
            async with s.post(url, json=payload) as r:
                body = await r.text()
                print("HTTP:", r.status)
                print("Body:", body[:500])
    except Exception as e:
        print("❌ Exception:", repr(e))

if __name__ == "__main__":
    asyncio.run(main())

# ===== tools/dump-repo.py ===== (106 lignes, modifié 2025-08-25 17:18:51)

#!/usr/bin/env python3
# scalp/tools/dump-repo.py
# -------------------------------------------------------------------
# Dump simple de /notebooks/scalp :
#   - exclut dossiers/fichiers inutiles (tests, backtest, csv, images…)
#   - inclut le code complet des fichiers restants
#   - ajoute nb lignes + date modif
#   - écrit dans notebooks/scalp/dumps/DUMP_YYYYMMDD-HHMMSS.txt
# -------------------------------------------------------------------

from __future__ import annotations
import sys, io, time
from pathlib import Path
from datetime import datetime

ROOT = Path("/notebooks/scalp")
OUT_DIR = ROOT / "dumps"
OUT_DIR.mkdir(parents=True, exist_ok=True)

# Extensions considérées comme texte utile
ALLOW_EXT = {".py", ".yml", ".yaml", ".sh", ".txt", ".md", ".ini", ".cfg"}

# Dossiers exclus
EXCLUDE_DIRS = {
    ".git", ".github", ".idea", ".vscode",
    ".ipynb_checkpoints", "__pycache__", ".mypy_cache", ".pytest_cache",
    "backups", "dumps", "dump", "build", "dist",
    "dash", "tests", "scalp0", "scalp1", "scalp2", "scalp3",
    "engine/backtest",
}

# Suffixes exclus (binaires / data lourdes)
EXCLUDE_SUFFIX = {
    ".csv", ".parquet", ".feather", ".log",
    ".gz", ".zip", ".xz", ".bz2",
    ".png", ".jpg", ".jpeg", ".gif", ".svg", ".pdf",
    ".ipynb",
}

def is_excluded(path: Path) -> bool:
    parts = path.relative_to(ROOT).parts
    if len(parts) >= 2 and f"{parts[0]}/{parts[1]}" in EXCLUDE_DIRS:
        return True
    if any(p in EXCLUDE_DIRS for p in parts):
        return True
    if path.suffix.lower() in EXCLUDE_SUFFIX:
        return True
    return False

def fmt_mtime(ts: float) -> str:
    try:
        return datetime.fromtimestamp(ts).strftime("%Y-%m-%d %H:%M:%S")
    except Exception:
        return "1970-01-01 00:00:00"

def main() -> int:
    if not ROOT.exists():
        print(f"[!] Dossier introuvable : {ROOT}", file=sys.stderr)
        return 2

    stamp = time.strftime("%Y%m%d-%H%M%S")
    out_path = OUT_DIR / f"DUMP_{stamp}.txt"

    files_info = []
    for p in ROOT.rglob("*"):
        if not p.is_file():
            continue
        if is_excluded(p):
            continue
        if p.suffix.lower() not in ALLOW_EXT:
            continue
        rel = p.relative_to(ROOT)
        try:
            code = p.read_text(encoding="utf-8", errors="ignore")
        except Exception:
            code = ""
        nlines = code.count("\n") + 1 if code else 0
        mtime = fmt_mtime(p.stat().st_mtime)
        files_info.append((str(rel), nlines, mtime, code))

    files_info.sort()

    buf = io.StringIO()
    buf.write("# ---- DUMP SCALP ----\n")
    buf.write(f"time   : {fmt_mtime(time.time())}\n")
    buf.write(f"root   : {ROOT}\n")
    buf.write(f"output : {out_path}\n\n")

    total_lines = 0
    for rel, n, mt, code in files_info:
        total_lines += n
        buf.write(f"\n# ===== {rel} ===== ({n} lignes, modifié {mt})\n\n")
        buf.write(code)
        if not code.endswith("\n"):
            buf.write("\n")

    buf.write(f"\n# ---- Résumé ----\n")
    buf.write(f"Fichiers : {len(files_info)}\n")
    buf.write(f"Lignes   : {total_lines}\n")

    out_path.write_text(buf.getvalue(), encoding="utf-8")
    print(f"[dump] écrit: {out_path} ({len(files_info)} fichiers, {total_lines} lignes)")
    return 0

if __name__ == "__main__":
    raise SystemExit(main())

# ===== tools/migrate-to-engine.py ===== (48 lignes, modifié 2025-08-25 17:18:51)

# ops/migrate_to_engine.py
from __future__ import annotations
import re, shutil
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
ENGINE = ROOT / "engine"
ENGINE.mkdir(exist_ok=True)

# 1) Déplacer anciens packages s'ils existent
CANDIDATE_PKGS = ["scalper", "scalp"]  # anciens noms possibles de package interne
for name in CANDIDATE_PKGS:
    src = ROOT / name
    if src.exists() and src.is_dir():
        dst = ENGINE
        # on déplace le contenu interne dans engine/
        for p in src.iterdir():
            dest = dst / p.name
            if dest.exists():
                continue
            shutil.move(str(p), str(dest))
        # on laisse le répertoire racine (vide) à supprimer manuellement si besoin

# 2) Mettre à jour les imports dans tout le repo (hors TRASH et .git)
PATTERNS = [
    (re.compile(r"\bscalper\."), "engine."),
    (re.compile(r"\bscalp\."), "engine."),   # ancien package interne homonyme du repo
]
def fix_file(path: Path) -> None:
    try:
        txt = path.read_text(encoding="utf-8")
    except Exception:
        return
    orig = txt
    for rx, repl in PATTERNS:
        txt = rx.sub(repl, txt)
    if txt != orig:
        path.write_text(txt, encoding="utf-8")

for p in ROOT.rglob("*.py"):
    rel = p.relative_to(ROOT)
    if any(part.startswith("TRASH_") for part in rel.parts):
        continue
    if rel.parts and rel.parts[0] in (".git",):
        continue
    fix_file(p)

print("[✓] Migration terminée. Vérifie les imports et supprime l’ancien dossier vide si présent.")

# ===== tools/trashify.py ===== (167 lignes, modifié 2025-08-25 17:18:51)

#!/usr/bin/env python3
# tools/trashify.py
"""
Ménage du dépôt : déplace les éléments legacy/ inutiles vers .trash/<TIMESTAMP>/
- DRY RUN par défaut (aucune action tant que --apply n'est pas passé)
- Liste adaptée au dump le plus récent
- Prend soin de garder le dernier dump dans dumps/
- Sécurisé : ne touche jamais .git/ ni .trash/

Usage :
  python tools/trashify.py                 # aperçu (DRY RUN)
  python tools/trashify.py --apply         # exécute les déplacements
  python tools/trashify.py --restore PATH  # restaure depuis .trash/
  python tools/trashify.py --aggressive    # inclut fichiers/dev en plus (toujours DRY tant que --apply pas présent)
"""

from __future__ import annotations
import argparse
import os
import shutil
import time
from pathlib import Path
from typing import Iterable, List

REPO_ROOT = Path(__file__).resolve().parents[1]


# --- Cibles principales (safe) ------------------------------------------------
TRASH_DIRS_SAFE = [
    "scalper",                 # ancien moteur non utilisé par bot.py
    "tests",                   # dossiers de tests obsolètes
    "data",                    # les données doivent être hors dépôt
]

TRASH_GLOBS_COMMON = [
    "**/__pycache__",          # caches py
    "**/.ipynb_checkpoints",   # artefacts jupyter
]

TRASH_FILES_SAFE = [
    "engine/core/signal.py",   # doublon vs signals.py
    "dump.txt",                # vieux dump
    "requirements-dash.txt",   # on garde un seul requirements.txt
    "requirements-dev.txt",
]

# --- Cibles 'agressives' optionnelles ----------------------------------------
TRASH_FILES_AGGRESSIVE = [
    "pytest.ini",
    ".pytest_cache",
]


# --- Helpers ------------------------------------------------------------------
def _existing(paths: Iterable[Path]) -> List[Path]:
    out: List[Path] = []
    for p in paths:
        try:
            if p.exists():
                out.append(p)
        except OSError:
            pass
    return out

def _is_protected(p: Path) -> bool:
    rp = p.resolve()
    # ne jamais toucher au repo root lui‑même, ni .git, ni .trash
    for forbid in [REPO_ROOT, REPO_ROOT / ".git", REPO_ROOT / ".trash"]:
        try:
            if rp == forbid.resolve() or str(rp).startswith(str(forbid.resolve())):
                return True
        except Exception:
            continue
    return False

def _collect_basic_targets(aggressive: bool) -> List[Path]:
    items: List[Path] = []

    # dossiers exacts
    items += _existing([REPO_ROOT / d for d in TRASH_DIRS_SAFE])

    # fichiers exacts
    base_files = TRASH_FILES_SAFE + (TRASH_FILES_AGGRESSIVE if aggressive else [])
    items += _existing([REPO_ROOT / f for f in base_files])

    # globs
    for pat in TRASH_GLOBS_COMMON:
        for p in REPO_ROOT.glob(pat):
            items.append(p)

    # filtre de sécurité
    safe = [p for p in items if not _is_protected(p)]
    # dédupliquer et trier (dossiers parents avant enfants)
    safe_sorted = sorted(set(safe), key=lambda x: (str(x).count(os.sep), str(x)))
    return safe_sorted

def _collect_old_dumps() -> List[Path]:
    """Dans dumps/, garder le fichier le plus récent et déplacer les autres."""
    d = REPO_ROOT / "dumps"
    if not d.exists() or not d.is_dir():
        return []
    files = sorted([p for p in d.glob("DUMP_*.txt") if p.is_file()],
                   key=lambda p: p.stat().st_mtime, reverse=True)
    if len(files) <= 1:
        return []
    # on garde files[0] (le plus récent), on déplace le reste
    return files[1:]

def _move_to_trash(paths: List[Path], apply: bool, label: str = "") -> None:
    if not paths:
        return
    dest_root = REPO_ROOT / ".trash" / time.strftime("%Y%m%d-%H%M%S")
    print(f"Destination: {dest_root} {label}".rstrip())
    for p in paths:
        rel = p.relative_to(REPO_ROOT)
        dest = dest_root / rel
        print(f"- {rel}  ->  .trash/{dest.relative_to(REPO_ROOT / '.trash')}")
        if apply:
            dest.parent.mkdir(parents=True, exist_ok=True)
            try:
                shutil.move(str(p), str(dest))
            except Exception as e:
                print(f"  [!] move failed: {e}")

def _restore_from_trash(src: Path) -> None:
    src = src.resolve()
    if (REPO_ROOT / ".trash") not in src.parents:
        raise SystemExit("Le chemin à restaurer doit provenir de .trash/")
    rel = src.relative_to(REPO_ROOT / ".trash")
    dest = REPO_ROOT / rel
    print(f"RESTORE  .trash/{rel} -> {rel}")
    dest.parent.mkdir(parents=True, exist_ok=True)
    shutil.move(str(src), str(dest))


# --- Main ---------------------------------------------------------------------
def main(argv: Iterable[str] | None = None) -> int:
    ap = argparse.ArgumentParser()
    ap.add_argument("--apply", action="store_true", help="Exécuter réellement (sinon DRY RUN).")
    ap.add_argument("--restore", type=str, default="", help="Chemin à restaurer depuis .trash/")
    ap.add_argument("--aggressive", action="store_true", help="Inclut aussi fichiers/dev optionnels (pytest.ini, etc.).")
    args = ap.parse_args(list(argv) if argv is not None else None)

    if args.restore:
        _restore_from_trash(Path(args.restore))
        return 0

    print(f"[trashify] Repo : {REPO_ROOT}")
    basic = _collect_basic_targets(args.aggressive)
    print(f"[trashify] Cibles de base détectées : {len(basic)}")
    _move_to_trash(basic, apply=args.apply)

    # dumps obsolètes (garde le plus récent)
    old_dumps = _collect_old_dumps()
    if old_dumps:
        print(f"[trashify] Dumps obsolètes : {len(old_dumps)} (le plus récent est conservé)")
        _move_to_trash(old_dumps, apply=args.apply, label="(dumps)")

    if not args.apply:
        print("\nDRY RUN — ajoute --apply pour déplacer réellement.")
    else:
        print("\n[✓] Déplacement terminé. Vérifie .trash/, puis commit/push si ok.")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())

# ---- Résumé ----
Fichiers : 110
Lignes   : 9121
