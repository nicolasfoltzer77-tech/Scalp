# DUMP 20250824-112618
Repo: /notebooks/scalp

================================================================================
ARBORESCENCE
================================================================================
.gitignore
CHANGELOG.md
Makefile
PROMPT.md
README.md
STRATEGY.md
bot.py
cli.py
data/
data/BTCUSDT-1m.csv
data/__init__.py
dump.txt
dumps/
dumps/DUMP_20250824-112618.txt
init.py
pytest.ini
requirements-dev.txt
requirements.txt
resultat.log
scalper/
scalper/VERSION
scalper/__init__.py
scalper/adapters/
scalper/adapters/__init__.py
scalper/adapters/bitget.py
scalper/adapters/bitget_fetch.py
scalper/adapters/market_data.py
scalper/backtest/
scalper/backtest/__init__.py
scalper/backtest/cache.py
scalper/backtest/cli.py
scalper/backtest/engine.py
scalper/backtest/grid_search.py
scalper/backtest/loader_csv.py
scalper/backtest/market_data.py
scalper/backtest/metrics.py
scalper/backtest/optimize.py
scalper/backtest/position_sizing.py
scalper/backtest/run_multi.py
scalper/backtest/runner.py
scalper/backtest/walkforward.py
scalper/bitget_client.py
scalper/client.py
scalper/config/
scalper/config/__init__.py
scalper/config/loader.py
scalper/config/strategies.yml
scalper/core/
scalper/core/indicators.py
scalper/core/signal.py
scalper/exchange/
scalper/exchange/__init__.py
scalper/exchange/bitget.py
scalper/exchange/bitget_ccxt.py
scalper/exchange/fees.py
scalper/hooks/
scalper/hooks/prewarm_cache.py
scalper/live/
scalper/live/__init__.py
scalper/live/backtest_telegram.py
scalper/live/commands.py
scalper/live/data_utils.py
scalper/live/fetcher.py
scalper/live/journal.py
scalper/live/logs.py
scalper/live/loops/
scalper/live/loops/trade.py
scalper/live/notify.py
scalper/live/ohlcv_service.py
scalper/live/orchestrator.py
scalper/live/orders.py
scalper/live/position_fsm.py
scalper/live/runner.py
scalper/live/setup_wizard.py
scalper/live/state_store.py
scalper/live/telegram_async.py
scalper/live/watchlist.py
scalper/logging_utils.py
scalper/metrics.py
scalper/pairs.py
scalper/positions/
scalper/positions/__init__.py
scalper/positions/state.py
scalper/risk/
scalper/risk/__init__.py
scalper/risk/manager.py
scalper/selection/
scalper/selection/__init__.py
scalper/selection/momentum.py
scalper/selection/scanner.py
scalper/selfcheck.py
scalper/services/
scalper/services/__init__.py
scalper/services/data_cache.py
scalper/services/order_service.py
scalper/services/utils.py
scalper/signals/
scalper/signals/__init__.py
scalper/signals/current.py
scalper/signals/factory.py
scalper/signals/generator.py
scalper/strategy/
scalper/strategy/factory.py
scalper/strategy.py
scalper/trade_utils.py
scalper/version.py
scalper/ws.py
sitecustomize.py
tests/
tests/conftest.py
tests/test_analyse_risque.py
tests/test_backtest.py
tests/test_backtest_multi.py
tests/test_backtest_position.py
tests/test_bitget_futures_pairs.py
tests/test_bot_place_order_caps.py
tests/test_bot_update.py
tests/test_break_even_stop.py
tests/test_calc_pnl_pct.py
tests/test_check_config.py
tests/test_cli.py
tests/test_client.py
tests/test_compute_position_size.py
tests/test_compute_position_size_cap.py
tests/test_dynamic_allocation.py
tests/test_effective_leverage.py
tests/test_env_loading.py
tests/test_grid_search.py
tests/test_heat_score.py
tests/test_indicators.py
tests/test_min_qty_rules.py
tests/test_notifier.py
tests/test_notional_and_pnl_units.py
tests/test_pair_selection.py
tests/test_pairs.py
tests/test_risk_manager.py
tests/test_risk_utils.py
tests/test_signal_risk.py
tests/test_slippage.py
tests/test_strategy_v2.py
tests/test_telegram_bot.py
tests/test_utils.py
tests/test_version.py
tests/test_walk_forward.py
tests/test_ws.py
tg_diag.py
tools/
tools/dump-repo.py
tools/trashify.py

================================================================================
FICHIERS COMPLETS
================================================================================

--------------------------------------------------------------------------------
FILE: .gitignore
--------------------------------------------------------------------------------
__pycache__/
*.pyc
.pytest_cache/
logs/


--------------------------------------------------------------------------------
FILE: CHANGELOG.md
--------------------------------------------------------------------------------
# Changelog

## Unreleased

- Trigger trade entries via `strategy.generate_signal` with weighted scoring and
  signal levels.
- Dynamic risk management adapting `risk_pct` and leverage based on signal and
  user risk level.
- Notional and margin caps with available balance check to avoid Bitget error
  `40762`.
- Risk notifications with green/yellow/red indicators for terminal and
  Telegram.


--------------------------------------------------------------------------------
FILE: Makefile
--------------------------------------------------------------------------------
.PHONY: test

test:
	pytest


--------------------------------------------------------------------------------
FILE: PROMPT.md
--------------------------------------------------------------------------------
# Prompt de re-création du bot Scalp (version spot)

Ce fichier résume les modules et fonctions essentiels afin de recréer le bot de trading **spot** Bitget (paires USDT) à partir de zéro. Chaque fonction liste son rôle principal et les paramètres indispensables. Le fichier `.env` contenant les clés API se trouve dans le dossier parent du bot.

## Structure principale

### bot.py
- `_noop_event(*args, **kwargs)` : fonction vide pour le logging d'événements.
- `check_config()` : vérifie la présence des clés API Bitget et journalise un avertissement si elles manquent.
- `BitgetSpotClient` : sous-classe du client spot Bitget qui injecte `requests` et la fonction `log_event`.
- `find_trade_positions(client, pairs, interval="1m", ema_fast_n=None, ema_slow_n=None)` : applique la stratégie EMA sur une liste de paires et renvoie les signaux.
- `send_selected_pairs(client, top_n=40, tg_bot=None)` : sélectionne et notifie les paires les plus actives.
- `update(client, top_n=40, tg_bot=None)` : rafraîchit la liste des paires et renvoie la charge utile envoyée.
- `main(argv=None)` : initialise la configuration, le client, le `RiskManager`, le bot Telegram et exécute la boucle de trading.

### cli.py
- `run_parallel_optimization(pairs, timeframe, jobs)` : lance une optimisation paramétrique (exemple minimal).
- `run_walkforward_analysis(pair, timeframe, splits, train_ratio)` : exécute une analyse walk-forward.
- `run_live_pipeline(pairs, tfs)` : exécute la pipeline live asynchrone.
- `create_parser()` : construit l’analyseur d’arguments avec les sous-commandes `opt`, `walkforward`, `live` et `bump-version`.
- `main(argv=None)` : point d'entrée qui déclenche la commande choisie.

### init.py
- `install_packages(*args)` : installe des paquets via `pip`.
- `main()` : installe tous les fichiers `requirements*.txt` et `pytest`.

## Modules `scalp`

### bot_config.py
- `CONFIG` : dictionnaire global des paramètres (clés API, symbole, EMA, ATR, risques, etc.).

### metrics.py
- `calc_pnl_pct(entry_price, exit_price, side, fee_rate=0)` : pourcentage de PnL net des frais.
- `calc_rsi(prices, period=14)` : calcul du RSI (Wilder).
- `calc_atr(highs, lows, closes, period=14)` : ATR avec lissage de Wilder.
- `calc_macd(prices, fast=12, slow=26, signal=9)` : renvoie MACD, ligne signal et histogramme.
- `backtest_position(prices, entry_idx, exit_idx, side)` : valide qu’une position est cohérente avec le mouvement des prix.

### strategy.py
- `ema(series, window)` : moyenne mobile exponentielle.
- `vwap(highs, lows, closes, volumes)` : prix moyen pondéré par le volume.
- `obv(closes, volumes)` : série On Balance Volume.
- `cross(last_fast, last_slow, prev_fast, prev_slow)` : détecte les croisements EMA.
- `order_book_imbalance(bid_vol, ask_vol)` : mesure le déséquilibre du carnet d'ordres.
- `swing_levels(highs, lows, lookback)` : renvoie le dernier plus haut et plus bas.
- `Signal` : dataclass contenant `symbol`, `side`, `price`, `sl`, `tp1`, `tp2`, `qty`.
- `generate_signal(symbol, ohlcv, equity, risk_pct, ...)` : produit un `Signal` si toutes les conditions de stratégie sont réunies.
- `scan_pairs` et `select_active_pairs` sont re-exportés pour la sélection des paires.

### trade_utils.py
- `compute_position_size(equity_usdt, price, risk_pct, symbol=None)` : calcule la quantité à acheter/vendre en fonction du risque et du prix.
- `analyse_risque(open_positions, equity_usdt, price, risk_pct, symbol=None, side="long", risk_level=2)` : renvoie la taille de position conseillée selon l’exposition actuelle (sans effet de levier).
- `trailing_stop(side, current_price, atr, sl, mult=0.75)` : met à jour le stop loss en fonction de l'ATR.
- `break_even_stop(side, entry_price, current_price, atr, sl, mult=1.0)` : déplace le stop loss à break-even après un mouvement favorable.
- `should_scale_in(entry_price, current_price, last_entry, atr, side, distance_mult=0.5)` : indique si la position doit être renforcée.
- `timeout_exit(entry_time, now, entry_price, current_price, side, progress_min=15, timeout_min=30)` : ferme une position si aucune progression n’est constatée.
- `marketable_limit_price(side, best_bid, best_ask, slippage=0.001)` : calcule un prix limite pour une exécution quasi immédiate.

### risk
- `calc_risk_amount(equity, risk_pct)` : montant d'argent risqué sur un trade.
- `calc_position_size(equity, risk_pct, stop_distance)` : taille de position selon le stop.
- `adjust_risk_pct(risk_pct, win_streak, loss_streak, increase=0.12, decrease=0.25, min_pct=0.001, max_pct=0.05)` : ajuste le pourcentage de risque selon les séries de gains/pertes.
- `RiskManager` : classe gérant limites journalières, kill switch et ajustement de risque.
  - `reset_day()`, `register_trade(pnl_pct)`/`record_trade`, `dynamic_risk_pct(signal_quality, score)`, `apply_trailing(direction, price, sl, atr, params)`, `pause_duration()`, `can_open(current_positions)`.

### notifier.py
- `_pair_name(symbol)` : formatte le nom d’une paire.
- `_format_text(event, payload=None)` : construit un message lisible.
- `notify(event, payload=None)` : envoie des notifications via webhook HTTP et/ou Telegram.

### logging_utils.py
- `get_jsonl_logger(path, max_bytes=0, backup_count=0)` : renvoie une fonction de logging JSONL avec rotation optionnelle.
- `TradeLogger(csv_path, sqlite_path)` : enregistre chaque trade dans un CSV et une base SQLite (`log(data)`).

### bitget_client.py
- `BitgetSpotClient(access_key, secret_key, base_url, recv_window=30, paper_trade=True, requests_module=requests, log_event=None)` : client REST léger pour le marché spot.
  - `get_symbol_info(symbol=None)`, `get_kline(symbol, interval="1m", start=None, end=None)`, `get_ticker(symbol=None)`.
  - `_private_request(method, path, params=None, body=None)` : signe et exécute les requêtes privées.
  - `get_account()`, `get_open_orders(symbol=None)`.
  - `place_order(symbol, side, quantity, order_type, price=None, stop_loss=None, take_profit=None)`.
  - `cancel_order(symbol, order_id)`, `cancel_all(symbol)`.

### pairs.py
- `get_trade_pairs(client)` : récupère toutes les paires via `get_ticker`.
- `filter_trade_pairs(client, volume_min=5_000_000, max_spread_bps=5, top_n=40)` : filtre par volume/spread.
- `select_top_pairs(client, top_n=40, key="volume")` : trie par volume ou autre clé.
- `find_trade_positions(client, pairs, interval="1m", ema_fast_n=None, ema_slow_n=None, ema_func=ema, cross_func=cross)` : signaux EMA croisement.
- `send_selected_pairs(client, top_n=40, select_fn=select_top_pairs, notify_fn=notify)` : déduplique USD/USDT/USDC et notifie la liste.
- `heat_score(volatility, volume, news=False)` : score combinant volatilite et volume.
- `select_top_heat_pairs(pairs, top_n=3)` : sélection des paires les plus "chaudes".
- `decorrelate_pairs(pairs, corr, threshold=0.8, top_n=3)` : choisit des paires peu corrélées.

### telegram_bot.py
- `TelegramBot(token, chat_id, client, config, risk_mgr, requests_module=requests)` : mini bot Telegram.
  - `send_main_menu(session_pnl)`, `update_pairs()`, `send(text, keyboard=None)`, `answer_callback(cb_id)`,
  - `fetch_updates()`, `handle_updates(session_pnl)`, `handle_callback(data, session_pnl)`.
  - Helpers privés `_base_symbol`, `_build_stop_keyboard`, `_menu_text`.
- `init_telegram_bot(client, config, risk_mgr)` : instancie un `TelegramBot` si les variables d’environnement `TELEGRAM_BOT_TOKEN` et `TELEGRAM_CHAT_ID` sont définies.

## Utilisation
1. Définir les variables d’environnement (clés Bitget, token Telegram, etc.).
2. Exécuter `init.py` pour installer les dépendances.
3. Lancer `bot.py` pour démarrer le trading.
4. Utiliser `cli.py` pour les outils d’optimisation ou de tests.

Ce résumé fournit les éléments nécessaires à la reconstruction du bot et à la compréhension de chaque fonction essentielle.



--------------------------------------------------------------------------------
FILE: README.md
--------------------------------------------------------------------------------
# Scalp

Bot de trading pour les futures USDT-M de Bitget. Ce projet est **expérimental** et fourni à des fins éducatives.

## Installation

Assurez-vous d'avoir Python 3.8 ou supérieur puis installez les dépendances :

```bash
pip install -r requirements.txt
```

Pour développer ou exécuter les tests :

```bash
pip install -r requirements-dev.txt
pytest  # ou make test
```

## Configuration

Le bot lit sa configuration via des variables d'environnement :

- `BITGET_ACCESS_KEY`, `BITGET_SECRET_KEY` : clés API Bitget (laisser les valeurs par défaut pour rester en mode papier).
- `PAPER_TRADE` (`true`/`false`) : par défaut `true`, n'envoie aucun ordre réel.
- `SYMBOL` : symbole du contrat futures (par défaut, `BTCUSDT`).
- `INTERVAL` : intervalle des chandeliers, ex. `1m`, `5m`.
- `EMA_FAST`, `EMA_SLOW` : périodes des EMA utilisées par la stratégie.
- `MACD_FAST`, `MACD_SLOW`, `MACD_SIGNAL` : paramètres du filtre de tendance MACD.
- `EMA_TREND_PERIOD` : période de l'EMA longue utilisée comme filtre de tendance général.
- `RISK_PCT_EQUITY`, `LEVERAGE`, `STOP_LOSS_PCT`, `TAKE_PROFIT_PCT` : paramètres de gestion du risque.
- `ATR_PERIOD`, `TRAIL_ATR_MULT`, `SCALE_IN_ATR_MULT`, `PROGRESS_MIN`, `TIMEOUT_MIN` : réglages pour l'ATR, l'ajout à la position, le trailing stop et la sortie par timeout.
- `MAX_DAILY_LOSS_PCT`, `MAX_DAILY_PROFIT_PCT`, `MAX_POSITIONS` (par défaut 3) : limites globales (kill switch après perte ou gain, nombre maximal de positions).
- `LOG_DIR` : dossier où seront écrits les fichiers de log.
- `ALLOWED_SYMBOLS` : liste de paires autorisées séparées par des virgules. Vide par défaut pour autoriser toutes les paires.

- `NOTIFY_URL` : URL d'un webhook HTTP pour recevoir les événements (optionnel, peut être utilisé en plus de Telegram).
- `TELEGRAM_BOT_TOKEN`, `TELEGRAM_CHAT_ID` : pour envoyer les notifications sur Telegram (optionnel, peut être combiné avec le webhook).

Pour éviter de versionner vos clés sensibles, vous pouvez créer un fichier
`.env` dans le dossier parent du dépôt (par exemple `Notebooks/.env` si le
code se trouve dans `Notebooks/scalp`).  Ce fichier est automatiquement chargé
au démarrage et toutes les variables qu'il contient seront disponibles pour le
bot.


Exemple :

```bash
export BITGET_ACCESS_KEY="votre_cle"
export BITGET_SECRET_KEY="votre_secret"
export PAPER_TRADE=true
export TELEGRAM_BOT_TOKEN="123456:ABCDEF..."
export TELEGRAM_CHAT_ID="123456789"
python bot.py
```

## Lancement

Après configuration, lancez simplement :

```bash
python bot.py
```

Le terminal reste silencieux au démarrage sauf en cas d'absence de variables critiques (`BITGET_ACCESS_KEY`, `BITGET_SECRET_KEY`). Les journaux sont écrits dans `logs/` et affichés sur la console. Le bot tourne jusqu'à `Ctrl+C`. Les ouvertures et fermetures de positions sont consignées dans `bot_events.jsonl`.

Lors du démarrage, deux notifications Telegram sont émises : la première affiche « Bot démarré » avec un logo, la seconde « Listing ok » sans détailler les paires sélectionnées.

Ensuite, un rappel du marché est envoyé chaque minute et l'interface Telegram propose un bouton « Fermer Bot » pour arrêter proprement l'exécution.


## Stratégie

Scalp cherche à capter de courts mouvements de tendance tout en coupant
rapidement les pertes.

Principes généraux :

- sélection de paires liquides au fort momentum ;
- trade uniquement dans le sens de la tendance dominante (MACD + EMA longue) ;
- confirmation multi‑indicateurs (VWAP, volume/OBV, RSI multi‑UT) ;
- stop‑loss et take‑profit dynamiques basés sur l’ATR avec taille de position
  calculée selon le risque ;
- limites quotidiennes pour protéger le capital.

Les règles détaillées et l’algorithme complet sont décrits dans
`STRATEGY.md`.

## Version

La version du bot est stockée dans le fichier `scalp/VERSION` et exposée dans
le code via la variable `scalp.__version__` :

```python
from scalp import __version__
print(__version__)
```

Pour incrémenter la version, utilisez `scalp.version.bump_version` avec

`"major"`, `"minor"` ou `"patch"` comme argument. La fonction
`scalp.version.bump_version_from_message` permet également de déterminer
automatiquement l'incrément à appliquer à partir d'un message de commit
suivant la convention [Conventional Commits](https://www.conventionalcommits.org).

Exemple d'incrément basé sur un message :

```python
from scalp.version import bump_version_from_message
bump_version_from_message("feat: add new strategy")
```

Exécuté en tant que script, `python -m scalp.version` lit le dernier
message de commit `git` et met à jour le fichier `VERSION` en
conséquence.

La même opération peut être déclenchée depuis la ligne de commande via
`cli.py` :

```bash
python cli.py bump-version
```


## Changelog

- Ajout d'un contrôle de marge disponible avant chaque ordre afin d'éviter l'erreur Bitget « The order amount exceeds the balance » (code 40762).

## Avertissement

© 2025 — Usage à vos risques. Ceci n'est pas un conseil financier.


--------------------------------------------------------------------------------
FILE: STRATEGY.md
--------------------------------------------------------------------------------
# Stratégie de trading

Ce document décrit la logique de trading utilisée par le bot **Scalp**. Elle vise un scalping court terme sur les futures USDT‑M de Bitget.

## Principes généraux

- ne traiter que des actifs liquides à fort momentum ;
- suivre la tendance dominante et éviter les marchés plats ;
- utiliser des confirmations multi‑unités de temps pour limiter les faux signaux ;
- dimensionner chaque position selon un pourcentage fixe du capital ;
- couper rapidement les pertes et laisser courir les gains via un suivi dynamique.

## Sélection des paires

1. `scan_pairs` récupère les tickers Bitget et filtre ceux qui possèdent un volume quotidien suffisant et un spread réduit.
2. `select_active_pairs` affine la liste en conservant les paires présentant le plus de **momentum** :
   - croisement entre EMA20 et EMA50 ;
   - ATR élevé pour privilégier les actifs volatils.

## Génération du signal

`generate_signal` produit un signal d’entrée long ou court lorsque les conditions suivantes sont réunies :

- prix au‑dessus ou en dessous du **VWAP** et des EMA20/50 selon la direction recherchée ;
- **RSI(14)** traversant les niveaux 40/60 avec confirmation d’un **RSI 15 min** et de la pente de l’**EMA 1 h** ;
- **MACD** alignée avec la tendance et **EMA** longue en filtrage global ;
- hausse d’**OBV** ou volume supérieur à la moyenne ;
- cassure du dernier **swing high/low** ;
- éventuel filtre d’**order book imbalance** et de ratio de ticks.

Les distances de stop et de take profit sont calculées à partir de l’**ATR**, ce qui permet également de dimensionner la taille de position via `calc_position_size`.

## Gestion du risque

La classe `RiskManager` applique plusieurs garde‑fous :

- limite de perte quotidienne (`max_daily_loss_pct`) et optionnellement de gain (`max_daily_profit_pct`) déclenchant un *kill switch* ;
- suivi des séries de gains/pertes pour ajuster le pourcentage de risque par trade ;
- pause forcée en cas de pertes consécutives prolongées ;
- contrôle du nombre maximal de positions ouvertes.

Ces règles combinées visent à protéger le capital tout en conservant une exposition opportuniste au marché.


--------------------------------------------------------------------------------
FILE: bot.py
--------------------------------------------------------------------------------
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Point d'entrée unique (scan/orchestrate).

Modes d'accès:
- --exchange wrapper (défaut) : passe par TON wrapper Bitget (get_ohlcv). Le bot
  ajoute automatiquement le suffixe si absent:
    --market umcbl -> _UMCBL (perp USDT)  [défaut]
    --market spot  -> _SPBL
- --exchange ccxt : client ccxt.bitget (fetch_ohlcv), pour debug rapide.
- --csv / --csv_1h : scan offline.

Exemples:
  python bot.py --symbols BTCUSDT --tf 5m                     # wrapper, auto -> BTCUSDT_UMCBL
  python bot.py --symbols BTCUSDT --tf 5m --market spot       # wrapper, auto -> BTCUSDT_SPBL
  python bot.py --symbols BTCUSDT --tf 5m --exchange ccxt     # ccxt (transforme en BTC/USDT:USDT)
  python bot.py --csv data/BTCUSDT-5m.csv --csv_1h data/BTCUSDT-1h.csv
"""

from __future__ import annotations
import os, sys, argparse
from typing import Dict, List, Any, Optional, Tuple

# ---------- .env (facultatif) ----------
def _load_dotenv_if_any() -> None:
    try:
        from dotenv import load_dotenv  # type: ignore
        here = os.getcwd()
        for p in (os.path.join(here, ".env"), os.path.join(os.path.dirname(here), ".env")):
            if os.path.isfile(p):
                load_dotenv(p)
                break
    except Exception:
        pass
_load_dotenv_if_any()

# ---------- Strategies ----------
def _import_strategy_factory():
    from scalper.signals.factory import load_strategies_cfg, resolve_signal_fn
    return load_strategies_cfg, resolve_signal_fn

# ---------- Orchestrator ----------
def _import_orchestrator():
    from scalper.live.orchestrator import Orchestrator
    return Orchestrator

# ---------- Exchange loader ----------
def _import_wrapper_class() -> Optional[Any]:
    for mod_name in (
        "scalper.exchange.bitget",   # ton wrapper
        "scalper.exchanges.bitget",
    ):
        try:
            mod = __import__(mod_name, fromlist=["BitgetExchange"])
            cls = getattr(mod, "BitgetExchange", None)
            if cls is not None:
                return cls
        except Exception:
            continue
    return None

def _build_ccxt_bitget():
    try:
        import ccxt  # type: ignore
    except Exception:
        return None
    k = os.getenv("BITGET_API_KEY","")
    s = os.getenv("BITGET_API_SECRET","")
    p = os.getenv("BITGET_API_PASSPHRASE","")
    default_type = os.getenv("BITGET_DEFAULT_TYPE","swap")
    opts = {"options": {"defaultType": default_type}}
    if any([k,s,p]):
        return ccxt.bitget({"apiKey": k, "secret": s, "password": p, **opts})
    return ccxt.bitget(opts)

def _resolve_exchange(mode: str) -> Tuple[Optional[Any], str, str]:
    """Retourne (ExchangeCtorOrClient, message, detected_mode['wrapper'|'ccxt'])."""
    if mode == "wrapper":
        cls = _import_wrapper_class()
        if cls is None:
            return None, "Wrapper Bitget introuvable (scalper.exchange.bitget).", ""
        return cls, "", "wrapper"
    if mode == "ccxt":
        client = _build_ccxt_bitget()
        if client is None:
            return None, "ccxt non installé (pip install ccxt).", ""
        return client, "", "ccxt"
    # auto
    cls = _import_wrapper_class()
    if cls is not None:
        return cls, "", "wrapper"
    client = _build_ccxt_bitget()
    if client is not None:
        return client, "", "ccxt"
    return None, "Aucun exchange Bitget trouvé (wrapper ou ccxt).", ""

# ---------- Helpers symboles ----------
def _ensure_suffix_for_wrapper(sym: str, market: str) -> str:
    """Ajoute _UMCBL/_SPBL si manquant, pour le wrapper Bitget."""
    up = sym.upper()
    if "_" in up:   # suffixe déjà présent (ex: BTCUSDT_UMCBL / _SPBL)
        return up
    if market == "spot":
        return up + "_SPBL"
    return up + "_UMCBL"  # défaut: perp USDT

def _to_ccxt_symbol(sym: str) -> str:
    """BTCUSDT -> BTC/USDT:USDT (defaultType=swap) ; si déjà au format ccxt, renvoie tel quel."""
    if "/" in sym:
        return sym
    base, quote = sym[:-4], sym[-4:]
    default_type = os.getenv("BITGET_DEFAULT_TYPE","swap")
    if default_type == "swap":
        return f"{base}/{quote}:{quote}"
    return f"{base}/{quote}"

# ---------- Utils OHLCV offline ----------
def _read_csv(path: str) -> Dict[str, List[float]]:
    import csv
    cols = ("timestamp","open","high","low","close","volume")
    out = {k: [] for k in cols}
    with open(path, "r", newline="", encoding="utf-8") as f:
        r = csv.DictReader(f)
        for row in r:
            for k in cols:
                out[k].append(float(row[k]))
    return out

def _ohlcv_to_dict(rows: List[List[float]]) -> Dict[str, List[float]]:
    cols = ("timestamp","open","high","low","close","volume")
    out = {k: [] for k in cols}
    for r in rows:
        if len(r) < 6:
            raise ValueError("Ligne OHLCV invalide (6 colonnes attendues).")
        out["timestamp"].append(float(r[0])); out["open"].append(float(r[1]))
        out["high"].append(float(r[2])); out["low"].append(float(r[3]))
        out["close"].append(float(r[4])); out["volume"].append(float(r[5]))
    return out

# ---------- Modes ----------
def mode_scan(
    *, symbols: List[str], timeframe: str, cfg_path: str,
    csv: Optional[str], csv_1h: Optional[str],
    equity: float, risk: float, exchange_mode: str, market: str
) -> None:
    load_strategies_cfg, resolve_signal_fn = _import_strategy_factory()
    cfg = load_strategies_cfg(cfg_path)

    data_by_symbol: Dict[str, Dict[str, List[float]]] = {}
    data_1h_by_symbol: Dict[str, Dict[str, List[float]]] = {}

    if csv:
        data = _read_csv(csv)
        for s in symbols:
            data_by_symbol[s] = data
        if csv_1h:
            d1h = _read_csv(csv_1h)
            for s in symbols:
                data_1h_by_symbol[s] = d1h
    else:
        ExCtorOrClient, msg, detected = _resolve_exchange(exchange_mode)
        if ExCtorOrClient is None:
            print(msg); return

        if detected == "wrapper":
            client = ExCtorOrClient(
                api_key=os.getenv("BITGET_API_KEY",""),
                api_secret=os.getenv("BITGET_API_SECRET",""),
                api_passphrase=os.getenv("BITGET_API_PASSPHRASE",""),
            )
            fetch = getattr(client, "get_ohlcv")
            for s in symbols:
                s_eff = _ensure_suffix_for_wrapper(s, market)  # << auto-suffix
                rows = fetch(symbol=s_eff, timeframe=timeframe, limit=1500)
                data_by_symbol[s] = _ohlcv_to_dict(rows)
                try:
                    s_eff_1h = _ensure_suffix_for_wrapper(s, market)
                    rows_1h = fetch(symbol=s_eff_1h, timeframe="1h", limit=1500)
                    data_1h_by_symbol[s] = _ohlcv_to_dict(rows_1h)
                except Exception:
                    pass
        else:
            client = ExCtorOrClient  # ccxt
            for s in symbols:
                s_eff = _to_ccxt_symbol(s)
                rows = client.fetch_ohlcv(s_eff, timeframe=timeframe, limit=1500)
                data_by_symbol[s] = _ohlcv_to_dict(rows)
                try:
                    rows_1h = client.fetch_ohlcv(s_eff, timeframe="1h", limit=1500)
                    data_1h_by_symbol[s] = _ohlcv_to_dict(rows_1h)
                except Exception:
                    pass

    for s in symbols:
        fn = resolve_signal_fn(s, timeframe, cfg)
        ohlcv = data_by_symbol.get(s)
        print(f"\n=== {s} / {timeframe} ===")
        if not ohlcv:
            print("Pas de données OHLCV."); continue
        sig = fn(symbol=s, timeframe=timeframe, ohlcv=ohlcv,
                 equity=equity, risk_pct=risk, ohlcv_1h=data_1h_by_symbol.get(s))
        if sig is None:
            print("Aucun signal.")
        else:
            d = sig.as_dict()
            print(f"Signal: side={d['side']} entry={d['entry']:.6f} sl={d['sl']:.6f} "
                  f"tp1={d['tp1']:.6f} tp2={d['tp2']:.6f} score={d['score']} "
                  f"quality={d['quality']:.2f}")
            print("Reasons:", d.get("reasons",""))

def mode_orchestrate(
    *, symbols: List[str], timeframe: str, cfg_path: str,
    interval_sec: int, equity: float, risk: float, exchange_mode: str, market: str
) -> None:
    Orchestrator = _import_orchestrator()
    load_strategies_cfg, _ = _import_strategy_factory()
    cfg = load_strategies_cfg(cfg_path)

    ExCtorOrClient, msg, detected = _resolve_exchange(exchange_mode)
    if ExCtorOrClient is None:
        print(msg); return

    if detected == "wrapper":
        client = ExCtorOrClient(
            api_key=os.getenv("BITGET_API_KEY",""),
            api_secret=os.getenv("BITGET_API_SECRET",""),
            api_passphrase=os.getenv("BITGET_API_PASSPHRASE",""),
        )
    else:
        client = ExCtorOrClient  # ccxt

    jobs = [(s, timeframe) for s in symbols]
    orch = Orchestrator(
        exchange_client=client, strategies_cfg=cfg, jobs=jobs,
        interval_sec=interval_sec, equity=equity, risk_pct=risk
    )
    try:
        orch.loop()
    except KeyboardInterrupt:
        print("\nArrêt demandé (CTRL+C).")

# ---------- CLI ----------
def parse_args() -> argparse.Namespace:
    ap = argparse.ArgumentParser(description="Bot (scan/orchestrate)")
    ap.add_argument("--symbols", default=os.getenv("DEFAULT_SYMBOLS","BTCUSDT"),
                    help="Ex: BTCUSDT (suffixe auto en wrapper) ou BTC/USDT:USDT (ccxt).")
    ap.add_argument("--tf", default=os.getenv("DEFAULT_TF","5m"), help="Ex: 1m, 5m, 15m, 1h")
    ap.add_argument("--cfg", default="scalper/config/strategies.yml", help="Fichier stratégies (YAML/JSON)")
    ap.add_argument("--equity", type=float, default=1000.0)
    ap.add_argument("--risk", type=float, default=0.01)
    ap.add_argument("--mode", choices=["scan","orchestrate"], default="scan")
    ap.add_argument("--interval", type=int, default=60)
    ap.add_argument("--exchange", choices=["auto","wrapper","ccxt"],
                    default=os.getenv("EXCHANGE_MODE","wrapper"),
                    help="wrapper = ton module (get_ohlcv) ; ccxt = client ccxt (fetch_ohlcv).")
    ap.add_argument("--market", choices=["umcbl","spot"], default=os.getenv("BITGET_MARKET","umcbl"),
                    help="Utilisé seulement en wrapper pour suffixe auto (_UMCBL/_SPBL).")
    ap.add_argument("--csv", default="", help="CSV OHLCV principal (scan offline)")
    ap.add_argument("--csv_1h", default="", help="CSV 1h (scan offline)")
    return ap.parse_args()

def main():
    args = parse_args()
    symbols = [s.strip() for s in (args.symbols or "").split(",") if s.strip()]
    if not symbols:
        print("Aucun symbole fourni (utilise --symbols ou DEFAULT_SYMBOLS).")
        return

    if args.mode == "scan":
        mode_scan(
            symbols=symbols, timeframe=args.tf, cfg_path=args.cfg,
            csv=(args.csv or None), csv_1h=(args.csv_1h or None),
            equity=args.equity, risk=args.risk,
            exchange_mode=args.exchange, market=args.market
        )
    else:
        mode_orchestrate(
            symbols=symbols, timeframe=args.tf, cfg_path=args.cfg,
            interval_sec=args.interval, equity=args.equity, risk=args.risk,
            exchange_mode=args.exchange, market=args.market
        )

if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
FILE: cli.py
--------------------------------------------------------------------------------
"""Command line utilities for the Scalp project.

This module exposes a small command line interface used throughout the
project.  The actual trading logic lives in other modules, however the CLI is
responsible for parsing parameters and dispatching the appropriate routines.

The implementation intentionally keeps the invoked functions minimal so that
tests can patch them easily.  In a real deployment these functions would
perform optimisation, walk‑forward analysis or run the live pipeline.
"""

from __future__ import annotations

import argparse
import asyncio
from typing import Iterable, List

from scalper.version import bump_version_from_git


# ---------------------------------------------------------------------------
# Placeholder implementations
# ---------------------------------------------------------------------------


def run_parallel_optimization(pairs: List[str], timeframe: str, jobs: int) -> None:
    """Run a parallel parameter optimisation.

    The real project dispatches a potentially heavy optimisation routine.  The
    function is kept trivial so unit tests can verify that the CLI wiring works
    without actually performing the optimisation.
    """

    print(f"Optimising {pairs} on {timeframe} with {jobs} jobs")


def run_walkforward_analysis(
    pair: str, timeframe: str, splits: int, train_ratio: float
) -> None:
    """Execute a walk-forward analysis."""

    print(
        f"Walk-forward on {pair} ({timeframe}), splits={splits}, train_ratio={train_ratio}"
    )


async def run_live_pipeline(pairs: List[str], tfs: Iterable[str]) -> None:
    """Run the live trading pipeline."""

    print(f"Running live pipeline for pairs={pairs} on tfs={list(tfs)}")


# ---------------------------------------------------------------------------
# Argument parsing
# ---------------------------------------------------------------------------


def create_parser() -> argparse.ArgumentParser:
    """Create the top-level argument parser."""

    parser = argparse.ArgumentParser(description="Scalp command line tools")
    sub = parser.add_subparsers(dest="command")

    # --- ``opt`` command -------------------------------------------------
    opt_p = sub.add_parser("opt", help="run optimisation in parallel")
    opt_p.add_argument("--pairs", nargs="+", required=True, help="trading pairs")
    opt_p.add_argument("--tf", required=True, help="timeframe")
    opt_p.add_argument("--jobs", type=int, default=1, help="number of workers")
    opt_p.set_defaults(
        func=lambda a: run_parallel_optimization(a.pairs, a.tf, a.jobs)
    )

    # --- ``walkforward`` command ----------------------------------------
    wf_p = sub.add_parser("walkforward", help="perform walk-forward analysis")
    wf_p.add_argument("--pair", required=True, help="trading pair")
    wf_p.add_argument("--tf", required=True, help="timeframe")
    wf_p.add_argument("--splits", type=int, default=1, help="number of splits")
    wf_p.add_argument(
        "--train-ratio",
        type=float,
        default=0.7,
        help="portion of data used for training",
    )
    wf_p.set_defaults(
        func=lambda a: run_walkforward_analysis(
            a.pair, a.tf, a.splits, a.train_ratio
        )
    )

    # --- ``live`` command -----------------------------------------------
    live_p = sub.add_parser("live", help="run the live async pipeline")
    live_p.add_argument("--pairs", nargs="+", required=True, help="trading pairs")
    live_p.add_argument("--tfs", nargs="+", required=True, help="timeframes")
    live_p.set_defaults(func=lambda a: asyncio.run(run_live_pipeline(a.pairs, a.tfs)))

    # --- ``bump-version`` command -------------------------------------
    bv_p = sub.add_parser(
        "bump-version",
        help="update the VERSION file based on the latest git commit",
    )
    bv_p.set_defaults(func=lambda a: print(bump_version_from_git()))

    return parser


def main(argv: Iterable[str] | None = None) -> int:
    """Entry point used by tests and ``if __name__ == '__main__'`` block."""

    parser = create_parser()
    args = parser.parse_args(argv)
    if not hasattr(args, "func"):
        parser.print_help()
        return 0
    result = args.func(args)
    return 0 if result is None else int(result)


if __name__ == "__main__":  # pragma: no cover - manual invocation
    raise SystemExit(main())



--------------------------------------------------------------------------------
FILE: data/BTCUSDT-1m.csv
--------------------------------------------------------------------------------
ts,open,high,low,close,volume
1625097600000,34000,34100,33950,34050,123.4
1625097660000,34050,34200,34000,34150,150.7
1625097720000,34150,34300,34100,34250,180.3
1625097780000,34250,34400,34200,34350,200.1
1625097840000,34350,34500,34300,34450,220.8

--------------------------------------------------------------------------------
FILE: data/__init__.py
--------------------------------------------------------------------------------
"""Indicator computation helpers."""

from .indicators import compute_all

__all__ = ["compute_all"]


--------------------------------------------------------------------------------
FILE: dump.txt
--------------------------------------------------------------------------------
Dump created: 2025-08-24 03:12:35
Repository tree:
Scalp/
    CHANGELOG.md
    Makefile
    PROMPT.md
    README.md
    STRATEGY.md
    bot.py
    cli.py
    init.py
    pytest.ini
    requirements-dev.txt
    requirements.txt
    sitecustomize.py
    tg_diag.py
    scalper/
        VERSION
        __init__.py
        bitget_client.py
        client.py
        logging_utils.py
        metrics.py
        pairs.py
        selfcheck.py
        strategy.py
        trade_utils.py
        version.py
        ws.py
        positions/
            __init__.py
            state.py
        risk/
            __init__.py
            manager.py
        hooks/
            prewarm_cache.py
        exchange/
            __init__.py
            bitget_ccxt.py
            fees.py
        selection/
            __init__.py
            momentum.py
            scanner.py
        config/
            __init__.py
            loader.py
        backtest/
            __init__.py
            cache.py
            cli.py
            engine.py
            grid_search.py
            loader_csv.py
            market_data.py
            metrics.py
            optimize.py
            run_multi.py
            runner.py
            walkforward.py
        services/
            __init__.py
            data_cache.py
            order_service.py
            utils.py
        signals/
            __init__.py
            current.py
            factory.py
            generator.py
        adapters/
            __init__.py
            bitget.py
            bitget_fetch.py
            market_data.py
        live/
            __init__.py
            backtest_telegram.py
            commands.py
            journal.py
            logs.py
            notify.py
            ohlcv_service.py
            orchestrator.py
            orders.py
            position_fsm.py
            setup_wizard.py
            state_store.py
            telegram_async.py
            watchlist.py
            loops/
                trade.py
    TRASH_20250823-124533/
        bitget_futures_pairs.py
        dashboard.py
        dump_repo.py
        quick_order.py
        rr.py
        run_backtest.py
        short_one_way.py
        notebooks/
            spot/
                bitget_bot.py
        scalper/
            bot_config.py
            legacy_config.py
            notifier.py
            telegram_bot.py
        result/
    data/
        BTCUSDT-1m.csv
        __init__.py
        indicators.py
    tests/
        conftest.py
        test_analyse_risque.py
        test_backtest.py
        test_backtest_multi.py
        test_backtest_position.py
        test_bitget_futures_pairs.py
        test_bot_place_order_caps.py
        test_bot_update.py
        test_break_even_stop.py
        test_calc_pnl_pct.py
        test_check_config.py
        test_cli.py
        test_client.py
        test_compute_position_size.py
        test_compute_position_size_cap.py
        test_dynamic_allocation.py
        test_effective_leverage.py
        test_env_loading.py
        test_grid_search.py
        test_heat_score.py
        test_indicators.py
        test_min_qty_rules.py
        test_notifier.py
        test_notional_and_pnl_units.py
        test_pair_selection.py
        test_pairs.py
        test_risk_manager.py
        test_risk_utils.py
        test_signal_risk.py
        test_slippage.py
        test_strategy_v2.py
        test_telegram_bot.py
        test_utils.py
        test_version.py
        test_walk_forward.py
        test_ws.py

## CHANGELOG.md (last modified: 2025-08-23 20:57:14)
     1: # Changelog
     2: 
     3: ## Unreleased
     4: 
     5: - Trigger trade entries via `strategy.generate_signal` with weighted scoring and
     6:   signal levels.
     7: - Dynamic risk management adapting `risk_pct` and leverage based on signal and
     8:   user risk level.
     9: - Notional and margin caps with available balance check to avoid Bitget error
    10:   `40762`.
    11: - Risk notifications with green/yellow/red indicators for terminal and
    12:   Telegram.


## Makefile (last modified: 2025-08-23 20:57:14)
     1: .PHONY: test
     2: 
     3: test:
     4: 	pytest


## PROMPT.md (last modified: 2025-08-23 20:57:14)
     1: # Prompt de re-création du bot Scalp (version spot)
     2: 
     3: Ce fichier résume les modules et fonctions essentiels afin de recréer le bot de trading **spot** Bitget (paires USDT) à partir de zéro. Chaque fonction liste son rôle principal et les paramètres indispensables. Le fichier `.env` contenant les clés API se trouve dans le dossier parent du bot.
     4: 
     5: ## Structure principale
     6: 
     7: ### bot.py
     8: - `_noop_event(*args, **kwargs)` : fonction vide pour le logging d'événements.
     9: - `check_config()` : vérifie la présence des clés API Bitget et journalise un avertissement si elles manquent.
    10: - `BitgetSpotClient` : sous-classe du client spot Bitget qui injecte `requests` et la fonction `log_event`.
    11: - `find_trade_positions(client, pairs, interval="1m", ema_fast_n=None, ema_slow_n=None)` : applique la stratégie EMA sur une liste de paires et renvoie les signaux.
    12: - `send_selected_pairs(client, top_n=40, tg_bot=None)` : sélectionne et notifie les paires les plus actives.
    13: - `update(client, top_n=40, tg_bot=None)` : rafraîchit la liste des paires et renvoie la charge utile envoyée.
    14: - `main(argv=None)` : initialise la configuration, le client, le `RiskManager`, le bot Telegram et exécute la boucle de trading.
    15: 
    16: ### cli.py
    17: - `run_parallel_optimization(pairs, timeframe, jobs)` : lance une optimisation paramétrique (exemple minimal).
    18: - `run_walkforward_analysis(pair, timeframe, splits, train_ratio)` : exécute une analyse walk-forward.
    19: - `run_live_pipeline(pairs, tfs)` : exécute la pipeline live asynchrone.
    20: - `create_parser()` : construit l’analyseur d’arguments avec les sous-commandes `opt`, `walkforward`, `live` et `bump-version`.
    21: - `main(argv=None)` : point d'entrée qui déclenche la commande choisie.
    22: 
    23: ### init.py
    24: - `install_packages(*args)` : installe des paquets via `pip`.
    25: - `main()` : installe tous les fichiers `requirements*.txt` et `pytest`.
    26: 
    27: ## Modules `scalp`
    28: 
    29: ### bot_config.py
    30: - `CONFIG` : dictionnaire global des paramètres (clés API, symbole, EMA, ATR, risques, etc.).
    31: 
    32: ### metrics.py
    33: - `calc_pnl_pct(entry_price, exit_price, side, fee_rate=0)` : pourcentage de PnL net des frais.
    34: - `calc_rsi(prices, period=14)` : calcul du RSI (Wilder).
    35: - `calc_atr(highs, lows, closes, period=14)` : ATR avec lissage de Wilder.
    36: - `calc_macd(prices, fast=12, slow=26, signal=9)` : renvoie MACD, ligne signal et histogramme.
    37: - `backtest_position(prices, entry_idx, exit_idx, side)` : valide qu’une position est cohérente avec le mouvement des prix.
    38: 
    39: ### strategy.py
    40: - `ema(series, window)` : moyenne mobile exponentielle.
    41: - `vwap(highs, lows, closes, volumes)` : prix moyen pondéré par le volume.
    42: - `obv(closes, volumes)` : série On Balance Volume.
    43: - `cross(last_fast, last_slow, prev_fast, prev_slow)` : détecte les croisements EMA.
    44: - `order_book_imbalance(bid_vol, ask_vol)` : mesure le déséquilibre du carnet d'ordres.
    45: - `swing_levels(highs, lows, lookback)` : renvoie le dernier plus haut et plus bas.
    46: - `Signal` : dataclass contenant `symbol`, `side`, `price`, `sl`, `tp1`, `tp2`, `qty`.
    47: - `generate_signal(symbol, ohlcv, equity, risk_pct, ...)` : produit un `Signal` si toutes les conditions de stratégie sont réunies.
    48: - `scan_pairs` et `select_active_pairs` sont re-exportés pour la sélection des paires.
    49: 
    50: ### trade_utils.py
    51: - `compute_position_size(equity_usdt, price, risk_pct, symbol=None)` : calcule la quantité à acheter/vendre en fonction du risque et du prix.
    52: - `analyse_risque(open_positions, equity_usdt, price, risk_pct, symbol=None, side="long", risk_level=2)` : renvoie la taille de position conseillée selon l’exposition actuelle (sans effet de levier).
    53: - `trailing_stop(side, current_price, atr, sl, mult=0.75)` : met à jour le stop loss en fonction de l'ATR.
    54: - `break_even_stop(side, entry_price, current_price, atr, sl, mult=1.0)` : déplace le stop loss à break-even après un mouvement favorable.
    55: - `should_scale_in(entry_price, current_price, last_entry, atr, side, distance_mult=0.5)` : indique si la position doit être renforcée.
    56: - `timeout_exit(entry_time, now, entry_price, current_price, side, progress_min=15, timeout_min=30)` : ferme une position si aucune progression n’est constatée.
    57: - `marketable_limit_price(side, best_bid, best_ask, slippage=0.001)` : calcule un prix limite pour une exécution quasi immédiate.
    58: 
    59: ### risk
    60: - `calc_risk_amount(equity, risk_pct)` : montant d'argent risqué sur un trade.
    61: - `calc_position_size(equity, risk_pct, stop_distance)` : taille de position selon le stop.
    62: - `adjust_risk_pct(risk_pct, win_streak, loss_streak, increase=0.12, decrease=0.25, min_pct=0.001, max_pct=0.05)` : ajuste le pourcentage de risque selon les séries de gains/pertes.
    63: - `RiskManager` : classe gérant limites journalières, kill switch et ajustement de risque.
    64:   - `reset_day()`, `register_trade(pnl_pct)`/`record_trade`, `dynamic_risk_pct(signal_quality, score)`, `apply_trailing(direction, price, sl, atr, params)`, `pause_duration()`, `can_open(current_positions)`.
    65: 
    66: ### notifier.py
    67: - `_pair_name(symbol)` : formatte le nom d’une paire.
    68: - `_format_text(event, payload=None)` : construit un message lisible.
    69: - `notify(event, payload=None)` : envoie des notifications via webhook HTTP et/ou Telegram.
    70: 
    71: ### logging_utils.py
    72: - `get_jsonl_logger(path, max_bytes=0, backup_count=0)` : renvoie une fonction de logging JSONL avec rotation optionnelle.
    73: - `TradeLogger(csv_path, sqlite_path)` : enregistre chaque trade dans un CSV et une base SQLite (`log(data)`).
    74: 
    75: ### bitget_client.py
    76: - `BitgetSpotClient(access_key, secret_key, base_url, recv_window=30, paper_trade=True, requests_module=requests, log_event=None)` : client REST léger pour le marché spot.
    77:   - `get_symbol_info(symbol=None)`, `get_kline(symbol, interval="1m", start=None, end=None)`, `get_ticker(symbol=None)`.
    78:   - `_private_request(method, path, params=None, body=None)` : signe et exécute les requêtes privées.
    79:   - `get_account()`, `get_open_orders(symbol=None)`.
    80:   - `place_order(symbol, side, quantity, order_type, price=None, stop_loss=None, take_profit=None)`.
    81:   - `cancel_order(symbol, order_id)`, `cancel_all(symbol)`.
    82: 
    83: ### pairs.py
    84: - `get_trade_pairs(client)` : récupère toutes les paires via `get_ticker`.
    85: - `filter_trade_pairs(client, volume_min=5_000_000, max_spread_bps=5, top_n=40)` : filtre par volume/spread.
    86: - `select_top_pairs(client, top_n=40, key="volume")` : trie par volume ou autre clé.
    87: - `find_trade_positions(client, pairs, interval="1m", ema_fast_n=None, ema_slow_n=None, ema_func=ema, cross_func=cross)` : signaux EMA croisement.
    88: - `send_selected_pairs(client, top_n=40, select_fn=select_top_pairs, notify_fn=notify)` : déduplique USD/USDT/USDC et notifie la liste.
    89: - `heat_score(volatility, volume, news=False)` : score combinant volatilite et volume.
    90: - `select_top_heat_pairs(pairs, top_n=3)` : sélection des paires les plus "chaudes".
    91: - `decorrelate_pairs(pairs, corr, threshold=0.8, top_n=3)` : choisit des paires peu corrélées.
    92: 
    93: ### telegram_bot.py
    94: - `TelegramBot(token, chat_id, client, config, risk_mgr, requests_module=requests)` : mini bot Telegram.
    95:   - `send_main_menu(session_pnl)`, `update_pairs()`, `send(text, keyboard=None)`, `answer_callback(cb_id)`,
    96:   - `fetch_updates()`, `handle_updates(session_pnl)`, `handle_callback(data, session_pnl)`.
    97:   - Helpers privés `_base_symbol`, `_build_stop_keyboard`, `_menu_text`.
    98: - `init_telegram_bot(client, config, risk_mgr)` : instancie un `TelegramBot` si les variables d’environnement `TELEGRAM_BOT_TOKEN` et `TELEGRAM_CHAT_ID` sont définies.
    99: 
   100: ## Utilisation
   101: 1. Définir les variables d’environnement (clés Bitget, token Telegram, etc.).
   102: 2. Exécuter `init.py` pour installer les dépendances.
   103: 3. Lancer `bot.py` pour démarrer le trading.
   104: 4. Utiliser `cli.py` pour les outils d’optimisation ou de tests.
   105: 
   106: Ce résumé fournit les éléments nécessaires à la reconstruction du bot et à la compréhension de chaque fonction essentielle.
   107: 


## README.md (last modified: 2025-08-23 20:57:14)
     1: # Scalp
     2: 
     3: Bot de trading pour les futures USDT-M de Bitget. Ce projet est **expérimental** et fourni à des fins éducatives.
     4: 
     5: ## Installation
     6: 
     7: Assurez-vous d'avoir Python 3.8 ou supérieur puis installez les dépendances :
     8: 
     9: ```bash
    10: pip install -r requirements.txt
    11: ```
    12: 
    13: Pour développer ou exécuter les tests :
    14: 
    15: ```bash
    16: pip install -r requirements-dev.txt
    17: pytest  # ou make test
    18: ```
    19: 
    20: ## Configuration
    21: 
    22: Le bot lit sa configuration via des variables d'environnement :
    23: 
    24: - `BITGET_ACCESS_KEY`, `BITGET_SECRET_KEY` : clés API Bitget (laisser les valeurs par défaut pour rester en mode papier).
    25: - `PAPER_TRADE` (`true`/`false`) : par défaut `true`, n'envoie aucun ordre réel.
    26: - `SYMBOL` : symbole du contrat futures (par défaut, `BTCUSDT`).
    27: - `INTERVAL` : intervalle des chandeliers, ex. `1m`, `5m`.
    28: - `EMA_FAST`, `EMA_SLOW` : périodes des EMA utilisées par la stratégie.
    29: - `MACD_FAST`, `MACD_SLOW`, `MACD_SIGNAL` : paramètres du filtre de tendance MACD.
    30: - `EMA_TREND_PERIOD` : période de l'EMA longue utilisée comme filtre de tendance général.
    31: - `RISK_PCT_EQUITY`, `LEVERAGE`, `STOP_LOSS_PCT`, `TAKE_PROFIT_PCT` : paramètres de gestion du risque.
    32: - `ATR_PERIOD`, `TRAIL_ATR_MULT`, `SCALE_IN_ATR_MULT`, `PROGRESS_MIN`, `TIMEOUT_MIN` : réglages pour l'ATR, l'ajout à la position, le trailing stop et la sortie par timeout.
    33: - `MAX_DAILY_LOSS_PCT`, `MAX_DAILY_PROFIT_PCT`, `MAX_POSITIONS` (par défaut 3) : limites globales (kill switch après perte ou gain, nombre maximal de positions).
    34: - `LOG_DIR` : dossier où seront écrits les fichiers de log.
    35: - `ALLOWED_SYMBOLS` : liste de paires autorisées séparées par des virgules. Vide par défaut pour autoriser toutes les paires.
    36: 
    37: - `NOTIFY_URL` : URL d'un webhook HTTP pour recevoir les événements (optionnel, peut être utilisé en plus de Telegram).
    38: - `TELEGRAM_BOT_TOKEN`, `TELEGRAM_CHAT_ID` : pour envoyer les notifications sur Telegram (optionnel, peut être combiné avec le webhook).
    39: 
    40: Pour éviter de versionner vos clés sensibles, vous pouvez créer un fichier
    41: `.env` dans le dossier parent du dépôt (par exemple `Notebooks/.env` si le
    42: code se trouve dans `Notebooks/scalp`).  Ce fichier est automatiquement chargé
    43: au démarrage et toutes les variables qu'il contient seront disponibles pour le
    44: bot.
    45: 
    46: 
    47: Exemple :
    48: 
    49: ```bash
    50: export BITGET_ACCESS_KEY="votre_cle"
    51: export BITGET_SECRET_KEY="votre_secret"
    52: export PAPER_TRADE=true
    53: export TELEGRAM_BOT_TOKEN="123456:ABCDEF..."
    54: export TELEGRAM_CHAT_ID="123456789"
    55: python bot.py
    56: ```
    57: 
    58: ## Lancement
    59: 
    60: Après configuration, lancez simplement :
    61: 
    62: ```bash
    63: python bot.py
    64: ```
    65: 
    66: Le terminal reste silencieux au démarrage sauf en cas d'absence de variables critiques (`BITGET_ACCESS_KEY`, `BITGET_SECRET_KEY`). Les journaux sont écrits dans `logs/` et affichés sur la console. Le bot tourne jusqu'à `Ctrl+C`. Les ouvertures et fermetures de positions sont consignées dans `bot_events.jsonl`.
    67: 
    68: Lors du démarrage, deux notifications Telegram sont émises : la première affiche « Bot démarré » avec un logo, la seconde « Listing ok » sans détailler les paires sélectionnées.
    69: 
    70: Ensuite, un rappel du marché est envoyé chaque minute et l'interface Telegram propose un bouton « Fermer Bot » pour arrêter proprement l'exécution.
    71: 
    72: 
    73: ## Stratégie
    74: 
    75: Scalp cherche à capter de courts mouvements de tendance tout en coupant
    76: rapidement les pertes.
    77: 
    78: Principes généraux :
    79: 
    80: - sélection de paires liquides au fort momentum ;
    81: - trade uniquement dans le sens de la tendance dominante (MACD + EMA longue) ;
    82: - confirmation multi‑indicateurs (VWAP, volume/OBV, RSI multi‑UT) ;
    83: - stop‑loss et take‑profit dynamiques basés sur l’ATR avec taille de position
    84:   calculée selon le risque ;
    85: - limites quotidiennes pour protéger le capital.
    86: 
    87: Les règles détaillées et l’algorithme complet sont décrits dans
    88: `STRATEGY.md`.
    89: 
    90: ## Version
    91: 
    92: La version du bot est stockée dans le fichier `scalp/VERSION` et exposée dans
    93: le code via la variable `scalp.__version__` :
    94: 
    95: ```python
    96: from scalp import __version__
    97: print(__version__)
    98: ```
    99: 
   100: Pour incrémenter la version, utilisez `scalp.version.bump_version` avec
   101: 
   102: `"major"`, `"minor"` ou `"patch"` comme argument. La fonction
   103: `scalp.version.bump_version_from_message` permet également de déterminer
   104: automatiquement l'incrément à appliquer à partir d'un message de commit
   105: suivant la convention [Conventional Commits](https://www.conventionalcommits.org).
   106: 
   107: Exemple d'incrément basé sur un message :
   108: 
   109: ```python
   110: from scalp.version import bump_version_from_message
   111: bump_version_from_message("feat: add new strategy")
   112: ```
   113: 
   114: Exécuté en tant que script, `python -m scalp.version` lit le dernier
   115: message de commit `git` et met à jour le fichier `VERSION` en
   116: conséquence.
   117: 
   118: La même opération peut être déclenchée depuis la ligne de commande via
   119: `cli.py` :
   120: 
   121: ```bash
   122: python cli.py bump-version
   123: ```
   124: 
   125: 
   126: ## Changelog
   127: 
   128: - Ajout d'un contrôle de marge disponible avant chaque ordre afin d'éviter l'erreur Bitget « The order amount exceeds the balance » (code 40762).
   129: 
   130: ## Avertissement
   131: 
   132: © 2025 — Usage à vos risques. Ceci n'est pas un conseil financier.


## STRATEGY.md (last modified: 2025-08-23 20:57:14)
     1: # Stratégie de trading
     2: 
     3: Ce document décrit la logique de trading utilisée par le bot **Scalp**. Elle vise un scalping court terme sur les futures USDT‑M de Bitget.
     4: 
     5: ## Principes généraux
     6: 
     7: - ne traiter que des actifs liquides à fort momentum ;
     8: - suivre la tendance dominante et éviter les marchés plats ;
     9: - utiliser des confirmations multi‑unités de temps pour limiter les faux signaux ;
    10: - dimensionner chaque position selon un pourcentage fixe du capital ;
    11: - couper rapidement les pertes et laisser courir les gains via un suivi dynamique.
    12: 
    13: ## Sélection des paires
    14: 
    15: 1. `scan_pairs` récupère les tickers Bitget et filtre ceux qui possèdent un volume quotidien suffisant et un spread réduit.
    16: 2. `select_active_pairs` affine la liste en conservant les paires présentant le plus de **momentum** :
    17:    - croisement entre EMA20 et EMA50 ;
    18:    - ATR élevé pour privilégier les actifs volatils.
    19: 
    20: ## Génération du signal
    21: 
    22: `generate_signal` produit un signal d’entrée long ou court lorsque les conditions suivantes sont réunies :
    23: 
    24: - prix au‑dessus ou en dessous du **VWAP** et des EMA20/50 selon la direction recherchée ;
    25: - **RSI(14)** traversant les niveaux 40/60 avec confirmation d’un **RSI 15 min** et de la pente de l’**EMA 1 h** ;
    26: - **MACD** alignée avec la tendance et **EMA** longue en filtrage global ;
    27: - hausse d’**OBV** ou volume supérieur à la moyenne ;
    28: - cassure du dernier **swing high/low** ;
    29: - éventuel filtre d’**order book imbalance** et de ratio de ticks.
    30: 
    31: Les distances de stop et de take profit sont calculées à partir de l’**ATR**, ce qui permet également de dimensionner la taille de position via `calc_position_size`.
    32: 
    33: ## Gestion du risque
    34: 
    35: La classe `RiskManager` applique plusieurs garde‑fous :
    36: 
    37: - limite de perte quotidienne (`max_daily_loss_pct`) et optionnellement de gain (`max_daily_profit_pct`) déclenchant un *kill switch* ;
    38: - suivi des séries de gains/pertes pour ajuster le pourcentage de risque par trade ;
    39: - pause forcée en cas de pertes consécutives prolongées ;
    40: - contrôle du nombre maximal de positions ouvertes.
    41: 
    42: Ces règles combinées visent à protéger le capital tout en conservant une exposition opportuniste au marché.


## TRASH_20250823-124533/bitget_futures_pairs.py (last modified: 2025-08-23 20:57:14)
     1: #!/usr/bin/env python3
     2: """Fetch the list of Bitget futures contracts.
     3: 
     4: This helper script queries the public Bitget REST API to retrieve futures
     5: trading pairs for the specified product types and saves them to CSV and JSON
     6: files. It mirrors the standalone example provided by the user but integrates
     7: with the repository's configuration system.
     8: 
     9: Usage examples::
    10: 
    11:     python bitget_futures_pairs.py
    12:     python bitget_futures_pairs.py --types USDT-FUTURES COIN-FUTURES
    13:     python bitget_futures_pairs.py --out pairs.csv --json-out pairs.json
    14: """
    15: from __future__ import annotations
    16: 
    17: import argparse
    18: import csv
    19: import json
    20: import sys
    21: import time
    22: from typing import Any, Dict, List
    23: 
    24: from scalper.bot_config import CONFIG
    25: 
    26: try:  # pragma: no cover - import guard
    27:     import requests
    28: except ModuleNotFoundError as exc:  # pragma: no cover - handled at runtime
    29:     sys.stderr.write(
    30:         "This script requires the 'requests' package. Install it with:\n  pip install requests\n"
    31:     )
    32:     raise
    33: 
    34: BASE_URL = CONFIG.get("BASE_URL", "https://api.bitget.com")
    35: CONTRACTS_ENDPOINT = "/api/v2/mix/market/contracts"
    36: DEFAULT_PRODUCT_TYPES = ["USDT-FUTURES", "USDC-FUTURES", "COIN-FUTURES"]
    37: 
    38: 
    39: def fetch_contracts(product_type: str, timeout: float = 10.0) -> List[Dict[str, Any]]:
    40:     """Return contract metadata for ``product_type``."""
    41:     url = f"{BASE_URL}{CONTRACTS_ENDPOINT}"
    42:     params = {"productType": product_type}
    43:     resp = requests.get(url, params=params, timeout=timeout)
    44:     try:
    45:         data = resp.json()
    46:     except json.JSONDecodeError as exc:  # pragma: no cover - network failure
    47:         raise RuntimeError(
    48:             f"Non-JSON response from Bitget API for {product_type}: {resp.text[:200]}"
    49:         ) from exc
    50:     if resp.status_code != 200 or data.get("code") != "00000":
    51:         raise RuntimeError(f"Bitget API error for {product_type}: HTTP {resp.status_code} body={data}")
    52:     return data.get("data", [])
    53: 
    54: 
    55: def normalize_rows(product_type: str, contracts: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    56:     """Select and rename key fields for CSV/JSON output."""
    57:     rows: List[Dict[str, Any]] = []
    58:     for c in contracts:
    59:         row = {
    60:             "productType": product_type,
    61:             "symbol": c.get("symbol"),
    62:             "baseCoin": c.get("baseCoin"),
    63:             "quoteCoin": c.get("quoteCoin"),
    64:             "symbolType": c.get("symbolType"),
    65:             "symbolStatus": c.get("symbolStatus"),
    66:             "maxLever": c.get("maxLever"),
    67:             "minLever": c.get("minLever"),
    68:             "minTradeNum": c.get("minTradeNum"),
    69:             "sizeMultiplier": c.get("sizeMultiplier"),
    70:             "pricePlace": c.get("pricePlace"),
    71:             "volumePlace": c.get("volumePlace"),
    72:             "launchTime": c.get("launchTime"),
    73:             "deliveryTime": c.get("deliveryTime"),
    74:         }
    75:         rows.append(row)
    76:     return rows
    77: 
    78: 
    79: def write_csv(rows: List[Dict[str, Any]], path: str) -> None:
    80:     """Write ``rows`` to ``path`` in CSV format."""
    81:     headers = [
    82:         "productType",
    83:         "symbol",
    84:         "baseCoin",
    85:         "quoteCoin",
    86:         "symbolType",
    87:         "symbolStatus",
    88:         "maxLever",
    89:         "minLever",
    90:         "minTradeNum",
    91:         "sizeMultiplier",
    92:         "pricePlace",
    93:         "volumePlace",
    94:         "launchTime",
    95:         "deliveryTime",
    96:     ]
    97:     with open(path, "w", newline="", encoding="utf-8") as fh:
    98:         writer = csv.DictWriter(fh, fieldnames=headers)
    99:         writer.writeheader()
   100:         if rows:
   101:             writer.writerows(rows)
   102: 
   103: 
   104: def main(argv: List[str] | None = None) -> int:
   105:     parser = argparse.ArgumentParser(
   106:         description="Fetch Bitget futures pairs (contracts) and save to CSV/JSON."
   107:     )
   108:     parser.add_argument(
   109:         "--types",
   110:         nargs="+",
   111:         default=DEFAULT_PRODUCT_TYPES,
   112:         help="Product types to fetch. Choices: USDT-FUTURES, USDC-FUTURES, COIN-FUTURES",
   113:     )
   114:     parser.add_argument("--out", default="bitget_futures_pairs.csv", help="CSV output file path")
   115:     parser.add_argument(
   116:         "--json-out", default="bitget_futures_pairs.json", help="JSON output file path"
   117:     )
   118:     parser.add_argument("--sleep", type=float, default=0.2, help="Seconds to sleep between requests")
   119:     args = parser.parse_args(argv)
   120: 
   121:     all_rows: List[Dict[str, Any]] = []
   122:     merged_json: Dict[str, List[Dict[str, Any]]] = {}
   123: 
   124:     for i, pt in enumerate(args.types):
   125:         try:
   126:             contracts = fetch_contracts(pt)
   127:         except Exception as exc:  # pragma: no cover - network/runtime error
   128:             sys.stderr.write(f"[!] Failed to fetch {pt}: {exc}\n")
   129:             continue
   130:         rows = normalize_rows(pt, contracts)
   131:         all_rows.extend(rows)
   132:         merged_json[pt] = contracts
   133:         if i < len(args.types) - 1 and args.sleep > 0:
   134:             time.sleep(args.sleep)
   135: 
   136:     all_rows.sort(key=lambda r: (r.get("productType") or "", r.get("symbol") or ""))
   137: 
   138:     write_csv(all_rows, args.out)
   139:     with open(args.json_out, "w", encoding="utf-8") as fh:
   140:         json.dump(merged_json, fh, ensure_ascii=False, indent=2)
   141: 
   142:     counts = {pt: len(merged_json.get(pt, [])) for pt in args.types}
   143:     total = sum(counts.values())
   144:     print(
   145:         f"Saved {total} futures pairs across {len(args.types)} product types to '{args.out}' and '{args.json_out}'."
   146:     )
   147:     for pt, n in counts.items():
   148:         print(f"  - {pt}: {n} pairs")
   149:     return 0
   150: 
   151: 
   152: if __name__ == "__main__":  # pragma: no cover - CLI execution
   153:     raise SystemExit(main())


## TRASH_20250823-124533/dashboard.py (last modified: 2025-08-23 20:57:14)
     1: # dashboard.py
     2: from __future__ import annotations
     3: 
     4: import os
     5: import time
     6: from pathlib import Path
     7: from typing import Dict, Tuple
     8: 
     9: import pandas as pd
    10: import streamlit as st
    11: 
    12: # ------------------------------------------------------------
    13: # Réglages
    14: # ------------------------------------------------------------
    15: LOG_DIR = Path("scalp/live/logs")  # emplacement des CSV créés par l'orchestrateur
    16: REFRESH_SECS = 5                   # auto-refresh UI
    17: MAX_ROWS_SHOW = 2000               # clamp mémoire
    18: 
    19: 
    20: # ------------------------------------------------------------
    21: # Utilitaires lecture robuste CSV
    22: # ------------------------------------------------------------
    23: def _safe_read_csv(path: Path) -> pd.DataFrame:
    24:     if not path.exists():
    25:         return pd.DataFrame()
    26:     try:
    27:         df = pd.read_csv(path)
    28:         # clamp pour éviter d’exploser en RAM si les logs deviennent énormes
    29:         if len(df) > MAX_ROWS_SHOW:
    30:             df = df.tail(MAX_ROWS_SHOW).reset_index(drop=True)
    31:         return df
    32:     except Exception:
    33:         # fichier en cours d’écriture → on réessaiera au prochain tick
    34:         return pd.DataFrame()
    35: 
    36: 
    37: def load_logs() -> Dict[str, pd.DataFrame]:
    38:     return {
    39:         "signals": _safe_read_csv(LOG_DIR / "signals.csv"),
    40:         "orders": _safe_read_csv(LOG_DIR / "orders.csv"),
    41:         "fills": _safe_read_csv(LOG_DIR / "fills.csv"),
    42:         "positions": _safe_read_csv(LOG_DIR / "positions.csv"),
    43:     }
    44: 
    45: 
    46: def _format_ts_ms_to_str(df: pd.DataFrame, col: str = "ts") -> pd.DataFrame:
    47:     if col in df.columns:
    48:         try:
    49:             df[col] = pd.to_datetime(df[col], unit="ms")
    50:         except Exception:
    51:             try:
    52:                 df[col] = pd.to_datetime(df[col])
    53:             except Exception:
    54:                 pass
    55:     return df
    56: 
    57: 
    58: # ------------------------------------------------------------
    59: # Métriques & agrégats simples
    60: # ------------------------------------------------------------
    61: def compute_activity_metrics(df_orders: pd.DataFrame, df_fills: pd.DataFrame) -> Tuple[float, float, int]:
    62:     """
    63:     Retourne: (volume notionnel approx, fees cumulés, nb fills)
    64:     - notionnel approx = somme(|price * qty|) sur les fills (indépendant du sens)
    65:     - fees = somme(fee) si dispo
    66:     """
    67:     notional = 0.0
    68:     fees = 0.0
    69:     n_fills = 0
    70: 
    71:     if not df_fills.empty:
    72:         # normalisation colonnes
    73:         price_col = next((c for c in ["price", "fillPrice", "fill_px"] if c in df_fills.columns), None)
    74:         qty_col = next((c for c in ["qty", "size", "fillQty", "fill_sz"] if c in df_fills.columns), None)
    75:         fee_col = next((c for c in ["fee", "fillFee"] if c in df_fills.columns), None)
    76: 
    77:         if price_col and qty_col:
    78:             notional = float((df_fills[price_col].abs() * df_fills[qty_col].abs()).sum())
    79:             n_fills = int(len(df_fills))
    80:         if fee_col:
    81:             fees = float(df_fills[fee_col].fillna(0).sum())
    82: 
    83:     return notional, fees, n_fills
    84: 
    85: 
    86: def last_positions_snapshot(df_positions: pd.DataFrame) -> pd.DataFrame:
    87:     """Dernier état par symbole (state/qty/entry)."""
    88:     if df_positions.empty:
    89:         return df_positions
    90:     df = df_positions.copy()
    91:     df = _format_ts_ms_to_str(df, "ts")
    92:     # on prend le dernier enregistrement par symbol
    93:     last = df.sort_values("ts").groupby("symbol", as_index=False).tail(1)
    94:     return last.sort_values("symbol").reset_index(drop=True)
    95: 
    96: 
    97: def recent_signals(df_signals: pd.DataFrame, limit: int = 30) -> pd.DataFrame:
    98:     if df_signals.empty:
    99:         return df_signals
   100:     df = df_signals.copy()
   101:     df = _format_ts_ms_to_str(df, "ts")
   102:     df = df.sort_values("ts", ascending=False).head(limit)
   103:     return df.reset_index(drop=True)
   104: 
   105: 
   106: def recent_orders(df_orders: pd.DataFrame, limit: int = 30) -> pd.DataFrame:
   107:     if df_orders.empty:
   108:         return df_orders
   109:     df = df_orders.copy()
   110:     df = _format_ts_ms_to_str(df, "ts")
   111:     df = df.sort_values("ts", ascending=False).head(limit)
   112:     # petites colonnes utiles en premier
   113:     cols = [c for c in ["ts", "symbol", "side", "status", "price", "sl", "tp", "risk_pct", "order_id"] if c in df.columns]
   114:     other = [c for c in df.columns if c not in cols]
   115:     return df[cols + other]
   116: 
   117: 
   118: def recent_fills(df_fills: pd.DataFrame, limit: int = 50) -> pd.DataFrame:
   119:     if df_fills.empty:
   120:         return df_fills
   121:     df = df_fills.copy()
   122:     df = _format_ts_ms_to_str(df, "ts")
   123:     df = df.sort_values("ts", ascending=False).head(limit)
   124:     cols = [c for c in ["ts", "symbol", "order_id", "trade_id", "price", "qty", "fee"] if c in df.columns]
   125:     other = [c for c in df.columns if c not in cols]
   126:     return df[cols + other]
   127: 
   128: 
   129: # ------------------------------------------------------------
   130: # UI
   131: # ------------------------------------------------------------
   132: st.set_page_config(page_title="ScalpBot Dashboard", layout="wide")
   133: st.title("📊 ScalpBot — Dashboard Live")
   134: 
   135: # auto-refresh
   136: st.caption("Auto-refresh toutes les {}s".format(REFRESH_SECS))
   137: st_autorefresh = st.experimental_rerun if False else None  # placeholder to keep code readable
   138: # Streamlit v1.32+ propose st.autorefresh :
   139: try:
   140:     st_autorefresh = st.experimental_rerun  # fallback compat
   141:     from streamlit.runtime.scriptrunner import add_script_run_ctx  # noqa: F401
   142:     st_autorefresh = None
   143: except Exception:
   144:     pass
   145: 
   146: try:
   147:     st_autorefresh = st.autorefresh(interval=REFRESH_SECS * 1000, key="autorf")
   148: except Exception:
   149:     pass
   150: 
   151: # Choix du dossier de logs (utile si on lance le dashboard depuis un autre cwd)
   152: default_dir = str(LOG_DIR.resolve())
   153: custom_dir = st.sidebar.text_input("Dossier de logs", value=default_dir)
   154: LOG_DIR = Path(custom_dir) if custom_dir else LOG_DIR
   155: 
   156: if not LOG_DIR.exists():
   157:     st.error(f"Dossier introuvable : {LOG_DIR}")
   158:     st.stop()
   159: 
   160: data = load_logs()
   161: df_sig, df_ord, df_fill, df_pos = data["signals"], data["orders"], data["fills"], data["positions"]
   162: 
   163: # KPIs rapides
   164: notional, fees, n_fills = compute_activity_metrics(df_ord, df_fill)
   165: col_a, col_b, col_c, col_d = st.columns(4)
   166: col_a.metric("Paires actives (Top 10)", "10")
   167: col_b.metric("Fills (total)", f"{n_fills}")
   168: col_c.metric("Notionnel cumulé (approx)", f"{notional:,.0f} USDT")
   169: col_d.metric("Frais cumulés", f"{fees:,.2f} USDT")
   170: 
   171: st.divider()
   172: 
   173: # 1) Positions snapshot
   174: st.subheader("📌 Positions (snapshot courant par symbole)")
   175: pos_snapshot = last_positions_snapshot(df_pos)
   176: if pos_snapshot.empty:
   177:     st.info("Aucune position pour l’instant.")
   178: else:
   179:     # Met un peu d'ordre dans les colonnes
   180:     order_cols = [c for c in ["symbol", "state", "qty", "entry", "ts"] if c in pos_snapshot.columns]
   181:     pos_snapshot = pos_snapshot[order_cols + [c for c in pos_snapshot.columns if c not in order_cols]]
   182:     st.dataframe(pos_snapshot, use_container_width=True, height=260)
   183: 
   184: # 2) Derniers signaux
   185: st.subheader("📣 Derniers signaux")
   186: sig_tbl = recent_signals(df_sig, limit=40)
   187: if sig_tbl.empty:
   188:     st.info("Pas encore de signaux.")
   189: else:
   190:     # comptage LONG/SHORT
   191:     try:
   192:         by_side = sig_tbl.assign(side_norm=sig_tbl["side"].astype(str).str.upper()).groupby("side_norm").size()
   193:         st.bar_chart(by_side)
   194:     except Exception:
   195:         pass
   196:     st.dataframe(sig_tbl, use_container_width=True, height=300)
   197: 
   198: # 3) Ordres récents
   199: st.subheader("🧾 Ordres récents")
   200: ord_tbl = recent_orders(df_ord, limit=40)
   201: if ord_tbl.empty:
   202:     st.info("Pas encore d’ordres.")
   203: else:
   204:     st.dataframe(ord_tbl, use_container_width=True, height=280)
   205: 
   206: # 4) Fills récents
   207: st.subheader("✅ Fills récents")
   208: fills_tbl = recent_fills(df_fill, limit=80)
   209: if fills_tbl.empty:
   210:     st.info("Pas encore d’exécutions (fills).")
   211: else:
   212:     st.dataframe(fills_tbl, use_container_width=True, height=320)
   213: 
   214: st.caption(f"Logs: {LOG_DIR}")

## TRASH_20250823-124533/dump_repo.py (last modified: 2025-08-23 20:57:14)
     1: import os
     2: from datetime import datetime
     3: from pathlib import Path
     4: 
     5: IGNORE_EXTENSIONS = {'.log', '.pyc'}
     6: IGNORE_DIRS = {'__pycache__'}
     7: 
     8: 
     9: def _is_ignored(path: Path) -> bool:
    10:     """Return True if the path should be ignored."""
    11:     if any(part.startswith('.') for part in path.parts):
    12:         return True
    13:     if path.suffix in IGNORE_EXTENSIONS:
    14:         return True
    15:     if any(part in IGNORE_DIRS for part in path.parts):
    16:         return True
    17:     return False
    18: 
    19: 
    20: def _build_tree(root: Path, ignore_path: Path) -> str:
    21:     lines = []
    22:     for dirpath, dirnames, filenames in os.walk(root):
    23:         dirpath = Path(dirpath)
    24:         dirnames[:] = [d for d in dirnames if not d.startswith('.') and d not in IGNORE_DIRS]
    25:         depth = len(dirpath.relative_to(root).parts)
    26:         indent = '    ' * depth
    27:         lines.append(f"{indent}{dirpath.name}/")
    28:         for fname in sorted(filenames):
    29:             fpath = dirpath / fname
    30:             if fpath == ignore_path or _is_ignored(fpath):
    31:                 continue
    32:             lines.append(f"{indent}    {fname}")
    33:     return '\n'.join(lines)
    34: 
    35: 
    36: def _iter_files(root: Path):
    37:     for path in sorted(root.rglob('*')):
    38:         if path.is_file() and not _is_ignored(path):
    39:             yield path
    40: 
    41: 
    42: def create_dump_file(output_path: str = 'dump.txt', root: str = '.') -> None:
    43:     """Create a text dump of the repository tree and file contents."""
    44:     root_path = Path(root).resolve()
    45:     output_path = root_path / output_path
    46:     now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    47:     with output_path.open('w', encoding='utf-8') as dump:
    48:         dump.write(f"Dump created: {now}\n")
    49:         dump.write('Repository tree:\n')
    50:         dump.write(_build_tree(root_path, output_path))
    51:         dump.write('\n\n')
    52:         for file_path in _iter_files(root_path):
    53:             rel_path = file_path.relative_to(root_path)
    54:             if file_path == output_path:
    55:                 continue
    56:             mod_time = datetime.fromtimestamp(file_path.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')
    57:             dump.write(f"## {rel_path} (last modified: {mod_time})\n")
    58:             try:
    59:                 with file_path.open('r', encoding='utf-8') as f:
    60:                     for i, line in enumerate(f, 1):
    61:                         dump.write(f"{i:6}: {line}")
    62:             except Exception:
    63:                 dump.write('[unreadable file]\n')
    64:             dump.write('\n\n')
    65: 
    66: 
    67: if __name__ == '__main__':
    68:     create_dump_file()


## TRASH_20250823-124533/notebooks/spot/bitget_bot.py (last modified: 2025-08-23 20:57:14)
     1: import os
     2: import time
     3: import hmac
     4: import hashlib
     5: import base64
     6: import logging
     7: from argparse import ArgumentParser
     8: from pathlib import Path
     9: from typing import Any, Dict, List
    10: from urllib.parse import urlencode
    11: 
    12: import requests
    13: from dotenv import load_dotenv
    14: 
    15: BASE_URL = "https://api.bitget.com"
    16: RECV_WINDOW = 5000
    17: 
    18: 
    19: def load_keys() -> Dict[str, str]:
    20:     parent = Path(__file__).resolve().parent.parent
    21:     load_dotenv(parent / ".env")
    22:     api_key = os.getenv("BITGET_API_KEY")
    23:     api_secret = os.getenv("BITGET_API_SECRET")
    24:     if not api_key or not api_secret:
    25:         raise RuntimeError("API keys not found in environment")
    26:     return {"key": api_key, "secret": api_secret}
    27: 
    28: 
    29: class BitgetClient:
    30:     def __init__(self) -> None:
    31:         creds = load_keys()
    32:         self.api_key = creds["key"]
    33:         self.api_secret = creds["secret"]
    34:         self.session = requests.Session()
    35:         self.session.headers.update({"X-BITGET-APIKEY": self.api_key})
    36:         self.time_offset = self._compute_time_offset()
    37: 
    38:     def _compute_time_offset(self) -> int:
    39:         server = self.server_time()
    40:         return int(server["serverTime"]) - int(time.time() * 1000)
    41: 
    42:     def _timestamp(self) -> int:
    43:         return int(time.time() * 1000) + self.time_offset
    44: 
    45:     def _request(
    46:         self, method: str, path: str, params: Dict[str, Any] | None = None, *, signed: bool = False
    47:     ) -> Any:
    48:         params = params or {}
    49:         if signed:
    50:             params["timestamp"] = self._timestamp()
    51:             params["recvWindow"] = RECV_WINDOW
    52:             query = urlencode(params)
    53:             signature = base64.b64encode(
    54:                 hmac.new(self.api_secret.encode(), query.encode(), hashlib.sha256).digest()
    55:             ).decode()
    56:             query += f"&signature={signature}"
    57:             headers = {"X-BITGET-APIKEY": self.api_key}
    58:             if method.upper() == "GET":
    59:                 url = f"{BASE_URL}{path}?{query}"
    60:                 resp = self.session.get(url, headers=headers)
    61:             else:
    62:                 url = f"{BASE_URL}{path}"
    63:                 headers["Content-Type"] = "application/x-www-form-urlencoded"
    64:                 resp = self.session.post(url, data=query, headers=headers)
    65:         else:
    66:             url = f"{BASE_URL}{path}"
    67:             resp = self.session.request(method, url, params=params)
    68: 
    69:         resp.raise_for_status()
    70:         if resp.text:
    71:             return resp.json()
    72:         return {}
    73: 
    74:     # Helpers
    75:     def server_time(self) -> Any:
    76:         return self._request("GET", "/api/v3/time")
    77: 
    78:     def ticker_price(self, symbol: str) -> Any:
    79:         return self._request("GET", "/api/v3/ticker/price", {"symbol": symbol})
    80: 
    81:     def klines(self, symbol: str, interval: str = "1m", limit: int = 100) -> Any:
    82:         return self._request(
    83:             "GET", "/api/v3/klines", {"symbol": symbol, "interval": interval, "limit": limit}
    84:         )
    85: 
    86:     def test_order(self, **params: Any) -> Any:
    87:         return self._request("POST", "/api/v3/order/test", params, signed=True)
    88: 
    89:     def place_order(self, **params: Any) -> Any:
    90:         return self._request("POST", "/api/v3/order", params, signed=True)
    91: 
    92:     def account_info(self) -> Any:
    93:         return self._request("GET", "/api/v3/account", signed=True)
    94: 
    95:     def book_ticker(self, symbol: str) -> Any:
    96:         return self._request("GET", "/api/v3/ticker/bookTicker", {"symbol": symbol})
    97: 
    98: 
    99: def sma(values: List[float], period: int) -> float:
   100:     if len(values) < period:
   101:         raise ValueError("Not enough data for SMA")
   102:     return sum(values[-period:]) / period
   103: 
   104: 
   105: def analyze(client: BitgetClient, symbol: str, quote_usdt: float, dry_run: bool) -> None:
   106:     kl = client.klines(symbol, limit=50)
   107:     closes = [float(k[4]) for k in kl]
   108:     sma9_prev = sma(closes[:-1], 9)
   109:     sma21_prev = sma(closes[:-1], 21)
   110:     sma9_curr = sma(closes, 9)
   111:     sma21_curr = sma(closes, 21)
   112: 
   113:     cross_up = sma9_prev <= sma21_prev and sma9_curr > sma21_curr
   114:     cross_down = sma9_prev >= sma21_prev and sma9_curr < sma21_curr
   115: 
   116:     log = logging.getLogger("bitget_bot")
   117: 
   118:     if cross_up:
   119:         book = client.book_ticker(symbol)
   120:         ask = float(book["askPrice"])
   121:         qty = quote_usdt / ask
   122:         params = {
   123:             "symbol": symbol,
   124:             "side": "BUY",
   125:             "type": "LIMIT",
   126:             "timeInForce": "IOC",
   127:             "quantity": f"{qty:.6f}",
   128:             "price": book["askPrice"],
   129:         }
   130:         log.info("BUY signal %s", params)
   131:         resp = client.test_order(**params) if dry_run else client.place_order(**params)
   132:         log.info("response %s", resp)
   133:     elif cross_down:
   134:         account = client.account_info()
   135:         base = symbol.rstrip("USDT")
   136:         bal = next((b for b in account["balances"] if b["asset"] == base), {"free": "0"})
   137:         qty = float(bal["free"])
   138:         if qty > 0:
   139:             book = client.book_ticker(symbol)
   140:             params = {
   141:                 "symbol": symbol,
   142:                 "side": "SELL",
   143:                 "type": "LIMIT",
   144:                 "timeInForce": "IOC",
   145:                 "quantity": f"{qty:.6f}",
   146:                 "price": book["bidPrice"],
   147:             }
   148:             log.info("SELL signal %s", params)
   149:             resp = client.test_order(**params) if dry_run else client.place_order(**params)
   150:             log.info("response %s", resp)
   151:         else:
   152:             log.info("No balance to sell")
   153: 
   154: 
   155: def interval_seconds(interval: str) -> int:
   156:     unit = interval[-1]
   157:     qty = int(interval[:-1])
   158:     if unit == "m":
   159:         return qty * 60
   160:     if unit == "h":
   161:         return qty * 3600
   162:     if unit == "d":
   163:         return qty * 86400
   164:     return 60
   165: 
   166: 
   167: def main() -> None:
   168:     logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")
   169:     parser = ArgumentParser(description="Bitget SMA crossover bot")
   170:     parser.add_argument("--symbol", default="BTCUSDT")
   171:     parser.add_argument("--quote-usdt", type=float, default=10.0)
   172:     parser.add_argument("--interval", default="1m")
   173:     parser.add_argument("--loop", action="store_true")
   174:     parser.add_argument("--dry-run", dest="dry_run", action="store_true")
   175:     parser.add_argument("--live", dest="dry_run", action="store_false")
   176:     parser.set_defaults(dry_run=True)
   177:     args = parser.parse_args()
   178: 
   179:     client = BitgetClient()
   180:     delay = interval_seconds(args.interval)
   181: 
   182:     while True:
   183:         try:
   184:             analyze(client, args.symbol, args.quote_usdt, args.dry_run)
   185:         except Exception as exc:
   186:             logging.getLogger("bitget_bot").error("Error: %s", exc, exc_info=True)
   187:         if not args.loop:
   188:             break
   189:         time.sleep(delay)
   190: 
   191: 
   192: if __name__ == "__main__":
   193:     main()


## TRASH_20250823-124533/quick_order.py (last modified: 2025-08-23 20:57:14)
     1: #!/usr/bin/env python3
     2: """Submit a simple market order on Bitget futures.
     3: 
     4: This helper reads API credentials and trade parameters from environment
     5: variables (optionally loaded from a `.env` file) and places a one-way
     6: market order.  Only the essential steps from the user's reference script
     7: are kept to minimise latency and redundant code.
     8: 
     9: Environment variables:
    10:     BITGET_API_KEY / BITGET_ACCESS_KEY
    11:     BITGET_API_SECRET / BITGET_SECRET_KEY
    12:     BITGET_API_PASSPHRASE
    13:     BITGET_BASE_URL (default https://api.bitget.com)
    14:     BITGET_PRODUCT_TYPE (default ``USDT-FUTURES``)
    15:     BITGET_MARGIN_COIN (default ``USDT``)
    16:     BITGET_SYMBOL (e.g. ``BTCUSDT``)
    17:     BITGET_TEST_NOTIONAL_USDT (default ``5``)
    18: 
    19: Usage:
    20:     python quick_order.py buy
    21:     python quick_order.py sell
    22: """
    23: 
    24: from __future__ import annotations
    25: 
    26: import os
    27: import sys
    28: from pathlib import Path
    29: 
    30: from dotenv import load_dotenv
    31: 
    32: from scalper.bitget_client import BitgetFuturesClient
    33: 
    34: # Load variables from `.env` if present
    35: load_dotenv(Path(__file__).resolve().parent / ".env")
    36: 
    37: side = sys.argv[1].lower() if len(sys.argv) > 1 else "buy"
    38: if side not in {"buy", "sell"}:
    39:     raise SystemExit("Usage: quick_order.py [buy|sell]")
    40: 
    41: base = os.getenv("BITGET_BASE_URL", "https://api.bitget.com")
    42: ak = os.getenv("BITGET_API_KEY") or os.getenv("BITGET_ACCESS_KEY")
    43: sk = os.getenv("BITGET_API_SECRET") or os.getenv("BITGET_SECRET_KEY")
    44: ph = os.getenv("BITGET_API_PASSPHRASE") or os.getenv("BITGET_PASSPHRASE")
    45: product_type = os.getenv("BITGET_PRODUCT_TYPE", "USDT-FUTURES").upper()
    46: margin_coin = os.getenv("BITGET_MARGIN_COIN", "USDT")
    47: symbol = (os.getenv("BITGET_SYMBOL", "BTCUSDT") or "BTCUSDT").replace("_", "").upper()
    48: notional = float(os.getenv("BITGET_TEST_NOTIONAL_USDT", "5"))
    49: 
    50: if not (ak and sk and ph):
    51:     raise SystemExit("❌ BITGET_API_KEY/SECRET/PASSPHRASE manquants")
    52: 
    53: client = BitgetFuturesClient(
    54:     access_key=ak,
    55:     secret_key=sk,
    56:     base_url=base,
    57:     passphrase=ph,
    58:     paper_trade=False,
    59: )
    60: 
    61: tick = client.get_ticker(symbol)
    62: price = None
    63: try:
    64:     data = tick.get("data")
    65:     if isinstance(data, list) and data:
    66:         price_str = data[0].get("lastPr") or data[0].get("lastPrice")
    67:         if price_str is not None:
    68:             price = float(price_str)
    69:     elif isinstance(data, dict):
    70:         price_str = data.get("lastPr") or data.get("lastPrice")
    71:         if price_str is not None:
    72:             price = float(price_str)
    73: except Exception:
    74:     pass
    75: if price is None or price <= 0:
    76:     raise SystemExit("Prix introuvable pour le ticker")
    77: 
    78: size = round(notional / price, 6)
    79: client.set_position_mode_one_way(symbol, product_type)
    80: client.set_leverage(symbol, product_type, margin_coin, leverage=2)
    81: resp = client.place_market_order_one_way(
    82:     symbol, side, size, product_type, margin_coin
    83: )
    84: print(resp)


## TRASH_20250823-124533/rr.py (last modified: 2025-08-23 20:57:14)
     1: #!/usr/bin/env python3
     2: from __future__ import annotations
     3: import argparse, shutil, re, os, datetime as dt
     4: from pathlib import Path
     5: 
     6: # ---------- helpers ----------
     7: def info(msg): print(f"[i] {msg}")
     8: def ok(msg):   print(f"[✓] {msg}")
     9: def warn(msg): print(f"[!] {msg}")
    10: 
    11: def backup_repo(repo: Path) -> Path:
    12:     ts = dt.datetime.utcnow().strftime("%Y%m%d-%H%M%S")
    13:     dst = repo.parent / f".backup-refactor-{ts}"
    14:     shutil.copytree(repo, dst)
    15:     ok(f"Sauvegarde créée: {dst}")
    16:     return dst
    17: 
    18: def ensure_pkg_init(path: Path):
    19:     initp = path / "__init__.py"
    20:     if not initp.exists():
    21:         initp.write_text("# package\n", encoding="utf-8")
    22: 
    23: def move_dir(src: Path, dst: Path):
    24:     if not src.exists(): return
    25:     dst.mkdir(parents=True, exist_ok=True)
    26:     for child in src.iterdir():
    27:         shutil.move(str(child), str(dst / child.name))
    28:     # supprime le répertoire source s'il est vide
    29:     try: src.rmdir()
    30:     except Exception: pass
    31: 
    32: # règles initiales (rangement)
    33: IMPORT_RULES_STAGE1 = [
    34:     (re.compile(r"from\s+scalp\.config\.loader\s+import\s+load_settings"), "from scalper.config import load_settings"),
    35:     (re.compile(r"from\s+config\.loader\s+import\s+load_settings"), "from scalper.config import load_settings"),
    36:     (re.compile(r"from\s+scalp\.config\s+import\s+load_settings"), "from scalper.config import load_settings"),
    37:     (re.compile(r"from\s+live(\.| import)"), r"from scalper.live\1"),
    38:     (re.compile(r"import\s+live(\s|$)"), r"import scalper.live\1"),
    39:     (re.compile(r"from\s+backtest(\.| import)"), r"from scalper.backtest\1"),
    40:     (re.compile(r"import\s+backtest(\s|$)"), r"import scalper.backtest\1"),
    41:     (re.compile(r"from\s+signals(\.| import)"), r"from scalper.signals\1"),
    42:     (re.compile(r"import\s+signals(\s|$)"), r"import scalper.signals\1"),
    43:     (re.compile(r"from\s+exchange(\.| import)"), r"from scalper.exchange\1"),
    44:     (re.compile(r"import\s+exchange(\s|$)"), r"import scalper.exchange\1"),
    45: ]
    46: 
    47: def rewrite_imports(root: Path, rules):
    48:     changed = 0
    49:     for py in root.rglob("*.py"):
    50:         if ".backup-" in str(py) or ".backup" in str(py):  # safety
    51:             continue
    52:         txt = py.read_text(encoding="utf-8")
    53:         new = txt
    54:         for pat, rep in rules:
    55:             new = pat.sub(rep, new)
    56:         if new != txt:
    57:             py.write_text(new, encoding="utf-8")
    58:             changed += 1
    59:     return changed
    60: 
    61: def ensure_config_package(scalp_pkg: Path):
    62:     """Transforme scalp/config.py en package scalp/config/loader.py et ajoute __init__.py exportant load_settings."""
    63:     flat = scalp_pkg / "config.py"
    64:     pkg = scalp_pkg / "config"
    65:     loader = pkg / "loader.py"
    66:     initp = pkg / "__init__.py"
    67: 
    68:     # si un config.py existe, le renommer pour archivage
    69:     if flat.exists():
    70:         legacy = scalp_pkg / "legacy_config.py"
    71:         if legacy.exists(): legacy.unlink()
    72:         shutil.move(str(flat), str(legacy))
    73:         info(f"renommé {flat} -> {legacy}")
    74: 
    75:     pkg.mkdir(parents=True, exist_ok=True)
    76:     ensure_pkg_init(pkg)
    77: 
    78:     # si pas de loader.py, créer un loader minimal (tu pourras le remplacer par ta version complète)
    79:     if not loader.exists():
    80:         loader.write_text(
    81:             'from __future__ import annotations\n'
    82:             'import os, json\n'
    83:             'from typing import Any, Dict, Tuple\n'
    84:             'try:\n'
    85:             '    import yaml\n'
    86:             'except Exception:\n'
    87:             '    yaml = None\n'
    88:             'try:\n'
    89:             '    from dotenv import load_dotenv\n'
    90:             'except Exception:\n'
    91:             '    load_dotenv = None\n'
    92:             '\n'
    93:             'def _read_yaml(path: str):\n'
    94:             '    if not os.path.exists(path): return {}\n'
    95:             '    with open(path, "r", encoding="utf-8") as f:\n'
    96:             '        if yaml: return yaml.safe_load(f) or {}\n'
    97:             '        return json.load(f)\n'
    98:             '\n'
    99:             'def load_settings(config_path: str="config.yml", config_local_path: str="config.local.yml"):\n'
   100:             '    if load_dotenv: load_dotenv(override=False)\n'
   101:             '    base = _read_yaml(config_path)\n'
   102:             '    local = _read_yaml(config_local_path)\n'
   103:             '    cfg = {**base, **local}\n'
   104:             '    runtime = {\n'
   105:             '        "quiet": bool(cfg.get("QUIET", 1)),\n'
   106:             '        "print_sample": bool(cfg.get("PRINT_OHLCV_SAMPLE", 0)),\n'
   107:             '        "timeframe": str(cfg.get("TIMEFRAME", "5m")),\n'
   108:             '        "cash": float(cfg.get("CASH", 10000)),\n'
   109:             '        "risk_pct": float(cfg.get("RISK_PCT", 0.5)),\n'
   110:             '        "slippage_bps": float(cfg.get("SLIPPAGE_BPS", 2)),\n'
   111:             '        "watchlist_mode": str(cfg.get("WATCHLIST_MODE", "local")),\n'
   112:             '        "watchlist_local_conc": int(cfg.get("WATCHLIST_LOCAL_CONC", 5)),\n'
   113:             '        "top_symbols": cfg.get("TOP_SYMBOLS", []),\n'
   114:             '        "top_candidates": cfg.get("TOP_CANDIDATES", []),\n'
   115:             '        "caps": cfg.get("CAPS", {}),\n'
   116:             '        "fees_by_symbol": {},\n'
   117:             '    }\n'
   118:             '    secrets = {\n'
   119:             '        "BITGET_API_KEY": os.getenv("BITGET_API_KEY", ""),\n'
   120:             '        "BITGET_API_SECRET": os.getenv("BITGET_API_SECRET", ""),\n'
   121:             '        "BITGET_API_PASSWORD": os.getenv("BITGET_API_PASSWORD", ""),\n'
   122:             '        "BITGET_USE_TESTNET": os.getenv("BITGET_USE_TESTNET", "1") in ("1","true","True"),\n'
   123:             '        "BITGET_PRODUCT": os.getenv("BITGET_PRODUCT", "umcbl"),\n'
   124:             '        "TELEGRAM_BOT_TOKEN": os.getenv("TELEGRAM_BOT_TOKEN", ""),\n'
   125:             '        "TELEGRAM_CHAT_ID": os.getenv("TELEGRAM_CHAT_ID", ""),\n'
   126:             '    }\n'
   127:             '    return runtime, secrets\n',
   128:             encoding="utf-8"
   129:         )
   130:     # __init__.py exporte load_settings
   131:     initp.write_text("from .loader import load_settings\n__all__ = ['load_settings']\n", encoding="utf-8")
   132: 
   133: def stage1_restructure(repo: Path):
   134:     """Range les modules à l’intérieur du package 'scalp/' + fix imports."""
   135:     scalp_pkg = repo / "scalp"
   136:     scalp_pkg.mkdir(exist_ok=True)
   137:     ensure_pkg_init(scalp_pkg)
   138: 
   139:     for mod in ("live", "backtest", "signals", "config", "exchange"):
   140:         src = repo / mod
   141:         if src.exists() and src.is_dir():
   142:             dst = scalp_pkg / mod
   143:             info(f"déplacement {src} -> {dst}")
   144:             move_dir(src, dst)
   145:             ensure_pkg_init(dst)
   146: 
   147:     # gérer config.py -> package config/loader.py
   148:     ensure_config_package(scalp_pkg)
   149: 
   150:     # réécriture imports vers scalper.*
   151:     changed = rewrite_imports(repo, IMPORT_RULES_STAGE1)
   152:     ok(f"imports stage1 réécrits dans {changed} fichier(s)")
   153: 
   154: def stage2_rename_package(repo: Path, old="scalp", new="scalper"):
   155:     """Renomme le package interne old -> new et réécrit tous les imports."""
   156:     pkg_old = repo / old
   157:     pkg_new = repo / new
   158:     if not pkg_old.exists():
   159:         warn(f"package {pkg_old} introuvable (déjà renommé ?)")
   160:     else:
   161:         shutil.move(str(pkg_old), str(pkg_new))
   162:         ok(f"package renommé {pkg_old.name} -> {pkg_new.name}")
   163: 
   164:     # réécriture imports 'old.' -> 'new.'
   165:     pat = re.compile(rf"\b{old}\.")
   166:     changed = 0
   167:     for py in repo.rglob("*.py"):
   168:         if ".backup" in str(py): continue
   169:         txt = py.read_text(encoding="utf-8")
   170:         new_txt = pat.sub(f"{new}.", txt)
   171:         if new_txt != txt:
   172:             py.write_text(new_txt, encoding="utf-8")
   173:             changed += 1
   174:     ok(f"imports stage2 réécrits dans {changed} fichier(s)")
   175: 
   176: def main():
   177:     ap = argparse.ArgumentParser(description="Restructure + rename Python package (scalp -> scalper).")
   178:     ap.add_argument("--repo", default="./", help="Chemin du repo (racine qui contient bot.py).")
   179:     args = ap.parse_args()
   180:     repo = Path(args.repo).resolve()
   181:     if not repo.exists(): raise SystemExit(f"Repo introuvable: {repo}")
   182: 
   183:     # 1) sauvegarde
   184:     backup_repo(repo)
   185: 
   186:     # 2) ranger les modules sous scalp/ (package) + fixer imports
   187:     stage1_restructure(repo)
   188: 
   189:     # 3) renommer le package interne scalp/ -> scalper/ + fixer imports
   190:     stage2_rename_package(repo, old="scalp", new="scalper")
   191: 
   192:     ok("Refactor complet terminé.")
   193:     print("\n➡️ Vérifie maintenant:\n"
   194:           "   python - <<'PY'\n"
   195:           "import importlib; m = importlib.import_module('scalper.config'); print('OK:', hasattr(m, 'load_settings'))\n"
   196:           "PY\n"
   197:           "\nPuis lance:\n"
   198:           "   python bot.py\n")
   199: 
   200: if __name__ == "__main__":
   201:     main()

## TRASH_20250823-124533/run_backtest.py (last modified: 2025-08-23 20:57:14)
     1: #!/usr/bin/env python3
     2: import os
     3: from scalper.backtest.engine import BacktestEngine
     4: 
     5: def main():
     6:     print("[*] Lancement du backtest...")
     7:     
     8:     # ⚡ Tu pourras changer ces paramètres
     9:     pairs = ["BTCUSDT", "ETHUSDT"]  # pour commencer simple
    10:     start_date = "2024-01-01"
    11:     end_date = "2024-02-01"
    12: 
    13:     # Dossier résultat
    14:     result_dir = os.path.join(os.path.dirname(__file__), "result")
    15:     os.makedirs(result_dir, exist_ok=True)
    16: 
    17:     # Création du moteur
    18:     engine = BacktestEngine(
    19:         pairs=pairs,
    20:         start_date=start_date,
    21:         end_date=end_date,
    22:         result_dir=result_dir
    23:     )
    24: 
    25:     # Lancer le backtest
    26:     engine.run()
    27: 
    28:     print("[✅] Backtest terminé ! Résultats disponibles dans /result/")
    29: 
    30: if __name__ == "__main__":
    31:     main()

## TRASH_20250823-124533/scalper/bot_config.py (last modified: 2025-08-23 20:57:14)
     1: import os
     2: 
     3: 
     4: DEFAULT_SYMBOL = os.getenv("SYMBOL") or "BTCUSDT"
     5: 
     6: CONFIG = {
     7:     "BITGET_ACCESS_KEY": os.getenv("BITGET_API_KEY")
     8:     or os.getenv("BITGET_ACCESS_KEY", "A_METTRE"),
     9:     "BITGET_SECRET_KEY": os.getenv("BITGET_API_SECRET")
    10:     or os.getenv("BITGET_SECRET_KEY", "B_METTRE"),
    11:     "BITGET_PASSPHRASE": os.getenv("BITGET_API_PASSPHRASE", ""),
    12:     "PAPER_TRADE": os.getenv("PAPER_TRADE", "true").lower() in ("1", "true", "yes", "y"),
    13:     "SYMBOL": DEFAULT_SYMBOL,
    14:     "PRODUCT_TYPE": os.getenv("BITGET_PRODUCT_TYPE", "USDT-FUTURES"),
    15:     "MARGIN_COIN": os.getenv("BITGET_MARGIN_COIN", "USDT"),
    16:     "INTERVAL": os.getenv("INTERVAL", "1m"),
    17:     "EMA_FAST": int(os.getenv("EMA_FAST", "9")),
    18:     "EMA_SLOW": int(os.getenv("EMA_SLOW", "21")),
    19:     "MACD_FAST": int(os.getenv("MACD_FAST", "12")),
    20:     "MACD_SLOW": int(os.getenv("MACD_SLOW", "26")),
    21:     "MACD_SIGNAL": int(os.getenv("MACD_SIGNAL", "9")),
    22:     "EMA_TREND_PERIOD": int(os.getenv("EMA_TREND_PERIOD", "200")),
    23:     "RISK_PCT_EQUITY": float(os.getenv("RISK_PCT_EQUITY", "0.01")),
    24:     "LEVERAGE": int(os.getenv("LEVERAGE", "5")),
    25:     "RISK_LEVEL": int(os.getenv("RISK_LEVEL", "2")),
    26:     "OPEN_TYPE": int(os.getenv("OPEN_TYPE", "1")),
    27:     "STOP_LOSS_PCT": float(os.getenv("STOP_LOSS_PCT", "0.006")),
    28:     "TAKE_PROFIT_PCT": float(os.getenv("TAKE_PROFIT_PCT", "0.012")),
    29:     "ATR_PERIOD": int(os.getenv("ATR_PERIOD", "14")),
    30:     "TRAIL_ATR_MULT": float(os.getenv("TRAIL_ATR_MULT", "0.75")),
    31:     "SCALE_IN_ATR_MULT": float(os.getenv("SCALE_IN_ATR_MULT", "0.5")),
    32:     "PROGRESS_MIN": float(os.getenv("PROGRESS_MIN", "15")),
    33:     "TIMEOUT_MIN": float(os.getenv("TIMEOUT_MIN", "30")),
    34:     "MAX_KLINES": int(os.getenv("MAX_KLINES", "400")),
    35:     "LOOP_SLEEP_SECS": int(os.getenv("LOOP_SLEEP_SECS", "10")),
    36:     "RECV_WINDOW": int(os.getenv("RECV_WINDOW", "30")),
    37:     "LOG_DIR": os.getenv("LOG_DIR", "./logs"),
    38:     # --- Sécurité / Sizing -------------------------------------------------
    39:     "ALLOWED_SYMBOLS": [
    40:         s.strip().upper()
    41:         for s in os.getenv("ALLOWED_SYMBOLS", "").split(",")
    42:         if s.strip()
    43:     ],
    44:     "NOTIONAL_CAP_USDT": float(os.getenv("NOTIONAL_CAP_USDT", "100.0")),
    45:     "MARGIN_CAP_RATIO": float(os.getenv("MARGIN_CAP_RATIO", "0.9")),
    46:     "RISK_PCT_MIN": float(os.getenv("RISK_PCT_MIN", "0.0005")),
    47:     "RISK_PCT_MAX": float(os.getenv("RISK_PCT_MAX", "0.02")),
    48:     "BASE_URL": os.getenv("BITGET_CONTRACT_BASE_URL", "https://api.bitget.com"),
    49:     "FEE_RATE": float(os.getenv("FEE_RATE", "0.0")),
    50:     "MAX_DAILY_LOSS_PCT": float(os.getenv("MAX_DAILY_LOSS_PCT", "5.0")),
    51:     "MAX_DAILY_PROFIT_PCT": float(os.getenv("MAX_DAILY_PROFIT_PCT", "5.0")),
    52:     "MAX_POSITIONS": int(os.getenv("MAX_POSITIONS", "3")),
    53: }
    54: 


## TRASH_20250823-124533/scalper/legacy_config.py (last modified: 2025-08-23 20:57:14)
     1: # scalp/config.py
     2: from __future__ import annotations
     3: import os, sys
     4: from typing import Optional
     5: 
     6: # ---------------------------
     7: #  Chargement .env (sans dep)
     8: # ---------------------------
     9: def _load_dotenv_if_present(path: str = ".env") -> None:
    10:     try:
    11:         if not os.path.isfile(path):
    12:             return
    13:         with open(path, "r", encoding="utf-8") as f:
    14:             for line in f:
    15:                 s = line.strip()
    16:                 if not s or s.startswith("#") or "=" not in s:
    17:                     continue
    18:                 k, v = s.split("=", 1)
    19:                 k = k.strip()
    20:                 v = v.strip().strip('"').strip("'")
    21:                 # ne pas écraser une var déjà définie par l'env
    22:                 os.environ.setdefault(k, v)
    23:     except Exception:
    24:         pass
    25: 
    26: _load_dotenv_if_present()
    27: 
    28: # ---------------------------
    29: #  Aliases variables d'env
    30: # ---------------------------
    31: def _env_alias(name: str, *aliases: str) -> Optional[str]:
    32:     """Retourne la première valeur non nulle parmi name et ses alias."""
    33:     if name in os.environ and os.environ[name]:
    34:         return os.environ[name]
    35:     for a in aliases:
    36:         v = os.environ.get(a)
    37:         if v:
    38:             return v
    39:     return None
    40: 
    41: def _env_bool(name: str, default: bool) -> bool:
    42:     raw = os.environ.get(name)
    43:     if raw is None:
    44:         return default
    45:     return raw.lower() in ("1", "true", "yes", "on")
    46: 
    47: # ---------------------------
    48: #  Pydantic v1 si dispo
    49: # ---------------------------
    50: try:
    51:     from pydantic import BaseModel, Field, ValidationError  # type: ignore
    52:     _HAVE_PYDANTIC = True
    53: except Exception:
    54:     _HAVE_PYDANTIC = False
    55: 
    56: if _HAVE_PYDANTIC:
    57: 
    58:     class AppConfig(BaseModel):
    59:         # Clés Bitget
    60:         BITGET_API_KEY: str = Field(..., min_length=3)
    61:         BITGET_API_SECRET: str = Field(..., min_length=3)
    62:         BITGET_PASSPHRASE: str = Field(..., min_length=1)
    63: 
    64:         # Trading
    65:         RISK_PCT: float = Field(0.01, ge=0.0, le=0.2)
    66:         MIN_TRADE_USDT: float = Field(5.0, ge=0.0)
    67:         LEVERAGE: float = Field(1.0, ge=1.0, le=125.0)
    68:         PAPER_TRADE: bool = Field(True)
    69: 
    70:         # Telegram (facultatif)
    71:         TELEGRAM_BOT_TOKEN: Optional[str] = None
    72:         TELEGRAM_CHAT_ID: Optional[str] = None
    73: 
    74:     def load_or_exit() -> "AppConfig":
    75:         try:
    76:             # supporte aussi ACCESS_KEY/SECRET_KEY (alias)
    77:             api_key = _env_alias("BITGET_API_KEY", "BITGET_ACCESS_KEY")
    78:             api_sec = _env_alias("BITGET_API_SECRET", "BITGET_SECRET_KEY")
    79:             api_pass = _env_alias("BITGET_PASSPHRASE", "BITGET_PASSWORD", "API_PASSPHRASE")
    80: 
    81:             return AppConfig(
    82:                 BITGET_API_KEY=api_key,
    83:                 BITGET_API_SECRET=api_sec,
    84:                 BITGET_PASSPHRASE=api_pass,
    85:                 RISK_PCT=float(os.environ.get("RISK_PCT", "0.01")),
    86:                 MIN_TRADE_USDT=float(os.environ.get("MIN_TRADE_USDT", "5")),
    87:                 LEVERAGE=float(os.environ.get("LEVERAGE", "1")),
    88:                 PAPER_TRADE=_env_bool("PAPER_TRADE", True),
    89:                 TELEGRAM_BOT_TOKEN=_env_alias("TELEGRAM_BOT_TOKEN"),
    90:                 TELEGRAM_CHAT_ID=_env_alias("TELEGRAM_CHAT_ID"),
    91:             )
    92:         except ValidationError as e:
    93:             print("[CONFIG] Invalid configuration:", e, file=sys.stderr)
    94:             sys.exit(2)
    95: 
    96: else:
    97:     # ---------------------------
    98:     #  Fallback dataclass simple
    99:     # ---------------------------
   100:     from dataclasses import dataclass
   101: 
   102:     @dataclass
   103:     class AppConfig:
   104:         BITGET_API_KEY: str
   105:         BITGET_API_SECRET: str
   106:         BITGET_PASSPHRASE: str
   107: 
   108:         RISK_PCT: float = 0.01
   109:         MIN_TRADE_USDT: float = 5.0
   110:         LEVERAGE: float = 1.0
   111:         PAPER_TRADE: bool = True
   112: 
   113:         TELEGRAM_BOT_TOKEN: Optional[str] = None
   114:         TELEGRAM_CHAT_ID: Optional[str] = None
   115: 
   116:     def load_or_exit() -> "AppConfig":
   117:         api_key = _env_alias("BITGET_API_KEY", "BITGET_ACCESS_KEY")
   118:         api_sec = _env_alias("BITGET_API_SECRET", "BITGET_SECRET_KEY")
   119:         api_pass = _env_alias("BITGET_PASSPHRASE", "BITGET_PASSWORD", "API_PASSPHRASE")
   120: 
   121:         if not api_key or not api_sec or not api_pass:
   122:             print("[CONFIG] Missing Bitget credentials. Expected either:", file=sys.stderr)
   123:             print("        - BITGET_API_KEY / BITGET_API_SECRET / BITGET_PASSPHRASE", file=sys.stderr)
   124:             print("          or", file=sys.stderr)
   125:             print("        - BITGET_ACCESS_KEY / BITGET_SECRET_KEY / BITGET_PASSPHRASE", file=sys.stderr)
   126:             sys.exit(2)
   127: 
   128:         try:
   129:             return AppConfig(
   130:                 BITGET_API_KEY=api_key,
   131:                 BITGET_API_SECRET=api_sec,
   132:                 BITGET_PASSPHRASE=api_pass,
   133:                 RISK_PCT=float(os.environ.get("RISK_PCT", "0.01")),
   134:                 MIN_TRADE_USDT=float(os.environ.get("MIN_TRADE_USDT", "5")),
   135:                 LEVERAGE=float(os.environ.get("LEVERAGE", "1")),
   136:                 PAPER_TRADE=_env_bool("PAPER_TRADE", True),
   137:                 TELEGRAM_BOT_TOKEN=_env_alias("TELEGRAM_BOT_TOKEN"),
   138:                 TELEGRAM_CHAT_ID=_env_alias("TELEGRAM_CHAT_ID"),
   139:             )
   140:         except Exception as e:
   141:             print(f"[CONFIG] Invalid configuration values: {e!r}", file=sys.stderr)
   142:             sys.exit(2)

## TRASH_20250823-124533/scalper/notifier.py (last modified: 2025-08-23 20:57:14)
     1: """Simple notifier for bot events."""
     2: 
     3: from __future__ import annotations
     4: 
     5: import logging
     6: import os
     7: from typing import Any, Dict
     8: 
     9: try:  # pragma: no cover - guarded import for optional dependency
    10:     import requests as _requests
    11: 
    12:     # ``requests`` may be provided as a stub during tests. Ensure it exposes a
    13:     # ``post`` attribute so callers can monkeypatch it reliably.
    14:     if not hasattr(_requests, "post"):
    15:         raise ImportError
    16:     requests = _requests
    17: except Exception:  # pragma: no cover - fallback when ``requests`` is missing
    18: 
    19:     class _Requests:
    20:         """Minimal stand‑in for :mod:`requests` when the real library is absent."""
    21: 
    22:         def post(self, *args: Any, **kwargs: Any) -> None:  # pragma: no cover - safety
    23:             raise RuntimeError("requests.post unavailable")
    24: 
    25:     requests = _Requests()  # type: ignore[assignment]
    26: 
    27: 
    28: def _pair_name(symbol: str) -> str:
    29:     """Return a human friendly pair name without the base ``USDT``."""
    30:     if "_" in symbol:
    31:         base, quote = symbol.split("_", 1)
    32:     elif symbol.endswith("USDT"):
    33:         base, quote = symbol[:-4], "USDT"
    34:     else:
    35:         base, quote = symbol, ""
    36:     if not quote or quote == "USDT":
    37:         return base
    38:     return f"{base}/{quote}"
    39: 
    40: 
    41: def _format_position_event(event: str, payload: Dict[str, Any]) -> str:
    42:     """Format a position open/close payload."""
    43: 
    44:     side = payload.get("side")
    45:     symbol = payload.get("symbol")
    46:     if symbol:
    47:         symbol = _pair_name(symbol)
    48: 
    49:     if event == "position_opened":
    50:         rc = payload.get("risk_color", "")
    51:         head = f"{rc} Ouvre {side} {symbol}".strip()
    52:         lines = [head]
    53:         lines.append(
    54:             f"Notional: {payload.get('notional_usdt')} USDT   Levier: x{payload.get('leverage')}"
    55:         )
    56:         lines.append(
    57:             "Marge estimée: {} USDT (dispo: {} USDT)".format(
    58:                 payload.get("required_margin_usdt"), payload.get("available_usdt")
    59:             )
    60:         )
    61:         lines.append(
    62:             "Risque: lvl {}/{} (risk_pct={:.4f}%)".format(
    63:                 payload.get("signal_level"),
    64:                 payload.get("risk_level_user"),
    65:                 float(payload.get("risk_pct_eff", 0.0)) * 100,
    66:             )
    67:         )
    68:         lines.append(
    69:             "Prix: {}   Vol: {} (cs={})".format(
    70:                 payload.get("price"),
    71:                 payload.get("vol"),
    72:                 payload.get("contract_size"),
    73:             )
    74:         )
    75:         return "\n".join(lines)
    76: 
    77:     # position_closed
    78:     rc = payload.get("risk_color", "")
    79:     head = f"Ferme {side} {symbol} {rc}".strip()
    80:     lines = [head]
    81:     pnl_usdt = payload.get("pnl_usdt")
    82:     fees = payload.get("fees_usdt")
    83:     if pnl_usdt is not None and fees is not None:
    84:         lines.append(f"PnL net: {pnl_usdt:+.2f} USDT (frais: {fees:.2f})")
    85:     pct = payload.get("pnl_pct_on_margin")
    86:     if pct is not None:
    87:         lines.append(f"% sur marge: {pct:.2f}%")
    88:     lines.append(
    89:         "Entrée: {}  Sortie: {}".format(
    90:             payload.get("entry_price"), payload.get("exit_price")
    91:         )
    92:     )
    93:     lines.append(
    94:         "Vol: {}  Notional: in {} → out {} USDT".format(
    95:             payload.get("vol"),
    96:             payload.get("notional_entry_usdt"),
    97:             payload.get("notional_exit_usdt"),
    98:         )
    99:     )
   100:     return "\n".join(lines)
   101: 
   102: 
   103: def _format_pair_list(payload: Dict[str, Any]) -> str:
   104:     """Format the pair list payload.
   105: 
   106:     The detailed pair listing is intentionally hidden from terminal output to
   107:     reduce noise. Only an acknowledgement message is returned.
   108:     """
   109: 
   110:     return "Listing ok"
   111: 
   112: 
   113: def _format_generic(event: str, payload: Dict[str, Any]) -> str:
   114:     text = event
   115:     if payload:
   116:         items = "\n".join(f"{k}={v}" for k, v in payload.items())
   117:         text = f"{text}\n{items}"
   118:     return text
   119: 
   120: 
   121: def _format_text(event: str, payload: Dict[str, Any] | None = None) -> str:
   122:     """Return a human readable text describing the event payload."""
   123:     payload = payload or {}
   124:     if event in {"position_opened", "position_closed"}:
   125:         return _format_position_event(event, payload)
   126:     if event == "pair_list":
   127:         return _format_pair_list(payload)
   128:     if event == "bot_started":
   129:         return "🤖 Bot démarré"
   130:     return _format_generic(event, payload)
   131: 
   132: 
   133: def notify(event: str, payload: Dict[str, Any] | None = None) -> None:
   134:     """Send an event payload to configured endpoints.
   135: 
   136:     Notifications are delivered via a generic webhook defined by ``NOTIFY_URL``
   137:     and/or directly to Telegram when ``TELEGRAM_BOT_TOKEN`` and
   138:     ``TELEGRAM_CHAT_ID`` are provided. Network errors are logged but otherwise
   139:     ignored so they do not interrupt the bot's execution.
   140:     """
   141: 
   142:     data = {"event": event}
   143:     if payload:
   144:         data.update(payload)
   145: 
   146:     # Generic HTTP webhook
   147:     url = os.getenv("NOTIFY_URL")
   148:     if url:
   149:         try:
   150:             requests.post(url, json=data, timeout=5)
   151:         except Exception as exc:  # pragma: no cover - best effort only
   152:             logging.error("Notification error for %s: %s", event, exc)
   153: 
   154:     # Telegram notification
   155:     token = os.getenv("TELEGRAM_BOT_TOKEN")
   156:     chat_id = os.getenv("TELEGRAM_CHAT_ID")
   157:     # ``pair_list`` notifications are intentionally not forwarded to Telegram
   158:     if token and chat_id and event != "pair_list":
   159:         text = _format_text(event, payload or {})
   160:         t_url = f"https://api.telegram.org/bot{token}/sendMessage"
   161:         t_payload = {"chat_id": chat_id, "text": text}
   162:         try:  # pragma: no cover - network
   163:             requests.post(t_url, json=t_payload, timeout=5)
   164:         except Exception as exc:  # pragma: no cover - best effort only
   165:             logging.error("Telegram notification error for %s: %s", event, exc)


## TRASH_20250823-124533/scalper/telegram_bot.py (last modified: 2025-08-23 20:57:14)
     1: from __future__ import annotations
     2: 
     3: import logging
     4: import os
     5: from typing import Any, Dict, Optional
     6: 
     7: try:  # pragma: no cover - optional dependency
     8:     import requests as _requests
     9:     requests = _requests
    10: except Exception:  # pragma: no cover
    11:     class _Requests:
    12:         def get(self, *a: Any, **k: Any) -> Any:  # pragma: no cover - fallback
    13:             raise RuntimeError("requests.get unavailable")
    14: 
    15:         def post(self, *a: Any, **k: Any) -> Any:  # pragma: no cover - fallback
    16:             raise RuntimeError("requests.post unavailable")
    17: 
    18:     requests = _Requests()  # type: ignore[assignment]
    19: 
    20: 
    21: class TelegramBot:
    22:     """Minimal Telegram bot using the HTTP API.
    23: 
    24: 
    25:     The bot exposes a simple *menu* based interface with clickable buttons so
    26:     users do not have to remember text commands.  A sub-menu lets the user set
    27:     the risk level.
    28: 
    29:     """
    30: 
    31:     def __init__(
    32:         self,
    33:         token: str,
    34:         chat_id: str,
    35:         client: Any,
    36:         config: Dict[str, Any],
    37:         risk_mgr: Any,
    38:         *,
    39:         requests_module: Any = requests,
    40:     ) -> None:
    41:         self.token = token
    42:         self.chat_id = str(chat_id)
    43:         self.client = client
    44:         self.config = config
    45:         self.risk_mgr = risk_mgr
    46:         self.requests = requests_module
    47:         self.last_update_id: Optional[int] = None
    48:         self.stop_requested = False
    49: 
    50: 
    51:         self.main_keyboard = [
    52:             [{"text": "Positions ouvertes", "callback_data": "positions"}],
    53:             [{"text": "Update Cryptos", "callback_data": "update"}],
    54:             [{"text": "Réglages", "callback_data": "settings"}],
    55:             [{"text": "Arrêt bot", "callback_data": "shutdown"}],
    56:         ]
    57:         self.settings_keyboard = [
    58:             [{"text": "Stop trade", "callback_data": "stop"}],
    59:             [{"text": "Réglage risk", "callback_data": "risk"}],
    60:             [{"text": "Nb positions", "callback_data": "maxpos"}],
    61:             [{"text": "Reset risk", "callback_data": "reset_risk"}],
    62:             [{"text": "Reset total", "callback_data": "reset_all"}],
    63:             [{"text": "Retour", "callback_data": "back"}],
    64:         ]
    65:         self.risk_keyboard = [
    66:             [
    67:                 {"text": "🟢", "callback_data": "risk_green"},
    68:                 {"text": "🟠", "callback_data": "risk_orange"},
    69:                 {"text": "🔴", "callback_data": "risk_red"},
    70:             ],
    71:             [{"text": "Retour", "callback_data": "back"}],
    72:         ]
    73:         self.maxpos_keyboard = [
    74:             [
    75:                 {"text": "1", "callback_data": "maxpos_1"},
    76:                 {"text": "2", "callback_data": "maxpos_2"},
    77:                 {"text": "3", "callback_data": "maxpos_3"},
    78:             ],
    79:             [
    80:                 {"text": "4", "callback_data": "maxpos_4"},
    81:                 {"text": "5", "callback_data": "maxpos_5"},
    82:             ],
    83:             [{"text": "Retour", "callback_data": "back"}],
    84:         ]
    85: 
    86:         # Show menu on startup with zero PnL session
    87:         self.send_main_menu(0.0)
    88: 
    89: 
    90:     def _base_symbol(self, symbol: str) -> str:
    91:         sym = symbol.replace("_", "")
    92:         return sym[:-4] if sym.endswith("USDT") else sym
    93: 
    94:     def _build_stop_keyboard(self) -> list[list[Dict[str, str]]]:
    95:         pos = self.client.get_positions() or {}
    96:         buttons: list[list[Dict[str, str]]] = []
    97:         for p in pos.get("data") or []:
    98:             sym = p.get("symbol")
    99:             if not sym:
   100:                 continue
   101:             base = self._base_symbol(sym)
   102:             # Use the full symbol in the callback so we can properly
   103:             # identify the position to close.  Only the label shows the
   104:             # base asset to keep the interface concise.
   105:             buttons.append([{"text": base, "callback_data": f"stop_{sym}"}])
   106:         buttons.append([{"text": "Tous", "callback_data": "stop_all"}])
   107:         buttons.append([{"text": "Retour", "callback_data": "back"}])
   108:         return buttons
   109: 
   110: 
   111:     def _menu_text(self, session_pnl: float) -> str:
   112:         assets = self.client.get_assets() or {}
   113:         equity = 0.0
   114:         for row in assets.get("data") or []:
   115:             if row.get("currency") == "USDT":
   116:                 try:
   117:                     equity = float(row.get("equity", 0.0))
   118:                 except Exception:
   119:                     equity = 0.0
   120:                 break
   121:         return (
   122:             f"Solde: {equity:.2f} USDT\n"
   123:             f"PnL session: {session_pnl:.2f} USDT\n"
   124:             f"Positions max: {self.risk_mgr.max_positions}\n"
   125:             f"Risque actuel: {self.risk_mgr.risk_pct * 100:.2f}%\n"
   126:             "Choisissez une option:"
   127:         )
   128: 
   129:     def send_main_menu(self, session_pnl: float) -> None:
   130:         self.send(self._menu_text(session_pnl), self.main_keyboard)
   131: 
   132:     def update_pairs(self) -> None:
   133:         from bot import update as _update  # lazy import to avoid cycle
   134:         _update(self.client, top_n=40)
   135: 
   136:     # ------------------------------------------------------------------
   137:     def _api_url(self, method: str) -> str:
   138:         return f"https://api.telegram.org/bot{self.token}/{method}"
   139: 
   140: 
   141:     def send(self, text: str, keyboard: Optional[list[list[Dict[str, str]]]] = None) -> None:
   142:         payload: Dict[str, Any] = {"chat_id": self.chat_id, "text": text}
   143:         if keyboard:
   144:             payload["reply_markup"] = {"inline_keyboard": keyboard}
   145: 
   146:         try:  # pragma: no cover - network
   147:             self.requests.post(self._api_url("sendMessage"), json=payload, timeout=5)
   148:         except Exception as exc:  # pragma: no cover - best effort
   149:             logging.error("Telegram send error: %s", exc)
   150: 
   151:     def answer_callback(self, cb_id: str) -> None:
   152:         payload = {"callback_query_id": cb_id}
   153:         try:  # pragma: no cover - network
   154:             self.requests.post(
   155:                 self._api_url("answerCallbackQuery"), json=payload, timeout=5
   156:             )
   157:         except Exception as exc:  # pragma: no cover - best effort
   158:             logging.error("Telegram answerCallback error: %s", exc)
   159: 
   160: 
   161:     # ------------------------------------------------------------------
   162:     def fetch_updates(self) -> list[Dict[str, Any]]:
   163:         params: Dict[str, Any] = {}
   164:         if self.last_update_id is not None:
   165:             params["offset"] = self.last_update_id + 1
   166:         try:  # pragma: no cover - network
   167:             r = self.requests.get(self._api_url("getUpdates"), params=params, timeout=5)
   168:             r.raise_for_status()
   169:             data = r.json()
   170:         except Exception as exc:  # pragma: no cover - best effort
   171:             logging.error("Telegram getUpdates error: %s", exc)
   172:             return []
   173:         updates = data.get("result", [])
   174:         if updates:
   175:             self.last_update_id = updates[-1].get("update_id")
   176:         return updates
   177: 
   178:     # ------------------------------------------------------------------
   179:     def handle_updates(self, session_pnl: float) -> None:
   180:         for update in self.fetch_updates():
   181: 
   182:             callback = update.get("callback_query")
   183:             if callback:
   184:                 if str(callback.get("from", {}).get("id")) != self.chat_id:
   185:                     continue
   186:                 data = callback.get("data", "")
   187:                 reply, kb = self.handle_callback(data, session_pnl)
   188:                 if reply:
   189:                     self.send(reply, kb)
   190:                 cb_id = callback.get("id")
   191:                 if cb_id:
   192:                     self.answer_callback(cb_id)
   193:                 continue
   194: 
   195: 
   196:             msg = update.get("message") or {}
   197:             chat = msg.get("chat") or {}
   198:             if str(chat.get("id")) != self.chat_id:
   199:                 continue
   200: 
   201:             # Any text message triggers the main menu with balance and PnL
   202:             self.send_main_menu(session_pnl)
   203: 
   204:     # ------------------------------------------------------------------
   205:     def handle_callback(
   206:         self, data: str, session_pnl: float
   207:     ) -> tuple[Optional[str], Optional[list[list[Dict[str, str]]]]]:
   208:         if not data:
   209:             return None, None
   210:         if data == "balance":
   211:             assets = self.client.get_assets() or {}
   212:             equity = 0.0
   213:             for row in assets.get("data") or []:
   214:                 if row.get("currency") == "USDT":
   215:                     try:
   216:                         equity = float(row.get("equity", 0.0))
   217:                     except Exception:
   218:                         equity = 0.0
   219:                     break
   220: 
   221:             return f"Solde: {equity:.2f} USDT", self.main_keyboard
   222:         if data == "positions":
   223:             pos = self.client.get_positions() or {}
   224:             lines = []
   225:             for p in pos.get("data") or []:
   226:                 symbol = p.get("symbol", "")
   227:                 base = self._base_symbol(symbol)
   228:                 side = p.get("side")
   229:                 vol = p.get("vol")
   230:                 pnl = p.get("pnl_usdt")
   231:                 if pnl is None:
   232:                     pnl = p.get("pnl_usd")
   233:                 if pnl is None:
   234:                     pnl = p.get("pnl")
   235:                 pnl_pct = p.get("pnl_pct_on_margin")
   236:                 if pnl_pct is None:
   237:                     pnl_pct = p.get("pnl_pct")
   238:                 line = f"{base} {side} {vol}"
   239:                 if pnl is not None and pnl_pct is not None:
   240:                     line += f"\nPnL: {pnl:.2f} USDT ({pnl_pct:.2f}%)"
   241:                 lines.append(line)
   242:             if not lines:
   243: 
   244:                 return "Aucune position ouverte", self.main_keyboard
   245:             return "Positions:\n" + "\n".join(lines), self.main_keyboard
   246:         if data == "pnl":
   247:             return f"PnL session: {session_pnl:.2f} USDT", self.main_keyboard
   248:         if data == "risk":
   249:             return "Choisissez le niveau de risque:", self.risk_keyboard
   250:         if data == "settings":
   251:             return "Réglages:", self.settings_keyboard
   252:         if data == "maxpos":
   253:             return "Choisissez le nombre de positions:", self.maxpos_keyboard
   254:         if data == "reset_risk":
   255:             try:
   256:                 self.risk_mgr.reset_day()
   257:                 return "Risque réinitialisé", self.settings_keyboard
   258:             except Exception:
   259:                 return "Erreur reset risque", self.settings_keyboard
   260:         if data == "update":
   261:             try:
   262:                 self.update_pairs()
   263:                 return "Liste cryptos mise à jour", self.main_keyboard
   264:             except Exception:
   265:                 return "Erreur mise à jour", self.main_keyboard
   266:         if data.startswith("risk"):
   267:             mapping = {
   268:                 "risk_green": 1,
   269:                 "risk_orange": 2,
   270:                 "risk_red": 3,
   271:             }
   272:             lvl = mapping.get(data)
   273:             if lvl:
   274:                 self.config["RISK_LEVEL"] = lvl
   275:                 return f"Niveau de risque réglé sur {lvl}", self.main_keyboard
   276:             return "Niveau de risque inchangé", self.main_keyboard
   277: 
   278:         if data.startswith("maxpos_"):
   279:             try:
   280:                 lvl = int(data.split("_", 1)[1])
   281:             except Exception:
   282:                 lvl = None
   283:             if lvl:
   284:                 self.config["MAX_POSITIONS"] = lvl
   285:                 self.risk_mgr.max_positions = lvl
   286:                 return f"Nombre de positions réglé sur {lvl}", self.main_keyboard
   287:             return "Nombre de positions inchangé", self.main_keyboard
   288: 
   289:         if data == "reset_all":
   290:             try:
   291:                 self.client.close_all_positions()
   292:                 self.risk_mgr.reset_day()
   293:                 return "Positions et risque réinitialisés", self.settings_keyboard
   294:             except Exception:
   295:                 return "Erreur lors du reset total", self.settings_keyboard
   296: 
   297:         if data == "stop":
   298:             pos = self.client.get_positions() or {}
   299:             if not (pos.get("data") or []):
   300:                 return "Aucune crypto sélectionnée", self.settings_keyboard
   301:             return "Choisissez la position à fermer:", self._build_stop_keyboard()
   302:         if data == "stop_all":
   303:             try:
   304:                 self.client.close_all_positions()
   305:                 return "Toutes les positions fermées", self.settings_keyboard
   306:             except Exception:
   307:                 return "Erreur arrêt trade", self.settings_keyboard
   308:         if data.startswith("stop_"):
   309:             sym = data[5:]
   310:             try:
   311:                 self.client.close_position(sym)
   312:                 return f"Position {sym} fermée", self.settings_keyboard
   313:             except Exception:
   314:                 return f"Erreur arrêt trade {sym}", self.settings_keyboard
   315: 
   316:         if data == "shutdown":
   317:             self.stop_requested = True
   318:             return "Arrêt du bot demandé", self.main_keyboard
   319: 
   320:         if data == "back":
   321:             return self._menu_text(session_pnl), self.main_keyboard
   322:         return None, None
   323: 
   324: 
   325: def init_telegram_bot(client: Any, config: Dict[str, Any], risk_mgr: Any) -> Optional[TelegramBot]:
   326:     token = os.getenv("TELEGRAM_BOT_TOKEN")
   327:     chat_id = os.getenv("TELEGRAM_CHAT_ID")
   328:     if token and chat_id:
   329:         return TelegramBot(token, chat_id, client, config, risk_mgr)
   330:     return None


## TRASH_20250823-124533/short_one_way.py (last modified: 2025-08-23 20:57:14)
     1: #!/usr/bin/env python3
     2: # -*- coding: utf-8 -*-
     3: """Example script to open a one-way short on Bitget futures.
     4: 
     5: This standalone script signs and sends a market sell order using the
     6: Bitget REST API. Environment variables required (defined in a `.env`
     7: file alongside this script):
     8: 
     9: - ``BITGET_BASE_URL`` (optional, defaults to ``https://api.bitget.com``)
    10: - ``BITGET_API_KEY``
    11: - ``BITGET_API_SECRET``
    12: - ``BITGET_API_PASSPHRASE``
    13: - ``BITGET_PRODUCT_TYPE`` (e.g. ``USDT-FUTURES``)
    14: - ``BITGET_MARGIN_COIN`` (e.g. ``USDT``)
    15: - ``BITGET_SYMBOL`` (e.g. ``BTCUSDT``)
    16: - ``BITGET_TEST_NOTIONAL_USDT`` (trade notional for test order)
    17: 
    18: The script retrieves the current contract specification and price,
    19: ensures account settings (one-way mode & leverage) and finally places a
    20: market sell order sized to approximately ``BITGET_TEST_NOTIONAL_USDT``.
    21: 
    22: The intent is purely demonstrational; use at your own risk.
    23: """
    24: 
    25: import base64
    26: import hashlib
    27: import hmac
    28: import json
    29: import os
    30: import sys
    31: import time
    32: import uuid
    33: from pathlib import Path
    34: 
    35: import requests
    36: 
    37: try:  # lazy dependency import for dotenv
    38:     from dotenv import load_dotenv
    39: except ImportError:  # pragma: no cover - installation fallback
    40:     import subprocess
    41: 
    42:     subprocess.check_call([sys.executable, "-m", "pip", "install", "python-dotenv"])
    43:     from dotenv import load_dotenv
    44: 
    45: # load environment variables
    46: load_dotenv(Path(__file__).resolve().parent / ".env")
    47: 
    48: 
    49: def T(x):  # small helper used throughout configuration
    50:     return x.strip() if isinstance(x, str) else x
    51: 
    52: 
    53: BASE = T(os.getenv("BITGET_BASE_URL", "https://api.bitget.com"))
    54: AK = T(os.getenv("BITGET_API_KEY"))
    55: SK = T(os.getenv("BITGET_API_SECRET"))
    56: PH = T(os.getenv("BITGET_API_PASSPHRASE"))
    57: PT = T(os.getenv("BITGET_PRODUCT_TYPE", "USDT-FUTURES")).upper()
    58: MC = T(os.getenv("BITGET_MARGIN_COIN", "USDT"))
    59: SYMB = (T(os.getenv("BITGET_SYMBOL", "BTCUSDT")) or "BTCUSDT").replace("_", "").upper()
    60: NOTIONAL = float(os.getenv("BITGET_TEST_NOTIONAL_USDT", "5.0"))
    61: 
    62: if not (AK and SK and PH):
    63:     sys.exit("❌ .env incomplet (BITGET_API_KEY/SECRET/PASSPHRASE).")
    64: 
    65: print(f"Base={BASE}  PT={PT}  SYMB={SYMB}  MC={MC}  Notional≈{NOTIONAL}USDT")
    66: 
    67: 
    68: # ---------- signing helpers ----------
    69: def sign_get(ts, path, params):
    70:     qs = "&".join(f"{k}={v}" for k, v in sorted((params or {}).items()))
    71:     pre = f"{ts}GET{path}" + (f"?{qs}" if qs else "")
    72:     sig = base64.b64encode(hmac.new(SK.encode(), pre.encode(), hashlib.sha256).digest()).decode()
    73:     return sig, qs
    74: 
    75: 
    76: def sign_post(ts, path, body, params=None):
    77:     qs = "&".join(f"{k}={v}" for k, v in sorted((params or {}).items()))
    78:     body_str = json.dumps(body or {}, separators=(",", ":"), sort_keys=True, ensure_ascii=False)
    79:     pre = f"{ts}POST{path}" + (f"?{qs}" if qs else "") + body_str
    80:     sig = base64.b64encode(hmac.new(SK.encode(), pre.encode(), hashlib.sha256).digest()).decode()
    81:     return sig, body_str, qs
    82: 
    83: 
    84: def headers(sig, ts):
    85:     return {
    86:         "ACCESS-KEY": AK,
    87:         "ACCESS-SIGN": sig,
    88:         "ACCESS-TIMESTAMP": str(ts),
    89:         "ACCESS-PASSPHRASE": PH,
    90:         "ACCESS-RECV-WINDOW": "60000",
    91:         "Content-Type": "application/json",
    92:     }
    93: 
    94: 
    95: def pick_price(d: dict):
    96:     for k in ("last", "price", "close", "bestAsk", "bestBid", "markPrice", "settlementPrice"):
    97:         try:
    98:             v = float(d.get(k))
    99:             if v > 0:
   100:                 return v
   101:         except Exception:
   102:             pass
   103:     return None
   104: 
   105: 
   106: # ---------- public endpoints ----------
   107: def get_contract_spec():
   108:     r = requests.get(
   109:         f"{BASE}/api/v2/mix/market/contracts",
   110:         params={"productType": PT, "symbol": SYMB},
   111:         timeout=12,
   112:     )
   113:     r.raise_for_status()
   114:     arr = r.json().get("data") or []
   115:     if not arr:
   116:         raise RuntimeError("Contrat introuvable")
   117:     return arr[0]
   118: 
   119: 
   120: def get_price():
   121:     # 1) ticker (obj/list) avec productType
   122:     try:
   123:         r = requests.get(
   124:             f"{BASE}/api/v2/mix/market/ticker",
   125:             params={"symbol": SYMB, "productType": PT},
   126:             timeout=10,
   127:         )
   128:         r.raise_for_status()
   129:         data = r.json().get("data")
   130:         if isinstance(data, dict):
   131:             p = pick_price(data)
   132:             if p:
   133:                 return p
   134:         if isinstance(data, list) and data:
   135:             p = pick_price(data[0])
   136:             if p:
   137:                 return p
   138:     except requests.HTTPError as e:
   139:         print("⚠️ ticker HTTP:", e.response.status_code, e.response.text[:140])
   140:     except Exception as e:
   141:         print("⚠️ ticker err:", e)
   142: 
   143:     # 2) tickers (liste entière)
   144:     try:
   145:         r = requests.get(
   146:             f"{BASE}/api/v2/mix/market/tickers",
   147:             params={"productType": PT},
   148:             timeout=10,
   149:         )
   150:         r.raise_for_status()
   151:         arr = r.json().get("data") or []
   152:         row = next((x for x in arr if (x.get("symbol") or "").upper() == SYMB), None)
   153:         p = pick_price(row or {})
   154:         if p:
   155:             return p
   156:     except requests.HTTPError as e:
   157:         print("⚠️ tickers HTTP:", e.response.status_code, e.response.text[:140])
   158:     except Exception as e:
   159:         print("⚠️ tickers err:", e)
   160: 
   161:     # 3) candles 1m (close)
   162:     try:
   163:         # ``symbol`` must be provided as a query parameter; placing it in the
   164:         # path triggers a 404 response from Bitget.
   165:         r = requests.get(
   166:             f"{BASE}/api/v2/mix/market/candles",
   167:             params={"symbol": SYMB, "granularity": "1m"},
   168:             timeout=10,
   169:         )
   170:         r.raise_for_status()
   171:         arr = r.json().get("data") or []
   172:         if arr:
   173:             return float(arr[0][4])
   174:     except requests.HTTPError as e:
   175:         print("⚠️ candles HTTP:", e.response.status_code, e.response.text[:140])
   176:     except Exception as e:
   177:         print("⚠️ candles err:", e)
   178: 
   179:     raise RuntimeError("prix indisponible")
   180: 
   181: 
   182: # ---------- private endpoints ----------
   183: def check_accounts():
   184:     path = "/api/v2/mix/account/accounts"
   185:     ts = int(time.time() * 1000)
   186:     params = {"productType": PT}
   187:     sig, qs = sign_get(ts, path, params)
   188:     url = f"{BASE}{path}" + (f"?{qs}" if qs else "")
   189:     r = requests.get(url, headers=headers(sig, ts), timeout=12)
   190:     print("accounts", r.status_code, r.text[:160])
   191:     r.raise_for_status()
   192:     j = r.json()
   193:     if str(j.get("code")) not in ("00000", "0"):
   194:         raise RuntimeError(j)
   195: 
   196: 
   197: def set_position_mode_one_way():
   198:     path = "/api/v2/mix/account/set-position-mode"
   199:     ts = int(time.time() * 1000)
   200:     body = {"productType": PT, "symbol": SYMB, "posMode": "one_way_mode"}
   201:     sig, b, qs = sign_post(ts, path, body)
   202:     url = f"{BASE}{path}" + (f"?{qs}" if qs else "")
   203:     r = requests.post(url, headers=headers(sig, ts), data=b.encode(), timeout=12)
   204:     print("set-position-mode(one-way)", r.status_code, r.text[:160])
   205:     r.raise_for_status()
   206: 
   207: 
   208: def set_leverage(lv: int = 2):
   209:     path = "/api/v2/mix/account/set-leverage"
   210:     ts = int(time.time() * 1000)
   211:     body = {"symbol": SYMB, "productType": PT, "marginCoin": MC, "leverage": int(lv)}
   212:     sig, b, qs = sign_post(ts, path, body)
   213:     url = f"{BASE}{path}" + (f"?{qs}" if qs else "")
   214:     r = requests.post(url, headers=headers(sig, ts), data=b.encode(), timeout=12)
   215:     print("set-leverage", r.status_code, r.text[:160])
   216:     r.raise_for_status()
   217: 
   218: 
   219: def place_one_way_sell(size_coin: float):
   220:     """Ouvre un SHORT en one_way_mode (market SELL)."""
   221:     path = "/api/v2/mix/order/place-order"
   222:     ts = int(time.time() * 1000)
   223:     body = {
   224:         "symbol": SYMB,
   225:         "productType": PT,
   226:         "marginCoin": MC,
   227:         "marginMode": "crossed",
   228:         "posMode": "one_way_mode",
   229:         "orderType": "market",
   230:         "side": "sell",  # <-- SHORT
   231:         "size": str(size_coin),
   232:         "timeInForceValue": "normal",
   233:         "clientOid": str(uuid.uuid4())[:32],
   234:     }
   235:     sig, b, qs = sign_post(ts, path, body)
   236:     url = f"{BASE}{path}" + (f"?{qs}" if qs else "")
   237:     r = requests.post(url, headers=headers(sig, ts), data=b.encode(), timeout=15)
   238:     print("place-order(one-way SELL)", r.status_code, r.text[:220])
   239:     r.raise_for_status()
   240:     j = r.json()
   241:     if str(j.get("code")) not in ("00000", "0"):
   242:         raise RuntimeError(j)
   243:     return j
   244: 
   245: 
   246: # ---------- main ----------
   247: def main():
   248:     spec = get_contract_spec()
   249:     min_usdt = float(spec.get("minTradeUSDT") or 5)
   250:     min_num = float(spec.get("minTradeNum") or 0)
   251:     size_place = int(spec.get("sizePlace") or 6)
   252:     print(f"Spec OK | minUSDT={min_usdt} minNum={min_num} sizePlace={size_place}")
   253: 
   254:     px = get_price()
   255:     print(f"Prix OK ≈ {px}")
   256: 
   257:     check_accounts()
   258:     set_position_mode_one_way()
   259:     set_leverage(2)
   260: 
   261:     target = max(NOTIONAL, min_usdt)
   262:     size = max(target / px, min_num)
   263:     size = float(f"{size:.{size_place}f}")
   264:     print(f"Taille={size} (target≈{target}USDT)")
   265: 
   266:     j = place_one_way_sell(size)
   267:     print("✅ SHORT OK")
   268:     print(json.dumps(j, indent=2, ensure_ascii=False))
   269: 
   270: 
   271: if __name__ == "__main__":  # pragma: no cover - script entrypoint
   272:     main()


## bot.py (last modified: 2025-08-24 03:12:00)
     1: # bot.py
     2: from __future__ import annotations
     3: 
     4: import asyncio
     5: import os
     6: import sys
     7: import json
     8: from dataclasses import dataclass
     9: from pathlib import Path
    10: from typing import Sequence, Optional
    11: 
    12: # --- utils ---
    13: 
    14: def ensure_ccxt() -> None:
    15:     try:
    16:         import ccxt  # noqa: F401
    17:     except ImportError:
    18:         import subprocess
    19:         print("[setup] ccxt manquant, installation…")
    20:         subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "ccxt"])
    21:         import ccxt  # noqa: F401
    22: 
    23: def getenv(name: str, default: str = "") -> str:
    24:     """Lit d’abord les variables d’environnement, sinon .env local s’il existe."""
    25:     val = os.environ.get(name)
    26:     if val is not None:
    27:         return val
    28:     dot = Path(".env")
    29:     if dot.exists():
    30:         for line in dot.read_text().splitlines():
    31:             line = line.strip()
    32:             if not line or line.startswith("#") or "=" not in line:
    33:                 continue
    34:             k, v = line.split("=", 1)
    35:             if k == name:
    36:                 return v
    37:     return default
    38: 
    39: # --- config ---
    40: 
    41: @dataclass
    42: class RunConfig:
    43:     symbols: Sequence[str]
    44:     live_tf: str
    45:     data_dir: Path
    46:     csv_min_rows: int = 200           # seuil minimal d’un CSV “ok”
    47:     ready_flag: Path = Path("scalp/.ready.json")
    48: 
    49: # --- notifier (Telegram ou Null) ---
    50: 
    51: class NullNotifier:
    52:     async def send(self, msg: str) -> None:
    53:         print(f"[notify:null] {msg}")
    54: 
    55: async def build_notifier_and_commands() -> tuple[object, object]:
    56:     """Retourne (notifier, command_stream). Ici soit Telegram, soit Null."""
    57:     bot_token = getenv("TELEGRAM_BOT_TOKEN")
    58:     chat_id   = getenv("TELEGRAM_CHAT_ID")
    59:     if bot_token and chat_id:
    60:         # Implémentation simple via httpx/aiohttp → pour garder le fichier autonome, on renvoie un proxy minimal.
    61:         class TelegramNotifier:
    62:             def __init__(self, token: str, chat: str):
    63:                 self.token = token
    64:                 self.chat  = chat
    65:             async def send(self, msg: str) -> None:
    66:                 # en mode simple: on n’échoue pas si Telegram refuse le markdown
    67:                 import aiohttp
    68:                 url = f"https://api.telegram.org/bot{self.token}/sendMessage"
    69:                 payload = {"chat_id": self.chat, "text": msg, "disable_web_page_preview": True, "parse_mode": "Markdown"}
    70:                 try:
    71:                     async with aiohttp.ClientSession() as sess:
    72:                         async with sess.post(url, json=payload, timeout=15) as r:
    73:                             if r.status >= 400:
    74:                                 txt = await r.text()
    75:                                 print(f"[notify:telegram] send fail {r.status}: {txt[:180]}")
    76:                 except Exception as e:
    77:                     print(f"[notify:telegram] send error: {e}")
    78: 
    79:         notifier = TelegramNotifier(bot_token, chat_id)
    80:         # Pas de commandes interactives dans cette version : on renvoie un stream “nul”
    81:         return notifier, None
    82:     else:
    83:         print("[notify] TELEGRAM non configuré → Null notifier.")
    84:         return NullNotifier(), None
    85: 
    86: # --- préchauffage cache CSV ---
    87: 
    88: def csv_ok(p: Path, min_rows: int) -> bool:
    89:     if not p.exists():
    90:         return False
    91:     try:
    92:         # compte rapide des lignes
    93:         n = sum(1 for _ in p.open("r", encoding="utf-8", errors="ignore"))
    94:         return n >= min_rows
    95:     except Exception:
    96:         return False
    97: 
    98: async def prewarm_cache(cfg: RunConfig) -> None:
    99:     cfg.data_dir.mkdir(parents=True, exist_ok=True)
   100:     ok = True
   101:     for sym in cfg.symbols:
   102:         csv = cfg.data_dir / f"{sym}-{cfg.live_tf}.csv"
   103:         if csv_ok(csv, cfg.csv_min_rows):
   104:             print(f"[cache] ready -> {csv.relative_to(Path.cwd())}")
   105:         else:
   106:             ok = False
   107:             print(f"[cache] MISSING for {sym} -> {csv.relative_to(Path.cwd())}")
   108:     # ici on ne fetch pas pour rester autonome ; tu as déjà so.py si besoin
   109: 
   110: # --- orchestrateur glue ---
   111: 
   112: # ⛔️ ADAPTE CE CHEMIN SI TON WRAPPER N’EST PAS ICI
   113: # ex: from scalper.services.market import BitgetExchange
   114: from scalper.exchanges.bitget import BitgetExchange  # <-- ajuste ce chemin si besoin
   115: 
   116: async def run_orchestrator(exchange, cfg: RunConfig, notifier, command_stream=None):
   117:     """
   118:     Adapte-toi à la signature de ton vrai orchestrateur si tu en utilises un.
   119:     Ici on illustre une boucle “heartbeat + ticks_total” minimale.
   120:     """
   121:     ticks_total = 0
   122:     await notifier.send("🟢 Orchestrator PRELAUNCH. Utilise /setup ou /backtest. /resume pour démarrer le live.")
   123:     try:
   124:         while True:
   125:             await asyncio.sleep(30)
   126:             await notifier.send(f"[stats] ticks_total={ticks_total} (+0 /30s) | pairs={','.join(cfg.symbols)}")
   127:     except asyncio.CancelledError:
   128:         await notifier.send("🛑 Arrêt orchestrateur.")
   129:         raise
   130: 
   131: # --- setup + ready flag ---
   132: 
   133: def write_ready_flag(cfg: RunConfig, reason: str = "ok") -> None:
   134:     cfg.ready_flag.parent.mkdir(parents=True, exist_ok=True)
   135:     cfg.ready_flag.write_text(json.dumps({"status": "ok", "reason": reason}, ensure_ascii=False, indent=2))
   136: 
   137: def is_ready(cfg: RunConfig) -> bool:
   138:     return cfg.ready_flag.exists()
   139: 
   140: async def setup_once(cfg: RunConfig, notifier) -> None:
   141:     await prewarm_cache(cfg)
   142:     await notifier.send("Setup wizard terminé (cache vérifié).")
   143:     write_ready_flag(cfg, "cache verified")
   144: 
   145: # --- lance l’orchestrateur avec shim .symbols/.timeframe ---
   146: 
   147: async def launch_orchestrator(cfg: RunConfig):
   148:     notifier, command_stream = await build_notifier_and_commands()
   149: 
   150:     # Setup si nécessaire
   151:     if not is_ready(cfg):
   152:         await notifier.send("Setup requis → exécution…")
   153:         await setup_once(cfg, notifier)
   154:         await notifier.send(f"[setup] flag écrit -> {cfg.ready_flag}")
   155: 
   156:     # Crée l’exchange
   157:     ex = BitgetExchange(
   158:         api_key=getenv("BITGET_ACCESS"),
   159:         secret=getenv("BITGET_SECRET"),
   160:         password=getenv("BITGET_PASSPHRASE"),
   161:         data_dir=str(cfg.data_dir),
   162:         use_cache=True,
   163:         spot=True,
   164:     )
   165: 
   166:     # --- SHIM IMPORTANT : certains orchestrateurs lisent exchange.symbols / exchange.timeframe
   167:     if not hasattr(ex, "symbols"):
   168:         setattr(ex, "symbols", tuple(cfg.symbols))
   169:     if not hasattr(ex, "timeframe"):
   170:         setattr(ex, "timeframe", cfg.live_tf)
   171: 
   172:     # Démarre l’orchestrateur (remplace par ton vrai import/runner si tu en as un)
   173:     await run_orchestrator(ex, cfg, notifier, command_stream)
   174: 
   175: # --- main ---
   176: 
   177: async def main():
   178:     ensure_ccxt()
   179:     symbols = (
   180:         "BTCUSDT","ETHUSDT","SOLUSDT","BNBUSDT","XRPUSDT",
   181:         "DOGEUSDT","ADAUSDT","LTCUSDT","AVAXUSDT","LINKUSDT"
   182:     )
   183:     cfg = RunConfig(
   184:         symbols=symbols,
   185:         live_tf="5m",
   186:         data_dir=Path("scalp/data"),
   187:     )
   188:     await launch_orchestrator(cfg)
   189: 
   190: if __name__ == "__main__":
   191:     try:
   192:         asyncio.run(main())
   193:     except KeyboardInterrupt:
   194:         pass

## cli.py (last modified: 2025-08-23 20:57:14)
     1: """Command line utilities for the Scalp project.
     2: 
     3: This module exposes a small command line interface used throughout the
     4: project.  The actual trading logic lives in other modules, however the CLI is
     5: responsible for parsing parameters and dispatching the appropriate routines.
     6: 
     7: The implementation intentionally keeps the invoked functions minimal so that
     8: tests can patch them easily.  In a real deployment these functions would
     9: perform optimisation, walk‑forward analysis or run the live pipeline.
    10: """
    11: 
    12: from __future__ import annotations
    13: 
    14: import argparse
    15: import asyncio
    16: from typing import Iterable, List
    17: 
    18: from scalper.version import bump_version_from_git
    19: 
    20: 
    21: # ---------------------------------------------------------------------------
    22: # Placeholder implementations
    23: # ---------------------------------------------------------------------------
    24: 
    25: 
    26: def run_parallel_optimization(pairs: List[str], timeframe: str, jobs: int) -> None:
    27:     """Run a parallel parameter optimisation.
    28: 
    29:     The real project dispatches a potentially heavy optimisation routine.  The
    30:     function is kept trivial so unit tests can verify that the CLI wiring works
    31:     without actually performing the optimisation.
    32:     """
    33: 
    34:     print(f"Optimising {pairs} on {timeframe} with {jobs} jobs")
    35: 
    36: 
    37: def run_walkforward_analysis(
    38:     pair: str, timeframe: str, splits: int, train_ratio: float
    39: ) -> None:
    40:     """Execute a walk-forward analysis."""
    41: 
    42:     print(
    43:         f"Walk-forward on {pair} ({timeframe}), splits={splits}, train_ratio={train_ratio}"
    44:     )
    45: 
    46: 
    47: async def run_live_pipeline(pairs: List[str], tfs: Iterable[str]) -> None:
    48:     """Run the live trading pipeline."""
    49: 
    50:     print(f"Running live pipeline for pairs={pairs} on tfs={list(tfs)}")
    51: 
    52: 
    53: # ---------------------------------------------------------------------------
    54: # Argument parsing
    55: # ---------------------------------------------------------------------------
    56: 
    57: 
    58: def create_parser() -> argparse.ArgumentParser:
    59:     """Create the top-level argument parser."""
    60: 
    61:     parser = argparse.ArgumentParser(description="Scalp command line tools")
    62:     sub = parser.add_subparsers(dest="command")
    63: 
    64:     # --- ``opt`` command -------------------------------------------------
    65:     opt_p = sub.add_parser("opt", help="run optimisation in parallel")
    66:     opt_p.add_argument("--pairs", nargs="+", required=True, help="trading pairs")
    67:     opt_p.add_argument("--tf", required=True, help="timeframe")
    68:     opt_p.add_argument("--jobs", type=int, default=1, help="number of workers")
    69:     opt_p.set_defaults(
    70:         func=lambda a: run_parallel_optimization(a.pairs, a.tf, a.jobs)
    71:     )
    72: 
    73:     # --- ``walkforward`` command ----------------------------------------
    74:     wf_p = sub.add_parser("walkforward", help="perform walk-forward analysis")
    75:     wf_p.add_argument("--pair", required=True, help="trading pair")
    76:     wf_p.add_argument("--tf", required=True, help="timeframe")
    77:     wf_p.add_argument("--splits", type=int, default=1, help="number of splits")
    78:     wf_p.add_argument(
    79:         "--train-ratio",
    80:         type=float,
    81:         default=0.7,
    82:         help="portion of data used for training",
    83:     )
    84:     wf_p.set_defaults(
    85:         func=lambda a: run_walkforward_analysis(
    86:             a.pair, a.tf, a.splits, a.train_ratio
    87:         )
    88:     )
    89: 
    90:     # --- ``live`` command -----------------------------------------------
    91:     live_p = sub.add_parser("live", help="run the live async pipeline")
    92:     live_p.add_argument("--pairs", nargs="+", required=True, help="trading pairs")
    93:     live_p.add_argument("--tfs", nargs="+", required=True, help="timeframes")
    94:     live_p.set_defaults(func=lambda a: asyncio.run(run_live_pipeline(a.pairs, a.tfs)))
    95: 
    96:     # --- ``bump-version`` command -------------------------------------
    97:     bv_p = sub.add_parser(
    98:         "bump-version",
    99:         help="update the VERSION file based on the latest git commit",
   100:     )
   101:     bv_p.set_defaults(func=lambda a: print(bump_version_from_git()))
   102: 
   103:     return parser
   104: 
   105: 
   106: def main(argv: Iterable[str] | None = None) -> int:
   107:     """Entry point used by tests and ``if __name__ == '__main__'`` block."""
   108: 
   109:     parser = create_parser()
   110:     args = parser.parse_args(argv)
   111:     if not hasattr(args, "func"):
   112:         parser.print_help()
   113:         return 0
   114:     result = args.func(args)
   115:     return 0 if result is None else int(result)
   116: 
   117: 
   118: if __name__ == "__main__":  # pragma: no cover - manual invocation
   119:     raise SystemExit(main())
   120: 


## data/BTCUSDT-1m.csv (last modified: 2025-08-23 20:57:14)
     1: ts,open,high,low,close,volume
     2: 1625097600000,34000,34100,33950,34050,123.4
     3: 1625097660000,34050,34200,34000,34150,150.7
     4: 1625097720000,34150,34300,34100,34250,180.3
     5: 1625097780000,34250,34400,34200,34350,200.1
     6: 1625097840000,34350,34500,34300,34450,220.8

## data/__init__.py (last modified: 2025-08-23 20:57:14)
     1: """Indicator computation helpers."""
     2: 
     3: from .indicators import compute_all
     4: 
     5: __all__ = ["compute_all"]


## data/indicators.py (last modified: 2025-08-23 20:57:14)
     1: import pandas as pd
     2: 
     3: __all__ = ["compute_all"]
     4: 
     5: def compute_all(
     6:     df: pd.DataFrame,
     7:     *,
     8:     ema_fast: int = 20,
     9:     ema_slow: int = 50,
    10:     rsi_period: int = 14,
    11:     macd_fast: int = 12,
    12:     macd_slow: int = 26,
    13:     macd_signal: int = 9,
    14:     atr_period: int = 14,
    15:     swing_lookback: int = 5,
    16: ) -> pd.DataFrame:
    17:     """Compute common indicators and return enriched DataFrame.
    18: 
    19:     Parameters
    20:     ----------
    21:     df : pd.DataFrame
    22:         DataFrame containing at least ``open``, ``high``, ``low``, ``close`` and
    23:         ``volume`` columns ordered chronologically.
    24: 
    25:     Returns
    26:     -------
    27:     pd.DataFrame
    28:         New DataFrame with additional indicator columns.
    29:     """
    30: 
    31:     if df.empty:
    32:         return df.copy()
    33: 
    34:     df = df.copy()
    35: 
    36:     # --- VWAP ---------------------------------------------------------------
    37:     typical = (df["high"] + df["low"] + df["close"]) / 3.0
    38:     vwap = (typical * df["volume"]).cumsum() / df["volume"].cumsum()
    39:     df["vwap"] = vwap
    40: 
    41:     # --- EMAs ---------------------------------------------------------------
    42:     df["ema20"] = df["close"].ewm(span=ema_fast, adjust=False).mean()
    43:     df["ema50"] = df["close"].ewm(span=ema_slow, adjust=False).mean()
    44: 
    45:     # --- RSI ----------------------------------------------------------------
    46:     delta = df["close"].diff()
    47:     gain = delta.where(delta > 0, 0.0)
    48:     loss = -delta.where(delta < 0, 0.0)
    49:     avg_gain = gain.rolling(rsi_period).mean()
    50:     avg_loss = loss.rolling(rsi_period).mean()
    51:     rs = avg_gain / avg_loss
    52:     rsi = 100 - (100 / (1 + rs))
    53:     df["rsi"] = rsi.fillna(50.0)
    54: 
    55:     # --- MACD ---------------------------------------------------------------
    56:     ema_fast_series = df["close"].ewm(span=macd_fast, adjust=False).mean()
    57:     ema_slow_series = df["close"].ewm(span=macd_slow, adjust=False).mean()
    58:     macd = ema_fast_series - ema_slow_series
    59:     signal = macd.ewm(span=macd_signal, adjust=False).mean()
    60:     df["macd"] = macd
    61:     df["macd_signal"] = signal
    62:     df["macd_hist"] = macd - signal
    63: 
    64:     # --- OBV ----------------------------------------------------------------
    65:     obv = [0.0]
    66:     closes = df["close"].tolist()
    67:     vols = df["volume"].tolist()
    68:     for i in range(1, len(df)):
    69:         if closes[i] > closes[i - 1]:
    70:             obv.append(obv[-1] + vols[i])
    71:         elif closes[i] < closes[i - 1]:
    72:             obv.append(obv[-1] - vols[i])
    73:         else:
    74:             obv.append(obv[-1])
    75:     df["obv"] = obv
    76: 
    77:     # --- ATR ----------------------------------------------------------------
    78:     high_low = df["high"] - df["low"]
    79:     high_close = (df["high"] - df["close"].shift()).abs()
    80:     low_close = (df["low"] - df["close"].shift()).abs()
    81:     tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    82:     df["atr"] = tr.rolling(atr_period).mean()
    83: 
    84:     # --- Swing highs/lows ---------------------------------------------------
    85:     df["swing_high"] = df["high"].rolling(window=swing_lookback).max()
    86:     df["swing_low"] = df["low"].rolling(window=swing_lookback).min()
    87: 
    88:     return df


## init.py (last modified: 2025-08-23 20:57:14)
     1: #!/usr/bin/env python3
     2: """Install all project dependencies.
     3: 
     4: Run this script once to install every ``requirements*.txt`` file found in the
     5: repository as well as the packages needed for the test suite.  All subsequent
     6: invocations of the bot or its submodules will then share the same Python
     7: environment with the required dependencies available.
     8: """
     9: 
    10: from __future__ import annotations
    11: 
    12: import subprocess
    13: import sys
    14: from pathlib import Path
    15: 
    16: 
    17: def install_packages(*args: str) -> None:
    18:     """Install packages using pip for the current Python interpreter."""
    19:     cmd = [sys.executable, "-m", "pip", "install", *args]
    20:     subprocess.check_call(cmd)
    21: 
    22: 
    23: def main() -> None:
    24:     repo_root = Path(__file__).resolve().parent
    25: 
    26:     # Install from any requirements*.txt file across the repository so that
    27:     # sub-packages with their own dependency lists are also covered.
    28:     for req in sorted(repo_root.rglob("requirements*.txt")):
    29:         install_packages("-r", str(req))
    30: 
    31:     # Ensure test dependencies are available
    32:     install_packages("pytest")
    33: 
    34: 
    35: if __name__ == "__main__":
    36:     main()


## pytest.ini (last modified: 2025-08-23 20:57:14)
     1: [pytest]
     2: addopts = -q


## requirements-dev.txt (last modified: 2025-08-23 20:57:14)
     1: pytest


## requirements.txt (last modified: 2025-08-23 20:57:14)
     1: requests
     2: python-dotenv
     3: pydantic==1.10.15 ; python_version < "3.11"
     4: 
     5: # pydantic v1 déjà pin si environnement ancien
     6: # rien à ajouter ici pour market_data (pas de nouvelle dépendance)


## scalper/VERSION (last modified: 2025-08-23 20:57:14)
     1: 0.3.0
     2: 


## scalper/__init__.py (last modified: 2025-08-23 20:57:14)
     1: """Utilities and helpers for Scalp bot.
     2: 
     3: When the bot is executed from ``notebook/spot/bitget_bot.py`` it expects secret
     4: keys to live in ``notebook/.env``.  On import this module attempts to load the
     5: variables from that file so that API keys can remain outside of the repository
     6: yet still be available at runtime.
     7: """
     8: 
     9: from __future__ import annotations
    10: 
    11: import os
    12: from pathlib import Path
    13: import sys
    14: 
    15: 
    16: def _load_parent_env() -> None:
    17:     """Load environment variables from ``../.env`` relative to the entry script.
    18: 
    19:     The bot is typically launched from ``notebook/spot/bitget_bot.py`` and keys
    20:     are expected to be stored one directory above (``notebook/.env``).  If that
    21:     file is not found the function falls back to the historical behaviour of
    22:     checking ``../.env`` relative to the package itself.
    23:     """
    24: 
    25:     script_path = Path(sys.argv[0]).resolve()
    26:     env_file = script_path.parent.parent / ".env"
    27:     if not env_file.exists():
    28:         env_file = Path(__file__).resolve().parents[2] / ".env"
    29:         if not env_file.exists():
    30:             return
    31: 
    32:     try:
    33:         from dotenv import load_dotenv
    34: 
    35:         load_dotenv(env_file)
    36:     except Exception:  # pragma: no cover - optional dependency
    37:         for line in env_file.read_text().splitlines():
    38:             line = line.strip()
    39:             if not line or line.startswith("#") or "=" not in line:
    40:                 continue
    41:             key, value = line.split("=", 1)
    42:             os.environ.setdefault(key.strip(), value.strip().strip("'\""))
    43: 
    44: 
    45: _load_parent_env()
    46: 
    47: from .version import get_version, bump_version_from_message  # noqa: E402
    48: from .strategy import (  # noqa: E402
    49:     Signal,
    50:     scan_pairs,
    51:     select_active_pairs,
    52:     generate_signal,
    53:     backtest,
    54: )
    55: from .risk.manager import RiskManager  # noqa: E402
    56: 
    57: __all__ = [
    58:     "get_version",
    59:     "bump_version_from_message",
    60:     "__version__",
    61:     "Signal",
    62:     "scan_pairs",
    63:     "select_active_pairs",
    64:     "generate_signal",
    65:     "RiskManager",
    66:     "backtest",
    67: ]
    68: 
    69: __version__ = get_version()


## scalper/adapters/__init__.py (last modified: 2025-08-23 20:57:14)


## scalper/adapters/bitget.py (last modified: 2025-08-23 20:57:14)
     1: # scalp/adapters/bitget.py
     2: from __future__ import annotations
     3: from typing import Any, Dict, List, Optional
     4: import inspect, os
     5: import requests
     6: 
     7: # Client bas-niveau fourni par le repo
     8: from scalper.bitget_client import BitgetFuturesClient as _Base
     9: 
    10: 
    11: def _to_float(x, default: float = 0.0) -> float:
    12:     try:
    13:         return float(x)
    14:     except Exception:
    15:         return default
    16: 
    17: 
    18: def _select_base_url() -> str:
    19:     env = os.environ.get("BITGET_BASE_URL")
    20:     if env:
    21:         return env
    22:     paper = os.environ.get("PAPER_TRADE", "true").lower() in ("1", "true", "yes", "on")
    23:     return "https://api-testnet.bitget.com" if paper else "https://api.bitget.com"
    24: 
    25: 
    26: class BitgetFuturesClient(_Base):
    27:     """
    28:     Adaptateur Bitget:
    29:       - __init__ dynamique (passe seulement les kwargs que le client accepte)
    30:       - Normalisations robustes: assets, ticker(s), positions, fills
    31:     """
    32: 
    33:     # --------------------- INIT dynamique ---------------------
    34:     def __init__(self, *args: Any, **kwargs: Any) -> None:
    35:         """
    36:         Accepte indifféremment:
    37:           api_key/apiKey/access_key/accessKey/key
    38:           api_secret/apiSecret/secret/secret_key/secretKey
    39:           passphrase/password/api_passphrase/apiPassphrase
    40:           base_url/baseUrl/host/endpoint (ou auto)
    41:         On n'envoie au client de base que les noms présents dans sa signature.
    42:         """
    43:         user_kwargs = dict(kwargs)
    44: 
    45:         # Collecte des valeurs possibles (tous alias)
    46:         incoming_key = (
    47:             user_kwargs.pop("api_key", None)
    48:             or user_kwargs.pop("apiKey", None)
    49:             or user_kwargs.pop("access_key", None)
    50:             or user_kwargs.pop("accessKey", None)
    51:             or user_kwargs.pop("key", None)
    52:             or user_kwargs.pop("API_KEY", None)
    53:         )
    54:         incoming_secret = (
    55:             user_kwargs.pop("api_secret", None)
    56:             or user_kwargs.pop("apiSecret", None)
    57:             or user_kwargs.pop("secret_key", None)
    58:             or user_kwargs.pop("secretKey", None)
    59:             or user_kwargs.pop("secret", None)
    60:             or user_kwargs.pop("API_SECRET", None)
    61:         )
    62:         incoming_pass = (
    63:             user_kwargs.pop("passphrase", None)
    64:             or user_kwargs.pop("password", None)
    65:             or user_kwargs.pop("api_passphrase", None)
    66:             or user_kwargs.pop("apiPassphrase", None)
    67:         )
    68:         incoming_base = (
    69:             user_kwargs.pop("base_url", None)
    70:             or user_kwargs.pop("baseUrl", None)
    71:             or user_kwargs.pop("host", None)
    72:             or user_kwargs.pop("endpoint", None)
    73:             or _select_base_url()
    74:         )
    75: 
    76:         # Signature réelle du client bas-niveau
    77:         sig = inspect.signature(_Base.__init__)
    78:         param_names = set(sig.parameters.keys())  # ex: {'self','access_key','secret_key','passphrase','base_url',...}
    79: 
    80:         def pick_name(cands: List[str]) -> Optional[str]:
    81:             for c in cands:
    82:                 if c in param_names:
    83:                     return c
    84:             return None
    85: 
    86:         # Noms réellement supportés
    87:         key_name = pick_name(["api_key", "apiKey", "access_key", "accessKey", "key"])
    88:         sec_name = pick_name(["api_secret", "apiSecret", "secret_key", "secretKey", "secret"])
    89:         pas_name = pick_name(["passphrase", "password", "api_passphrase", "apiPassphrase"])
    90:         base_name = pick_name(["base_url", "baseUrl", "host", "endpoint"])
    91:         req_mod_name = "requests_module" if "requests_module" in param_names else None
    92: 
    93:         # Construire kwargs à transmettre (une seule fois par nom)
    94:         base_kwargs: Dict[str, Any] = {}
    95:         if key_name and incoming_key is not None:
    96:             base_kwargs[key_name] = incoming_key
    97:         if sec_name and incoming_secret is not None:
    98:             base_kwargs[sec_name] = incoming_secret
    99:         if pas_name and incoming_pass is not None:
   100:             base_kwargs[pas_name] = incoming_pass
   101:         if base_name:
   102:             base_kwargs[base_name] = incoming_base
   103:         if req_mod_name:
   104:             base_kwargs[req_mod_name] = requests
   105: 
   106:         # Ne transmettre aucun doublon : si user_kwargs contient un nom supporté
   107:         # qui n'a pas été défini ci-dessus, on le relaie.
   108:         for k, v in list(user_kwargs.items()):
   109:             if k in param_names and k not in base_kwargs:
   110:                 base_kwargs[k] = v
   111: 
   112:         # Appel propre, 100% mots-clés (évite “missing positional arg” et “multiple values”)
   113:         super().__init__(**base_kwargs)
   114: 
   115:     # --------------------- COMPTES / ASSETS ---------------------
   116:     def get_assets(self) -> Dict[str, Any]:
   117:         raw = super().get_assets()
   118:         data = raw.get("data") or raw.get("result") or raw.get("assets") or []
   119:         norm: List[Dict[str, Any]] = []
   120:         for a in data:
   121:             currency = a.get("currency") or a.get("marginCoin") or a.get("coin") or "USDT"
   122:             equity = _to_float(a.get("equity", a.get("usdtEquity", a.get("totalEquity", 0))))
   123:             available = _to_float(a.get("available", a.get("availableBalance", a.get("availableUSDT", 0))))
   124:             norm.append({"currency": currency, "equity": equity, "available": available, **a})
   125:         return {"success": True, "data": norm}
   126: 
   127:     # ------------------------ TICKER(S) -------------------------
   128:     def get_ticker(self, symbol: Optional[str] = None) -> Dict[str, Any]:
   129:         """
   130:         Normalise vers liste d'objets: {symbol,lastPrice,bidPrice,askPrice,volume}
   131:         Tolère top-level dict/list et items dict/list.
   132:         """
   133:         try:
   134:             raw: Any = super().get_ticker(symbol) if symbol else super().get_tickers()
   135:         except Exception as e:
   136:             return {"success": False, "error": repr(e), "data": []}
   137: 
   138:         items: List[Any] = []
   139:         if isinstance(raw, dict):
   140:             d = raw.get("data")
   141:             if symbol and isinstance(d, dict):
   142:                 items = [d]
   143:             else:
   144:                 items = d or raw.get("result") or raw.get("tickers") or []
   145:         elif isinstance(raw, (list, tuple)):
   146:             items = list(raw)
   147: 
   148:         norm: List[Dict[str, Any]] = []
   149:         for t in items:
   150:             if isinstance(t, dict):
   151:                 s = (t.get("symbol") or t.get("instId") or t.get("instrumentId") or "").replace("_", "")
   152:                 last_ = t.get("lastPrice", t.get("last", t.get("close", t.get("markPrice", 0))))
   153:                 bid_ = t.get("bidPrice", t.get("bestBidPrice", t.get("bestBid", t.get("buyOne", last_))))
   154:                 ask_ = t.get("askPrice", t.get("bestAskPrice", t.get("bestAsk", t.get("sellOne", last_))))
   155:                 vol_usdt = t.get("usdtVolume", t.get("quoteVolume", t.get("turnover24h", None)))
   156:                 vol_base = t.get("baseVolume", t.get("volume", t.get("size24h", 0)))
   157:                 volume = _to_float(vol_usdt if vol_usdt is not None else vol_base)
   158:                 norm.append({
   159:                     "symbol": s,
   160:                     "lastPrice": _to_float(last_),
   161:                     "bidPrice": _to_float(bid_),
   162:                     "askPrice": _to_float(ask_),
   163:                     "volume": volume
   164:                 })
   165:             else:
   166:                 seq = list(t)
   167:                 if len(seq) >= 5:
   168:                     first_ts = isinstance(seq[0], (int, float)) and seq[0] > 10**10
   169:                     if first_ts:
   170:                         close = _to_float(seq[4]); vol = _to_float(seq[5] if len(seq) > 5 else 0.0)
   171:                     else:
   172:                         close = _to_float(seq[3]); vol = _to_float(seq[4] if len(seq) > 4 else 0.0)
   173:                 else:
   174:                     close = _to_float(seq[-1] if seq else 0.0); vol = 0.0
   175:                 s = (symbol or "").replace("_", "")
   176:                 norm.append({"symbol": s, "lastPrice": close, "bidPrice": close, "askPrice": close, "volume": vol})
   177: 
   178:         return {"success": True, "data": norm}
   179: 
   180:     # --------------- POSITIONS / ORDRES / FILLS -----------------
   181:     def get_open_positions(self, symbol: Optional[str] = None) -> Dict[str, Any]:
   182:         raw: Dict[str, Any] = super().get_positions() if hasattr(super(), "get_positions") else {}
   183:         items = raw.get("data") or raw.get("result") or raw.get("positions") or []
   184:         out: List[Dict[str, Any]] = []
   185:         for p in items:
   186:             s = (p.get("symbol") or p.get("instId") or "").replace("_", "")
   187:             if symbol and s != symbol:
   188:                 continue
   189:             side = (p.get("holdSide") or p.get("posSide") or p.get("side") or "").lower()
   190:             qty = _to_float(p.get("size", p.get("holdAmount", p.get("total", 0))))
   191:             avg = _to_float(p.get("avgOpenPrice", p.get("avgPrice", p.get("entryPrice", 0))))
   192:             out.append({"symbol": s, "side": side, "qty": qty, "avgEntryPrice": avg})
   193:         return {"success": True, "data": out}
   194: 
   195:     def get_fills(self, symbol: str, order_id: Optional[str] = None, limit: int = 100) -> Dict[str, Any]:
   196:         raw: Dict[str, Any] = super().get_fills(symbol=symbol) if hasattr(super(), "get_fills") else {}
   197:         items = raw.get("data") or raw.get("result") or []
   198:         out: List[Dict[str, Any]] = []
   199:         for f in items[:limit]:
   200:             s = (f.get("symbol") or f.get("instId") or "").replace("_", "")
   201:             if s != symbol:
   202:                 continue
   203:             if order_id and str(f.get("orderId") or f.get("ordId") or "") != str(order_id):
   204:                 continue
   205:             out.append({
   206:                 "orderId": str(f.get("orderId") or f.get("ordId") or ""),
   207:                 "tradeId": str(f.get("tradeId") or f.get("fillId") or f.get("execId") or ""),
   208:                 "price": _to_float(f.get("price", f.get("fillPx", 0))),
   209:                 "qty": _to_float(f.get("size", f.get("fillSz", 0))),
   210:                 "fee": _to_float(f.get("fee", f.get("fillFee", 0))),
   211:                 "ts": int(f.get("ts", f.get("time", 0))),
   212:             })
   213:         return {"success": True, "data": out}
   214: 
   215:     def cancel_order(self, symbol: str, order_id: str) -> Dict[str, Any]:
   216:         raw = super().cancel_order(symbol=symbol, orderId=order_id) if hasattr(super(), "cancel_order") else {}
   217:         ok = bool(raw.get("success", True)) if isinstance(raw, dict) else True
   218:         return {"success": ok, "data": {"orderId": order_id}}

## scalper/adapters/bitget_fetch.py (last modified: 2025-08-23 20:57:14)
     1: # scalper/adapters/bitget_fetch.py
     2: from __future__ import annotations
     3: 
     4: import asyncio
     5: import inspect
     6: import os
     7: from typing import Any, Optional
     8: 
     9: BT_DEBUG = int(os.getenv("BT_DEBUG", "0") or "0")
    10: 
    11: def _log(msg: str) -> None:
    12:     if BT_DEBUG:
    13:         print(f"[bt.debug] {msg}", flush=True)
    14: 
    15: _TF_TO_SECS = {
    16:     "1m": 60, "3m": 180, "5m": 300, "15m": 900, "30m": 1800,
    17:     "1h": 3600, "4h": 14400, "1d": 86400,
    18: }
    19: _TF_TO_MIX = {  # granularity pour mix (docs Bitget)
    20:     "1m": "1min", "3m": "3min", "5m": "5min", "15m": "15min",
    21:     "30m": "30min", "1h": "1h", "4h": "4h", "1d": "1day",
    22: }
    23: _TF_TO_SPOT = {  # period pour spot (docs Bitget)
    24:     "1m": "1min", "3m": "3min", "5m": "5min", "15m": "15min",
    25:     "30m": "30min", "1h": "1hour", "4h": "4hour", "1d": "1day",
    26: }
    27: 
    28: def _await_if_needed(val: Any) -> Any:
    29:     if inspect.isawaitable(val):
    30:         try:
    31:             asyncio.get_running_loop()
    32:         except RuntimeError:
    33:             return asyncio.run(val)
    34:         else:
    35:             fut = asyncio.run_coroutine_threadsafe(val, asyncio.get_running_loop())
    36:             return fut.result()
    37:     return val
    38: 
    39: class BitgetFetchAdapter:
    40:     """
    41:     Adaptateur qui fournit une méthode CCXT-like:
    42:       fetch_ohlcv(symbol, timeframe='5m', since=None, limit=1000)
    43:     au-dessus d'un client Bitget existant (sync ou async).
    44:     """
    45:     def __init__(self, client: Any, *, market_hint: str | None = None):
    46:         self.client = client
    47:         self.market_hint = (market_hint or "").lower() or None
    48:         _log(f"BitgetFetchAdapter attaché sur {type(client).__name__} (market_hint={self.market_hint})")
    49:         if hasattr(client, "fetch_ohlcv") and callable(getattr(client, "fetch_ohlcv")):
    50:             _log("Client expose déjà fetch_ohlcv → adaptation inutile (utilisation directe).")
    51: 
    52:     @staticmethod
    53:     def _possible_methods(client: Any) -> list[str]:
    54:         names = dir(client)
    55:         base = [
    56:             "fetch_ohlcv",
    57:             "get_candlesticks", "candlesticks", "get_candles", "candles",
    58:             "klines", "get_klines", "kline",
    59:             "mix_get_candles", "mix_candles",
    60:             "spot_get_candles", "spot_candles",
    61:             "market_candles", "public_candles",
    62:         ]
    63:         # + heuristique: tout ce qui contient candle/kline
    64:         extra = [n for n in names if ("candle" in n.lower() or "kline" in n.lower()) and callable(getattr(client, n))]
    65:         out = []
    66:         for n in base + extra:
    67:             if n in names and callable(getattr(client, n)) and n not in out:
    68:                 out.append(n)
    69:         _log(f"Méthodes candidates détectées: {out or '(aucune)'}")
    70:         return out
    71: 
    72:     @staticmethod
    73:     def _sym_variants(sym: str) -> list[str]:
    74:         s = sym.upper()
    75:         out = [s]
    76:         if not s.endswith("_UMCBL"):
    77:             out.append(f"{s}_UMCBL")
    78:         if not s.endswith("_SPBL"):
    79:             out.append(f"{s}_SPBL")
    80:         _log(f"Variantes symbole testées: {out}")
    81:         return out
    82: 
    83:     @staticmethod
    84:     def _param_variants(timeframe: str, market_hint: Optional[str]) -> list[dict]:
    85:         secs = _TF_TO_SECS.get(timeframe, 300)
    86:         mix = _TF_TO_MIX.get(timeframe, "5min")
    87:         spot = _TF_TO_SPOT.get(timeframe, "5min")
    88:         variants = []
    89:         if market_hint == "mix":
    90:             variants.append({"granularity": mix})
    91:         if market_hint == "spot":
    92:             variants.append({"period": spot})
    93:         variants += [
    94:             {"timeframe": timeframe},
    95:             {"interval": timeframe},
    96:             {"k": secs},
    97:             {"granularity": mix},
    98:             {"period": spot},
    99:         ]
   100:         _log(f"Variantes params testées pour tf={timeframe}: {variants}")
   101:         return variants
   102: 
   103:     @staticmethod
   104:     def _normalize_rows(raw: Any) -> list[list[float]]:
   105:         import pandas as pd  # local import
   106:         if raw is None:
   107:             raise ValueError("OHLCV vide")
   108:         if isinstance(raw, dict) and "data" in raw:
   109:             raw = raw["data"]
   110:         if isinstance(raw, (list, tuple)) and raw and isinstance(raw[0], (list, tuple)):
   111:             out = []
   112:             for r in raw:
   113:                 ts = int(str(r[0]))
   114:                 o, h, l, c, v = map(float, (r[1], r[2], r[3], r[4], r[5]))
   115:                 out.append([ts, o, h, l, c, v])
   116:             return out
   117:         if "pandas" in str(type(raw)):
   118:             df = raw
   119:             if "timestamp" in df.columns:
   120:                 df["timestamp"] = pd.to_datetime(df["timestamp"], utc=True, infer_datetime_format=True)
   121:                 df = df.set_index("timestamp").sort_index()
   122:             df = df[["open", "high", "low", "close", "volume"]]
   123:             return [[int(ts.value // 10**6), *map(float, row)] for ts, row in df.itertuples()]
   124:         raise ValueError(f"Format OHLCV inattendu: {type(raw)}")
   125: 
   126:     def fetch_ohlcv(self, symbol: str, timeframe: str = "5m", since: Any | None = None, limit: int = 1000):
   127:         methods = self._possible_methods(self.client)
   128:         if not methods:
   129:             raise AttributeError("Aucune méthode OHLCV trouvée sur le client Bitget")
   130: 
   131:         last_err: Exception | None = None
   132:         for mname in methods:
   133:             fn = getattr(self.client, mname)
   134:             for sym in self._sym_variants(symbol):
   135:                 for par in self._param_variants(timeframe, self.market_hint):
   136:                     kwargs = dict(par)
   137:                     kwargs.setdefault("symbol", sym)
   138:                     kwargs.setdefault("limit", limit)
   139:                     if since is not None:
   140:                         kwargs.setdefault("since", since)
   141:                     try:
   142:                         _log(f"→ Essai {mname}(kwargs={kwargs})")
   143:                         res = _await_if_needed(fn(**kwargs))
   144:                         rows = self._normalize_rows(res)
   145:                         if rows:
   146:                             unit = "ms" if rows and rows[0][0] > 10_000_000_000 else "s"
   147:                             first = rows[0][0]; last = rows[-1][0]
   148:                             _log(f"✓ OK via {mname} {sym} {par} | n={len(rows)} | "
   149:                                  f"t0={first} {unit}, t1={last} {unit}")
   150:                             return rows
   151:                     except TypeError as e:
   152:                         _log(f"TypeError {mname} {sym} {par}: {e}")
   153:                         last_err = e
   154:                     except Exception as e:
   155:                         _log(f"Erreur {mname} {sym} {par}: {e}")
   156:                         last_err = e
   157:         raise last_err or RuntimeError("Impossible d'obtenir l'OHLCV via le client Bitget")
   158: 
   159: def ensure_bitget_fetch(exchange: Any, *, market_hint: str | None = None) -> Any:
   160:     """Renvoie l'exchange si fetch_ohlcv existe, sinon un wrapper qui l’implémente. Log debug si BT_DEBUG=1."""
   161:     if hasattr(exchange, "fetch_ohlcv") and callable(getattr(exchange, "fetch_ohlcv")):
   162:         _log("exchange.fetch_ohlcv() déjà présent.")
   163:         return exchange
   164:     _log("exchange.fetch_ohlcv() absent → usage BitgetFetchAdapter.")
   165:     return BitgetFetchAdapter(exchange, market_hint=market_hint)

## scalper/adapters/market_data.py (last modified: 2025-08-23 20:57:14)
     1: # scalper/backtest/market_data.py
     2: from __future__ import annotations
     3: 
     4: import os
     5: from pathlib import Path
     6: from typing import Any
     7: 
     8: import pandas as pd
     9: 
    10: BT_DEBUG = int(os.getenv("BT_DEBUG", "0") or "0")
    11: 
    12: def _log(msg: str) -> None:
    13:     if BT_DEBUG:
    14:         print(f"[bt.debug] {msg}", flush=True)
    15: 
    16: def _csv_path(data_dir: str | Path, symbol: str, timeframe: str) -> Path:
    17:     root = Path(data_dir)
    18:     root.mkdir(parents=True, exist_ok=True)
    19:     tf = timeframe.replace(":", "")
    20:     return root / f"{symbol}-{tf}.csv"
    21: 
    22: def _read_csv(path: Path) -> pd.DataFrame:
    23:     _log(f"lecture CSV: {path}")
    24:     df = pd.read_csv(path)
    25:     ts_col = next((c for c in df.columns if c.lower() in ("ts", "timestamp", "time", "date")), None)
    26:     if ts_col is None:
    27:         raise ValueError("Colonne temps introuvable (timestamp/time/date)")
    28:     df = df.rename(columns={ts_col: "timestamp"})
    29:     df["timestamp"] = pd.to_datetime(df["timestamp"], utc=True, infer_datetime_format=True)
    30:     df = df.set_index("timestamp").sort_index()
    31:     _log(f"→ CSV ok, n={len(df)}, t0={df.index.min()}, t1={df.index.max()}")
    32:     return df
    33: 
    34: def _write_csv(path: Path, df: pd.DataFrame) -> None:
    35:     tmp = df.reset_index().rename(columns={"index": "timestamp"})
    36:     if "timestamp" not in tmp.columns:
    37:         tmp = tmp.rename(columns={"index": "timestamp"})
    38:     tmp.to_csv(path, index=False)
    39:     _log(f"écrit CSV: {path} (n={len(df)})")
    40: 
    41: def fetch_ohlcv_via_exchange(exchange: Any, symbol: str, timeframe: str, *, limit: int = 1000) -> pd.DataFrame:
    42:     _log(f"fetch via exchange.fetch_ohlcv: symbol={symbol} tf={timeframe} limit={limit}")
    43:     raw = exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=limit)  # peut être sync ou adapté
    44:     # Normalisation minimaliste (liste de listes)
    45:     rows = []
    46:     for r in raw:
    47:         ts = int(r[0])
    48:         unit = "ms" if ts > 10_000_000_000 else "s"
    49:         ts = pd.to_datetime(ts, unit=unit, utc=True)
    50:         rows.append([ts, float(r[1]), float(r[2]), float(r[3]), float(r[4]), float(r[5])])
    51:     df = pd.DataFrame(rows, columns=["timestamp", "open", "high", "low", "close", "volume"]).set_index("timestamp").sort_index()
    52:     _log(f"→ exchange ok, n={len(df)}, t0={df.index.min()}, t1={df.index.max()}")
    53:     return df
    54: 
    55: def hybrid_loader_from_exchange(exchange: Any, data_dir: str = "data", *, api_limit: int = 1000):
    56:     """
    57:     Loader hybride:
    58:       1) lit data/<SYMBOL>-<TF>.csv si présent,
    59:       2) sinon fetch via exchange.fetch_ohlcv, puis écrit le CSV en cache.
    60:     """
    61:     def load(symbol: str, timeframe: str, start: str | None, end: str | None) -> pd.DataFrame:
    62:         path = _csv_path(data_dir, symbol, timeframe)
    63:         if path.exists():
    64:             df = _read_csv(path)
    65:             src = "csv"
    66:         else:
    67:             df = fetch_ohlcv_via_exchange(exchange, symbol, timeframe, limit=api_limit)
    68:             _write_csv(path, df)
    69:             src = "exchange"
    70:         if start:
    71:             df = df.loc[pd.Timestamp(start, tz="UTC") :]
    72:         if end:
    73:             df = df.loc[: pd.Timestamp(end, tz="UTC")]
    74:         _log(f"loader -> {symbol} {timeframe} (src={src}) n={len(df)} "
    75:              f"range=[{df.index.min()} .. {df.index.max()}]")
    76:         return df
    77:     return load

## scalper/backtest/__init__.py (last modified: 2025-08-23 20:57:14)
     1: # scalper/backtest/__init__.py
     2: from .runner import (
     3:     BTCfg, BTConfig,        # BTConfig = alias rétro-compat
     4:     run_multi, run_single,  # mêmes signatures async
     5:     save_results,           # no-op compat
     6: )
     7: from .cache import (
     8:     ensure_csv_cache, csv_path, read_csv_ohlcv, dump_validation_report,
     9:     tf_to_seconds,
    10: )

## scalper/backtest/cache.py (last modified: 2025-08-23 20:57:14)
     1: # scalper/backtest/cache.py
     2: from __future__ import annotations
     3: 
     4: import csv
     5: import json
     6: import os
     7: import time
     8: from dataclasses import dataclass
     9: from pathlib import Path
    10: from typing import Dict, List, Tuple, Iterable, Optional
    11: 
    12: # ---------------- Timeframe utils ----------------
    13: 
    14: _TF_SECONDS = {
    15:     "1m": 60, "3m": 180, "5m": 300, "15m": 900, "30m": 1800,
    16:     "1h": 3600, "2h": 7200, "4h": 14400, "6h": 21600, "12h": 43200,
    17:     "1d": 86400, "3d": 259200, "1w": 604800,
    18: }
    19: 
    20: def tf_to_seconds(tf: str) -> int:
    21:     tf = tf.strip().lower()
    22:     if tf not in _TF_SECONDS:
    23:         raise ValueError(f"Timeframe inconnu: {tf}")
    24:     return _TF_SECONDS[tf]
    25: 
    26: # ---------------- Fraîcheur cible par TF ----------------
    27: 
    28: _DEFAULT_MAX_AGE = {
    29:     # règle empirique (peut être surchargée par ENV)
    30:     "1m": 2 * 3600,        # 2h
    31:     "3m": 4 * 3600,        # 4h
    32:     "5m": 12 * 3600,       # 12h
    33:     "15m": 24 * 3600,      # 24h
    34:     "30m": 36 * 3600,      # 36h
    35:     "1h": 3 * 86400,       # 3 jours
    36:     "2h": 5 * 86400,       # 5 jours
    37:     "4h": 10 * 86400,      # 10 jours
    38:     "6h": 15 * 86400,      # 15 jours
    39:     "12h": 20 * 86400,     # 20 jours
    40:     "1d": 3 * 86400,       # 3 jours (ok si 2 jours comme tu voulais)
    41:     "3d": 10 * 86400,
    42:     "1w": 30 * 86400,
    43: }
    44: 
    45: def max_age_for_tf(tf: str) -> int:
    46:     """Autorise override ENV via BACKTEST_MAX_AGE_<TF> (en secondes)."""
    47:     tf = tf.lower()
    48:     env_key = f"BACKTEST_MAX_AGE_{tf.replace('m','M').replace('h','H').replace('d','D').replace('w','W')}"
    49:     if env_key in os.environ:
    50:         try:
    51:             return int(os.environ[env_key])
    52:         except Exception:
    53:             pass
    54:     return _DEFAULT_MAX_AGE.get(tf, 7 * 86400)
    55: 
    56: # ---------------- CSV I/O ----------------
    57: 
    58: def data_dir() -> Path:
    59:     d = Path(os.getenv("DATA_DIR", "data"))
    60:     d.mkdir(parents=True, exist_ok=True)
    61:     return d
    62: 
    63: def csv_path(symbol: str, tf: str) -> Path:
    64:     return data_dir() / f"{symbol.upper()}-{tf}.csv"
    65: 
    66: def read_csv_ohlcv(path: Path) -> List[List[float]]:
    67:     out: List[List[float]] = []
    68:     if not path.exists():
    69:         return out
    70:     with path.open("r", newline="") as f:
    71:         r = csv.reader(f)
    72:         header = next(r, None)
    73:         for row in r:
    74:             # columns: timestamp,open,high,low,close,volume
    75:             try:
    76:                 ts, o, h, l, c, v = row[:6]
    77:                 out.append([int(ts), float(o), float(h), float(l), float(c), float(v)])
    78:             except Exception:
    79:                 continue
    80:     return out
    81: 
    82: def write_csv_ohlcv(path: Path, rows: Iterable[Iterable[float]]) -> None:
    83:     new_file = not path.exists()
    84:     with path.open("w", newline="") as f:
    85:         w = csv.writer(f)
    86:         w.writerow(["timestamp","open","high","low","close","volume"])
    87:         for r in rows:
    88:             w.writerow(r)
    89: 
    90: # ---------------- Validation / Chargement / Fetch ----------------
    91: 
    92: @dataclass
    93: class CacheInfo:
    94:     symbol: str
    95:     tf: str
    96:     path: Path
    97:     exists: bool
    98:     fresh: bool
    99:     last_ts: Optional[int] = None
   100:     rows: int = 0
   101: 
   102: def _is_fresh(last_ts: Optional[int], tf: str) -> bool:
   103:     if not last_ts:
   104:         return False
   105:     age = int(time.time()) - int(last_ts / 1000)
   106:     return age <= max_age_for_tf(tf)
   107: 
   108: def inspect_csv(symbol: str, tf: str) -> CacheInfo:
   109:     p = csv_path(symbol, tf)
   110:     if not p.exists():
   111:         return CacheInfo(symbol, tf, p, exists=False, fresh=False)
   112:     rows = read_csv_ohlcv(p)
   113:     last_ts = rows[-1][0] if rows else None
   114:     return CacheInfo(symbol, tf, p, exists=True, fresh=_is_fresh(last_ts, tf), last_ts=last_ts, rows=len(rows))
   115: 
   116: async def fetch_ohlcv_via_exchange(exchange, symbol: str, tf: str, limit: int) -> List[List[float]]:
   117:     # exchange: objet CCXT-like fourni par le live (déjà configuré Bitget)
   118:     return await exchange.fetch_ohlcv(symbol=symbol, timeframe=tf, limit=limit)
   119: 
   120: async def ensure_csv_for_symbol(exchange, symbol: str, tf: str, limit: int) -> Tuple[CacheInfo, List[List[float]]]:
   121:     info = inspect_csv(symbol, tf)
   122:     if info.exists and info.fresh:
   123:         data = read_csv_ohlcv(info.path)
   124:         return info, data
   125: 
   126:     # fetch & persist
   127:     data = await fetch_ohlcv_via_exchange(exchange, symbol, tf, limit=limit)
   128:     if data:
   129:         write_csv_ohlcv(info.path, data)
   130:         info = inspect_csv(symbol, tf)  # refresh stats
   131:     return info, data
   132: 
   133: async def ensure_csv_cache(exchange, symbols: List[str], tf: str, limit: int) -> Dict[str, List[List[float]]]:
   134:     """Vérifie le cache CSV et (re)charge depuis l'exchange si nécessaire."""
   135:     out: Dict[str, List[List[float]]] = {}
   136:     for s in symbols:
   137:         info, rows = await ensure_csv_for_symbol(exchange, s, tf, limit)
   138:         out[s] = rows
   139:     return out
   140: 
   141: def dump_validation_report(symbols: List[str], tf: str, out_path: Path) -> None:
   142:     report = []
   143:     for s in symbols:
   144:         info = inspect_csv(s, tf)
   145:         report.append({
   146:             "symbol": s,
   147:             "tf": tf,
   148:             "path": str(info.path),
   149:             "exists": info.exists,
   150:             "fresh": info.fresh,
   151:             "last_ts": info.last_ts,
   152:             "rows": info.rows,
   153:             "max_age": max_age_for_tf(tf),
   154:         })
   155:     out_path.parent.mkdir(parents=True, exist_ok=True)
   156:     out_path.write_text(json.dumps(report, indent=2))

## scalper/backtest/cli.py (last modified: 2025-08-23 20:57:14)
     1: from __future__ import annotations
     2: 
     3: import argparse
     4: from scalper.backtest.runner import run_multi, csv_loader_factory
     5: 
     6: def create_parser() -> argparse.ArgumentParser:
     7:     p = argparse.ArgumentParser(prog="backtest", description="Backtest multi symboles / multi timeframes")
     8:     p.add_argument("--symbols", required=True, help="Liste, ex: BTCUSDT,ETHUSDT,SOLUSDT")
     9:     p.add_argument("--timeframes", required=True, help="Liste, ex: 1m,5m,15m")
    10:     p.add_argument("--data-dir", default="data", help="Répertoire CSV OHLCV")
    11:     p.add_argument("--out-dir", default="result", help="Répertoire de sortie")
    12:     p.add_argument("--cash", type=float, default=10_000.0)
    13:     p.add_argument("--risk", type=float, default=0.005, help="risk_pct par trade (0.005 = 0.5%)")
    14:     p.add_argument("--slippage-bps", type=float, default=1.5)
    15:     return p
    16: 
    17: def main(argv: list[str] | None = None) -> int:
    18:     p = create_parser()
    19:     a = p.parse_args(argv)
    20:     symbols = [s.strip().upper() for s in a.symbols.split(",") if s.strip()]
    21:     tfs = [t.strip() for t in a.timeframes.split(",") if t.strip()]
    22:     loader = csv_loader_factory(a.data_dir)
    23:     run_multi(
    24:         symbols=symbols,
    25:         timeframes=tfs,
    26:         loader=loader,
    27:         out_dir=a.out_dir,
    28:         initial_cash=a.cash,
    29:         risk_pct=a.risk,
    30:         slippage_bps=a.slippage_bps,
    31:     )
    32:     print(f"✅ Backtests terminés → {a.out_dir}/ (equity_curve/trades/fills/metrics/summary)")
    33:     return 0
    34: 
    35: if __name__ == "__main__":
    36:     raise SystemExit(main())

## scalper/backtest/engine.py (last modified: 2025-08-23 20:57:14)
     1: # scalper/backtest/engine.py
     2: from __future__ import annotations
     3: 
     4: import math
     5: from dataclasses import dataclass, asdict
     6: from typing import Callable, Dict, List, Optional, Tuple
     7: 
     8: import pandas as pd
     9: 
    10: from scalper.strategy import generate_signal
    11: from scalper.trade_utils import compute_position_size
    12: from scalper.exchange.fees import get_fee
    13: 
    14: OHLCVLoader = Callable[[str, str, Optional[str], Optional[str]], pd.DataFrame]
    15: 
    16: 
    17: @dataclass
    18: class Fill:
    19:     ts: pd.Timestamp
    20:     symbol: str
    21:     side: str       # "long" | "short" | "flat"
    22:     price: float
    23:     qty: float
    24:     fee: float
    25:     reason: str     # "entry"|"tp"|"sl"|"exit"|"reverse"|"final_exit"
    26: 
    27: 
    28: @dataclass
    29: class Trade:
    30:     symbol: str
    31:     side: str
    32:     entry_ts: pd.Timestamp
    33:     entry_px: float
    34:     qty: float
    35:     exit_ts: pd.Timestamp
    36:     exit_px: float
    37:     fee_entry: float
    38:     fee_exit: float
    39:     pnl: float
    40:     pnl_pct: float
    41: 
    42: 
    43: @dataclass
    44: class EquityPoint:
    45:     ts: pd.Timestamp
    46:     equity: float
    47: 
    48: 
    49: def _apply_slippage(price: float, side: str, slippage_bps: float) -> float:
    50:     if slippage_bps <= 0:
    51:         return price
    52:     mult = 1.0 + (slippage_bps / 10_000.0)
    53:     return price * (mult if side in ("buy", "long") else 1.0 / mult)
    54: 
    55: 
    56: def _hit_tp_sl(row: pd.Series, side: str, tp: float, sl: float) -> Tuple[bool, str, float]:
    57:     high, low, close = float(row.high), float(row.low), float(row.close)
    58:     if side == "long":
    59:         if low <= sl <= high:
    60:             return True, "sl", sl
    61:         if low <= tp <= high:
    62:             return True, "tp", tp
    63:         return False, "", close
    64:     else:
    65:         if low <= tp <= high:
    66:             return True, "tp", tp
    67:         if low <= sl <= high:
    68:             return True, "sl", sl
    69:         return False, "", close
    70: 
    71: 
    72: def run_single(
    73:     *,
    74:     symbol: str,
    75:     timeframe: str,
    76:     loader: OHLCVLoader,
    77:     start: str | None = None,
    78:     end: str | None = None,
    79:     initial_cash: float = 10_000.0,
    80:     risk_pct: float = 0.005,
    81:     slippage_bps: float = 1.5,
    82:     taker: bool = True,
    83:     quiet: bool = True,
    84: ) -> Dict[str, object]:
    85:     df = loader(symbol, timeframe, start, end).copy()
    86:     if df.empty:
    87:         raise ValueError(f"Pas de données pour {symbol} {timeframe}")
    88:     df.columns = [c.lower() for c in df.columns]
    89:     for c in ("open", "high", "low", "close", "volume"):
    90:         if c not in df.columns:
    91:             raise ValueError(f"OHLCV invalide: colonne {c} manquante")
    92: 
    93:     fee_rate = get_fee(symbol, "taker" if taker else "maker")
    94: 
    95:     equity = float(initial_cash)
    96:     pos_side: str = "flat"
    97:     pos_qty: float = 0.0
    98:     entry_px: float = 0.0
    99:     fee_entry: float = 0.0
   100:     sl: float = math.nan
   101:     tp: float = math.nan
   102: 
   103:     eq: List[EquityPoint] = []
   104:     fills: List[Fill] = []
   105:     closed: List[Trade] = []
   106: 
   107:     for ts, row in df.iterrows():
   108:         ts = pd.Timestamp(ts)
   109: 
   110:         # gérer SL/TP quand en position
   111:         if pos_side in ("long", "short"):
   112:             hit, reason, exec_px = _hit_tp_sl(row, pos_side, tp, sl)
   113:             if hit:
   114:                 px = _apply_slippage(exec_px, "sell" if pos_side == "long" else "buy", slippage_bps)
   115:                 fee = abs(px * pos_qty) * fee_rate
   116:                 pnl = (px - entry_px) * pos_qty if pos_side == "long" else (entry_px - px) * pos_qty
   117:                 equity += pnl - fee
   118:                 fills.append(Fill(ts, symbol, "flat", px, -pos_qty if pos_side == "long" else pos_qty, fee, reason))
   119:                 closed.append(
   120:                     Trade(
   121:                         symbol=symbol, side=pos_side, entry_ts=ts, entry_px=entry_px, qty=pos_qty,
   122:                         exit_ts=ts, exit_px=px, fee_entry=fee_entry, fee_exit=fee,
   123:                         pnl=pnl - fee_entry - fee,
   124:                         pnl_pct=((equity / initial_cash) - 1.0) * 100.0 if initial_cash else 0.0,
   125:                     )
   126:                 )
   127:                 pos_side, pos_qty, entry_px, sl, tp, fee_entry = "flat", 0.0, 0.0, math.nan, math.nan, 0.0
   128: 
   129:         # signal de la stratégie live
   130:         sig = generate_signal(
   131:             symbol=symbol,
   132:             ohlcv=df.loc[:ts].tail(300),
   133:             equity=equity,
   134:             risk_pct=risk_pct,
   135:         )
   136:         if sig and getattr(sig, "side", None) and pos_side == "flat":
   137:             side = sig.side  # "long"|"short"
   138:             px = _apply_slippage(float(sig.price), "buy" if side == "long" else "sell", slippage_bps)
   139:             qty = float(getattr(sig, "qty", 0.0)) or compute_position_size(equity, px, risk_pct, symbol=symbol)
   140:             if qty > 0:
   141:                 fee = abs(px * qty) * fee_rate
   142:                 pos_side, pos_qty, entry_px = side, qty, px
   143:                 sl = float(getattr(sig, "sl", px * (0.995 if side == "long" else 1.005)))
   144:                 tp = float(getattr(sig, "tp", getattr(sig, "tp1", px * (1.005 if side == "long" else 0.995))))
   145:                 fee_entry = fee
   146:                 equity -= fee
   147:                 fills.append(Fill(ts, symbol, side, px, qty if side == "long" else -qty, fee, "entry"))
   148: 
   149:         eq.append(EquityPoint(ts, equity))
   150: 
   151:     # sortie forcée fin de série
   152:     if pos_side in ("long", "short"):
   153:         last_ts = pd.Timestamp(df.index[-1])
   154:         px = _apply_slippage(float(df["close"].iloc[-1]), "sell" if pos_side == "long" else "buy", slippage_bps)
   155:         fee = abs(px * pos_qty) * fee_rate
   156:         pnl = (px - entry_px) * pos_qty if pos_side == "long" else (entry_px - px) * pos_qty
   157:         equity += pnl - fee
   158:         fills.append(Fill(last_ts, symbol, "flat", px, -pos_qty if pos_side == "long" else pos_qty, fee, "final_exit"))
   159:         closed.append(
   160:             Trade(
   161:                 symbol=symbol, side=pos_side, entry_ts=last_ts, entry_px=entry_px, qty=pos_qty,
   162:                 exit_ts=last_ts, exit_px=px, fee_entry=fee_entry, fee_exit=fee,
   163:                 pnl=pnl - fee_entry - fee, pnl_pct=((equity / initial_cash) - 1.0) * 100.0 if initial_cash else 0.0,
   164:             )
   165:         )
   166: 
   167:     eq_df = pd.DataFrame([asdict(e) for e in eq])
   168:     tr_df = pd.DataFrame([asdict(t) for t in closed])
   169:     fills_df = pd.DataFrame([asdict(f) for f in fills])
   170: 
   171:     metrics = {
   172:         "symbol": symbol,
   173:         "timeframe": timeframe,
   174:         "initial_cash": initial_cash,
   175:         "final_equity": float(eq_df["equity"].iloc[-1] if not eq_df.empty else initial_cash),
   176:         "return_pct": float(((eq_df["equity"].iloc[-1] / initial_cash) - 1.0) * 100.0 if initial_cash and not eq_df.empty else 0.0),
   177:         "n_trades": int(len(tr_df)),
   178:         "win_rate_pct": float((tr_df["pnl"] > 0).mean() * 100.0) if not tr_df.empty else 0.0,
   179:         "avg_trade_pnl": float(tr_df["pnl"].mean()) if not tr_df.empty else 0.0,
   180:         "max_dd_pct": float(((eq_df["equity"].cummax() - eq_df["equity"]) / eq_df["equity"].cummax()).max() * 100.0) if not eq_df.empty else 0.0,
   181:     }
   182: 
   183:     return {"equity_curve": eq_df, "trades": tr_df, "fills": fills_df, "metrics": metrics}

## scalper/backtest/grid_search.py (last modified: 2025-08-23 20:57:14)
     1: """Grid-search express module to evaluate hyperparameter combinations.
     2: 
     3: This module builds combinations of strategy and engine parameters, runs the
     4: existing multi symbol backtester for each combination, collects key metrics and
     5: selects the best configuration according to:
     6: 
     7: 1. Profit factor (descending)
     8: 2. Maximum drawdown percentage (ascending)
     9: 3. Net PnL in USDT (descending)
    10: 4. Number of trades (ascending)
    11: 
    12: Results are written under ``result/grid`` by default and a short summary is
    13: printed to the console.
    14: """
    15: from __future__ import annotations
    16: 
    17: from dataclasses import dataclass
    18: import csv
    19: import json
    20: import os
    21: import random
    22: from itertools import product
    23: from typing import Any, Callable, Dict, Iterable, List, Sequence
    24: 
    25: # ---------------------------------------------------------------------------
    26: # Utilities
    27: # ---------------------------------------------------------------------------
    28: 
    29: 
    30: def parse_hours(hours: str) -> List[int]:
    31:     """Parse hours specification like ``"7-11,13-17"`` into a list of ints.
    32: 
    33:     Each comma separated element can either be a single hour (``"8"``) or a
    34:     range ``"7-11"`` which is inclusive.  Returned hours are sorted and unique.
    35:     """
    36: 
    37:     if not hours:
    38:         return []
    39:     result: List[int] = []
    40:     for part in hours.split(","):
    41:         part = part.strip()
    42:         if not part:
    43:             continue
    44:         if "-" in part:
    45:             start_s, end_s = part.split("-", 1)
    46:             start, end = int(start_s), int(end_s)
    47:             result.extend(range(start, end + 1))
    48:         else:
    49:             result.append(int(part))
    50:     return sorted(set(result))
    51: 
    52: 
    53: # Order of parameters used throughout the module and in CSV output
    54: PARAM_KEYS = [
    55:     "timeframe",
    56:     "score_min",
    57:     "atr_min_ratio",
    58:     "rr_min",
    59:     "risk_pct",
    60:     "slippage_bps",
    61:     "fee_rate",
    62:     "cooldown_secs",
    63:     "hours",
    64: ]
    65: 
    66: # Default values used if a parameter is not provided in the grid
    67: DEFAULTS = {
    68:     "score_min": 55,
    69:     "atr_min_ratio": 0.002,
    70:     "rr_min": 1.2,
    71:     "risk_pct": 0.01,
    72:     "slippage_bps": 2,
    73:     "fee_rate": 0.001,
    74:     "cooldown_secs": 300,
    75:     "hours": "7-11,13-17",
    76: }
    77: 
    78: 
    79: @dataclass
    80: class GridResult:
    81:     params: Dict[str, Any]
    82:     metrics: Dict[str, float]
    83: 
    84: 
    85: def _ensure_list(val: Sequence[Any] | Any) -> List[Any]:
    86:     if isinstance(val, (list, tuple, set)):
    87:         return list(val)
    88:     return [val]
    89: 
    90: 
    91: def build_param_grid(param_lists: Dict[str, Sequence[Any]], grid_max: int) -> List[Dict[str, Any]]:
    92:     """Return a list of parameter combinations.
    93: 
    94:     ``param_lists`` maps parameter names to a sequence of values.  Missing keys
    95:     fall back to ``DEFAULTS``.  The resulting cartesian product is uniformly
    96:     sampled to ``grid_max`` elements when necessary while trying to maintain a
    97:     variety of timeframes and ``atr_min_ratio`` values.
    98:     """
    99: 
   100:     lists: Dict[str, List[Any]] = {}
   101:     for key in PARAM_KEYS:
   102:         if key == "timeframe":
   103:             # timeframe must be explicitly provided; default empty -> "1m"
   104:             vals = param_lists.get(key) or ["1m"]
   105:         else:
   106:             vals = param_lists.get(key)
   107:             if not vals:
   108:                 default = DEFAULTS[key]
   109:                 vals = [default]
   110:         lists[key] = _ensure_list(vals)
   111: 
   112:     combos: List[Dict[str, Any]] = [
   113:         dict(zip(PARAM_KEYS, values)) for values in product(*(lists[k] for k in PARAM_KEYS))
   114:     ]
   115: 
   116:     # Uniform sampling if exceeding grid_max
   117:     if len(combos) > grid_max:
   118:         step = len(combos) / float(grid_max)
   119:         sampled = []
   120:         for i in range(grid_max):
   121:             idx = int(round(i * step))
   122:             if idx >= len(combos):
   123:                 idx = len(combos) - 1
   124:             sampled.append(combos[idx])
   125:         # ensure each timeframe appears at least once
   126:         wanted_tfs = set(lists["timeframe"])
   127:         present_tfs = {c["timeframe"] for c in sampled}
   128:         missing = list(wanted_tfs - present_tfs)
   129:         if missing:
   130:             for tf in missing:
   131:                 for c in combos:
   132:                     if c["timeframe"] == tf and c not in sampled:
   133:                         sampled.append(c)
   134:                         break
   135:             sampled = sampled[:grid_max]
   136:         combos = sampled
   137:     return combos
   138: 
   139: 
   140: # ---------------------------------------------------------------------------
   141: # Core runner
   142: # ---------------------------------------------------------------------------
   143: 
   144: 
   145: def run_grid_search(
   146:     *,
   147:     symbols: Sequence[str],
   148:     exchange: str,
   149:     base_params: Dict[str, Any],
   150:     param_lists: Dict[str, Sequence[Any]],
   151:     grid_max: int = 12,
   152:     csv_dir: str | None = None,
   153:     initial_equity: float = 1000.0,
   154:     leverage: float = 1.0,
   155:     paper_constraints: bool = True,
   156:     seed: int | None = None,
   157:     out_dir: str = "./result/grid",
   158:     match_exchange_semantics: bool = False,  # placeholder for compatibility
   159:     run_func: Callable[..., Any] | None = None,
   160: ) -> List[GridResult]:
   161:     """Execute grid search across parameter combinations.
   162: 
   163:     ``base_params`` provides default single values for parameters. ``param_lists``
   164:     contains the grid specifications from CLI (already parsed into sequences).
   165:     ``run_func`` should have the same signature as :func:`run_backtest_multi`.
   166:     """
   167: 
   168:     if seed is not None:
   169:         random.seed(seed)
   170: 
   171:     if run_func is None:  # avoid circular import at module load
   172:         from .run_multi import run_backtest_multi  # late import
   173: 
   174:         run_func = run_backtest_multi
   175: 
   176:     # merge lists with defaults
   177:     full_lists: Dict[str, Sequence[Any]] = {}
   178:     for k in PARAM_KEYS:
   179:         if k == "timeframe":
   180:             full_lists[k] = param_lists.get(k) or [base_params.get("timeframe", "1m")]
   181:         else:
   182:             if param_lists.get(k) is not None:
   183:                 full_lists[k] = param_lists[k]
   184:             else:
   185:                 full_lists[k] = [base_params.get(k, DEFAULTS[k])]
   186: 
   187:     combos = build_param_grid(full_lists, grid_max)
   188: 
   189:     results: List[GridResult] = []
   190:     os.makedirs(out_dir, exist_ok=True)
   191: 
   192:     for combo in combos:
   193:         # Build parameters for backtester
   194:         tf = combo["timeframe"]
   195:         fee = float(combo["fee_rate"])
   196:         slip = float(combo["slippage_bps"])
   197:         risk = float(combo["risk_pct"])
   198: 
   199:         summary, _trades = run_func(
   200:             symbols=list(symbols),
   201:             exchange=exchange,
   202:             timeframe=tf,
   203:             csv_dir=csv_dir,
   204:             fee_rate=fee,
   205:             slippage_bps=slip,
   206:             risk_pct=risk,
   207:             initial_equity=initial_equity,
   208:             leverage=leverage,
   209:             paper_constraints=paper_constraints,
   210:             seed=seed,
   211:             out_dir=os.path.join(out_dir, "tmp"),
   212:             plot=False,
   213:             dry_run=True,
   214:         )
   215:         total = next((r for r in summary if r.get("symbol") == "TOTAL"), summary[-1])
   216:         metrics = {
   217:             "pnl_usdt": float(total.get("pnl_usdt", 0.0)),
   218:             "profit_factor": float(total.get("profit_factor", 0.0)),
   219:             "max_dd_pct": float(total.get("max_drawdown_pct", 0.0)),
   220:             "winrate_pct": float(total.get("winrate_pct", 0.0)),
   221:             "trades": float(total.get("trades", 0.0)),
   222:             "final_equity": initial_equity + float(total.get("pnl_usdt", 0.0)),
   223:         }
   224:         results.append(GridResult(params=combo, metrics=metrics))
   225: 
   226:     # sort results
   227:     results.sort(
   228:         key=lambda r: (
   229:             -r.metrics["profit_factor"],
   230:             r.metrics["max_dd_pct"],
   231:             -r.metrics["pnl_usdt"],
   232:             r.metrics["trades"],
   233:         )
   234:     )
   235: 
   236:     # console output -------------------------------------------------------
   237:     print(
   238:         f"Grid-search express ({len(results)} combinaisons testées, top trié par PF↓ puis MaxDD%↑)"
   239:     )
   240:     header = (
   241:         f"{'timeframe':<8} {'PF':>6} {'MaxDD%':>8} {'PnL':>8} {'Trades':>8}"
   242:     )
   243:     print(header)
   244:     for r in results[:10]:
   245:         m = r.metrics
   246:         print(
   247:             f"{r.params['timeframe']:<8} {m['profit_factor']:>6.2f} {m['max_dd_pct']:>8.2f} {m['pnl_usdt']:>8.2f} {int(m['trades']):>8}"
   248:         )
   249: 
   250:     # write csv ------------------------------------------------------------
   251:     csv_cols = PARAM_KEYS + [
   252:         "pnl_usdt",
   253:         "profit_factor",
   254:         "max_dd_pct",
   255:         "winrate_pct",
   256:         "trades",
   257:         "final_equity",
   258:     ]
   259:     with open(os.path.join(out_dir, "grid_results.csv"), "w", newline="") as fh:
   260:         writer = csv.DictWriter(fh, fieldnames=csv_cols)
   261:         writer.writeheader()
   262:         for r in results:
   263:             row = {**r.params, **r.metrics}
   264:             writer.writerow(row)
   265: 
   266:     best = results[0]
   267:     with open(os.path.join(out_dir, "best_config.json"), "w", encoding="utf8") as fh:
   268:         json.dump({"params": best.params, "metrics": best.metrics}, fh, indent=2)
   269: 
   270:     # markdown summary -----------------------------------------------------
   271:     md_path = os.path.join(out_dir, "grid_summary.md")
   272:     with open(md_path, "w", encoding="utf8") as fh:
   273:         fh.write(
   274:             "| timeframe | PF | MaxDD% | PnL | trades |\n|---|---|---|---|---|\n"
   275:         )
   276:         for r in results[:10]:
   277:             m = r.metrics
   278:             fh.write(
   279:                 f"| {r.params['timeframe']} | {m['profit_factor']:.2f} | {m['max_dd_pct']:.2f} | {m['pnl_usdt']:.2f} | {int(m['trades'])} |\n"
   280:             )
   281: 
   282:     # optional scatter plot ------------------------------------------------
   283:     try:  # pragma: no cover - optional dependency
   284:         import matplotlib.pyplot as plt
   285: 
   286:         pf = [r.metrics["profit_factor"] for r in results]
   287:         dd = [r.metrics["max_dd_pct"] for r in results]
   288:         trades = [r.metrics["trades"] for r in results]
   289:         tfs = [r.params["timeframe"] for r in results]
   290:         colors = {tf: i for i, tf in enumerate(sorted(set(tfs)))}
   291:         c = [colors[tf] for tf in tfs]
   292:         plt.figure(figsize=(6, 4))
   293:         plt.scatter(dd, pf, c=c, s=[max(10, t) for t in trades], alpha=0.7)
   294:         plt.xlabel("MaxDD%")
   295:         plt.ylabel("Profit Factor")
   296:         plt.title("PF vs MaxDD")
   297:         plt.savefig(os.path.join(out_dir, "pf_vs_dd.png"))
   298:         plt.close()
   299:     except Exception:  # pragma: no cover
   300:         pass
   301: 
   302:     return results
   303: 
   304: 
   305: __all__ = ["run_grid_search", "build_param_grid", "parse_hours", "GridResult"]


## scalper/backtest/loader_csv.py (last modified: 2025-08-23 20:57:14)
     1: # scalper/backtest/loader_csv.py
     2: from __future__ import annotations
     3: 
     4: import csv
     5: from typing import Dict, List
     6: 
     7: from scalper.services.data_cache import csv_path
     8: 
     9: # Format de sortie : liste de bougies [ts, open, high, low, close, volume]
    10: def load_ohlcv_csv(symbol: str, timeframe: str) -> List[List[float]]:
    11:     path = csv_path(symbol, timeframe)
    12:     rows: List[List[float]] = []
    13:     with open(path, "r") as f:
    14:         r = csv.DictReader(f)
    15:         for row in r:
    16:             rows.append([
    17:                 int(row["timestamp"]),
    18:                 float(row["open"]),
    19:                 float(row["high"]),
    20:                 float(row["low"]),
    21:                 float(row["close"]),
    22:                 float(row["volume"]),
    23:             ])
    24:     rows.sort(key=lambda x: x[0])
    25:     return rows
    26: 
    27: 
    28: def load_many(symbols: List[str], timeframe: str) -> Dict[str, List[List[float]]]:
    29:     out: Dict[str, List[List[float]]] = {}
    30:     for s in symbols:
    31:         out[s] = load_ohlcv_csv(s, timeframe)
    32:     return out

## scalper/backtest/market_data.py (last modified: 2025-08-23 20:57:14)
     1: from __future__ import annotations
     2: 
     3: import json
     4: import os
     5: import time
     6: from pathlib import Path
     7: from typing import Any, Iterable, Optional, Sequence, Tuple
     8: from urllib.request import Request, urlopen
     9: from urllib.error import URLError, HTTPError
    10: 
    11: import pandas as pd
    12: 
    13: # ============================================================================
    14: # Logs & utilitaires
    15: # ============================================================================
    16: BT_DEBUG = int(os.getenv("BT_DEBUG", "0") or "0")
    17: def _log(msg: str) -> None:
    18:     if BT_DEBUG:
    19:         print(f"[bt.debug] {msg}", flush=True)
    20: 
    21: def _now_ms() -> int:
    22:     return int(time.time() * 1000)
    23: 
    24: def _tf_to_seconds(tf: str) -> int:
    25:     tf = tf.lower().strip()
    26:     table = {"1m":60,"3m":180,"5m":300,"15m":900,"30m":1800,"1h":3600,"4h":14400,"1d":86400}
    27:     if tf not in table:
    28:         raise ValueError(f"Timeframe non supporté: {tf}")
    29:     return table[tf]
    30: 
    31: def _parse_duration(s: str) -> int:
    32:     """
    33:     '90s','15m','2h','3d' -> secondes
    34:     """
    35:     s = s.strip().lower()
    36:     if s.endswith("s"): return int(float(s[:-1]))
    37:     if s.endswith("m"): return int(float(s[:-1])*60)
    38:     if s.endswith("h"): return int(float(s[:-1])*3600)
    39:     if s.endswith("d"): return int(float(s[:-1])*86400)
    40:     return int(float(s))  # secondes
    41: 
    42: # ============================================================================
    43: # Politique de fraîcheur (par défaut + overrides via ENV)
    44: # ============================================================================
    45: def _default_max_age_seconds(tf: str) -> int:
    46:     """
    47:     Règles par défaut (conservatrices) :
    48:       - 1m..15m : 2 × TF  (ex: 5m -> 10m)
    49:       - 30m     : 1h
    50:       - 1h      : 6h
    51:       - 4h      : 24h
    52:       - 1d      : 3d
    53:     """
    54:     tf = tf.lower()
    55:     if tf in ("1m","3m","5m","15m"):
    56:         return 2 * _tf_to_seconds(tf)
    57:     if tf == "30m":
    58:         return 3600
    59:     if tf == "1h":
    60:         return 6*3600
    61:     if tf == "4h":
    62:         return 24*3600
    63:     if tf == "1d":
    64:         return 3*86400
    65:     raise ValueError(tf)
    66: 
    67: def _max_age_seconds(tf: str) -> int:
    68:     """
    69:     Overrides possibles (au choix) :
    70:       - CSV_MAX_AGE_MULT=NN → NN × TF  (ex: 50 pour 1m => 50 minutes)
    71:       - CSV_MAX_AGE_5m="45m" (prioritaire si présent)
    72:       - CSV_MAX_AGE_DEFAULT="2h" (fallback global)
    73:     """
    74:     tfk = tf.lower().replace(":", "")
    75:     env_spec = os.getenv(f"CSV_MAX_AGE_{tfk}")
    76:     if env_spec:
    77:         return _parse_duration(env_spec)
    78:     mult = os.getenv("CSV_MAX_AGE_MULT")
    79:     if mult:
    80:         return int(float(mult) * _tf_to_seconds(tf))
    81:     g = os.getenv("CSV_MAX_AGE_DEFAULT")
    82:     if g:
    83:         return _parse_duration(g)
    84:     return _default_max_age_seconds(tf)
    85: 
    86: # ============================================================================
    87: # CSV helpers + validation
    88: # ============================================================================
    89: def _data_dir(default: str = "data") -> Path:
    90:     root = Path(os.getenv("DATA_DIR", default))
    91:     root.mkdir(parents=True, exist_ok=True)
    92:     return root
    93: 
    94: def _csv_path(symbol: str, timeframe: str) -> Path:
    95:     tf = timeframe.replace(":", "")
    96:     return _data_dir() / f"{symbol}-{tf}.csv"
    97: 
    98: def _rows_to_df(rows: Iterable[Iterable[float]]) -> pd.DataFrame:
    99:     rows = list(rows)
   100:     if not rows:
   101:         raise ValueError("OHLCV vide")
   102:     unit = "ms" if rows[0][0] > 10_000_000_000 else "s"
   103:     df = pd.DataFrame(rows, columns=["ts","open","high","low","close","volume"])
   104:     df["timestamp"] = pd.to_datetime(df["ts"], unit=unit, utc=True)
   105:     return df.drop(columns=["ts"]).set_index("timestamp").sort_index()
   106: 
   107: def _read_csv(path: Path) -> pd.DataFrame:
   108:     df = pd.read_csv(path)
   109:     # tolère quelques variations de colonnes
   110:     cols = {c.lower(): c for c in df.columns}
   111:     ts_col = cols.get("timestamp") or cols.get("time") or cols.get("date") or cols.get("ts")
   112:     if not ts_col:
   113:         raise ValueError("Colonne temps absente (timestamp/time/date/ts)")
   114:     rename = {ts_col: "timestamp"}
   115:     for c in ("open","high","low","close","volume"):
   116:         if c not in cols:
   117:             raise ValueError(f"Colonne manquante: {c}")
   118:         rename[cols[c]] = c
   119:     df = df.rename(columns=rename)
   120:     df["timestamp"] = pd.to_datetime(df["timestamp"], utc=True, infer_datetime_format=True)
   121:     df = df[["timestamp","open","high","low","close","volume"]].sort_values("timestamp")
   122:     df = df.drop_duplicates("timestamp")
   123:     df = df.set_index("timestamp")
   124:     return df
   125: 
   126: def _write_csv(path: Path, df: pd.DataFrame) -> None:
   127:     out = df.reset_index().rename(columns={"index": "timestamp"})
   128:     out.to_csv(path, index=False)
   129: 
   130: def _is_csv_fresh_and_valid(path: Path, timeframe: str, *, min_rows: int = 100) -> Tuple[bool, str]:
   131:     """
   132:     Retourne (ok, reason). ok=True si le CSV est utilisable:
   133:       - schéma valide
   134:       - assez de lignes
   135:       - fraîcheur < seuil selon TF
   136:     """
   137:     if not path.exists():
   138:         return False, "absent"
   139:     try:
   140:         df = _read_csv(path)
   141:     except Exception as e:
   142:         return False, f"invalid({e})"
   143:     if len(df) < min_rows:
   144:         return False, f"too_few_rows({len(df)}<{min_rows})"
   145:     # Fraîcheur
   146:     last_ts = int(df.index.max().timestamp())
   147:     age_s = int(time.time()) - last_ts
   148:     max_age = _max_age_seconds(timeframe)
   149:     if age_s > max_age:
   150:         return False, f"stale({age_s}s>{max_age}s)"
   151:     # Monotonicité (échantillon)
   152:     if not df.index.is_monotonic_increasing:
   153:         return False, "not_monotonic"
   154:     return True, "ok"
   155: 
   156: # ============================================================================
   157: # Fallback réseau (CCXT d'abord, HTTP sinon)
   158: # ============================================================================
   159: def _ensure_ccxt() -> Any | None:
   160:     try:
   161:         import ccxt  # type: ignore
   162:         return ccxt
   163:     except Exception:
   164:         return None
   165: 
   166: def _fetch_via_ccxt(symbol: str, timeframe: str, limit: int = 1000) -> Optional[pd.DataFrame]:
   167:     ccxt = _ensure_ccxt()
   168:     if not ccxt:
   169:         _log("ccxt indisponible")
   170:         return None
   171:     ex = ccxt.bitget({"enableRateLimit": True, "options": {"defaultType": "swap"}})
   172:     ex.load_markets()
   173:     base = symbol.upper()
   174:     if not base.endswith("USDT"):
   175:         raise ValueError("symbol doit finir par USDT (ex: BTCUSDT)")
   176:     coin = base[:-4]
   177:     candidates = [f"{coin}/USDT:USDT", f"{coin}/USDT"]  # perp puis spot
   178:     for ccxt_sym in candidates:
   179:         try:
   180:             rows = ex.fetch_ohlcv(ccxt_sym, timeframe=timeframe, limit=limit)
   181:             if rows:
   182:                 return _rows_to_df(sorted(rows, key=lambda r: r[0]))
   183:         except Exception as e:
   184:             _log(f"ccxt fail {ccxt_sym}: {e}")
   185:             continue
   186:     return None
   187: 
   188: # === (facultatif) HTTP Bitget v1 minimal ===
   189: _GRAN_MIX = {"1m":"1min","3m":"3min","5m":"5min","15m":"15min","30m":"30min","1h":"1h","4h":"4h","1d":"1day"}
   190: _PERIOD_SPOT = {"1m":"1min","3m":"3min","5m":"5min","15m":"15min","30m":"30min","1h":"1hour","4h":"4hour","1d":"1day"}
   191: 
   192: def _http_get(url: str, timeout: int = 20) -> dict | list:
   193:     req = Request(url, headers={"User-Agent":"backtest-marketdata/1.0"})
   194:     with urlopen(req, timeout=timeout) as resp:
   195:         return json.loads(resp.read().decode("utf-8"))
   196: 
   197: def _normalize_http_rows(payload: dict | list) -> list[list[float]]:
   198:     rows = payload.get("data") if isinstance(payload, dict) else payload
   199:     if not isinstance(rows, list):
   200:         raise ValueError(f"Réponse inattendue: {payload}")
   201:     out = []
   202:     for r in rows:
   203:         ts = int(str(r[0])); o,h,l,c,v = map(float,(r[1],r[2],r[3],r[4],r[5]))
   204:         out.append([ts,o,h,l,c,v])
   205:     out.sort(key=lambda x:x[0])
   206:     return out
   207: 
   208: def _fetch_via_http(symbol: str, timeframe: str, limit: int = 1000) -> Optional[pd.DataFrame]:
   209:     tf = timeframe.lower()
   210:     g = _GRAN_MIX.get(tf); p = _PERIOD_SPOT.get(tf)
   211:     if not (g and p):
   212:         return None
   213:     # mix umcbl puis spot spbl, paramètres minimum (v1)
   214:     trials = [
   215:         f"https://api.bitget.com/api/mix/v1/market/candles?symbol={symbol}_UMCBL&granularity={g}&limit={limit}",
   216:         f"https://api/bitget.com/api/mix/v1/market/candles?symbol={symbol}&granularity={g}&limit={limit}",
   217:         f"https://api.bitget.com/api/spot/v1/market/candles?symbol={symbol}_SPBL&period={p}&limit={limit}",
   218:         f"https://api.bitget.com/api/spot/v1/market/candles?symbol={symbol}&period={p}&limit={limit}",
   219:     ]
   220:     for url in trials:
   221:         try:
   222:             payload = _http_get(url)
   223:             if isinstance(payload, dict) and "code" in payload and str(payload["code"]) != "00000" and "data" not in payload:
   224:                 raise RuntimeError(f"Bitget error {payload.get('code')}: {payload.get('msg')}")
   225:             rows = _normalize_http_rows(payload)
   226:             if rows:
   227:                 return _rows_to_df(rows)
   228:         except Exception as e:
   229:             _log(f"HTTP fail: {url} -> {e}")
   230:             continue
   231:     return None
   232: 
   233: # ============================================================================
   234: # API publique utilisée par l’orchestrateur/backtest
   235: # ============================================================================
   236: def fetch_ohlcv_best(symbol: str, timeframe: str, *, limit: int = 1000) -> pd.DataFrame:
   237:     """
   238:     Tente d’abord CCXT (si présent), sinon HTTP v1. Lève si tout échoue.
   239:     """
   240:     df = _fetch_via_ccxt(symbol, timeframe, limit=limit)
   241:     if df is not None:
   242:         _log(f"source=ccxt  n={len(df)}")
   243:         return df
   244:     df = _fetch_via_http(symbol, timeframe, limit=limit)
   245:     if df is not None:
   246:         _log(f"source=http  n={len(df)}")
   247:         return df
   248:     raise RuntimeError(f"Aucune source OHLCV pour {symbol} {timeframe}")
   249: 
   250: def hybrid_loader(
   251:     data_dir: str = "data",
   252:     *,
   253:     use_cache_first: bool = True,
   254:     min_rows: int = 100,
   255:     refill_if_stale: bool = True,
   256:     network_limit: int = 1000,
   257: ):
   258:     """
   259:     Loader smart :
   260:       1) si CSV présent ET frais/valide → le renvoie
   261:       2) sinon, si refill_if_stale → recharge (CCXT>HTTP) puis écrit CSV
   262:       3) sinon → lève
   263:     """
   264:     os.environ.setdefault("DATA_DIR", data_dir)
   265: 
   266:     def load(symbol: str, timeframe: str, start: str | None, end: str | None) -> pd.DataFrame:
   267:         path = _csv_path(symbol, timeframe)
   268: 
   269:         if use_cache_first:
   270:             ok, why = _is_csv_fresh_and_valid(path, timeframe, min_rows=min_rows)
   271:             if ok:
   272:                 _log(f"CSV OK: {path}")
   273:                 df = _read_csv(path)
   274:             else:
   275:                 _log(f"CSV non utilisable ({why}): {path}")
   276:                 if not refill_if_stale:
   277:                     raise RuntimeError(f"CSV invalide et recharge désactivée: {path} ({why})")
   278:                 df = fetch_ohlcv_best(symbol, timeframe, limit=network_limit)
   279:                 _write_csv(path, df)
   280:         else:
   281:             df = fetch_ohlcv_best(symbol, timeframe, limit=network_limit)
   282:             _write_csv(path, df)
   283: 
   284:         # Fenêtrage temporel si demandé (timestamps UTC)
   285:         if start:
   286:             df = df.loc[pd.Timestamp(start, tz="UTC") :]
   287:         if end:
   288:             df = df.loc[: pd.Timestamp(end, tz="UTC")]
   289:         return df
   290: 
   291:     return load

## scalper/backtest/metrics.py (last modified: 2025-08-23 20:57:14)
     1: from __future__ import annotations
     2: import math
     3: from dataclasses import dataclass
     4: from typing import List, Dict
     5: 
     6: @dataclass
     7: class Trade:
     8:     ts: int
     9:     side: str
    10:     entry: float
    11:     exit: float
    12:     pnl_abs: float
    13:     pnl_pct: float
    14:     dur_min: float
    15: 
    16: def equity_to_drawdown(equity: List[float]) -> float:
    17:     peak = -1e18; maxdd = 0.0
    18:     for v in equity:
    19:         if v > peak: peak = v
    20:         dd = 0.0 if peak == 0 else (peak - v) / peak
    21:         if dd > maxdd: maxdd = dd
    22:     return maxdd
    23: 
    24: def sharpe(returns: List[float], rf: float = 0.0, period_per_year: int = 365*24*12) -> float:
    25:     # returns: per-bar (ex: par 5m) log or simple; ici simple
    26:     if not returns: return 0.0
    27:     mean = sum(returns)/len(returns)
    28:     var = sum((r-mean)**2 for r in returns)/max(1, len(returns)-1)
    29:     std = math.sqrt(var) if var>0 else 0.0
    30:     if std == 0: return 0.0
    31:     return (mean - rf) / std * math.sqrt(period_per_year)
    32: 
    33: def summarize(trades: List[Trade], equity: List[float], bar_returns: List[float], start_ts: int, end_ts: int) -> Dict:
    34:     wins = [t for t in trades if t.pnl_abs > 0]
    35:     losses = [t for t in trades if t.pnl_abs < 0]
    36:     wr = len(wins)/len(trades) if trades else 0.0
    37:     gross_win = sum(t.pnl_abs for t in wins)
    38:     gross_loss = abs(sum(t.pnl_abs for t in losses))
    39:     pf = (gross_win / gross_loss) if gross_loss > 0 else float('inf') if gross_win > 0 else 0.0
    40:     mdd = equity_to_drawdown(equity)
    41:     shp = sharpe(bar_returns)
    42:     expectancy = (gross_win - gross_loss) / max(1, len(trades))
    43:     n_years = max(1e-9, (end_ts - start_ts) / (365*24*3600*1000))
    44:     cagr = (equity[-1]/equity[0])**(1/n_years) - 1 if equity and equity[0] > 0 else 0.0
    45:     score = (wr*0.2) + (min(pf,3.0)/3.0*0.3) + (max(0.0,1.0-mdd)*0.3) + (max(0.0, min(shp/3,1.0))*0.2)
    46:     return {
    47:         "trades": len(trades),
    48:         "winrate": wr, "pf": pf, "maxdd": mdd, "sharpe": shp,
    49:         "expectancy": expectancy, "cagr": cagr, "score": score,
    50:         "equity_start": equity[0] if equity else None,
    51:         "equity_end": equity[-1] if equity else None,
    52:     }

## scalper/backtest/optimize.py (last modified: 2025-08-23 20:57:14)
     1: from __future__ import annotations
     2: 
     3: """Parameter sweep utilities for strategy optimisation.
     4: 
     5: This module performs a grid search over a parameter space in parallel.  It
     6: tries to use :mod:`ray` for distributed execution when available and falls
     7: back to :mod:`multiprocessing` otherwise.
     8: """
     9: 
    10: import itertools
    11: import json
    12: import multiprocessing as mp
    13: import os
    14: from typing import Any, Dict, Iterable, List, Sequence
    15: 
    16: try:  # Optional dependency
    17:     import ray  # type: ignore
    18: except Exception:  # pragma: no cover - ray is optional
    19:     ray = None
    20: 
    21: from scalper.backtest import backtest_trades
    22: 
    23: 
    24: # ---------------------------------------------------------------------------
    25: # Parameter space
    26: # ---------------------------------------------------------------------------
    27: 
    28: def param_space_default() -> Dict[str, Sequence[Any]]:
    29:     """Return the default parameter search space.
    30: 
    31:     The keys correspond to strategy parameters while the values are iterables
    32:     of possible settings.  The defaults represent a small but representative
    33:     grid and can be overridden by callers.
    34:     """
    35: 
    36:     return {
    37:         "ema_fast": [10, 20, 30],
    38:         "ema_slow": [50, 100, 200],
    39:         "rsi_period": [14, 21],
    40:         "atr_period": [14, 21],
    41:     }
    42: 
    43: 
    44: def _param_grid(space: Dict[str, Iterable[Any]]) -> List[Dict[str, Any]]:
    45:     """Expand *space* into a list of parameter combinations."""
    46: 
    47:     keys = list(space)
    48:     values = [space[k] for k in keys]
    49:     return [dict(zip(keys, combo)) for combo in itertools.product(*values)]
    50: 
    51: 
    52: # ---------------------------------------------------------------------------
    53: # Evaluation
    54: # ---------------------------------------------------------------------------
    55: 
    56: def eval_params_one(grid_item: Dict[str, Any]) -> Dict[str, Any]:
    57:     """Run a backtest for a single parameter combination.
    58: 
    59:     ``grid_item`` contains the parameter values along with optional ``trades``
    60:     to evaluate.  The function returns a copy of the parameters augmented with
    61:     the computed PnL under the key ``pnl``.
    62:     """
    63: 
    64:     params = dict(grid_item)
    65:     trades = params.pop("trades", [])
    66:     fee_rate = params.pop("fee_rate", None)
    67:     pnl = backtest_trades(trades, fee_rate=fee_rate)
    68:     params["pnl"] = pnl
    69:     return params
    70: 
    71: 
    72: # ---------------------------------------------------------------------------
    73: # Orchestration
    74: # ---------------------------------------------------------------------------
    75: 
    76: def run_param_sweep(space: Dict[str, Iterable[Any]] | None = None, *, jobs: int | None = None) -> List[Dict[str, Any]]:
    77:     """Evaluate the full parameter grid in parallel and return results."""
    78: 
    79:     space = space or param_space_default()
    80:     grid = _param_grid(space)
    81: 
    82:     # Determine execution backend
    83:     use_ray = False
    84:     if ray is not None:
    85:         try:  # pragma: no cover - depends on ray
    86:             ray.init(ignore_reinit_error=True)
    87:             use_ray = True
    88:         except Exception:
    89:             use_ray = False
    90: 
    91:     if use_ray:
    92:         remote_eval = ray.remote(eval_params_one)  # type: ignore
    93:         futures = [remote_eval.remote(g) for g in grid]
    94:         results = ray.get(futures)
    95:     else:
    96:         jobs = jobs or int(os.getenv("OPT_JOBS", "0")) or mp.cpu_count()
    97:         with mp.Pool(processes=jobs) as pool:
    98:             results = pool.map(eval_params_one, grid)
    99: 
   100:     return results
   101: 
   102: 
   103: def optimize(space: Dict[str, Iterable[Any]] | None = None, *, outfile: str = "opt_results.json", jobs: int | None = None) -> List[Dict[str, Any]]:
   104:     """High level helper executing the sweep and saving aggregated results."""
   105: 
   106:     results = run_param_sweep(space, jobs=jobs)
   107:     with open(outfile, "w", encoding="utf8") as fh:
   108:         json.dump(results, fh, indent=2, sort_keys=True)
   109:     return results
   110: 
   111: 
   112: def main() -> None:  # pragma: no cover - convenience CLI
   113:     optimize()
   114: 
   115: 
   116: if __name__ == "__main__":  # pragma: no cover
   117:     main()


## scalper/backtest/run_multi.py (last modified: 2025-08-23 20:57:14)
     1: # annulé

## scalper/backtest/runner.py (last modified: 2025-08-23 20:57:14)
     1: # scalper/backtest/runner.py
     2: from __future__ import annotations
     3: 
     4: import json
     5: import math
     6: import os
     7: import time
     8: from dataclasses import dataclass, replace
     9: from pathlib import Path
    10: from typing import Dict, List, Tuple, Callable
    11: 
    12: from .cache import ensure_csv_cache, read_csv_ohlcv, csv_path, tf_to_seconds, dump_validation_report
    13: 
    14: # --------- Chargement de la stratégie ---------
    15: def load_signal_fn() -> Callable[[str, List[List[float]], float, float], Tuple[str, float]]:
    16:     try:
    17:         from scalper.signals.factory import load_signal  # type: ignore
    18:         name = os.getenv("STRATEGY", "current")
    19:         return load_signal(name)
    20:     except Exception:
    21:         def _fallback(symbol: str, ohlcv: List[List[float]], cash: float, risk_pct: float) -> Tuple[str, float]:
    22:             closes = [r[4] for r in (ohlcv[-10:] if len(ohlcv) >= 10 else ohlcv)]
    23:             if not closes:
    24:                 return "HOLD", 0.0
    25:             avg = sum(closes) / len(closes)
    26:             last = closes[-1]
    27:             if last > avg * 1.002:
    28:                 return "BUY", 1.0
    29:             if last < avg * 0.998:
    30:                 return "SELL", 1.0
    31:             return "HOLD", 0.0
    32:         return _fallback
    33: 
    34: # --------- Config ---------
    35: @dataclass
    36: class BTCfg:
    37:     symbols: List[str]
    38:     timeframe: str = "5m"
    39:     limit: int = 1500
    40:     cash: float = 10_000.0
    41:     risk_pct: float = 0.05
    42:     slippage_bps: float = 0.0
    43:     fee_bps: float = 6.0
    44:     data_dir: str = "data"
    45:     strategy: str = os.getenv("STRATEGY", "current")
    46: 
    47: # --------- Petit moteur PnL ---------
    48: def _bps(x: float) -> float: return x / 10_000.0
    49: 
    50: def simulate_symbol(ohlcv: List[List[float]], cfg: BTCfg, signal_fn: Callable) -> Tuple[List[Tuple[int,float]], Dict]:
    51:     equity = cfg.cash
    52:     position = 0.0
    53:     entry_price = 0.0
    54:     equity_curve: List[Tuple[int, float]] = []
    55:     trades = 0
    56: 
    57:     fee = _bps(cfg.fee_bps)
    58:     slip = _bps(cfg.slippage_bps)
    59: 
    60:     for i in range(1, len(ohlcv)):
    61:         window = ohlcv[: i+1]
    62:         ts, _, _, _, price, _ = ohlcv[i]
    63:         signal, strength = signal_fn("SYMBOL", window, equity, cfg.risk_pct)
    64: 
    65:         if position != 0:
    66:             equity += position * (price - ohlcv[i-1][4])
    67: 
    68:         target_pos = 0.0
    69:         if signal == "BUY":
    70:             notional = equity * cfg.risk_pct * strength
    71:             target_pos = max(0.0, notional / price)
    72:         elif signal == "SELL":
    73:             notional = equity * cfg.risk_pct * strength
    74:             target_pos = - max(0.0, notional / price)
    75: 
    76:         if target_pos != position:
    77:             delta = target_pos - position
    78:             if delta != 0:
    79:                 trades += 1
    80:                 trade_price = price * (1 + slip * (1 if delta > 0 else -1))
    81:                 equity -= abs(delta) * trade_price * fee
    82:                 position = target_pos
    83:                 entry_price = trade_price if position != 0 else 0.0
    84: 
    85:         equity_curve.append((ts, equity))
    86: 
    87:     if position != 0 and ohlcv:
    88:         last_price = ohlcv[-1][4]
    89:         equity += position * (last_price - entry_price)
    90:         equity -= abs(position) * last_price * fee
    91:         position = 0
    92: 
    93:     eq = [e for _, e in equity_curve]
    94:     ret_tot = (eq[-1] / eq[0] - 1.0) if len(eq) >= 2 else 0.0
    95:     max_dd = 0.0
    96:     peak = -1.0
    97:     for v in eq:
    98:         if v > peak: peak = v
    99:         dd = (peak - v) / peak if peak > 0 else 0.0
   100:         max_dd = max(max_dd, dd)
   101: 
   102:     tf_sec = tf_to_seconds(cfg.timeframe)
   103:     bpy = int((365.0 * 86400.0) / tf_sec)
   104:     rets = []
   105:     for i in range(1, len(eq)):
   106:         r = (eq[i] / eq[i-1]) - 1.0
   107:         rets.append(r)
   108:     if len(rets) > 1:
   109:         mu = sum(rets) / len(rets)
   110:         var = sum((x - mu) ** 2 for x in rets) / (len(rets) - 1)
   111:         std = math.sqrt(var) if var > 0 else 0.0
   112:         sharpe = (mu * bpy) / (std * math.sqrt(bpy)) if std > 0 else 0.0
   113:     else:
   114:         sharpe = 0.0
   115: 
   116:     metrics = {
   117:         "final_equity": round(eq[-1], 4) if eq else cfg.cash,
   118:         "total_return_pct": round(ret_tot * 100, 4),
   119:         "max_drawdown_pct": round(max_dd * 100, 4),
   120:         "sharpe_like": round(sharpe, 4),
   121:         "trades": trades,
   122:     }
   123:     return equity_curve, metrics
   124: 
   125: # --------- Runner principal ---------
   126: async def run_multi(cfg: BTCfg, exchange) -> Dict:
   127:     data = await ensure_csv_cache(exchange, cfg.symbols, cfg.timeframe, cfg.limit)
   128: 
   129:     signal_fn = load_signal_fn()
   130:     per_symbol: Dict[str, Dict] = {}
   131:     aligned_ts: List[int] = []
   132: 
   133:     sets_ts = []
   134:     for s in cfg.symbols:
   135:         rows = data.get(s) or read_csv_ohlcv(csv_path(s, cfg.timeframe))
   136:         sets_ts.append({r[0] for r in rows})
   137:     if sets_ts:
   138:         aligned_ts = sorted(list(set.intersection(*sets_ts)))
   139: 
   140:     results_curves: Dict[str, List[Tuple[int, float]]] = {}
   141:     for s in cfg.symbols:
   142:         rows = data.get(s) or read_csv_ohlcv(csv_path(s, cfg.timeframe))
   143:         rows = [r for r in rows if r[0] in set(aligned_ts)]
   144:         curve, metr = simulate_symbol(rows, cfg, signal_fn)
   145:         results_curves[s] = curve
   146:         per_symbol[s] = metr
   147: 
   148:     fused: List[Tuple[int, float]] = []
   149:     for i in range(len(aligned_ts)):
   150:         ts = aligned_ts[i]
   151:         vals = []
   152:         for s in cfg.symbols:
   153:             cv = results_curves[s]
   154:             if i < len(cv) and cv[i][0] == ts:
   155:                 vals.append(cv[i][1])
   156:         if vals:
   157:             fused.append((ts, sum(vals) / len(vals)))
   158: 
   159:     glob_metrics = {}
   160:     if fused:
   161:         eq = [e for _, e in fused]
   162:         ret_tot = (eq[-1]/eq[0]-1.0) if len(eq)>=2 else 0.0
   163:         peak = -1.0; max_dd = 0.0
   164:         for v in eq:
   165:             if v > peak: peak = v
   166:             dd = (peak - v) / peak if peak > 0 else 0.0
   167:             max_dd = max(max_dd, dd)
   168:         tf_sec = tf_to_seconds(cfg.timeframe)
   169:         bpy = int((365.0*86400.0)/tf_sec)
   170:         rets = []
   171:         for i in range(1, len(eq)):
   172:             rets.append((eq[i]/eq[i-1]) - 1.0)
   173:         if len(rets) > 1:
   174:             mu = sum(rets)/len(rets)
   175:             var = sum((x-mu)**2 for x in rets)/(len(rets)-1)
   176:             std = math.sqrt(var) if var>0 else 0.0
   177:             sharpe = (mu*bpy)/(std*math.sqrt(bpy)) if std>0 else 0.0
   178:         else:
   179:             sharpe = 0.0
   180:         glob_metrics = {
   181:             "final_equity": round(eq[-1], 4),
   182:             "total_return_pct": round(ret_tot*100, 4),
   183:             "max_drawdown_pct": round(max_dd*100, 4),
   184:             "sharpe_like": round(sharpe, 4),
   185:         }
   186: 
   187:     stamp = time.strftime("%Y%m%d-%H%M%S")
   188:     out_dir = Path(os.getenv("BACKTEST_OUT", f"result/backtest-{stamp}"))
   189:     out_dir.mkdir(parents=True, exist_ok=True)
   190: 
   191:     (out_dir / "equity_curve.csv").write_text(
   192:         "timestamp,equity\n" + "\n".join(f"{ts},{eq:.6f}" for ts, eq in fused)
   193:     )
   194:     all_metrics = {"global": glob_metrics, "per_symbol": per_symbol}
   195:     (out_dir / "metrics.json").write_text(json.dumps(all_metrics, indent=2))
   196:     dump_validation_report(cfg.symbols, cfg.timeframe, out_dir / "csv_validation.json")
   197: 
   198:     return {
   199:         "out_dir": str(out_dir),
   200:         "equity_curve": str(out_dir / "equity_curve.csv"),
   201:         "metrics": str(out_dir / "metrics.json"),
   202:         "csv_validation": str(out_dir / "csv_validation.json"),
   203:     }
   204: 
   205: # --------- Alias rétro-compatibilité ---------
   206: # Certains fichiers live importaient: BTConfig, run_single, save_results
   207: BTConfig = BTCfg  # alias
   208: 
   209: async def run_single(cfg: BTCfg, exchange, symbol: str | None = None) -> Dict:
   210:     """Compat : lance un backtest mono-symbole en réutilisant run_multi."""
   211:     if symbol:
   212:         cfg = replace(cfg, symbols=[symbol])
   213:     return await run_multi(cfg, exchange)
   214: 
   215: def save_results(res: Dict) -> Dict:
   216:     """Compat no-op : les fichiers sont déjà écrits par run_multi."""
   217:     return res
   218: 
   219: # --------- CLI ---------
   220: if __name__ == "__main__":
   221:     import asyncio
   222:     try:
   223:         import ccxt.async_support as ccxt  # type: ignore
   224:     except Exception:
   225:         raise SystemExit("Installe ccxt: pip install ccxt")
   226: 
   227:     symbols = os.getenv("SYMBOLS", "BTCUSDT,ETHUSDT").split(",")
   228:     cfg = BTCfg(
   229:         symbols=[s.strip().upper() for s in symbols if s.strip()],
   230:         timeframe=os.getenv("TF", "5m"),
   231:         limit=int(os.getenv("LIMIT", "1500")),
   232:         cash=float(os.getenv("CASH", "10000")),
   233:         risk_pct=float(os.getenv("RISK_PCT", "0.05")),
   234:         slippage_bps=float(os.getenv("SLIPPAGE_BPS", "0.0")),
   235:         fee_bps=float(os.getenv("FEE_BPS", "6.0")),
   236:     )
   237:     exchange = ccxt.bitget()
   238:     res = asyncio.run(run_multi(cfg, exchange))
   239:     print("Résultats écrits dans:", res["out_dir"])

## scalper/backtest/walkforward.py (last modified: 2025-08-23 20:57:14)
     1: from __future__ import annotations
     2: 
     3: from itertools import product
     4: from statistics import mean, stdev
     5: from typing import Dict, Iterable, Optional
     6: 
     7: from ..strategy import max_drawdown
     8: 
     9: 
    10: def _sharpe(returns: Iterable[float]) -> float:
    11:     vals = list(returns)
    12:     if not vals:
    13:         return 0.0
    14:     mu = mean(vals)
    15:     if len(vals) > 1:
    16:         sd = stdev(vals)
    17:     else:
    18:         sd = 0.0
    19:     return mu / sd if sd > 0 else 0.0
    20: 
    21: 
    22: def _stability(equity: Iterable[float]) -> float:
    23:     curve = list(equity)
    24:     n = len(curve)
    25:     if n < 2:
    26:         return 0.0
    27:     x = list(range(n))
    28:     x_mean = sum(x) / n
    29:     y_mean = sum(curve) / n
    30:     ss_tot = sum((y - y_mean) ** 2 for y in curve)
    31:     denom = sum((xi - x_mean) ** 2 for xi in x)
    32:     if denom == 0 or ss_tot == 0:
    33:         return 0.0
    34:     b = sum((xi - x_mean) * (yi - y_mean) for xi, yi in zip(x, curve)) / denom
    35:     a = y_mean - b * x_mean
    36:     ss_res = sum((yi - (a + b * xi)) ** 2 for xi, yi in zip(x, curve))
    37:     return 1 - ss_res / ss_tot
    38: 
    39: 
    40: def walk_forward(
    41:     df,
    42:     splits: int = 5,
    43:     train_ratio: float = 0.7,
    44:     params: Optional[Dict[str, Iterable]] = None,
    45: ) -> Dict[str, float]:
    46:     """Perform walk-forward optimisation and evaluation.
    47: 
    48:     Parameters
    49:     ----------
    50:     df:
    51:         DataFrame containing per-period percentage returns. The first column is
    52:         used when a dedicated ``"returns"`` column is not found.
    53:     splits:
    54:         Number of walk-forward test windows.
    55:     train_ratio:
    56:         Proportion of the data used for training in the initial window.
    57:     params:
    58:         Optional parameter grid. If provided, columns in ``df`` matching each
    59:         parameter combination are evaluated and the best Sharpe ratio on the
    60:         training window is selected. When ``None``, the first column is used.
    61:     """
    62: 
    63:     if df.empty:
    64:         return {"sharpe": 0.0, "mdd": 0.0, "pnl": 0.0, "stability": 0.0}
    65: 
    66:     returns_col = "returns" if "returns" in df.columns else df.columns[0]
    67:     data = df.copy()
    68: 
    69:     n = len(data)
    70:     train_len = max(1, int(n * train_ratio))
    71:     test_len = max(1, (n - train_len) // splits) if splits else max(1, n - train_len)
    72: 
    73:     sharpe_list = []
    74:     mdd_list = []
    75:     pnl_list = []
    76:     stability_list = []
    77: 
    78:     from . import walk_forward_windows
    79: 
    80:     indices = list(range(n))
    81: 
    82:     for tr_idx, te_idx in walk_forward_windows(indices, train_len, test_len):
    83:         train_df = data.iloc[tr_idx]
    84:         test_df = data.iloc[te_idx]
    85: 
    86:         # Parameter optimisation based on Sharpe ratio
    87:         if params:
    88:             best_col = None
    89:             best_score = float("-inf")
    90:             keys, values = zip(*params.items()) if params else ([], [])
    91:             for combo in product(*values):
    92:                 col_name = "_".join(f"{k}={v}" for k, v in zip(keys, combo))
    93:                 if col_name not in data.columns:
    94:                     continue
    95:                 score = _sharpe(train_df[col_name])
    96:                 if score > best_score:
    97:                     best_score = score
    98:                     best_col = col_name
    99:             series = test_df[best_col] if best_col else test_df[returns_col]
   100:         else:
   101:             series = test_df[returns_col]
   102: 
   103:         sharpe_list.append(_sharpe(series))
   104:         equity = (1 + series / 100.0).cumprod()
   105:         mdd_list.append(max_drawdown(equity))
   106:         pnl_list.append((equity.iloc[-1] - 1) * 100 if len(equity) else 0.0)
   107:         stability_list.append(_stability(equity))
   108: 
   109:     count = len(sharpe_list) or 1
   110:     mean_sharpe = sum(sharpe_list) / count
   111:     mean_mdd = sum(mdd_list) / count
   112:     mean_pnl = sum(pnl_list) / count
   113:     mean_stability = sum(stability_list) / count
   114: 
   115:     return {
   116:         "sharpe": mean_sharpe,
   117:         "mdd": mean_mdd,
   118:         "pnl": mean_pnl,
   119:         "stability": mean_stability,
   120:     }


## scalper/bitget_client.py (last modified: 2025-08-23 20:57:14)
     1: import json
     2: import logging
     3: import time
     4: import hmac
     5: import hashlib
     6: import base64
     7: import uuid
     8: from typing import Any, Dict, List, Optional
     9: 
    10: import requests
    11: 
    12: 
    13: # Mapping of deprecated v1 product type identifiers to the new v2 names
    14: _PRODUCT_TYPE_ALIASES = {
    15:     "UMCBL": "USDT-FUTURES",
    16:     "DMCBL": "USDC-FUTURES",
    17:     "CMCBL": "COIN-FUTURES",
    18: }
    19: 
    20: # Granularity aliases from v1 to v2 nomenclature
    21: _GRANULARITY_ALIASES = {
    22:     "MIN1": "1m",
    23:     "MIN3": "3m",
    24:     "MIN5": "5m",
    25:     "MIN15": "15m",
    26:     "MIN30": "30m",
    27:     "HOUR1": "1H",
    28:     "HOUR4": "4H",
    29:     "HOUR12": "12H",
    30:     "DAY1": "1D",
    31:     "WEEK1": "1W",
    32: }
    33: 
    34: 
    35: # Default margin coin for each product type. Some authenticated endpoints
    36: # require ``marginCoin`` in addition to ``productType``; supplying a sensible
    37: # default avoids ``400 Bad Request`` responses when the caller does not provide
    38: # it explicitly.
    39: _DEFAULT_MARGIN_COIN = {
    40:     "USDT-FUTURES": "USDT",
    41:     "USDC-FUTURES": "USDC",
    42: }
    43: 
    44: 
    45: class BitgetFuturesClient:
    46:     """Lightweight REST client for Bitget LAPI v2 futures endpoints."""
    47: 
    48:     def __init__(
    49:         self,
    50:         access_key: str,
    51:         secret_key: str,
    52:         base_url: str,
    53:         *,
    54:         product_type: str = "USDT-FUTURES",
    55:         recv_window: int = 30,
    56:         paper_trade: bool = True,
    57:         requests_module: Any = requests,
    58:         log_event: Optional[Any] = None,
    59:         passphrase: Optional[str] = None,
    60:     ) -> None:
    61:         self.ak = access_key
    62:         self.sk = secret_key
    63:         self.base = base_url.rstrip("/")
    64:         pt = product_type.upper()
    65:         self.product_type = _PRODUCT_TYPE_ALIASES.get(pt, pt)
    66:         self.recv_window = recv_window
    67:         self.paper_trade = paper_trade
    68:         self.requests = requests_module
    69:         self.log_event = log_event or (lambda *a, **k: None)
    70:         self.passphrase = passphrase
    71:         if not self.ak or not self.sk or self.ak == "A_METTRE" or self.sk == "B_METTRE":
    72:             logging.warning(
    73:                 "\u26a0\ufe0f Cl\u00e9s API non d\u00e9finies. Le mode r\u00e9el ne fonctionnera pas.",
    74:             )
    75:         # Cache for contract precision details to avoid repeated network calls
    76:         self._contract_cache: Dict[str, Dict[str, Any]] = {}
    77: 
    78:     # ------------------------------------------------------------------
    79:     # Helpers
    80:     # ------------------------------------------------------------------
    81:     @staticmethod
    82:     def _ms() -> int:
    83:         return int(time.time() * 1000)
    84: 
    85:     @staticmethod
    86:     def _urlencode_sorted(params: Dict[str, Any]) -> str:
    87:         if not params:
    88:             return ""
    89:         items = []
    90:         for k in sorted(params.keys()):
    91:             v = "" if params[k] is None else str(params[k])
    92:             items.append(f"{k}={v}")
    93:         return "&".join(items)
    94: 
    95:     def _sign(self, prehash: str) -> str:
    96:         """Return a base64-encoded HMAC SHA256 signature."""
    97:         digest = hmac.new(self.sk.encode(), prehash.encode(), hashlib.sha256).digest()
    98:         return base64.b64encode(digest).decode()
    99: 
   100:     def _headers(self, signature: str, timestamp: int) -> Dict[str, str]:
   101:         headers = {
   102:             "ACCESS-KEY": self.ak,
   103:             "ACCESS-SIGN": signature,
   104:             "ACCESS-TIMESTAMP": str(timestamp),
   105:             "ACCESS-RECV-WINDOW": str(self.recv_window),
   106:             "Content-Type": "application/json",
   107:         }
   108:         if self.passphrase:
   109:             headers["ACCESS-PASSPHRASE"] = self.passphrase
   110:         return headers
   111: 
   112:     def _format_symbol(self, symbol: str) -> str:
   113:         """Return ``symbol`` formatted for Bitget API.
   114: 
   115:         The v2 endpoints expect the trading pair without any product type
   116:         suffix (``BTCUSDT``). Older configurations may provide symbols like
   117:         ``BTC_USDT`` or ``BTCUSDT_UMCBL``; these are normalised by removing the
   118:         separators and any trailing product type string (legacy or v2).
   119:         """
   120: 
   121:         if not symbol:
   122:             return symbol
   123: 
   124:         sym = symbol.replace("_", "").upper()
   125:         # Strip product type suffix if present (e.g. BTCUSDTUMCBL)
   126:         if sym.endswith(self.product_type):
   127:             sym = sym[: -len(self.product_type)]
   128:         else:
   129:             for old in _PRODUCT_TYPE_ALIASES.keys():
   130:                 if sym.endswith(old):
   131:                     sym = sym[: -len(old)]
   132:                     break
   133:         return sym
   134: 
   135:     def _product_type(self, pt: Optional[str] = None) -> str:
   136:         """Normalise ``pt`` to a valid v2 product type identifier."""
   137:         key = (pt or self.product_type or "").upper()
   138:         return _PRODUCT_TYPE_ALIASES.get(key, key)
   139: 
   140:     # ------------------------------------------------------------------
   141:     # Public endpoints
   142:     # ------------------------------------------------------------------
   143:     def get_contract_detail(self, symbol: Optional[str] = None) -> Dict[str, Any]:
   144:         """Return futures contract information.
   145: 
   146:         The previous implementation queried ``/contract-detail`` which does not
   147:         exist on Bitget's v2 API and resulted in a 404 error.  The correct
   148:         endpoint is ``/contracts`` with the symbol supplied as a query
   149:         parameter."""
   150: 
   151:         url = f"{self.base}/api/v2/mix/market/contracts"
   152:         params: Dict[str, Any] = {"productType": self.product_type}
   153:         if symbol:
   154:             params["symbol"] = self._format_symbol(symbol)
   155:         r = self.requests.get(url, params=params, timeout=15)
   156:         if r.status_code == 404:  # pragma: no cover - depends on network
   157:             logging.error("Contract detail introuvable pour %s", symbol)
   158:             return {"success": False, "code": 404, "data": None}
   159:         r.raise_for_status()
   160:         return r.json()
   161: 
   162:     # ------------------------------------------------------------------
   163:     def _get_contract_precision(self, symbol: str) -> tuple[int, int]:
   164:         """Return price and volume precision for ``symbol``.
   165: 
   166:         Results are cached to minimise HTTP requests. If the contract
   167:         information cannot be retrieved, ``(0, 0)`` is returned.
   168:         """
   169:         sym = self._format_symbol(symbol)
   170:         info = self._contract_cache.get(sym)
   171:         if info is None:
   172:             detail = self.get_contract_detail(sym)
   173:             try:
   174:                 data = detail.get("data", [])
   175:                 if isinstance(data, list) and data:
   176:                     info = data[0]
   177:                 else:
   178:                     info = {}
   179:             except Exception:
   180:                 info = {}
   181:             self._contract_cache[sym] = info
   182:         price_place = int(info.get("pricePlace") or 0)
   183:         volume_place = int(info.get("volumePlace") or 0)
   184:         return price_place, volume_place
   185: 
   186:     def get_kline(
   187:         self,
   188:         symbol: str,
   189:         interval: str = "1m",
   190:         start: Optional[int] = None,
   191:         end: Optional[int] = None,
   192:     ) -> Dict[str, Any]:
   193:         # Endpoint expects the trading pair in query parameters rather than
   194:         # encoded in the path. Using ``/candles/{symbol}`` results in a 404
   195:         # response from Bitget. See: https://api.bitget.com/api/v2/mix/market/candles
   196:         url = f"{self.base}/api/v2/mix/market/candles"
   197:         interval_norm = _GRANULARITY_ALIASES.get(interval.replace("_", "").upper(), interval)
   198:         params: Dict[str, Any] = {
   199:             "symbol": self._format_symbol(symbol),
   200:             "productType": self.product_type,
   201:             "granularity": interval_norm,
   202:         }
   203:         if start is not None:
   204:             params["startTime"] = int(start)
   205:         if end is not None:
   206:             params["endTime"] = int(end)
   207:         r = self.requests.get(url, params=params, timeout=15)
   208:         r.raise_for_status()
   209:         data = r.json()
   210: 
   211:         rows = data.get("data") if isinstance(data, dict) else None
   212:         if isinstance(rows, list) and rows and isinstance(rows[0], list):
   213:             cols = {"ts": [], "open": [], "high": [], "low": [], "close": [], "volume": [], "quoteVolume": []}
   214:             for row in rows:
   215:                 if len(row) < 7:
   216:                     continue
   217:                 try:
   218:                     ts, op, hi, lo, cl, vol, qv = row[:7]
   219:                     cols["ts"].append(int(ts))
   220:                     cols["open"].append(float(op))
   221:                     cols["high"].append(float(hi))
   222:                     cols["low"].append(float(lo))
   223:                     cols["close"].append(float(cl))
   224:                     cols["volume"].append(float(vol))
   225:                     cols["quoteVolume"].append(float(qv))
   226:                 except (TypeError, ValueError):
   227:                     continue
   228:             data["data"] = cols
   229:         elif isinstance(rows, list):
   230:             data["data"] = {"ts": [], "open": [], "high": [], "low": [], "close": [], "volume": [], "quoteVolume": []}
   231:         return data
   232: 
   233:     def get_ticker(self, symbol: Optional[str] = None) -> Dict[str, Any]:
   234:         if symbol:
   235:             url = f"{self.base}/api/v2/mix/market/ticker"
   236:             params = {
   237:                 "symbol": self._format_symbol(symbol),
   238:                 "productType": self.product_type,
   239:             }
   240:         else:
   241:             url = f"{self.base}/api/v2/mix/market/tickers"
   242:             params = {"productType": self.product_type}
   243:         r = self.requests.get(url, params=params, timeout=15)
   244:         r.raise_for_status()
   245:         return r.json()
   246: 
   247:     # ------------------------------------------------------------------
   248:     # Private endpoints
   249:     # ------------------------------------------------------------------
   250:     def _private_request(
   251:         self,
   252:         method: str,
   253:         path: str,
   254:         *,
   255:         params: Optional[Dict[str, Any]] = None,
   256:         body: Optional[Dict[str, Any]] = None,
   257:     ) -> Dict[str, Any]:
   258:         method = method.upper()
   259:         ts = self._ms()
   260: 
   261:         if method in ("GET", "DELETE"):
   262:             qs = self._urlencode_sorted(params or {})
   263:             req_path = path + (f"?{qs}" if qs else "")
   264:             sig = self._sign(f"{ts}{method}{req_path}")
   265:             headers = self._headers(sig, ts)
   266:             url = f"{self.base}{req_path}"
   267:             r = self.requests.request(method, url, headers=headers, timeout=20)
   268:         elif method == "POST":
   269:             qs = self._urlencode_sorted(params or {})
   270:             req_path = path + (f"?{qs}" if qs else "")
   271:             body_str = json.dumps(body or {}, separators=(",", ":"), ensure_ascii=False)
   272:             sig = self._sign(f"{ts}{method}{req_path}{body_str}")
   273:             headers = self._headers(sig, ts)
   274:             url = f"{self.base}{req_path}"
   275:             r = self.requests.post(
   276:                 url,
   277:                 data=body_str.encode("utf-8"),
   278:                 headers=headers,
   279:                 timeout=20,
   280:             )
   281:         else:
   282:             raise ValueError("M\u00e9thode non support\u00e9e")
   283: 
   284:         resp_text = getattr(r, "text", "")
   285:         try:
   286:             data = r.json()
   287:         except Exception:
   288:             data = {
   289:                 "success": False,
   290:                 "error": resp_text,
   291:                 "status_code": getattr(r, "status_code", None),
   292:             }
   293: 
   294:         status = getattr(r, "status_code", 0)
   295:         if status >= 400:
   296:             code = str(data.get("code")) if isinstance(data, dict) else ""
   297:             if code == "22001":
   298:                 logging.info("Aucun ordre à annuler (%s %s)", method, path)
   299:             else:
   300:                 try:
   301:                     r.raise_for_status()
   302:                 except Exception as e:
   303:                     if not resp_text:
   304:                         resp_text = getattr(r, "text", "") or str(e)
   305:                 logging.error(
   306:                     "Erreur HTTP/JSON %s %s -> %s %s",
   307:                     method,
   308:                     path,
   309:                     status,
   310:                     resp_text,
   311:                 )
   312:                 if isinstance(data, dict):
   313:                     data.setdefault("success", False)
   314:                     data.setdefault("status_code", status)
   315:                     data.setdefault("error", resp_text)
   316: 
   317:         self.log_event(
   318:             "http_private",
   319:             {"method": method, "path": path, "params": params, "body": body, "response": data},
   320:         )
   321:         return data
   322: 
   323:     # Accounts & positions -------------------------------------------------
   324:     def get_assets(self, margin_coin: Optional[str] = None) -> Dict[str, Any]:
   325:         if self.paper_trade:
   326:             return {
   327:                 "success": True,
   328:                 "code": 0,
   329:                 "data": [
   330:                     {
   331:                         "currency": "USDT",
   332:                         "equity": 100.0,
   333:                     }
   334:                 ],
   335:             }
   336: 
   337:         params = {"productType": self.product_type}
   338:         if margin_coin is None:
   339:             margin_coin = _DEFAULT_MARGIN_COIN.get(self.product_type)
   340:         if margin_coin:
   341:             params["marginCoin"] = margin_coin
   342:         data = self._private_request(
   343:             "GET", "/api/v2/mix/account/accounts", params=params
   344:         )
   345:         if isinstance(data, dict):
   346:             data.setdefault("success", str(data.get("code")) == "00000")
   347:         try:
   348:             for row in data.get("data", []):
   349:                 if "currency" not in row and row.get("marginCoin"):
   350:                     row["currency"] = str(row["marginCoin"]).upper()
   351:                 chosen = None
   352:                 for key in ("available", "cashBalance", "equity", "usdtEquity"):
   353:                     val = row.get(key)
   354:                     if val is not None:
   355:                         chosen = val
   356:                         break
   357:                 if chosen is not None:
   358:                     row["equity"] = chosen
   359:                 try:
   360:                     row["equity"] = float(row["equity"])
   361:                 except Exception:
   362:                     pass
   363:         except Exception:  # pragma: no cover - best effort
   364:             pass
   365:         return data
   366: 
   367:     def get_positions(self, product_type: Optional[str] = None) -> Dict[str, Any]:
   368:         if self.paper_trade:
   369:             return {"success": True, "code": 0, "data": []}
   370:         data = self._private_request(
   371:             "GET",
   372:             "/api/v2/mix/position/all-position",
   373:             params={"productType": self._product_type(product_type)},
   374:         )
   375:         try:
   376:             positions = data.get("data", [])
   377:             filtered = []
   378:             for pos in positions:
   379:                 vol = pos.get("vol")
   380:                 try:
   381:                     if vol is not None and float(vol) > 0:
   382:                         filtered.append(pos)
   383:                 except (TypeError, ValueError):
   384:                     continue
   385:             data["data"] = filtered
   386:         except Exception:  # pragma: no cover - best effort
   387:             pass
   388:         return data
   389: 
   390:     def get_open_orders(self, symbol: Optional[str] = None) -> Dict[str, Any]:
   391:         if self.paper_trade:
   392:             return {"success": True, "code": 0, "data": []}
   393:         params: Dict[str, Any] = {"productType": self.product_type}
   394:         if symbol:
   395:             params["symbol"] = self._format_symbol(symbol)
   396:         return self._private_request("GET", "/api/v2/mix/order/orders-pending", params=params)
   397: 
   398:     # Account configuration -------------------------------------------------
   399:     def set_position_mode_one_way(self, symbol: str, product_type: Optional[str] = None) -> Dict[str, Any]:
   400:         body = {
   401:             "productType": self._product_type(product_type),
   402:             "symbol": self._format_symbol(symbol),
   403:             "posMode": "one_way_mode",
   404:         }
   405:         return self._private_request("POST", "/api/v2/mix/account/set-position-mode", body=body)
   406: 
   407:     def set_leverage(
   408:         self,
   409:         symbol: str,
   410:         product_type: Optional[str] = None,
   411:         margin_coin: str = "USDT",
   412:         leverage: int = 1,
   413:     ) -> Dict[str, Any]:
   414:         body = {
   415:             "symbol": self._format_symbol(symbol),
   416:             "productType": self._product_type(product_type),
   417:             "marginCoin": margin_coin,
   418:             "leverage": int(leverage),
   419:         }
   420:         return self._private_request(
   421:             "POST", "/api/v2/mix/account/set-leverage", body=body
   422:         )
   423: 
   424:     def place_market_order_one_way(
   425:         self,
   426:         symbol: str,
   427:         side: str,
   428:         size: float,
   429:         product_type: Optional[str] = None,
   430:         margin_coin: str = "USDT",
   431:         *,
   432:         time_in_force: str = "normal",
   433:     ) -> Dict[str, Any]:
   434:         side = side.lower()
   435:         if side not in {"buy", "sell"}:
   436:             raise ValueError("side must be 'buy' or 'sell'")
   437:         body = {
   438:             "symbol": self._format_symbol(symbol),
   439:             "productType": self._product_type(product_type),
   440:             "marginCoin": margin_coin,
   441:             "marginMode": "crossed",
   442:             "posMode": "one_way_mode",
   443:             "orderType": "market",
   444:             "side": side,
   445:             "size": str(size),
   446:             "timeInForceValue": time_in_force,
   447:             "clientOid": str(uuid.uuid4())[:32],
   448:         }
   449:         return self._private_request(
   450:             "POST", "/api/v2/mix/order/place-order", body=body
   451:         )
   452: 
   453:     # Orders ---------------------------------------------------------------
   454:     def place_order(
   455:         self,
   456:         symbol: str,
   457:         side: int,
   458:         vol: int,
   459:         order_type: int,
   460:         *,
   461:         price: Optional[float] = None,
   462:         open_type: int = 1,
   463:         leverage: Optional[int] = None,
   464:         position_id: Optional[int] = None,
   465:         external_oid: Optional[str] = None,
   466:         stop_loss: Optional[float] = None,
   467:         take_profit: Optional[float] = None,
   468:         position_mode: Optional[int] = None,
   469:         margin_coin: Optional[str] = None,
   470:         time_in_force: str = "normal",
   471:     ) -> Dict[str, Any]:
   472:         """Submit an order.
   473: 
   474:         This helper keeps backward compatibility with the older numeric
   475:         parameters used by the bot while translating them to the string based
   476:         fields required by Bitget's v2 API.
   477:         """
   478:         if self.paper_trade:
   479:             logging.info(
   480:                 "PAPER_TRADE=True -> ordre simul\u00e9: side=%s vol=%s type=%s price=%s",
   481:                 side,
   482:                 vol,
   483:                 order_type,
   484:                 price,
   485:             )
   486:             return {
   487:                 "success": True,
   488:                 "paperTrade": True,
   489:                 "simulated": {
   490:                     "symbol": symbol,
   491:                     "side": side,
   492:                     "vol": vol,
   493:                     "type": order_type,
   494:                     "price": price,
   495:                     "openType": open_type,
   496:                     "leverage": leverage,
   497:                     "stopLossPrice": stop_loss,
   498:                     "takeProfitPrice": take_profit,
   499:                 },
   500:             }
   501: 
   502:         # ------------------------------------------------------------------
   503:         # Parameter mapping
   504:         # ------------------------------------------------------------------
   505:         side_map = {
   506:             1: ("buy", "long"),
   507:             2: ("buy", "short"),
   508:             3: ("sell", "short"),
   509:             4: ("sell", "long"),
   510:         }
   511:         if isinstance(side, int):
   512:             mapped = side_map.get(side)
   513:             if not mapped:
   514:                 raise ValueError(f"Invalid side value: {side}")
   515:             side_str, pos_side = mapped
   516:         else:
   517:             side_str = str(side)
   518:             pos_side = None
   519: 
   520:         order_map = {1: "market", 2: "limit", 3: "post_only", 4: "fok", 5: "limit"}
   521:         if isinstance(order_type, int):
   522:             order_str = order_map.get(order_type)
   523:             if order_str is None:
   524:                 order_str = "limit" if price is not None else "market"
   525:         else:
   526:             order_str = str(order_type)
   527: 
   528:         margin_mode = "crossed" if int(open_type) == 1 else "isolated"
   529: 
   530:         if margin_coin is None:
   531:             margin_coin = _DEFAULT_MARGIN_COIN.get(self.product_type)
   532: 
   533:         # ------------------------------------------------------------------
   534:         # Precision handling
   535:         # ------------------------------------------------------------------
   536:         try:
   537:             price_place, volume_place = self._get_contract_precision(symbol)
   538:         except Exception:  # pragma: no cover - best effort
   539:             price_place = volume_place = 0
   540:         if price is not None:
   541:             price = round(float(price), price_place)
   542:         if vol is not None:
   543:             vol = round(float(vol), volume_place)
   544: 
   545:         body = {
   546:             "symbol": self._format_symbol(symbol),
   547:             "productType": self.product_type,
   548:             "marginMode": margin_mode,
   549:             "orderType": order_str,
   550:             "side": side_str,
   551:             "size": vol,
   552:             "timeInForceValue": time_in_force,
   553:         }
   554:         if pos_side is not None:
   555:             body["posSide"] = pos_side
   556:         if margin_coin:
   557:             body["marginCoin"] = margin_coin
   558:         if price is not None:
   559:             body["price"] = float(price)
   560:         if leverage is not None:
   561:             body["leverage"] = int(leverage)
   562:         if position_id is not None:
   563:             body["positionId"] = int(position_id)
   564:         if external_oid:
   565:             body["clientOid"] = str(external_oid)[:32]
   566:         else:
   567:             body["clientOid"] = str(uuid.uuid4())[:32]
   568:         if stop_loss is not None:
   569:             body["stopLossPrice"] = float(stop_loss)
   570:         if take_profit is not None:
   571:             body["takeProfitPrice"] = float(take_profit)
   572:         if position_mode is not None:
   573:             body["posMode"] = "one_way_mode" if int(position_mode) == 1 else "hedge_mode"
   574:         elif pos_side is not None:
   575:             body["posMode"] = "hedge_mode"
   576: 
   577:         return self._private_request("POST", "/api/v2/mix/order/place-order", body=body)
   578: 
   579:     def cancel_order(self, order_ids: List[int]) -> Dict[str, Any]:
   580:         if self.paper_trade:
   581:             logging.info(
   582:                 "PAPER_TRADE=True -> annulation simulée: order_ids=%s", order_ids
   583:             )
   584:             return {"success": True, "code": 0}
   585:         return self._private_request(
   586:             "POST", "/api/v2/mix/order/cancel-order", body={"orderIds": order_ids}
   587:         )
   588: 
   589:     def cancel_all(
   590:         self,
   591:         symbol: Optional[str] = None,
   592:         margin_coin: Optional[str] = None,
   593:     ) -> Dict[str, Any]:
   594:         if self.paper_trade:
   595:             logging.info(
   596:                 "PAPER_TRADE=True -> annulation simulée de tous les ordres"
   597:             )
   598:             return {"success": True, "code": 0}
   599:         body = {"productType": self.product_type}
   600:         if symbol:
   601:             body["symbol"] = self._format_symbol(symbol)
   602:         if margin_coin is None:
   603:             margin_coin = _DEFAULT_MARGIN_COIN.get(self.product_type)
   604:         if margin_coin:
   605:             body["marginCoin"] = margin_coin
   606:         return self._private_request(
   607:             "POST", "/api/v2/mix/order/cancel-all-orders", body=body
   608:         )
   609: 
   610:     def close_position(
   611:         self,
   612:         symbol: str,
   613:         size: Optional[int] = None,
   614:         hold_side: Optional[str] = None,
   615:     ) -> Dict[str, Any]:
   616:         """Close an open position for ``symbol``.
   617: 
   618:         Parameters
   619:         ----------
   620:         symbol:
   621:             Trading symbol to close.
   622:         size:
   623:             Optional number of contracts to close. If omitted the entire
   624:             position is closed.
   625:         hold_side:
   626:             Optional side (``"long"``/``"short"``) to close when ``size`` is
   627:             specified. If not provided the exchange will infer it.
   628:         """
   629: 
   630:         if self.paper_trade:
   631:             logging.info(
   632:                 "PAPER_TRADE=True -> fermeture simulée de la position %s", symbol
   633:             )
   634:             return {"success": True, "code": 0}
   635: 
   636:         body = {"symbol": self._format_symbol(symbol)}
   637:         if size is not None:
   638:             body["size"] = int(size)
   639:         if hold_side:
   640:             body["holdSide"] = hold_side
   641: 
   642:         body["productType"] = self.product_type
   643:         return self._private_request(
   644:             "POST", "/api/v2/mix/position/close-position", body=body
   645:         )
   646: 
   647:     def close_all_positions(self, product_type: Optional[str] = None) -> Dict[str, Any]:
   648:         """Close all open positions."""
   649:         results = []
   650:         try:
   651:             for pos in self.get_positions(product_type).get("data", []):
   652:                 sym = pos.get("symbol")
   653:                 if sym:
   654:                     results.append(self.close_position(sym))
   655:         except Exception as exc:  # pragma: no cover - best effort
   656:             logging.error("Erreur fermeture de toutes les positions: %s", exc)
   657:         return {"success": True, "data": results}


## scalper/client.py (last modified: 2025-08-23 20:57:14)
     1: import logging
     2: from typing import Any, Dict, Optional
     3: 
     4: import requests
     5: from requests.adapters import HTTPAdapter
     6: from urllib3.util.retry import Retry
     7: 
     8: 
     9: class HTTPError(RuntimeError):
    10:     """Raised when an HTTP request fails"""
    11: 
    12: 
    13: class HttpClient:
    14:     """Simple HTTP client with persistent session and retry logic.
    15: 
    16:     The client exposes a :py:meth:`close` method and implements the context
    17:     manager protocol so it can be used with ``with`` statements to ensure
    18:     that the underlying :class:`requests.Session` is properly closed.
    19:     """
    20: 
    21:     def __init__(
    22:         self,
    23:         base_url: str,
    24:         *,
    25:         timeout: float = 10.0,
    26:         max_retries: int = 3,
    27:         backoff_factor: float = 0.3,
    28:         status_forcelist: Optional[list[int]] = None,
    29:     ) -> None:
    30:         self.base_url = base_url.rstrip("/")
    31:         self.timeout = timeout
    32:         self.session = requests.Session()
    33:         retry = Retry(
    34:             total=max_retries,
    35:             backoff_factor=backoff_factor,
    36:             status_forcelist=status_forcelist or [429, 500, 502, 503, 504],
    37:             allowed_methods=[
    38:                 "HEAD",
    39:                 "GET",
    40:                 "OPTIONS",
    41:                 "POST",
    42:                 "PUT",
    43:                 "DELETE",
    44:                 "PATCH",
    45:             ],
    46:         )
    47:         adapter = HTTPAdapter(max_retries=retry)
    48:         self.session.mount("http://", adapter)
    49:         self.session.mount("https://", adapter)
    50: 
    51:     def close(self) -> None:
    52:         """Close the underlying :class:`requests.Session`."""
    53:         self.session.close()
    54: 
    55:     # ------------------------------------------------------------------
    56:     # Context manager support
    57:     # ------------------------------------------------------------------
    58:     def __enter__(self) -> "HttpClient":
    59:         return self
    60: 
    61:     def __exit__(self, exc_type, exc, tb) -> None:  # type: ignore[override]
    62:         self.close()
    63: 
    64:     def request(
    65:         self,
    66:         method: str,
    67:         path: str,
    68:         *,
    69:         params: Optional[Dict[str, Any]] = None,
    70:         json: Optional[Dict[str, Any]] = None,
    71:         headers: Optional[Dict[str, str]] = None,
    72:     ) -> Dict[str, Any]:
    73:         """Perform an HTTP request and return JSON data.
    74: 
    75:         Errors during the request raise ``HTTPError``. If the response cannot
    76:         be decoded as JSON, a dictionary describing the issue is returned.
    77:         """
    78:         url = f"{self.base_url}{path}"
    79:         try:
    80:             resp = self.session.request(
    81:                 method,
    82:                 url,
    83:                 params=params,
    84:                 json=json,
    85:                 headers=headers,
    86:                 timeout=self.timeout,
    87:             )
    88:             resp.raise_for_status()
    89:         except requests.RequestException as exc:  # network or HTTP errors
    90:             msg = f"HTTP error calling {url}: {exc}"
    91:             logging.error(msg)
    92:             raise HTTPError(msg) from exc
    93: 
    94:         try:
    95:             return resp.json()
    96:         except ValueError:  # invalid JSON
    97:             msg = "Invalid JSON in response"
    98:             logging.error("%s for %s: %s", msg, url, resp.text)
    99:             return {"success": False, "error": msg, "text": resp.text}


## scalper/config/__init__.py (last modified: 2025-08-23 20:57:14)
     1: from .loader import load_settings
     2: __all__ = ['load_settings']


## scalper/config/loader.py (last modified: 2025-08-23 20:57:14)
     1: # scalp/config/loader.py
     2: from __future__ import annotations
     3: import os, json
     4: from typing import Any, Dict, Tuple
     5: 
     6: # YAML est recommandé, mais on fallback proprement si PyYAML n'est pas installé
     7: try:
     8:     import yaml  # type: ignore
     9: except Exception:
    10:     yaml = None  # fallback JSON si besoin
    11: 
    12: # dotenv (facultatif) pour charger un .env automatiquement
    13: try:
    14:     from dotenv import load_dotenv  # type: ignore
    15: except Exception:
    16:     load_dotenv = None
    17: 
    18: # ---------------- Utils ----------------
    19: 
    20: def _parse_bool(x: Any, default: bool = False) -> bool:
    21:     if isinstance(x, bool): return x
    22:     s = str(x).strip().lower()
    23:     if s in ("1","true","yes","y","on"): return True
    24:     if s in ("0","false","no","n","off",""): return False
    25:     return default
    26: 
    27: def _parse_float(x: Any, default: float | None = None) -> float | None:
    28:     try: return float(x)
    29:     except Exception: return default
    30: 
    31: def _parse_int(x: Any, default: int | None = None) -> int | None:
    32:     try: return int(str(x).strip())
    33:     except Exception: return default
    34: 
    35: def _parse_csv(x: Any) -> list[str]:
    36:     if x is None: return []
    37:     if isinstance(x, (list, tuple)): return [str(v).strip() for v in x if str(v).strip()]
    38:     return [t.strip() for t in str(x).replace(" ", "").split(",") if t.strip()]
    39: 
    40: def _read_yaml(path: str) -> Dict[str, Any]:
    41:     if not os.path.exists(path): return {}
    42:     with open(path, "r", encoding="utf-8") as f:
    43:         if yaml:
    44:             return yaml.safe_load(f) or {}
    45:         # fallback JSON si quelqu’un met du JSON dans config.yml (rare mais safe)
    46:         try:
    47:             return json.load(f)
    48:         except Exception:
    49:             raise RuntimeError(f"Impossible de lire {path}: installe PyYAML (`pip install pyyaml`) ou fournis du JSON valide.")
    50: 
    51: def _merge_dict(a: Dict[str, Any], b: Dict[str, Any]) -> Dict[str, Any]:
    52:     # shallow merge suffisant ici (structure plate)
    53:     out = dict(a)
    54:     out.update({k: v for k, v in b.items() if v is not None})
    55:     return out
    56: 
    57: # ---------------- Public API ----------------
    58: 
    59: def load_settings(
    60:     config_path: str = "config.yml",
    61:     config_local_path: str = "config.local.yml",
    62: ) -> Tuple[Dict[str, Any], Dict[str, Any]]:
    63:     """
    64:     Retourne (config_runtime, secrets) :
    65:       - config_runtime : paramètres de stratégie / exécution (OK pour versionner)
    66:       - secrets        : clés API & tokens (NE PAS versionner)
    67:     Priorité : config.yml < config.local.yml < ENV (non sensibles)
    68:     Secrets proviennent EXCLUSIVEMENT de l'ENV (.env)
    69:     """
    70:     # 1) .env (pour secrets & env non sensibles). Faculatif.
    71:     if load_dotenv is not None:
    72:         load_dotenv(override=False)
    73: 
    74:     # 2) Charge YAML (config.yml + override local)
    75:     base = _read_yaml(config_path)
    76:     local = _read_yaml(config_local_path)
    77:     cfg = _merge_dict(base, local)
    78: 
    79:     # 3) Overlay ENV **non sensibles** (permet de surcharger sans toucher au YAML)
    80:     env_overlay: Dict[str, Any] = {}
    81:     # Verbosité
    82:     env_overlay["QUIET"] = _parse_bool(os.getenv("QUIET", cfg.get("QUIET", 0)), bool(cfg.get("QUIET", 0)))
    83:     env_overlay["PRINT_OHLCV_SAMPLE"] = _parse_bool(os.getenv("PRINT_OHLCV_SAMPLE", cfg.get("PRINT_OHLCV_SAMPLE", 0)),
    84:                                                     bool(cfg.get("PRINT_OHLCV_SAMPLE", 0)))
    85:     # Runtime / Stratégie
    86:     env_overlay["TIMEFRAME"] = os.getenv("TIMEFRAME", cfg.get("TIMEFRAME", "5m"))
    87:     env_overlay["CASH"] = _parse_float(os.getenv("CASH", cfg.get("CASH", 10000)), cfg.get("CASH", 10000))
    88:     env_overlay["RISK_PCT"] = _parse_float(os.getenv("RISK_PCT", cfg.get("RISK_PCT", 0.5)), cfg.get("RISK_PCT", 0.5))
    89:     env_overlay["SLIPPAGE_BPS"] = _parse_float(os.getenv("SLIPPAGE_BPS", cfg.get("SLIPPAGE_BPS", 0)), cfg.get("SLIPPAGE_BPS", 0))
    90:     # Watchlist
    91:     env_overlay["WATCHLIST_MODE"] = os.getenv("WATCHLIST_MODE", cfg.get("WATCHLIST_MODE", "static"))
    92:     env_overlay["WATCHLIST_LOCAL_CONC"] = _parse_int(
    93:         os.getenv("WATCHLIST_LOCAL_CONC", cfg.get("WATCHLIST_LOCAL_CONC", 4)), cfg.get("WATCHLIST_LOCAL_CONC", 4)
    94:     )
    95:     env_overlay["TOP_SYMBOLS"] = _parse_csv(os.getenv("TOP_SYMBOLS", cfg.get("TOP_SYMBOLS")))
    96:     env_overlay["TOP_CANDIDATES"] = _parse_csv(os.getenv("TOP_CANDIDATES", cfg.get("TOP_CANDIDATES")))
    97:     # Caps (optionnel) : on accepte YAML (dict) ou ENV JSON
    98:     caps_env = os.getenv("CAPS_JSON")
    99:     if caps_env:
   100:         try:
   101:             env_overlay["CAPS"] = json.loads(caps_env)
   102:         except Exception:
   103:             env_overlay["CAPS"] = cfg.get("CAPS", {})
   104:     else:
   105:         env_overlay["CAPS"] = cfg.get("CAPS", {})
   106: 
   107:     # 4) Secrets UNIQUEMENT via ENV (jamais via YAML)
   108:     secrets = {
   109:         "BITGET_API_KEY": os.getenv("BITGET_API_KEY", ""),
   110:         "BITGET_API_SECRET": os.getenv("BITGET_API_SECRET", ""),
   111:         "BITGET_API_PASSWORD": os.getenv("BITGET_API_PASSWORD", ""),
   112:         "BITGET_USE_TESTNET": _parse_bool(os.getenv("BITGET_USE_TESTNET", os.getenv("BITGET_TESTNET", "1")), True),
   113:         "BITGET_PRODUCT": os.getenv("BITGET_PRODUCT", "umcbl"),
   114:         "TELEGRAM_BOT_TOKEN": os.getenv("TELEGRAM_BOT_TOKEN", ""),
   115:         "TELEGRAM_CHAT_ID": os.getenv("TELEGRAM_CHAT_ID", ""),
   116:     }
   117: 
   118:     # 5) Runtime normalisé pour l’orchestrateur
   119:     runtime = {
   120:         "quiet": bool(env_overlay["QUIET"]),
   121:         "print_sample": bool(env_overlay["PRINT_OHLCV_SAMPLE"]),
   122:         "timeframe": str(env_overlay["TIMEFRAME"]),
   123:         "cash": float(env_overlay["CASH"]),
   124:         "risk_pct": float(env_overlay["RISK_PCT"]),
   125:         "slippage_bps": float(env_overlay["SLIPPAGE_BPS"]),
   126:         "watchlist_mode": str(env_overlay["WATCHLIST_MODE"]),
   127:         "watchlist_local_conc": int(env_overlay["WATCHLIST_LOCAL_CONC"]),
   128:         "top_symbols": env_overlay["TOP_SYMBOLS"],          # list[str]
   129:         "top_candidates": env_overlay["TOP_CANDIDATES"],    # list[str]
   130:         "caps": env_overlay["CAPS"],                        # dict
   131:         # rempli au boot par les frais Bitget
   132:         "fees_by_symbol": {}, 
   133:     }
   134: 
   135:     return runtime, secrets
   136:     

## scalper/exchange/__init__.py (last modified: 2025-08-23 20:57:14)
     1: # package


## scalper/exchange/bitget_ccxt.py (last modified: 2025-08-23 20:57:14)
     1: # scalper/exchange/bitget_ccxt.py
     2: from __future__ import annotations
     3: 
     4: import asyncio
     5: import csv
     6: import os
     7: import time
     8: from typing import Any, List, Optional
     9: 
    10: # CCXT async
    11: try:
    12:     import ccxt.async_support as ccxt
    13: except Exception as e:  # noqa: BLE001
    14:     raise RuntimeError("CCXT n'est pas installé. Fais `pip install ccxt`.") from e
    15: 
    16: 
    17: def _now_ms() -> int:
    18:     return int(time.time() * 1000)
    19: 
    20: 
    21: class BitgetExchange:
    22:     """
    23:     Échange Bitget via CCXT (async) avec cache CSV local.
    24:     - Orienté SPOT pour simplifier (BTCUSDT, ETHUSDT, ...).
    25:     - fetch_ohlcv(symbol, timeframe, limit) -> list[list] façon CCXT:
    26:         [[ts, open, high, low, close, volume], ...]
    27:     """
    28: 
    29:     def __init__(
    30:         self,
    31:         *,
    32:         api_key: Optional[str] = None,
    33:         secret: Optional[str] = None,
    34:         password: Optional[str] = None,  # Bitget a souvent "password" (API passphrase)
    35:         data_dir: str = "/notebooks/data",
    36:         use_cache: bool = True,
    37:         min_fresh_seconds: int = 0,  # fraicheur minimale requise (0 = on accepte tout)
    38:         spot: bool = True,           # True = SPOT (recommandé ici)
    39:     ) -> None:
    40:         self.data_dir = data_dir
    41:         self.use_cache = use_cache
    42:         self.min_fresh = int(min_fresh_seconds)
    43:         self.spot = spot
    44: 
    45:         os.makedirs(self.data_dir, exist_ok=True)
    46: 
    47:         # Instance CCXT (async)
    48:         self.ex = ccxt.bitget({
    49:             "apiKey": api_key or "",
    50:             "secret": secret or "",
    51:             "password": password or "",
    52:             "enableRateLimit": True,
    53:             # CCXT timeframe natif (pas besoin de rajouter des headers…)
    54:         })
    55: 
    56:         # Pré‑charge les marchés SPOT pour résoudre correctement symboles
    57:         self._markets_task: Optional[asyncio.Task[Any]] = None
    58: 
    59:     async def _ensure_markets(self) -> None:
    60:         if self._markets_task is None:
    61:             self._markets_task = asyncio.create_task(self.ex.load_markets())
    62:         await self._markets_task
    63: 
    64:     # ---------- CSV cache ----------
    65:     def _csv_path(self, symbol: str, timeframe: str) -> str:
    66:         safe = symbol.replace("/", "").replace(":", "")
    67:         return os.path.join(self.data_dir, f"{safe}-{timeframe}.csv")
    68: 
    69:     def _read_cache(self, path: str) -> List[List[float]]:
    70:         if not os.path.exists(path):
    71:             return []
    72:         rows: List[List[float]] = []
    73:         try:
    74:             with open(path, "r", newline="") as f:
    75:                 rd = csv.reader(f)
    76:                 for r in rd:
    77:                     if not r:
    78:                         continue
    79:                     # ts, o, h, l, c, v
    80:                     try:
    81:                         rows.append([
    82:                             int(r[0]),
    83:                             float(r[1]),
    84:                             float(r[2]),
    85:                             float(r[3]),
    86:                             float(r[4]),
    87:                             float(r[5]),
    88:                         ])
    89:                     except Exception:
    90:                         # on ignore les lignes corrompues
    91:                         continue
    92:         except Exception:
    93:             return []
    94:         return rows
    95: 
    96:     def _write_cache(self, path: str, data: List[List[float]]) -> None:
    97:         # On ré‑écrit intégralement (simple et sûr)
    98:         tmp = path + ".tmp"
    99:         with open(tmp, "w", newline="") as f:
   100:             wr = csv.writer(f)
   101:             wr.writerows(data)
   102:         os.replace(tmp, path)
   103: 
   104:     # ---------- API publique pour orchestrateur ----------
   105:     async def fetch_ohlcv(
   106:         self, symbol: str, timeframe: str, limit: int, since: Optional[int] = None
   107:     ) -> List[List[float]]:
   108:         """
   109:         Conformité orchestrateur : signature (symbol, timeframe, limit).
   110:         Retour CCXT OHLCV. Utilise cache si dispo/assez frais, sinon CCXT.
   111:         """
   112:         await self._ensure_markets()
   113: 
   114:         # Bitget (spot) symbol format CCXT: "BTC/USDT"
   115:         ccxt_symbol = symbol.replace("USDT", "/USDT")
   116:         cache_path = self._csv_path(symbol, timeframe)
   117: 
   118:         # 1) Cache
   119:         if self.use_cache:
   120:             cached = self._read_cache(cache_path)
   121:             if cached:
   122:                 # fraicheur = diff entre maintenant et ts dernière bougie
   123:                 last_ts = int(cached[-1][0])
   124:                 if self.min_fresh == 0 or (_now_ms() - last_ts) <= self.min_fresh * 1000:
   125:                     # suffisant => on retourne la fin
   126:                     if len(cached) >= limit:
   127:                         return cached[-limit:]
   128:                     # pas assez, on essaiera de compléter via CCXT plus bas
   129:                 # sinon: on tentera de rafraîchir plus loin
   130: 
   131:         # 2) Remote via CCXT
   132:         # CCXT fetch_ohlcv: since=None, limit=…  (since en ms)
   133:         # On demande 'limit' bougies; si cache partiel, on pourra fusionner ensuite.
   134:         params: dict[str, Any] = {}
   135:         if self.spot is True:
   136:             params["type"] = "spot"  # ccxt bitget accepte 'type' pour certain endpoints
   137: 
   138:         try:
   139:             ohlcv = await self.ex.fetch_ohlcv(ccxt_symbol, timeframe, since=since, limit=limit, params=params)
   140:         except Exception as e:  # noqa: BLE001
   141:             # En cas d’échec remote: si on a du cache, on le renvoie quand même
   142:             cached = self._read_cache(cache_path) if self.use_cache else []
   143:             if cached:
   144:                 return cached[-limit:]
   145:             raise RuntimeError(f"Bitget CCXT fetch_ohlcv failed for {symbol} {timeframe}: {e}") from e
   146: 
   147:         # 3) Merge simple cache + remote et ré‑écrit (sans doublons sur ts)
   148:         if self.use_cache:
   149:             base = self._read_cache(cache_path)
   150:             merged = _merge_ohlcv(base, ohlcv)
   151:             self._write_cache(cache_path, merged)
   152:             # retourne la fin
   153:             return merged[-limit:]
   154: 
   155:         return ohlcv[-limit:]
   156: 
   157:     async def close(self) -> None:
   158:         try:
   159:             await self.ex.close()
   160:         except Exception:
   161:             pass
   162: 
   163: 
   164: def _merge_ohlcv(a: List[List[float]], b: List[List[float]]) -> List[List[float]]:
   165:     """
   166:     Fusionne deux listes OHLCV par timestamp, en écrasant a par b sur collision.
   167:     """
   168:     if not a:
   169:         return list(b)
   170:     if not b:
   171:         return list(a)
   172: 
   173:     # index rapide par ts
   174:     by_ts: dict[int, List[float]] = {int(row[0]): row for row in a}
   175:     for row in b:
   176:         by_ts[int(row[0])] = row
   177:     return [by_ts[k] for k in sorted(by_ts)]

## scalper/exchange/fees.py (last modified: 2025-08-23 20:57:14)
     1: # scalper/exchange/fees.py
     2: from __future__ import annotations
     3: 
     4: from typing import Dict, Iterable
     5: 
     6: # Valeurs par défaut (Bitget spot/futures ~ ordre de grandeur ; sera écrasé quand on charge les frais)
     7: DEFAULT_TAKER_BPS = 6    # 0.06%
     8: DEFAULT_MAKER_BPS = 2    # 0.02%
     9: 
    10: # Cache local: symbol -> {"taker_bps": int, "maker_bps": int}
    11: _FEES_BY_SYMBOL: Dict[str, Dict[str, float]] = {}
    12: 
    13: 
    14: def get_fee(symbol: str, kind: str = "taker") -> float:
    15:     """
    16:     Retourne le fee rate (fraction, ex 0.0006) pour 'symbol' et 'kind' ("taker" ou "maker").
    17:     Utilise le cache alimenté par load_bitget_fees(), sinon valeurs par défaut.
    18:     """
    19:     rec = _FEES_BY_SYMBOL.get(symbol, {"taker_bps": DEFAULT_TAKER_BPS, "maker_bps": DEFAULT_MAKER_BPS})
    20:     bps = rec["taker_bps"] if kind == "taker" else rec["maker_bps"]
    21:     return float(bps) / 10_000.0
    22: 
    23: 
    24: async def load_bitget_fees(exchange, symbols: Iterable[str]) -> Dict[str, Dict[str, float]]:
    25:     """
    26:     Tente de charger les frais auprès de l'exchange (type ccxt):
    27:       - fetch_trading_fees(symbols) si dispo
    28:       - sinon fetch_trading_fee(symbol) pour chaque symbole
    29:     Remplit le cache _FEES_BY_SYMBOL avec des BPS (entiers).
    30:     """
    31:     symbols = list(symbols)
    32:     fees: Dict[str, Dict[str, float]] = {}
    33: 
    34:     try:
    35:         if hasattr(exchange, "fetch_trading_fees"):
    36:             data = await exchange.fetch_trading_fees(symbols)
    37:             for s in symbols:
    38:                 d = (data or {}).get(s, {}) or {}
    39:                 taker = float(d.get("taker", DEFAULT_TAKER_BPS / 10_000))
    40:                 maker = float(d.get("maker", DEFAULT_MAKER_BPS / 10_000))
    41:                 fees[s] = {"taker_bps": round(taker * 10_000), "maker_bps": round(maker * 10_000)}
    42:         else:
    43:             for s in symbols:
    44:                 try:
    45:                     d = await exchange.fetch_trading_fee(s)
    46:                 except Exception:
    47:                     d = {}
    48:                 taker = float(d.get("taker", DEFAULT_TAKER_BPS / 10_000))
    49:                 maker = float(d.get("maker", DEFAULT_MAKER_BPS / 10_000))
    50:                 fees[s] = {"taker_bps": round(taker * 10_000), "maker_bps": round(maker * 10_000)}
    51:     except Exception:
    52:         # fallback: défauts
    53:         for s in symbols:
    54:             fees[s] = {"taker_bps": DEFAULT_TAKER_BPS, "maker_bps": DEFAULT_MAKER_BPS}
    55: 
    56:     # maj du cache
    57:     _FEES_BY_SYMBOL.update(fees)
    58:     return fees

## scalper/hooks/prewarm_cache.py (last modified: 2025-08-24 03:12:00)
     1: # -*- coding: utf-8 -*-
     2: """
     3: Pré-chauffe léger du cache OHLCV.
     4: 
     5: Objectif: ne PAS bloquer le lancement. On log juste un statut "warmup OK"
     6: pour chaque symbole, et on s'assure que le dossier data existe.
     7: Si tu veux rebrancher un vrai downloader plus tard, expose simplement une
     8: fonction `prewarm_cache(cfg, symbols, timeframe, out_dir)` avec la même
     9: signature.
    10: """
    11: from __future__ import annotations
    12: from pathlib import Path
    13: from typing import Iterable
    14: 
    15: 
    16: def prewarm_cache(cfg: dict, symbols: Iterable[str], timeframe: str, out_dir: str | Path) -> None:
    17:     out = Path(out_dir)
    18:     out.mkdir(parents=True, exist_ok=True)
    19:     for sym in symbols:
    20:         # Marqueur vide; permet à d’autres services de voir que le symbole est "préparé"
    21:         (out / f"{sym}-{timeframe}.csv").touch(exist_ok=True)
    22:         print(f"[cache] warmup OK for {sym}")

## scalper/live/__init__.py (last modified: 2025-08-24 03:12:00)
     1: from .orchestrator import RunConfig, Orchestrator, run_orchestrator  # re‑exports
     2: from .notify import build_notifier_and_commands  # utile pour bot.py

## scalper/live/backtest_telegram.py (last modified: 2025-08-23 20:57:14)
     1: # scalper/live/backtest_telegram.py
     2: from __future__ import annotations
     3: 
     4: import asyncio
     5: import os
     6: from typing import List
     7: 
     8: from scalper.backtest import BTCfg, run_multi
     9: from scalper.services.utils import safe_call
    10: 
    11: # Exchange CCXT asynchrone pour OHLCV publics (Bitget)
    12: async def _get_exchange():
    13:     try:
    14:         import ccxt.async_support as ccxt  # type: ignore
    15:     except Exception:
    16:         raise RuntimeError("CCXT n'est pas installé. Lance: pip install ccxt")
    17:     return ccxt.bitget()
    18: 
    19: def _parse_symbols(defaults: List[str]) -> List[str]:
    20:     env = os.getenv("BACKTEST_SYMBOLS", "")
    21:     if env.strip():
    22:         return [s.strip().upper() for s in env.split(",") if s.strip()]
    23:     return defaults
    24: 
    25: async def handle_backtest_command(notifier, defaults: List[str], timeframe: str = "5m") -> None:
    26:     """Lancé par l'orchestrateur quand l'utilisateur tape /backtest sur Telegram."""
    27:     symbols = _parse_symbols(defaults)
    28:     cash = float(os.getenv("BT_CASH", "10000"))
    29:     risk = float(os.getenv("BT_RISK_PCT", "0.05"))
    30:     slip = float(os.getenv("BT_SLIPPAGE_BPS", "0.0"))
    31:     limit = int(os.getenv("BT_LIMIT", "1500"))
    32: 
    33:     await notifier.send(
    34:         "🧪 Backtest en cours...\n"
    35:         f"• Symbols: {', '.join(symbols)}\n"
    36:         f"• TF: {timeframe}\n"
    37:         f"• Cash: {cash:,.0f}  • Risk: {risk:0.4f}  • Slippage: {slip:0.1f} bps\n"
    38:         f"• Source: exchange.fetch_ohlcv (adapté) + cache CSV"
    39:     )
    40: 
    41:     async def _run():
    42:         exchange = await _get_exchange()
    43:         try:
    44:             cfg = BTCfg(symbols=symbols, timeframe=timeframe, cash=cash,
    45:                         risk_pct=risk, slippage_bps=slip, limit=limit)
    46:             res = await run_multi(cfg, exchange)
    47:             await notifier.send(f"✅ Backtest terminé. Résultats: `{res['out_dir']}`")
    48:         finally:
    49:             try:
    50:                 await exchange.close()
    51:             except Exception:
    52:                 pass
    53: 
    54:     try:
    55:         await safe_call(_run, label="backtest", max_retry=1)  # 1 tir = si fail on avertit
    56:     except Exception as e:
    57:         await notifier.send(f"⚠️ Backtest : erreur inattendue: {e}")

## scalper/live/commands.py (last modified: 2025-08-23 20:57:14)
     1: # scalper/live/commands.py
     2: from __future__ import annotations
     3: 
     4: import asyncio
     5: from typing import Awaitable, Callable
     6: 
     7: 
     8: class CommandHandler:
     9:     """
    10:     Gère les commandes reçues d'un CommandStream (Telegram ou Null).
    11:     Chaque commande est routée vers un callback approprié.
    12:     Les erreurs de callbacks sont capturées pour ne pas tuer l'orchestrateur.
    13:     """
    14: 
    15:     def __init__(self, notifier, command_stream, status_getter, status_sender):
    16:         self.notifier = notifier
    17:         self.stream = command_stream
    18:         self.status_getter = status_getter
    19:         self.status_sender = status_sender
    20: 
    21:     async def _safe_call(self, coro: Awaitable[None], err_msg: str) -> None:
    22:         try:
    23:             await coro
    24:         except Exception as e:
    25:             try:
    26:                 await self.notifier.send(f"⚠️ {err_msg}: {e}")
    27:             except Exception:
    28:                 pass  # on ne propage jamais
    29: 
    30:     async def run(
    31:         self,
    32:         on_pause: Callable[[], None],
    33:         on_resume: Callable[[], None],
    34:         on_stop: Callable[[], Awaitable[None]] | None,
    35:         on_setup_apply: Callable[[dict], None],
    36:         on_backtest: Callable[[str], Awaitable[None]] | None = None,
    37:     ):
    38:         """
    39:         Boucle asynchrone qui lit les lignes du CommandStream
    40:         et exécute le callback approprié.
    41:         TOUTE exception de callback est absorbée pour ne pas terminer cette task.
    42:         """
    43:         async for line in self.stream:
    44:             txt = (line or "").strip()
    45:             if not txt:
    46:                 continue
    47: 
    48:             try:
    49:                 if txt.startswith("/pause"):
    50:                     on_pause()
    51:                     await self.notifier.send("⏸️ Pause.")
    52: 
    53:                 elif txt.startswith("/resume"):
    54:                     on_resume()
    55:                     await self.notifier.send("▶️ Resume.")
    56: 
    57:                 elif txt.startswith("/stop"):
    58:                     if on_stop:
    59:                         await self._safe_call(on_stop(), "Arrêt échoué")
    60: 
    61:                 elif txt.startswith("/status"):
    62:                     snap = self.status_getter()
    63:                     await self.notifier.send(f"ℹ️ {snap}")
    64: 
    65:                 elif txt.startswith("/setup"):
    66:                     await self.notifier.send("🧩 Setup wizard à compléter.")
    67: 
    68:                 elif txt.startswith("/backtest"):
    69:                     if on_backtest:
    70:                         tail = txt[len("/backtest"):].strip()
    71:                         # IMPORTANT : on ne bloque PAS la boucle de commandes.
    72:                         asyncio.create_task(self._safe_call(
    73:                             on_backtest(tail), "Backtest échoué"
    74:                         ))
    75:                         await self.notifier.send("🧪 Backtest lancé en tâche de fond.")
    76:                     else:
    77:                         await self.notifier.send("⚠️ Backtest non disponible.")
    78: 
    79:                 else:
    80:                     await self.notifier.send(
    81:                         "❓ Commandes: /status /pause /resume /stop /setup /backtest"
    82:                     )
    83: 
    84:             except Exception as e:
    85:                 # On protège la boucle quoi qu'il arrive
    86:                 try:
    87:                     await self.notifier.send(f"⚠️ Erreur commande: {e}")
    88:                 except Exception:
    89:                     pass

## scalper/live/journal.py (last modified: 2025-08-23 20:57:14)
     1: from __future__ import annotations
     2: import os, csv
     3: from typing import Any, Dict, List
     4: 
     5: class LogWriter:
     6:     """Gestion simple des CSV (création à la volée + append)."""
     7:     def __init__(self, dirpath: str) -> None:
     8:         self.dir = dirpath
     9:         os.makedirs(self.dir, exist_ok=True)
    10: 
    11:     def init(self, fname: str, headers: List[str]) -> None:
    12:         p = os.path.join(self.dir, fname)
    13:         if not os.path.exists(p):
    14:             with open(p, "w", newline="", encoding="utf-8") as f:
    15:                 csv.DictWriter(f, fieldnames=headers).writeheader()
    16: 
    17:     def row(self, fname: str, row: Dict[str, Any]) -> None:
    18:         p = os.path.join(self.dir, fname)
    19:         with open(p, "a", newline="", encoding="utf-8") as f:
    20:             csv.DictWriter(f, fieldnames=list(row.keys())).writerow(row)

## scalper/live/logs.py (last modified: 2025-08-23 20:57:14)
     1: # scalp/live/logs.py
     2: from __future__ import annotations
     3: import os, csv
     4: from typing import Any, List, Dict
     5: 
     6: class CsvLog:
     7:     def __init__(self, path: str, headers: List[str]):
     8:         self.path = path
     9:         self.headers = headers
    10:         self._ensure_header()
    11: 
    12:     def _ensure_header(self):
    13:         must_write = not os.path.exists(self.path) or os.path.getsize(self.path) == 0
    14:         os.makedirs(os.path.dirname(self.path), exist_ok=True)
    15:         if must_write:
    16:             with open(self.path, "w", newline="") as f:
    17:                 csv.writer(f).writerow(self.headers)
    18: 
    19:     def write_row(self, row: Dict[str, Any]):
    20:         with open(self.path, "a", newline="") as f:
    21:             w = csv.DictWriter(f, fieldnames=self.headers)
    22:             w.writerow({k: row.get(k, "") for k in self.headers})

## scalper/live/loops/trade.py (last modified: 2025-08-23 20:57:14)
     1: # scalp/live/loops/trade.py
     2: from __future__ import annotations
     3: import asyncio, os
     4: from dataclasses import dataclass, field
     5: from typing import Any, Dict, List, Callable
     6: 
     7: from ...services.utils import safe_call
     8: from ...risk.manager import compute_size
     9: 
    10: QUIET = int(os.getenv("QUIET", "0") or "0")
    11: PRINT_OHLCV_SAMPLE = int(os.getenv("PRINT_OHLCV_SAMPLE", "0") or "0")
    12: 
    13: class PositionFSM:
    14:     def __init__(self):
    15:         self.state = "FLAT"
    16:         self.side = "flat"
    17:         self.entry = 0.0
    18:         self.qty = 0.0
    19:     def can_open(self): return self.state == "FLAT"
    20:     def on_open(self, side, entry, qty): self.state, self.side, self.entry, self.qty = "OPEN", side, entry, qty
    21:     def can_close(self): return self.state == "OPEN"
    22:     def on_close(self): self.state, self.side, self.entry, self.qty = "FLAT", "flat", 0.0, 0.0
    23: 
    24: @dataclass
    25: class SymbolContext:
    26:     symbol: str
    27:     timeframe: str
    28:     ohlcv: List[List[float]] = field(default_factory=list)
    29:     ticks: int = 0
    30:     fsm: PositionFSM = field(default_factory=PositionFSM)
    31: 
    32: class TradeLoop:
    33:     """
    34:     Boucle par symbole, indépendante de l'orchestrateur.
    35:     """
    36:     def __init__(
    37:         self,
    38:         symbol: str,
    39:         timeframe: str,
    40:         ohlcv_fetch: Callable[..., Any],           # async fn(symbol, timeframe, limit) -> ohlcv
    41:         order_market: Callable[..., Any],          # async fn(symbol, side, qty) -> order dict
    42:         generate_signal: Callable[[List[List[float]], Dict[str, Any]], Dict[str, Any]],
    43:         config: Dict[str, Any],
    44:         mode_getter: Callable[[], str],
    45:         log_signals, log_orders, log_fills,
    46:         tick_counter_add: Callable[[int], None],
    47:     ):
    48:         self.symbol = symbol
    49:         self.timeframe = timeframe
    50:         self.fetch = ohlcv_fetch
    51:         self.order_market = order_market
    52:         self.generate_signal = generate_signal
    53:         self.config = config
    54:         self.get_mode = mode_getter
    55:         self.log_signals = log_signals
    56:         self.log_orders = log_orders
    57:         self.log_fills = log_fills
    58:         self.ctx = SymbolContext(symbol, timeframe)
    59:         self._tick_add = tick_counter_add
    60: 
    61:         # Risk/frais
    62:         self.risk_pct = float(self.config.get("risk_pct", 0.5))
    63:         self.caps_by_symbol = self.config.get("caps", {})  # dict optionnel
    64:         self.fees_map = self.config.get("fees_by_symbol", {})  # {sym: {"maker_bps":..., "taker_bps":...}}
    65:         self.slippage_bps = float(self.config.get("slippage_bps", 0.0))
    66: 
    67:     def _bps_for(self, order_type: str = "market") -> float:
    68:         # market -> taker; limit post-only -> maker
    69:         per = self.fees_map.get(self.symbol, {})
    70:         if order_type == "limit":
    71:             return float(per.get("maker_bps", 0.0))
    72:         return float(per.get("taker_bps", 0.0))
    73: 
    74:     async def run(self, running: Callable[[], bool]):
    75:         lookback = 200
    76:         while running():
    77:             if self.get_mode() != "RUNNING":
    78:                 await asyncio.sleep(0.5); continue
    79: 
    80:             async def _fetch():
    81:                 return await self.fetch(self.symbol, timeframe=self.timeframe, limit=lookback+2)
    82:             ohlcv = await safe_call(_fetch, label=f"fetch_ohlcv:{self.symbol}")
    83:             if not ohlcv or len(ohlcv) < lookback+1:
    84:                 await asyncio.sleep(1.0); continue
    85: 
    86:             self.ctx.ohlcv = ohlcv
    87:             self.ctx.ticks += 1
    88:             self._tick_add(1)
    89: 
    90:             window = ohlcv[-(lookback+1):]
    91:             ts, _o, _h, _l, c, _v = window[-1]
    92: 
    93:             try:
    94:                 sig = self.generate_signal(window, self.config) or {}
    95:             except Exception as e:
    96:                 if not QUIET:
    97:                     print(f"[trade:{self.symbol}] generate_signal error: {e}", flush=True)
    98:                 await asyncio.sleep(0.5); continue
    99: 
   100:             side = sig.get("side","flat"); entry = float(sig.get("entry", c)); sl = sig.get("sl"); tp = sig.get("tp")
   101:             self.log_signals.write_row({"ts": ts, "symbol": self.symbol, "side": side, "entry": entry, "sl": sl, "tp": tp, "last": c})
   102: 
   103:             # --- Entrée (market -> taker)
   104:             if self.ctx.fsm.state == "FLAT" and side in ("long","short"):
   105:                 balance = float(self.config.get("cash", 10_000.0))
   106:                 qty = compute_size(
   107:                     symbol=self.symbol, price=entry or c, balance_cash=balance,
   108:                     risk_pct=self.risk_pct, caps_by_symbol=self.caps_by_symbol
   109:                 )
   110:                 if qty > 0:
   111:                     async def _place():
   112:                         return await self.order_market(self.symbol, side, qty)
   113:                     order = await safe_call(_place, label=f"order:{self.symbol}")
   114:                     self.ctx.fsm.on_open(side, entry or c, qty)
   115:                     self.log_orders.write_row({"ts": ts, "symbol": self.symbol, "side": side, "qty": qty,
   116:                                                "status": "placed", "order_id": (order or {}).get("id",""), "note": f"entry taker={self._bps_for('market')}bps"})
   117: 
   118:             # --- Sortie (market -> taker)
   119:             elif self.ctx.fsm.state == "OPEN" and (side == "flat" or (side in ("long","short") and side != self.ctx.fsm.side)):
   120:                 qty = self.ctx.fsm.qty
   121:                 exit_side = "sell" if self.ctx.fsm.side == "long" else "buy"
   122:                 async def _close():
   123:                     return await self.order_market(self.symbol, exit_side, qty)
   124:                 order = await safe_call(_close, label=f"close:{self.symbol}")
   125: 
   126:                 # fill avec slippage + frais (taker)
   127:                 price_fill = float(c)
   128:                 price_fill *= (1 + (self.slippage_bps/10000.0)) if exit_side == "buy" else (1 - (self.slippage_bps/10000.0))
   129:                 self.log_orders.write_row({"ts": ts, "symbol": self.symbol, "side": exit_side, "qty": qty,
   130:                                            "status": "placed", "order_id": (order or {}).get("id",""), "note": f"exit taker={self._bps_for('market')}bps"})
   131:                 self.log_fills.write_row({"ts": ts, "symbol": self.symbol, "side": exit_side, "price": price_fill, "qty": qty,
   132:                                           "order_id": (order or {}).get("id","")})
   133:                 self.ctx.fsm.on_close()
   134: 
   135:             if PRINT_OHLCV_SAMPLE and (self.ctx.ticks % 20 == 0) and not QUIET:
   136:                 print(f"[{self.symbol}] last={c} ticks={self.ctx.ticks}", flush=True)
   137: 
   138:             await asyncio.sleep(0.1 if QUIET else 0.01)

## scalper/live/notify.py (last modified: 2025-08-24 03:12:00)
     1: # -*- coding: utf-8 -*-
     2: from __future__ import annotations
     3: import os
     4: import asyncio
     5: from dataclasses import dataclass
     6: from typing import AsyncIterator, Optional
     7: 
     8: 
     9: @dataclass
    10: class BaseNotifier:
    11:     async def send(self, text: str) -> None:  # pragma: no cover
    12:         print(text)
    13: 
    14: 
    15: class NullNotifier(BaseNotifier):
    16:     pass
    17: 
    18: 
    19: class TelegramNotifier(BaseNotifier):
    20:     def __init__(self, token: str, chat_id: str, session: Optional[asyncio.AbstractEventLoop]=None):
    21:         import aiohttp  # lazy
    22:         self._token = token
    23:         self._chat = chat_id
    24:         self._session: aiohttp.ClientSession | None = None
    25: 
    26:     async def _ensure(self):
    27:         import aiohttp
    28:         if self._session is None or self._session.closed:
    29:             self._session = aiohttp.ClientSession()
    30: 
    31:     async def send(self, text: str) -> None:
    32:         import aiohttp
    33:         await self._ensure()
    34:         # pas de markdown pour éviter les erreurs 400 de parsing
    35:         url = f"https://api.telegram.org/bot{self._token}/sendMessage"
    36:         payload = {"chat_id": self._chat, "text": text, "disable_web_page_preview": True}
    37:         try:
    38:             async with self._session.post(url, json=payload, timeout=20) as r:
    39:                 await r.text()  # on ignore la réponse pour rester simple
    40:         except Exception:
    41:             # on fait un fallback silencieux pour ne pas casser le bot
    42:             print("[notify:telegram] send fail (ignored)")
    43: 
    44:     async def close(self):
    45:         if self._session and not self._session.closed:
    46:             await self._session.close()
    47: 
    48: 
    49: class _NullCommands:
    50:     """Itérateur async vide utilisé quand Telegram n'est pas configuré."""
    51:     def __aiter__(self) -> AsyncIterator[str]:
    52:         return self
    53:     async def __anext__(self) -> str:
    54:         await asyncio.sleep(3600)  # jamais
    55:         raise StopAsyncIteration
    56: 
    57: 
    58: async def build_notifier_and_commands(config: dict) -> tuple[BaseNotifier, AsyncIterator[str]]:
    59:     """
    60:     Retourne (notifier, command_stream).
    61: 
    62:     - Si TELEGRAM_BOT_TOKEN et TELEGRAM_CHAT_ID sont présents: TelegramNotifier,
    63:       et un flux (vide) – l’orchestreur n’en a besoin que si on implémente des
    64:       commandes interactives plus tard.
    65:     - Sinon: NullNotifier + flux vide.
    66:     """
    67:     token = os.getenv("TELEGRAM_BOT_TOKEN")
    68:     chat = os.getenv("TELEGRAM_CHAT_ID")
    69:     if token and chat:
    70:         print("[notify] TELEGRAM configured.")
    71:         return TelegramNotifier(token, chat), _NullCommands()
    72:     print("[notify] TELEGRAM not configured -> Null notifier will be used.")
    73:     return NullNotifier(), _NullCommands()

## scalper/live/ohlcv_service.py (last modified: 2025-08-23 20:57:14)
     1: from __future__ import annotations
     2: import time
     3: from typing import Any, Dict, List, Optional
     4: 
     5: try:
     6:     from scalper.adapters.market_data import MarketData
     7: except Exception:
     8:     MarketData = None  # type: ignore
     9: 
    10: class OhlcvService:
    11:     """Lecture/normalisation OHLCV avec fallback agressifs."""
    12:     def __init__(self, exchange) -> None:
    13:         self.exchange = exchange
    14:         self.md = MarketData(exchange) if MarketData is not None else None
    15: 
    16:     @staticmethod
    17:     def normalize_rows(rows: Any) -> List[Dict[str, float]]:
    18:         out: List[Dict[str, float]] = []
    19:         if not rows: return out
    20:         for r in rows:
    21:             if isinstance(r, dict):
    22:                 ts = int(r.get("ts") or r.get("time") or r.get("timestamp") or 0)
    23:                 o = float(r.get("open", 0.0)); h = float(r.get("high", o)); l = float(r.get("low", o)); c = float(r.get("close", o))
    24:                 v = float(r.get("volume", r.get("vol", 0.0)))
    25:             else:
    26:                 rr = list(r)
    27:                 if len(rr) >= 6 and isinstance(rr[0], (int, float)) and rr[0] > 10**10:
    28:                     ts, o, h, l, c = int(rr[0]), float(rr[1]), float(rr[2]), float(rr[3]), float(rr[4]); v = float(rr[5])
    29:                 else:
    30:                     o = float(rr[0]) if len(rr) > 0 else 0.0
    31:                     h = float(rr[1]) if len(rr) > 1 else o
    32:                     l = float(rr[2]) if len(rr) > 2 else o
    33:                     c = float(rr[3]) if len(rr) > 3 else o
    34:                     v = float(rr[4]) if len(rr) > 4 else 0.0
    35:                     ts = int(rr[5]) if len(rr) > 5 else 0
    36:             out.append({"ts": ts, "open": o, "high": h, "low": l, "close": c, "volume": v})
    37:         return out
    38: 
    39:     async def fetch_once(self, symbol: str, interval: str = "1m", limit: int = 100) -> List[Dict[str, float]]:
    40:         # 1) MarketData (si dispo)
    41:         if self.md is not None:
    42:             try:
    43:                 d = self.md.get_ohlcv(symbol, interval, limit)
    44:                 if isinstance(d, dict) and d.get("success") and d.get("data"):
    45:                     return self.normalize_rows(d["data"])
    46:             except Exception:
    47:                 pass
    48: 
    49:         # 2) Exchange natif
    50:         rows: List[Any] = []
    51:         try:
    52:             data = self.exchange.get_kline(symbol, interval=interval)
    53:         except Exception:
    54:             data = None
    55: 
    56:         if isinstance(data, dict):
    57:             rows = (
    58:                 data.get("data") or data.get("result") or data.get("records") or
    59:                 data.get("list") or data.get("items") or data.get("candles") or []
    60:             )
    61:             guard = 0
    62:             while isinstance(rows, dict) and guard < 3:
    63:                 rows = (
    64:                     rows.get("data") or rows.get("result") or rows.get("records") or
    65:                     rows.get("list") or rows.get("items") or rows.get("candles") or rows.get("klines") or rows.get("bars") or []
    66:                 )
    67:                 guard += 1
    68:         elif isinstance(data, (list, tuple)):
    69:             rows = list(data)
    70: 
    71:         out = self.normalize_rows(rows)[-limit:]
    72:         if out: return out
    73: 
    74:         # 3) Fallback strict via ticker -> bougie synthétique
    75:         try:
    76:             tkr = self.exchange.get_ticker(symbol)
    77:             items = []
    78:             if isinstance(tkr, dict): items = tkr.get("data") or tkr.get("result") or tkr.get("tickers") or []
    79:             elif isinstance(tkr, (list, tuple)): items = list(tkr)
    80:             if items:
    81:                 last = items[0]
    82:                 if isinstance(last, dict):
    83:                     p = float(last.get("lastPrice", last.get("close", last.get("markPrice", 0.0))))
    84:                     v = float(last.get("volume", last.get("usdtVolume", last.get("quoteVolume", 0.0))))
    85:                 else:
    86:                     seq = list(last); p = float(seq[3] if len(seq) > 3 else seq[-2]); v = float(seq[4] if len(seq) > 4 else seq[-1])
    87:                 ts = int(time.time()*1000)
    88:                 return [{"ts": ts, "open": p, "high": p, "low": p, "close": p, "volume": v}]
    89:         except Exception:
    90:             pass
    91:         return []

## scalper/live/orchestrator.py (last modified: 2025-08-24 03:12:00)
     1: # -*- coding: utf-8 -*-
     2: from __future__ import annotations
     3: import asyncio
     4: from dataclasses import dataclass, field
     5: from typing import Callable, Iterable, List, Optional, AsyncIterator
     6: 
     7: from scalper.hooks.prewarm_cache import prewarm_cache
     8: 
     9: 
    10: @dataclass
    11: class RunConfig:
    12:     symbols: List[str] = field(default_factory=lambda: [
    13:         "BTCUSDT","ETHUSDT","SOLUSDT","BNBUSDT","XRPUSDT",
    14:         "DOGEUSDT","ADAUSDT","LTCUSDT","AVAXUSDT","LINKUSDT"
    15:     ])
    16:     timeframe: str = "5m"
    17:     refresh_secs: float = 30.0
    18:     cache_dir: str = "/notebooks/data"
    19:     # Tu peux ajouter d'autres paramètres ici (risques, stratégie, etc.)
    20: 
    21: 
    22: class Orchestrator:
    23:     def __init__(self, cfg: RunConfig, notifier, cache_dir_factory: Optional[Callable[[], str]] = None):
    24:         self.cfg = cfg
    25:         self.notifier = notifier
    26:         self._cache_dir_factory = cache_dir_factory
    27:         self._bg_tasks: list[asyncio.Task] = []
    28:         self._ticks_total: int = 0
    29:         self._running: bool = False
    30: 
    31:     # --- getters exposés aux tâches de log/heartbeat
    32:     def ticks_total(self) -> int:
    33:         return self._ticks_total
    34: 
    35:     def symbols(self) -> List[str]:
    36:         return list(self.cfg.symbols)
    37: 
    38:     async def _heartbeat_task(self) -> None:
    39:         while self._running:
    40:             try:
    41:                 await self.notifier.send("heartbeat alive")
    42:             finally:
    43:                 await asyncio.sleep(30)
    44: 
    45:     async def _log_stats_task(self) -> None:
    46:         # log toutes les 30s
    47:         while self._running:
    48:             try:
    49:                 msg = f"[stats] ticks_total={self._ticks_total} (+0 /30s) | pairs={','.join(self.cfg.symbols) if self.cfg.symbols else ''}"
    50:                 await self.notifier.send(msg)
    51:             finally:
    52:                 await asyncio.sleep(30)
    53: 
    54:     async def _main_loop(self) -> None:
    55:         """Boucle principale ultra‑simple qui incrémente un compteur."""
    56:         refresh = max(2.0, float(self.cfg.refresh_secs))
    57:         while self._running:
    58:             # Ici tu brancheras fetch_ohlcv / signaux / stratégies
    59:             self._ticks_total += len(self.cfg.symbols)
    60:             await asyncio.sleep(refresh)
    61: 
    62:     async def start(self) -> None:
    63:         # Pré‑chauffe cache (non bloquant et robuste)
    64:         prewarm_cache(
    65:             cfg={},  # placeholder
    66:             symbols=self.cfg.symbols,
    67:             timeframe=self.cfg.timeframe,
    68:             out_dir=(self._cache_dir_factory() if self._cache_dir_factory else self.cfg.cache_dir),
    69:         )
    70:         await self.notifier.send("🟢 Orchestrator PRELAUNCH. Utilise /setup ou /backtest. /resume pour démarrer le live.")
    71: 
    72:         self._running = True
    73:         self._bg_tasks.append(asyncio.create_task(self._heartbeat_task()))
    74:         self._bg_tasks.append(asyncio.create_task(self._log_stats_task()))
    75:         try:
    76:             await self._main_loop()
    77:         finally:
    78:             # arrêt propre
    79:             self._running = False
    80:             for t in self._bg_tasks:
    81:                 t.cancel()
    82:             self._bg_tasks.clear()
    83: 
    84:     async def run(self) -> None:
    85:         await self.start()
    86: 
    87: 
    88: async def run_orchestrator(cfg: RunConfig, notifier, cache_dir_factory: Optional[Callable[[], str]] = None) -> None:
    89:     """Entrée unique utilisée par bot.py"""
    90:     orch = Orchestrator(cfg, notifier, cache_dir_factory)
    91:     await orch.run()

## scalper/live/orders.py (last modified: 2025-08-23 20:57:14)
     1: # live/orders.py
     2: from __future__ import annotations
     3: from dataclasses import dataclass
     4: from typing import Any, Optional
     5: 
     6: from scalper.services.order_service import OrderService, OrderRequest
     7: 
     8: @dataclass
     9: class OrderResult:
    10:     accepted: bool
    11:     order_id: str | None = None
    12:     status: str | None = None
    13:     reason: str | None = None
    14: 
    15: class OrderExecutor:
    16:     """
    17:     Fine couche autour d'OrderService + exchange :
    18:       - calcule l'équité USDT
    19:       - place une entrée (risk_pct)
    20:       - récupère les fills (normalisés)
    21:     L'orchestrateur n’appelle plus OrderService directement.
    22:     """
    23: 
    24:     def __init__(self, order_service: OrderService, exchange: Any, config: Any) -> None:
    25:         self.order_service = order_service
    26:         self.exchange = exchange
    27:         self.config = config
    28: 
    29:     # ---------- Equity ----------
    30:     def get_equity_usdt(self) -> float:
    31:         equity = 0.0
    32:         try:
    33:             assets = self.exchange.get_assets()
    34:             if isinstance(assets, dict):
    35:                 for a in (assets.get("data") or []):
    36:                     if str(a.get("currency")).upper() == "USDT":
    37:                         equity = float(a.get("equity", 0.0))
    38:                         break
    39:         except Exception:
    40:             pass
    41:         return equity
    42: 
    43:     # ---------- Entrée ----------
    44:     def place_entry(self, *, symbol: str, side: str, price: float,
    45:                     sl: float | None, tp: float | None, risk_pct: float) -> OrderResult:
    46:         """
    47:         side: 'long' | 'short'
    48:         Retourne OrderResult(accepted, order_id, status, reason)
    49:         """
    50:         equity = self.get_equity_usdt()
    51:         req = OrderRequest(symbol=symbol, side=side, price=float(price),
    52:                            sl=(float(sl) if sl else None), tp=(float(tp) if tp else None),
    53:                            risk_pct=float(risk_pct))
    54:         try:
    55:             res = self.order_service.prepare_and_place(equity, req)
    56:             return OrderResult(accepted=bool(getattr(res, "accepted", False)),
    57:                                order_id=getattr(res, "order_id", None),
    58:                                status=getattr(res, "status", None),
    59:                                reason=getattr(res, "reason", None))
    60:         except Exception as e:
    61:             return OrderResult(accepted=False, reason=str(e))
    62: 
    63:     # ---------- Fills ----------
    64:     def fetch_fills(self, symbol: str, order_id: str | None, limit: int = 50) -> list[dict]:
    65:         """
    66:         Normalise le format en liste de dicts {orderId, tradeId, price, qty, fee}
    67:         """
    68:         try:
    69:             raw = self.exchange.get_fills(symbol, order_id, limit)
    70:         except Exception:
    71:             return []
    72: 
    73:         items: list = []
    74:         if isinstance(raw, dict):
    75:             items = raw.get("data") or raw.get("result") or raw.get("fills") or []
    76:         elif isinstance(raw, (list, tuple)):
    77:             items = list(raw)
    78: 
    79:         out: list[dict] = []
    80:         for f in items:
    81:             if isinstance(f, dict):
    82:                 out.append({
    83:                     "orderId": f.get("orderId") or f.get("order_id") or "",
    84:                     "tradeId": f.get("tradeId") or f.get("trade_id") or "",
    85:                     "price": float(f.get("price", f.get("fillPrice", 0.0)) or 0.0),
    86:                     "qty": float(f.get("qty", f.get("size", f.get("fillQty", 0.0))) or 0.0),
    87:                     "fee": float(f.get("fee", f.get("fillFee", 0.0)) or 0.0),
    88:                 })
    89:             else:
    90:                 try:
    91:                     seq = list(f)
    92:                     out.append({
    93:                         "orderId": str(seq[0]) if seq else "",
    94:                         "tradeId": str(seq[1]) if len(seq) > 1 else "",
    95:                         "price": float(seq[2]) if len(seq) > 2 else 0.0,
    96:                         "qty": float(seq[3]) if len(seq) > 3 else 0.0,
    97:                         "fee": float(seq[4]) if len(seq) > 4 else 0.0,
    98:                     })
    99:                 except Exception:
   100:                     continue
   101:         return out

## scalper/live/position_fsm.py (last modified: 2025-08-23 20:57:14)
     1: # live/position_fsm.py
     2: from __future__ import annotations
     3: from dataclasses import dataclass
     4: from typing import Optional, Dict, Any, List
     5: 
     6: 
     7: STATE_FLAT = "FLAT"
     8: STATE_PENDING_ENTRY = "PENDING_ENTRY"
     9: STATE_OPEN = "OPEN"
    10: STATE_PENDING_EXIT = "PENDING_EXIT"
    11: 
    12: 
    13: @dataclass
    14: class PositionState:
    15:     symbol: str
    16:     state: str = STATE_FLAT
    17:     order_id: Optional[str] = None
    18:     side: Optional[str] = None   # "long" | "short"
    19:     qty: float = 0.0
    20:     entry: float = 0.0
    21: 
    22: 
    23: class PositionFSM:
    24:     """
    25:     FSM ultra-simple par symbole.
    26:     - set_pending_entry(order_id, side)
    27:     - reconcile(open_positions, fills) -> met à jour l'état à partir des données Bitget
    28:     """
    29: 
    30:     def __init__(self, symbols: List[str]) -> None:
    31:         self._by_symbol: Dict[str, PositionState] = {s: PositionState(s) for s in symbols}
    32: 
    33:     # -------- API utilisateur --------
    34:     def ensure_symbol(self, symbol: str) -> None:
    35:         if symbol not in self._by_symbol:
    36:             self._by_symbol[symbol] = PositionState(symbol)
    37: 
    38:     def set_pending_entry(self, symbol: str, order_id: str, side: str) -> None:
    39:         self.ensure_symbol(symbol)
    40:         st = self._by_symbol[symbol]
    41:         st.state = STATE_PENDING_ENTRY
    42:         st.order_id = order_id
    43:         st.side = side
    44: 
    45:     def mark_pending_exit(self, symbol: str) -> None:
    46:         self.ensure_symbol(symbol)
    47:         st = self._by_symbol[symbol]
    48:         st.state = STATE_PENDING_EXIT
    49: 
    50:     def force_flat(self, symbol: str) -> None:
    51:         self._by_symbol[symbol] = PositionState(symbol)
    52: 
    53:     # -------- Lecture --------
    54:     def get(self, symbol: str) -> PositionState:
    55:         self.ensure_symbol(symbol)
    56:         return self._by_symbol[symbol]
    57: 
    58:     def all(self) -> Dict[str, PositionState]:
    59:         return self._by_symbol
    60: 
    61:     # -------- Réconciliation --------
    62:     def reconcile(self, open_positions: List[Dict[str, Any]], fills: Dict[str, List[Dict[str, Any]]]) -> None:
    63:         """
    64:         open_positions: liste [{symbol, side, qty, avgEntryPrice}]
    65:         fills: dict symbol -> liste de fills [{orderId, price, qty, ...}]
    66:         """
    67:         # indexer positions ouvertes
    68:         idx_open = {p["symbol"]: p for p in open_positions if float(p.get("qty", 0.0)) > 0.0}
    69: 
    70:         for sym, st in self._by_symbol.items():
    71:             p = idx_open.get(sym)
    72: 
    73:             if st.state == STATE_PENDING_ENTRY:
    74:                 # si on voit des fills de l'ordre en attente -> OPEN
    75:                 f_list = fills.get(sym) or []
    76:                 qty_filled = sum(float(f.get("qty", 0.0)) for f in f_list if not st.order_id or str(f.get("orderId")) == str(st.order_id))
    77:                 if qty_filled > 0.0 or p:
    78:                     st.state = STATE_OPEN
    79:                     st.qty = float(p.get("qty", qty_filled)) if p else qty_filled
    80:                     st.entry = float(p.get("avgEntryPrice", f_list[0].get("price", 0.0) if f_list else 0.0)) if p else \
    81:                                float(f_list[0].get("price", 0.0)) if f_list else 0.0
    82:             elif st.state == STATE_OPEN:
    83:                 # si plus de position ouverte -> FLAT
    84:                 if not p:
    85:                     st.state = STATE_FLAT
    86:                     st.order_id = None
    87:                     st.side = None
    88:                     st.qty = 0.0
    89:                     st.entry = 0.0
    90:                 else:
    91:                     st.qty = float(p.get("qty", st.qty))
    92:                     st.entry = float(p.get("avgEntryPrice", st.entry))
    93:             elif st.state == STATE_PENDING_EXIT:
    94:                 # si plus de position -> FLAT ; sinon reste OPEN
    95:                 if not p:
    96:                     st.state = STATE_FLAT
    97:                     st.order_id = None
    98:                     st.side = None
    99:                     st.qty = 0.0
   100:                     st.entry = 0.0
   101:                 else:
   102:                     st.state = STATE_OPEN  # pas encore clos
   103:             else:
   104:                 # FLAT: si une position apparaît (cas reboot) -> OPEN
   105:                 if p:
   106:                     st.state = STATE_OPEN
   107:                     st.qty = float(p.get("qty", 0.0))
   108:                     st.entry = float(p.get("avgEntryPrice", 0.0))

## scalper/live/setup_wizard.py (last modified: 2025-08-23 20:57:14)
     1: from __future__ import annotations
     2: import asyncio, os
     3: from dataclasses import dataclass
     4: from typing import List, Dict, Optional, Callable
     5: from ..signals.factory import load_signal
     6: from ..backtest.runner import BacktestRunner
     7: from .notify import Notifier, CommandStream
     8: 
     9: @dataclass
    10: class SetupResult:
    11:     strategy: str
    12:     symbols: List[str]
    13:     timeframes: List[str]
    14:     risk_pct: float
    15:     accepted: bool
    16:     summary_path: str
    17: 
    18: class SetupWizard:
    19:     """
    20:     Wizard interactif Telegram avant lancement des trades.
    21:     Utilise Notifier (send/send_menu) + CommandStream (async iterator).
    22:     """
    23:     def __init__(self, notifier: Notifier, cmd_stream: CommandStream,
    24:                  ohlcv_loader_sync: Callable, out_dir: str = "out_bt_setup",
    25:                  admin_chat_id: Optional[int]=None):
    26:         self.notifier = notifier
    27:         self.cmd_stream = cmd_stream
    28:         self.loader = ohlcv_loader_sync
    29:         self.out_dir = out_dir
    30:         self.admin_chat_id = admin_chat_id
    31: 
    32:     async def _ask_list(self, prompt: str, choices: List[str], allow_multi=True) -> List[str]:
    33:         await self.notifier.send_menu(prompt, choices)
    34:         async for msg in self.cmd_stream:
    35:             txt = msg.strip()
    36:             if allow_multi and ("," in txt or " " in txt):
    37:                 sel = [t.strip() for t in txt.replace(" ", "").split(",") if t.strip()]
    38:                 return sel
    39:             if txt.isdigit():
    40:                 i = int(txt)-1
    41:                 if 0 <= i < len(choices):
    42:                     return [choices[i]]
    43:             if txt in choices:
    44:                 return [txt]
    45:             await self.notifier.send("Entrée invalide. Réessaie.")
    46: 
    47:     async def _ask_value(self, prompt: str, cast: Callable, default):
    48:         await self.notifier.send(f"{prompt} (défaut: {default})")
    49:         async for msg in self.cmd_stream:
    50:             txt = msg.strip()
    51:             if txt == "" or txt.lower() in ("d","defaut","default"):
    52:                 return default
    53:             try:
    54:                 return cast(txt)
    55:             except Exception:
    56:                 await self.notifier.send("Entrée invalide. Réessaie.")
    57: 
    58:     async def run(self, default_symbols: List[str], default_timeframes: List[str],
    59:                   default_strategy: str="current") -> SetupResult:
    60:         await self.notifier.send("🧪 Validation avant trading : choix strat/symbols/TF → backtest → validation.")
    61:         # 1) stratégie
    62:         strategies = ["current","ema_cross","vwap_break"]
    63:         [strategy] = await self._ask_list("Choisis la stratégie :", strategies, allow_multi=False)
    64: 
    65:         # 2) symboles
    66:         symbols = await self._ask_list("Sélectionne les symboles :", default_symbols, allow_multi=True)
    67: 
    68:         # 3) timeframes
    69:         timeframes = await self._ask_list("Sélectionne les timeframes :", default_timeframes, allow_multi=True)
    70: 
    71:         # 4) risk %
    72:         risk_pct = await self._ask_value("Risk % du solde (ex: 0.5 = 50%)", float, 0.5)
    73: 
    74:         # 5) période backtest
    75:         start = await self._ask_value("Date de début (YYYY-MM-DD)", str, "2024-01-01")
    76:         end   = await self._ask_value("Date de fin   (YYYY-MM-DD)", str, "2025-08-01")
    77: 
    78:         # 6) run backtest
    79:         from ..backtest.cli import parse_ts
    80:         start_ms, end_ms = parse_ts(start), parse_ts(end)
    81:         runner = BacktestRunner(self.loader, self.out_dir, strategy,
    82:                                 cfg={}, cash=10_000.0, risk_pct=risk_pct, max_conc=6)
    83:         res = await runner.run_all(symbols, timeframes, start_ms, end_ms)
    84: 
    85:         # 7) résumé
    86:         sum_path = os.path.join(self.out_dir, "metrics.json")
    87:         prop = res["proposal"]
    88:         lines = ["**Proposition** :"]
    89:         for sym, best in prop["per_symbol_best"].items():
    90:             lines.append(f"• {sym}: {best['timeframe']}  score={best['score']:.3f}  PF={best['pf']:.2f}  WR={best['winrate']:.1%}  DD={best['maxdd']:.1%}")
    91:         await self.notifier.send("\n".join(lines) + f"\nFichier: {sum_path}\n✅ Tape **ACCEPTER** pour lancer\n🔁 **MODIFIER** pour relancer\n❌ **ANNULER** pour quitter.")
    92: 
    93:         # 8) décision
    94:         async for msg in self.cmd_stream:
    95:             t = msg.strip().lower()
    96:             if t in ("accepter","accept","ok","go","start"):
    97:                 await self.notifier.send("✅ Validation reçue — passage en RUNNING.")
    98:                 return SetupResult(strategy, symbols, timeframes, risk_pct, True, sum_path)
    99:             if t in ("modifier","again","repeat"):
   100:                 return await self.run(default_symbols, default_timeframes, default_strategy=strategy)
   101:             if t in ("annuler","cancel","stop"):
   102:                 await self.notifier.send("❌ Annulé.")
   103:                 return SetupResult(strategy, symbols, timeframes, risk_pct, False, sum_path)

## scalper/live/state_store.py (last modified: 2025-08-23 20:57:14)
     1: # live/state_store.py
     2: from __future__ import annotations
     3: import json, os, time, asyncio
     4: from typing import Callable, Dict, Any
     5: 
     6: class StateStore:
     7:     """
     8:     Persistance légère de l'état (FSM + horodatages) dans un JSON.
     9:     - save_state(snapshot: dict) -> écrit sur disque
    10:     - load_state() -> dict
    11:     - task_autosave(get_snapshot: callable) -> boucle d’auto‑save
    12:     """
    13: 
    14:     def __init__(self, filepath: str, period_s: float = 10.0) -> None:
    15:         self.filepath = filepath
    16:         self.period_s = period_s
    17:         os.makedirs(os.path.dirname(self.filepath), exist_ok=True)
    18:         self._running = False
    19: 
    20:     # -------- I/O --------
    21:     def save_state(self, snapshot: Dict[str, Any]) -> None:
    22:         tmp = self.filepath + ".tmp"
    23:         with open(tmp, "w", encoding="utf-8") as f:
    24:             json.dump(snapshot, f, ensure_ascii=False, indent=2)
    25:         os.replace(tmp, self.filepath)
    26: 
    27:     def load_state(self) -> Dict[str, Any]:
    28:         if not os.path.exists(self.filepath):
    29:             return {}
    30:         try:
    31:             with open(self.filepath, "r", encoding="utf-8") as f:
    32:                 return json.load(f)
    33:         except Exception:
    34:             return {}
    35: 
    36:     # -------- Autosave --------
    37:     async def task_autosave(self, get_snapshot: Callable[[], Dict[str, Any]]):
    38:         self._running = True
    39:         while self._running:
    40:             try:
    41:                 snap = get_snapshot()
    42:                 snap["saved_at"] = int(time.time() * 1000)
    43:                 self.save_state(snap)
    44:             except Exception:
    45:                 pass
    46:             await asyncio.sleep(self.period_s)
    47: 
    48:     def stop(self): self._running = False

## scalper/live/telegram_async.py (last modified: 2025-08-23 20:57:14)
     1: from __future__ import annotations
     2: import time
     3: import requests
     4: import asyncio
     5: from typing import Optional, Dict, Any, List
     6: 
     7: 
     8: class TelegramAsync:
     9:     """
    10:     Client Telegram simple basé sur requests, utilisé de manière non bloquante via asyncio.to_thread.
    11:     Sans nouvelle dépendance.
    12:     """
    13:     def __init__(self, token: Optional[str], chat_id: Optional[str]) -> None:
    14:         self.token = token
    15:         self.chat_id = chat_id
    16:         self.base = f"https://api.telegram.org/bot{token}" if token else None
    17:         self._offset = 0
    18:         self._enabled = bool(token and chat_id)
    19: 
    20:     def enabled(self) -> bool:
    21:         return self._enabled
    22: 
    23:     # ---------- sync I/O (appelées via to_thread) ----------
    24:     def _send_message_sync(self, text: str) -> Dict[str, Any]:
    25:         if not self._enabled:
    26:             return {"ok": False, "reason": "disabled"}
    27:         url = f"{self.base}/sendMessage"
    28:         payload = {"chat_id": self.chat_id, "text": text}
    29:         try:
    30:             r = requests.post(url, json=payload, timeout=10)
    31:             return r.json()
    32:         except Exception as e:
    33:             return {"ok": False, "error": repr(e)}
    34: 
    35:     def _get_updates_sync(self, timeout_s: int = 30) -> Dict[str, Any]:
    36:         if not self._enabled:
    37:             return {"ok": True, "result": []}
    38:         url = f"{self.base}/getUpdates"
    39:         params = {"timeout": timeout_s, "offset": self._offset}
    40:         try:
    41:             r = requests.get(url, params=params, timeout=timeout_s + 5)
    42:             return r.json()
    43:         except Exception as e:
    44:             return {"ok": False, "error": repr(e), "result": []}
    45: 
    46:     # ---------- async wrappers ----------
    47:     async def send_message(self, text: str) -> None:
    48:         await asyncio.to_thread(self._send_message_sync, text)
    49: 
    50:     async def poll_commands(self, timeout_s: int = 30) -> List[Dict[str, Any]]:
    51:         data = await asyncio.to_thread(self._get_updates_sync, timeout_s)
    52:         if not data.get("ok"):
    53:             return []
    54:         out = []
    55:         for upd in data.get("result", []):
    56:             self._offset = max(self._offset, int(upd.get("update_id", 0)) + 1)
    57:             msg = upd.get("message") or {}
    58:             text = (msg.get("text") or "").strip()
    59:             if not text:
    60:                 continue
    61:             out.append({
    62:                 "date": msg.get("date"),
    63:                 "chat": str((msg.get("chat") or {}).get("id")),
    64:                 "text": text,
    65:                 "from": (msg.get("from") or {}).get("username") or (msg.get("from") or {}).get("first_name") or "unknown",
    66:             })
    67:         return out


## scalper/live/watchlist.py (last modified: 2025-08-24 03:12:00)
     1: # -*- coding: utf-8 -*-
     2: from __future__ import annotations
     3: from dataclasses import dataclass
     4: from typing import List
     5: 
     6: 
     7: @dataclass
     8: class WatchlistManager:
     9:     symbols: List[str]
    10: 
    11:     @classmethod
    12:     def from_env_or_default(cls) -> "WatchlistManager":
    13:         # Tu peux lire une variable d'env ici si tu veux surcharger
    14:         default = [
    15:             "BTCUSDT","ETHUSDT","SOLUSDT","BNBUSDT","XRPUSDT",
    16:             "DOGEUSDT","ADAUSDT","LTCUSDT","AVAXUSDT","LINKUSDT"
    17:         ]
    18:         return cls(default)

## scalper/logging_utils.py (last modified: 2025-08-23 20:57:14)
     1: """Logging helpers for the Scalp bot."""
     2: 
     3: from __future__ import annotations
     4: 
     5: import atexit
     6: import csv
     7: import json
     8: import os
     9: import sqlite3
    10: import time
    11: from pathlib import Path
    12: from typing import Any, Dict, List
    13: 
    14: 
    15: def get_jsonl_logger(path: str, max_bytes: int = 0, backup_count: int = 0):
    16:     """Return a callable that logs events as JSON lines.
    17: 
    18:     Parameters
    19:     ----------
    20:     path: str
    21:         Target file path for JSON lines.
    22:     max_bytes: int, optional
    23:         If >0, rotate the file when its size exceeds this value.
    24:     backup_count: int, optional
    25:         Number of rotated files to keep when ``max_bytes`` is set.
    26:     """
    27:     os.makedirs(os.path.dirname(path), exist_ok=True)
    28:     log_file = open(path, "a", encoding="utf-8")
    29: 
    30:     def _close_file() -> None:
    31:         try:
    32:             log_file.close()
    33:         except Exception:
    34:             pass
    35: 
    36:     atexit.register(_close_file)
    37: 
    38:     def _rotate() -> None:
    39:         nonlocal log_file
    40:         log_file.close()
    41:         for i in range(backup_count - 1, 0, -1):
    42:             src = f"{path}.{i}"
    43:             dst = f"{path}.{i + 1}"
    44:             if os.path.exists(src):
    45:                 os.replace(src, dst)
    46:         os.replace(path, f"{path}.1")
    47:         log_file = open(path, "a", encoding="utf-8")
    48: 
    49:     def _log(event: str, payload: Dict[str, Any]) -> None:
    50:         nonlocal log_file
    51:         payload = dict(payload or {})
    52:         payload["event"] = event
    53:         payload["ts"] = int(time.time() * 1000)
    54:         line = json.dumps(payload, ensure_ascii=False)
    55:         if max_bytes and backup_count > 0:
    56:             if log_file.tell() + len(line) + 1 > max_bytes:
    57:                 _rotate()
    58:         log_file.write(line + "\n")
    59:         log_file.flush()
    60: 
    61:     return _log
    62: 
    63: 
    64: class TradeLogger:
    65:     """Helper writing trade information to CSV and SQLite files."""
    66: 
    67:     fields = [
    68:         "pair",
    69:         "tf",
    70:         "dir",
    71:         "entry",
    72:         "sl",
    73:         "tp",
    74:         "score",
    75:         "reasons",
    76:         "pnl",
    77:     ]
    78: 
    79:     def __init__(self, csv_path: str, sqlite_path: str) -> None:
    80:         os.makedirs(os.path.dirname(csv_path), exist_ok=True)
    81:         self.csv_path = csv_path
    82:         self.sqlite_path = sqlite_path
    83: 
    84:         # Ensure CSV has header
    85:         if not os.path.exists(csv_path):
    86:             with open(csv_path, "w", newline="", encoding="utf-8") as f:
    87:                 writer = csv.DictWriter(f, fieldnames=self.fields)
    88:                 writer.writeheader()
    89: 
    90:         # Setup SQLite store
    91:         self.conn = sqlite3.connect(sqlite_path)
    92:         cur = self.conn.cursor()
    93:         cur.execute(
    94:             """
    95:             CREATE TABLE IF NOT EXISTS trades (
    96:                 pair TEXT,
    97:                 tf TEXT,
    98:                 dir TEXT,
    99:                 entry REAL,
   100:                 sl REAL,
   101:                 tp REAL,
   102:                 score REAL,
   103:                 reasons TEXT,
   104:                 pnl REAL
   105:             )
   106:             """
   107:         )
   108:         self.conn.commit()
   109:         atexit.register(self.conn.close)
   110: 
   111:     def log(self, data: Dict[str, Any]) -> None:
   112:         row = {k: data.get(k) for k in self.fields}
   113:         with open(self.csv_path, "a", newline="", encoding="utf-8") as f:
   114:             writer = csv.DictWriter(f, fieldnames=self.fields)
   115:             writer.writerow(row)
   116:         cur = self.conn.cursor()
   117:         cur.execute(
   118:             "INSERT INTO trades (pair, tf, dir, entry, sl, tp, score, reasons, pnl) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)",
   119:             (
   120:                 row["pair"],
   121:                 row["tf"],
   122:                 row["dir"],
   123:                 row["entry"],
   124:                 row["sl"],
   125:                 row["tp"],
   126:                 row["score"],
   127:                 row["reasons"],
   128:                 row["pnl"],
   129:             ),
   130:         )
   131:         self.conn.commit()
   132: 
   133: 
   134: BASE_DIR = Path(__file__).resolve().parents[2]
   135: 
   136: 
   137: def _append_csv(path: Path, fields: List[str], row: Dict[str, Any]) -> None:
   138:     """Append a row to ``path`` creating the file with ``fields`` if needed."""
   139:     path.parent.mkdir(parents=True, exist_ok=True)
   140:     file_exists = path.exists()
   141:     with path.open("a", newline="", encoding="utf-8") as f:
   142:         writer = csv.DictWriter(f, fieldnames=fields)
   143:         if not file_exists:
   144:             writer.writeheader()
   145:         writer.writerow({k: row.get(k) for k in fields})
   146: 
   147: 
   148: def log_position(data: Dict[str, Any]) -> None:
   149:     """Log a closed position to ``../positions.csv``."""
   150:     fields = [
   151:         "timestamp",
   152:         "pair",
   153:         "direction",
   154:         "entry",
   155:         "exit",
   156:         "pnl_pct",
   157:         "fee_rate",
   158:         "notes",
   159:     ]
   160:     _append_csv(BASE_DIR / "positions.csv", fields, data)
   161: 
   162: 
   163: def log_operation_memo(data: Dict[str, Any]) -> None:
   164:     """Log operation details to ``../operations_memo.csv``."""
   165:     fields = ["timestamp", "pair", "details"]
   166:     _append_csv(BASE_DIR / "operations_memo.csv", fields, data)


## scalper/metrics.py (last modified: 2025-08-23 20:57:14)
     1: """Utility metrics for trading calculations."""
     2: 
     3: from __future__ import annotations
     4: 
     5: 
     6: from typing import Iterable
     7: 
     8: __all__ = ["calc_pnl_pct", "calc_rsi", "calc_atr", "calc_macd", "backtest_position"]
     9: 
    10: 
    11: def calc_pnl_pct(
    12:     entry_price: float, exit_price: float, side: int, fee_rate: float = 0.0
    13: ) -> float:
    14:     """Return percentage PnL between entry and exit prices minus fees.
    15: 
    16: 
    17:     Parameters
    18:     ----------
    19:     entry_price: float
    20:         Trade entry price (>0).
    21:     exit_price: float
    22:         Trade exit price (>0).
    23:     side: int
    24:         +1 for long, -1 for short.
    25:     fee_rate: float, optional
    26:         Trading fee rate per operation (e.g., 0.0006 for 0.06%). The fee is
    27:         applied twice (entry + exit).
    28:     """
    29:     if entry_price <= 0 or exit_price <= 0:
    30:         raise ValueError("Prices must be positive")
    31:     if side not in (1, -1):
    32:         raise ValueError("side must be +1 (long) or -1 (short)")
    33: 
    34:     pnl = (exit_price - entry_price) / entry_price * 100.0 * side
    35:     fee_pct = fee_rate * 2 * 100.0  # entrée + sortie
    36:     return pnl - fee_pct
    37: 
    38: 
    39: def calc_rsi(prices: Iterable[float], period: int = 14) -> float:
    40:     """Compute the Relative Strength Index (RSI) using Wilder's smoothing.
    41: 
    42: 
    43:     Parameters
    44:     ----------
    45:     prices:
    46:         Ordered sequence of closing prices.
    47:     period:
    48:         Number of periods to use for the calculation. Must be positive and the
    49:         length of ``prices`` must be at least ``period + 1``.
    50:     """
    51: 
    52:     prices_list = [float(p) for p in prices]
    53: 
    54:     if period <= 0:
    55:         raise ValueError("period must be positive")
    56:     if len(prices_list) < period + 1:
    57: 
    58:         raise ValueError("len(prices) must be >= period + 1")
    59: 
    60:     gains: list[float] = []
    61:     losses: list[float] = []
    62:     for i in range(1, period + 1):
    63: 
    64:         diff = prices_list[i] - prices_list[i - 1]
    65: 
    66:         if diff >= 0:
    67:             gains.append(diff)
    68:             losses.append(0.0)
    69:         else:
    70:             gains.append(0.0)
    71:             losses.append(-diff)
    72: 
    73:     avg_gain = sum(gains) / period
    74:     avg_loss = sum(losses) / period
    75: 
    76:     for i in range(period + 1, len(prices_list)):
    77:         diff = prices_list[i] - prices_list[i - 1]
    78: 
    79:         gain = max(diff, 0.0)
    80:         loss = max(-diff, 0.0)
    81:         avg_gain = (avg_gain * (period - 1) + gain) / period
    82:         avg_loss = (avg_loss * (period - 1) + loss) / period
    83: 
    84:     if avg_gain == 0 and avg_loss == 0:
    85:         return 50.0
    86:     if avg_loss == 0:
    87:         return 100.0
    88:     if avg_gain == 0:
    89:         return 0.0
    90:     rs = avg_gain / avg_loss
    91:     return 100.0 - (100.0 / (1.0 + rs))
    92: 
    93: 
    94: def calc_atr(
    95:     highs: Iterable[float],
    96:     lows: Iterable[float],
    97:     closes: Iterable[float],
    98:     period: int = 14,
    99: ) -> float:
   100:     """Compute the Average True Range (ATR) using Wilder's smoothing.
   101: 
   102: 
   103:     Parameters
   104:     ----------
   105:     highs, lows, closes:
   106:         Ordered sequences of high, low and close prices. All sequences must
   107:         have the same length and contain at least ``period + 1`` elements.
   108:     period:
   109:         Number of periods to use for the calculation. Must be positive.
   110:     """
   111: 
   112:     highs_list = [float(h) for h in highs]
   113:     lows_list = [float(low) for low in lows]
   114:     closes_list = [float(c) for c in closes]
   115: 
   116:     length = len(highs_list)
   117:     if length != len(lows_list) or length != len(closes_list):
   118: 
   119:         raise ValueError("Input sequences must have the same length")
   120:     if period <= 0:
   121:         raise ValueError("period must be positive")
   122:     if length < period + 1:
   123:         raise ValueError("Input sequences must have at least period + 1 elements")
   124: 
   125:     trs: list[float] = []
   126:     for i in range(1, len(highs_list)):
   127:         tr = max(
   128:             highs_list[i] - lows_list[i],
   129:             abs(highs_list[i] - closes_list[i - 1]),
   130:             abs(lows_list[i] - closes_list[i - 1]),
   131:         )
   132:         trs.append(tr)
   133: 
   134:     atr = sum(trs[:period]) / period
   135:     for tr in trs[period:]:
   136:         atr = (atr * (period - 1) + tr) / period
   137:     return atr
   138: 
   139: 
   140: def calc_macd(
   141:     prices: Sequence[float],
   142:     fast: int = 12,
   143:     slow: int = 26,
   144:     signal: int = 9,
   145: ) -> tuple[float, float, float]:
   146:     """Return MACD, signal line and histogram values.
   147: 
   148:     The implementation computes exponential moving averages using Wilder's
   149:     smoothing. ``prices`` must contain at least ``slow + signal`` elements.
   150:     """
   151: 
   152:     prices_list = [float(p) for p in prices]
   153:     if fast <= 0 or slow <= 0 or signal <= 0:
   154:         raise ValueError("periods must be positive")
   155:     min_len = max(fast, slow) + signal
   156:     if len(prices_list) < min_len:
   157:         raise ValueError("len(prices) must be >= slow + signal")
   158: 
   159:     def _ema_series(series: Sequence[float], window: int) -> list[float]:
   160:         k = 2.0 / (window + 1.0)
   161:         out = [float(series[0])]
   162:         for x in series[1:]:
   163:             out.append(float(x) * k + out[-1] * (1.0 - k))
   164:         return out
   165: 
   166:     fast_ema = _ema_series(prices_list, fast)
   167:     slow_ema = _ema_series(prices_list, slow)
   168:     macd_series = [f - s for f, s in zip(fast_ema, slow_ema)]
   169:     signal_series = _ema_series(macd_series, signal)
   170:     macd_val = macd_series[-1]
   171:     signal_val = signal_series[-1]
   172:     hist = macd_val - signal_val
   173:     return macd_val, signal_val, hist
   174: 
   175: 
   176: def backtest_position(
   177:     prices: list[float], entry_idx: int, exit_idx: int, side: int
   178: ) -> bool:
   179:     """Run a basic backtest to verify a position's coherence.
   180: 
   181:     Parameters
   182:     ----------
   183:     prices: list[float]
   184:         Sequential list of prices to evaluate.
   185:     entry_idx: int
   186:         Index in ``prices`` where the position is opened.
   187:     exit_idx: int
   188:         Index in ``prices`` where the position is closed (must be > ``entry_idx``).
   189:     side: int
   190:         +1 for long, -1 for short.
   191: 
   192:     Returns
   193:     -------
   194:     bool
   195:         ``True`` if the resulting PnL is non-negative, meaning the position is
   196:         coherent with the direction of price movement. ``False`` otherwise.
   197:     """
   198:     if side not in (1, -1):
   199:         raise ValueError("side must be +1 (long) or -1 (short)")
   200:     if not (0 <= entry_idx < exit_idx < len(prices)):
   201:         raise ValueError(
   202:             "entry_idx and exit_idx must be valid and entry_idx < exit_idx"
   203:         )
   204: 
   205:     entry_price = float(prices[entry_idx])
   206:     exit_price = float(prices[exit_idx])
   207:     pnl = calc_pnl_pct(entry_price, exit_price, side)
   208:     return pnl >= 0.0


## scalper/pairs.py (last modified: 2025-08-23 20:57:14)
     1: """Utilities to select trading pairs and detect signals."""
     2: from __future__ import annotations
     3: from typing import Any, Dict, List, Optional, Callable
     4: from scalper.strategy import Signal
     5: 
     6: from scalper.bot_config import CONFIG
     7: from scalper.strategy import ema as default_ema, cross as default_cross
     8: from scalper.notifier import notify
     9: 
    10: 
    11: def get_trade_pairs(client: Any) -> List[Dict[str, Any]]:
    12:     """Return all trading pairs using the client's ``get_ticker`` method."""
    13:     tick = client.get_ticker()
    14:     data = tick.get("data") if isinstance(tick, dict) else []
    15:     if not data:
    16:         return []
    17:     return data if isinstance(data, list) else [data]
    18: 
    19: 
    20: def filter_trade_pairs(
    21:     client: Any,
    22:     *,
    23:     volume_min: float = 5_000_000,
    24:     max_spread_bps: float = 5.0,
    25:     top_n: int = 40,
    26: ) -> List[Dict[str, Any]]:
    27:     """Filter pairs by volume and spread."""
    28:     pairs = get_trade_pairs(client)
    29:     eligible: List[Dict[str, Any]] = []
    30: 
    31:     for info in pairs:
    32:         sym = info.get("symbol")
    33:         if not sym:
    34:             continue
    35:         try:
    36:             vol = float(info.get("volume", 0))
    37:         except (TypeError, ValueError):
    38:             continue
    39:         if vol < volume_min:
    40:             continue
    41:         try:
    42:             bid = float(info.get("bidPrice", 0))
    43:             ask = float(info.get("askPrice", 0))
    44:         except (TypeError, ValueError):
    45:             continue
    46:         if bid <= 0 or ask <= 0:
    47:             continue
    48:         spread_bps = (ask - bid) / ((ask + bid) / 2) * 10_000
    49:         if spread_bps >= max_spread_bps:
    50:             continue
    51:         eligible.append(info)
    52: 
    53:     eligible.sort(key=lambda row: float(row.get("volume", 0)), reverse=True)
    54:     return eligible[:top_n]
    55: 
    56: 
    57: def select_top_pairs(client: Any, top_n: int = 40, key: str = "volume") -> List[Dict[str, Any]]:
    58:     """Return ``top_n`` pairs sorted by ``key``."""
    59:     pairs = get_trade_pairs(client)
    60: 
    61:     def volume(row: Dict[str, Any]) -> float:
    62:         try:
    63:             return float(row.get(key, 0))
    64:         except (TypeError, ValueError):
    65:             return 0.0
    66: 
    67:     pairs.sort(key=volume, reverse=True)
    68:     return pairs[:top_n]
    69: 
    70: 
    71: def _ancienne_impl(
    72:     client: Any,
    73:     pairs: List[Dict[str, Any]],
    74:     *,
    75:     interval: str = "1m",
    76:     ema_fast_n: Optional[int] = None,
    77:     ema_slow_n: Optional[int] = None,
    78:     ema_func=default_ema,
    79:     cross_func=default_cross,
    80: ) -> List[Dict[str, Any]]:
    81:     """Original implementation returning dicts."""
    82:     ema_fast_n = ema_fast_n or CONFIG.get("EMA_FAST", 9)
    83:     ema_slow_n = ema_slow_n or CONFIG.get("EMA_SLOW", 21)
    84:     results: List[Dict[str, Any]] = []
    85: 
    86:     for info in pairs:
    87:         symbol = info.get("symbol")
    88:         if not symbol:
    89:             continue
    90:         k = client.get_kline(symbol, interval=interval)
    91:         closes = k.get("data", {}).get("close", []) if isinstance(k, dict) else []
    92:         if len(closes) < max(ema_fast_n, ema_slow_n) + 2:
    93:             continue
    94:         efull = ema_func(closes, ema_fast_n)
    95:         eslow = ema_func(closes, ema_slow_n)
    96:         signal = cross_func(efull[-1], eslow[-1], efull[-2], eslow[-2])
    97:         if signal == 1:
    98:             price_str = info.get("lastPr") or info.get("lastPrice") or 0.0
    99:             results.append({"symbol": symbol, "signal": "long", "price": float(price_str)})
   100:         elif signal == -1:
   101:             price_str = info.get("lastPr") or info.get("lastPrice") or 0.0
   102:             results.append({"symbol": symbol, "signal": "short", "price": float(price_str)})
   103:     return results
   104: 
   105: 
   106: def _to_signal(d: dict) -> Signal:
   107:     side = 1 if d.get("signal") in ("long", "buy", 1, True) else -1
   108:     return Signal(
   109:         symbol=d.get("symbol"),
   110:         side=side,
   111:         entry=float(d.get("price", d.get("entry", 0))),
   112:         sl=float(d.get("sl", 0)),
   113:         tp1=float(d.get("tp1", 0)) or None,
   114:         tp2=float(d.get("tp2", 0)) or None,
   115:         score=d.get("score"),
   116:         quality=d.get("quality"),
   117:         reasons=d.get("reasons", []),
   118:     )
   119: 
   120: 
   121: def find_trade_positions(
   122:     client: Any,
   123:     pairs: List[Dict[str, Any]],
   124:     *,
   125:     interval: str = "1m",
   126:     ema_fast_n: Optional[int] = None,
   127:     ema_slow_n: Optional[int] = None,
   128:     ema_func=default_ema,
   129:     cross_func=default_cross,
   130: ) -> List[Signal]:
   131:     raw = _ancienne_impl(
   132:         client,
   133:         pairs,
   134:         interval=interval,
   135:         ema_fast_n=ema_fast_n,
   136:         ema_slow_n=ema_slow_n,
   137:         ema_func=ema_func,
   138:         cross_func=cross_func,
   139:     )
   140:     return [_to_signal(x) for x in raw]
   141: 
   142: 
   143: def send_selected_pairs(
   144:     client: Any,
   145:     top_n: int = 40,
   146:     *,
   147:     select_fn: Callable[[Any, int], List[Dict[str, Any]]] = select_top_pairs,
   148:     notify_fn: Callable[[str, Optional[Dict[str, Any]]], None] = notify,
   149: ) -> Dict[str, str]:
   150:     """Fetch top pairs, drop USD/USDT/USDC duplicates and notify their list.
   151: 
   152:     Returns the payload sent to ``notify_fn``. The mapping contains the
   153:     comma-separated symbols for each color group (``green``, ``orange`` and
   154:     ``red``) or an empty dictionary when no pairs are available.
   155:     """
   156: 
   157:     def split_symbol(sym: str) -> tuple[str, str]:
   158:         if "_" in sym:
   159:             left, right = sym.split("_", 1)
   160:             # Legacy style: BTC_USDT
   161:             if len(right) <= 4:
   162:                 return left, right
   163:             # Bitget futures style: BTCUSDT_UMCBL
   164:             main = left
   165:             if main.endswith("USDT"):
   166:                 return main[:-4], "USDT"
   167:             if main.endswith("USDC"):
   168:                 return main[:-4], "USDC"
   169:             if main.endswith("USD"):
   170:                 return main[:-3], "USD"
   171:             return main, ""
   172:         if sym.endswith("USDT"):
   173:             return sym[:-4], "USDT"
   174:         if sym.endswith("USDC"):
   175:             return sym[:-4], "USDC"
   176:         if sym.endswith("USD"):
   177:             return sym[:-3], "USD"
   178:         return sym, ""
   179: 
   180:     pairs = select_fn(client, top_n=top_n * 3)
   181:     allowed = {s.split("_")[0].upper() for s in CONFIG.get("ALLOWED_SYMBOLS", [])}
   182:     by_base: Dict[str, Dict[str, Any]] = {}
   183:     for info in pairs:
   184:         sym = info.get("symbol")
   185:         if not sym:
   186:             continue
   187:         norm_sym = sym.split("_")[0].upper()
   188:         if allowed and norm_sym not in allowed:
   189:             continue
   190:         base, quote = split_symbol(sym)
   191:         existing = by_base.get(base)
   192:         priority = {"USDT": 3, "USDC": 2, "USD": 1}
   193:         if existing is None or priority.get(quote, 0) > priority.get(existing["quote"], 0):
   194:             by_base[base] = {"data": info, "quote": quote}
   195: 
   196:     unique = sorted(
   197:         (v["data"] for v in by_base.values()),
   198:         key=lambda row: float(row.get("volume", 0)),
   199:         reverse=True,
   200:     )
   201:     symbols: list[str] = []
   202:     for row in unique[:top_n]:
   203:         sym = row.get("symbol")
   204:         if not sym:
   205:             continue
   206:         base, _ = split_symbol(sym)
   207:         symbols.append(base)
   208:     if symbols:
   209:         n = len(symbols)
   210:         third = max(n // 3, 1)
   211:         green = symbols[:third]
   212:         orange = symbols[third : 2 * third]
   213:         red = symbols[2 * third :]
   214:         payload: Dict[str, str] = {}
   215:         if green:
   216:             payload["green"] = ", ".join(green)
   217:         if orange:
   218:             payload["orange"] = ", ".join(orange)
   219:         if red:
   220:             payload["red"] = ", ".join(red)
   221:         notify_fn("pair_list", payload)
   222:         return payload
   223:     return {}
   224: 
   225: 
   226: def heat_score(volatility: float, volume: float, news: bool = False) -> float:
   227:     """Return a heat score combining volatility, volume and a news flag."""
   228:     mult = 2.0 if news else 1.0
   229:     return volatility * volume * mult
   230: 
   231: 
   232: def select_top_heat_pairs(
   233:     pairs: List[Dict[str, Any]], *, top_n: int = 3
   234: ) -> List[Dict[str, Any]]:
   235:     """Return ``top_n`` pairs ranked by ``heat_score``."""
   236: 
   237:     scored: List[Dict[str, Any]] = []
   238:     for info in pairs:
   239:         try:
   240:             vol = float(info.get("volatility", 0))
   241:             volume = float(info.get("volume", 0))
   242:         except (TypeError, ValueError):
   243:             continue
   244:         score = heat_score(vol, volume, bool(info.get("news")))
   245:         row = dict(info)
   246:         row["heat_score"] = score
   247:         scored.append(row)
   248: 
   249:     scored.sort(key=lambda r: r["heat_score"], reverse=True)
   250:     return scored[:top_n]
   251: 
   252: 
   253: def decorrelate_pairs(
   254:     pairs: List[Dict[str, Any]],
   255:     corr: Dict[str, Dict[str, float]],
   256:     *,
   257:     threshold: float = 0.8,
   258:     top_n: int = 3,
   259: ) -> List[Dict[str, Any]]:
   260:     """Return top pairs while avoiding highly correlated symbols.
   261: 
   262:     ``corr`` is a mapping of pair symbol to correlation with other symbols.  Two
   263:     pairs are considered too correlated when the absolute value of the
   264:     correlation exceeds ``threshold``.
   265:     """
   266: 
   267:     selected: List[Dict[str, Any]] = []
   268:     for info in select_top_heat_pairs(pairs, top_n=len(pairs)):
   269:         sym = info.get("symbol")
   270:         if not sym:
   271:             continue
   272:         if all(abs(corr.get(sym, {}).get(p["symbol"], 0.0)) < threshold for p in selected):
   273:             selected.append(info)
   274:         if len(selected) >= top_n:
   275:             break
   276:     return selected


## scalper/positions/__init__.py (last modified: 2025-08-23 20:57:14)


## scalper/positions/state.py (last modified: 2025-08-23 20:57:14)
     1: from __future__ import annotations
     2: from dataclasses import dataclass, field
     3: from enum import Enum, auto
     4: from typing import List, Optional
     5: import time
     6: 
     7: class PositionStatus(Enum):
     8:     IDLE = auto()
     9:     PENDING_ENTRY = auto()
    10:     OPEN = auto()
    11:     PENDING_EXIT = auto()
    12:     CLOSED = auto()
    13: 
    14: class PositionSide(Enum):
    15:     LONG = 1
    16:     SHORT = -1
    17: 
    18: @dataclass
    19: class Fill:
    20:     order_id: str
    21:     trade_id: str
    22:     price: float
    23:     qty: float
    24:     fee: float
    25:     ts: int
    26: 
    27: @dataclass
    28: class PositionState:
    29:     symbol: str
    30:     side: PositionSide
    31:     status: PositionStatus = PositionStatus.IDLE
    32:     entry_order_id: Optional[str] = None
    33:     exit_order_id: Optional[str] = None
    34:     req_qty: float = 0.0
    35:     filled_qty: float = 0.0
    36:     avg_entry_price: float = 0.0
    37:     avg_exit_price: float = 0.0
    38:     sl: Optional[float] = None
    39:     tp: Optional[float] = None
    40:     realized_pnl: float = 0.0
    41:     fees: float = 0.0
    42:     opened_ts: Optional[int] = None
    43:     closed_ts: Optional[int] = None
    44:     fills: List[Fill] = field(default_factory=list)
    45:     last_sync_ts: int = field(default_factory=lambda: int(time.time()*1000))
    46: 
    47:     def apply_fill_entry(self, f: Fill) -> None:
    48:         self.fills.append(f)
    49:         self.filled_qty += f.qty
    50:         # moyenne pondérée
    51:         notional = self.avg_entry_price * (self.filled_qty - f.qty) + f.price * f.qty
    52:         self.avg_entry_price = notional / max(1e-12, self.filled_qty)
    53:         self.fees += abs(f.fee)
    54:         if self.opened_ts is None:
    55:             self.opened_ts = f.ts
    56:         if self.filled_qty > 1e-12:
    57:             self.status = PositionStatus.OPEN
    58: 
    59:     def apply_fill_exit(self, f: Fill) -> None:
    60:         self.fills.append(f)
    61:         qty = min(self.filled_qty, f.qty)
    62:         # realized pnl sur la quantité fermée
    63:         if self.side == PositionSide.LONG:
    64:             self.realized_pnl += (f.price - self.avg_entry_price) * qty
    65:         else:
    66:             self.realized_pnl += (self.avg_entry_price - f.price) * qty
    67:         self.fees += abs(f.fee)
    68:         self.filled_qty = max(0.0, self.filled_qty - qty)
    69:         # moyenne de sortie indicative
    70:         closed_q = (self.req_qty - self.filled_qty)
    71:         self.avg_exit_price = ((self.avg_exit_price * (closed_q - qty)) + f.price * qty) / max(1e-12, closed_q)
    72:         if self.filled_qty <= 1e-12:
    73:             self.status = PositionStatus.CLOSED
    74:             self.closed_ts = f.ts
    75: 


## scalper/risk/__init__.py (last modified: 2025-08-23 20:57:14)
     1: # scalp/risk/__init__.py
     2: from .manager import (
     3:     Caps,
     4:     compute_size,
     5:     calc_position_size,  # alias legacy
     6:     RiskManager,         # shim legacy
     7: )
     8: 
     9: __all__ = ["Caps", "compute_size", "calc_position_size", "RiskManager"]

## scalper/risk/manager.py (last modified: 2025-08-23 20:57:14)
     1: # scalp/risk/manager.py
     2: from __future__ import annotations
     3: from dataclasses import dataclass
     4: from typing import Optional, Dict, Any
     5: 
     6: @dataclass
     7: class Caps:
     8:     min_qty: float = 0.0
     9:     min_notional: float = 0.0
    10:     max_leverage: float = 20.0
    11: 
    12: def _get_caps(caps_by_symbol: Optional[Dict[str, Any]], symbol: str) -> Caps:
    13:     if not caps_by_symbol:
    14:         return Caps()
    15:     c = caps_by_symbol.get(symbol, {})
    16:     return Caps(
    17:         min_qty=float(c.get("min_qty", 0.0) or 0.0),
    18:         min_notional=float(c.get("min_notional", 0.0) or 0.0),
    19:         max_leverage=float(c.get("max_leverage", 20.0) or 20.0),
    20:     )
    21: 
    22: def compute_size(
    23:     *,
    24:     symbol: str,
    25:     price: float,
    26:     balance_cash: float,
    27:     risk_pct: float = 0.5,
    28:     caps_by_symbol: Optional[Dict[str, Any]] = None,
    29: ) -> float:
    30:     """Sizing robuste avec gardes min_notional / min_qty."""
    31:     price = max(1e-9, float(price))
    32:     balance_cash = max(0.0, float(balance_cash))
    33:     risk_pct = max(0.0, float(risk_pct))
    34: 
    35:     notionnel = balance_cash * risk_pct
    36:     qty = notionnel / price
    37: 
    38:     caps = _get_caps(caps_by_symbol, symbol)
    39:     if caps.min_notional > 0 and (qty * price) < caps.min_notional:
    40:         qty = caps.min_notional / price
    41:     if caps.min_qty > 0 and qty < caps.min_qty:
    42:         qty = caps.min_qty
    43:     return max(0.0, qty)
    44: 
    45: # --- Shims pour compatibilité ancienne API -----------------------------------
    46: 
    47: def calc_position_size(symbol: str, price: float, balance_cash: float,
    48:                        risk_pct: float = 0.5,
    49:                        caps_by_symbol: Optional[Dict[str, Any]] = None) -> float:
    50:     """Alias legacy → compute_size."""
    51:     return compute_size(
    52:         symbol=symbol, price=price, balance_cash=balance_cash,
    53:         risk_pct=risk_pct, caps_by_symbol=caps_by_symbol
    54:     )
    55: 
    56: class RiskManager:
    57:     """
    58:     Shim minimal compatible avec l'ancien code:
    59:       rm = RiskManager(risk_pct=0.5, caps_by_symbol={...})
    60:       qty = rm.size(symbol, price, balance_cash)
    61:     """
    62:     def __init__(self, risk_pct: float = 0.5, caps_by_symbol: Optional[Dict[str, Any]] = None):
    63:         self.risk_pct = float(risk_pct)
    64:         self.caps_by_symbol = caps_by_symbol or {}
    65: 
    66:     def size(self, symbol: str, price: float, balance_cash: float) -> float:
    67:         return compute_size(
    68:             symbol=symbol, price=price, balance_cash=balance_cash,
    69:             risk_pct=self.risk_pct, caps_by_symbol=self.caps_by_symbol
    70:         )

## scalper/selection/__init__.py (last modified: 2025-08-23 20:57:14)
     1: """Pair selection helpers for the Scalp bot.
     2: 
     3: This package exposes two utilities used during the preparation phase of the
     4: trading strategy:
     5: 
     6: ``scan_pairs``
     7:     Performs the first level market scan by filtering pairs based on volume,
     8:     spread and hourly volatility.
     9: 
    10: ``select_active_pairs``
    11:     Refines a list of pairs by keeping only those showing an EMA20/EMA50
    12:     crossover and a sufficiently high ATR.
    13: """
    14: 
    15: from .scanner import scan_pairs
    16: from .momentum import select_active_pairs
    17: 
    18: __all__ = ["scan_pairs", "select_active_pairs"]
    19: 


## scalper/selection/momentum.py (last modified: 2025-08-23 20:57:14)
     1: """Utilities to select pairs exhibiting strong momentum."""
     2: 
     3: from __future__ import annotations
     4: 
     5: from typing import Any, Dict, List, Sequence
     6: 
     7: from ..metrics import calc_atr
     8: 
     9: 
    10: def ema(series: Sequence[float], window: int) -> List[float]:
    11:     """Simple exponential moving average implementation."""
    12: 
    13:     if window <= 1 or not series:
    14:         return list(series)
    15:     k = 2.0 / (window + 1.0)
    16:     out: List[float] = [float(series[0])]
    17:     prev = out[0]
    18:     for x in series[1:]:
    19:         prev = float(x) * k + prev * (1.0 - k)
    20:         out.append(prev)
    21:     return out
    22: 
    23: 
    24: def cross(last_fast: float, last_slow: float, prev_fast: float, prev_slow: float) -> int:
    25:     """Return 1 if a bullish cross occurred, -1 for bearish, 0 otherwise."""
    26: 
    27:     if prev_fast <= prev_slow and last_fast > last_slow:
    28:         return 1
    29:     if prev_fast >= prev_slow and last_fast < last_slow:
    30:         return -1
    31:     return 0
    32: 
    33: 
    34: def _quantile(values: Sequence[float], q: float) -> float:
    35:     """Return the *q* quantile of *values* (0 <= q <= 1)."""
    36: 
    37:     if not values:
    38:         return 0.0
    39:     q = min(max(q, 0.0), 1.0)
    40:     vals = sorted(values)
    41:     idx = int((len(vals) - 1) * q)
    42:     return vals[idx]
    43: 
    44: 
    45: def select_active_pairs(
    46:     client: Any,
    47:     pairs: Sequence[Dict[str, Any]],
    48:     *,
    49:     interval: str = "Min5",
    50:     ema_fast: int = 20,
    51:     ema_slow: int = 50,
    52:     atr_period: int = 14,
    53:     atr_quantile: float = 0.5,
    54:     top_n: int = 5,
    55: ) -> List[Dict[str, Any]]:
    56:     """Return pairs with an EMA crossover and high ATR.
    57: 
    58:     Only pairs where ``EMA20`` crosses ``EMA50`` on the latest candle are kept.
    59:     Among those candidates, the Average True Range is computed and only pairs
    60:     whose ATR is above the provided quantile are returned.  The resulting
    61:     dictionaries include an ``atr`` key for convenience.
    62:     """
    63: 
    64:     candidates: List[Dict[str, Any]] = []
    65:     atrs: List[float] = []
    66: 
    67:     for info in pairs:
    68:         sym = info.get("symbol")
    69:         if not sym:
    70:             continue
    71:         k = client.get_kline(sym, interval=interval)
    72:         kdata = k.get("data") if isinstance(k, dict) else {}
    73:         closes = kdata.get("close", [])
    74:         highs = kdata.get("high", [])
    75:         lows = kdata.get("low", [])
    76:         if len(closes) < max(ema_slow, atr_period) + 2:
    77:             continue
    78:         efast = ema(closes, ema_fast)
    79:         eslow = ema(closes, ema_slow)
    80:         if cross(efast[-1], eslow[-1], efast[-2], eslow[-2]) == 0:
    81:             continue
    82:         atr_val = calc_atr(highs, lows, closes, atr_period)
    83:         row = dict(info)
    84:         row["atr"] = atr_val
    85:         candidates.append(row)
    86:         atrs.append(atr_val)
    87: 
    88:     if not candidates:
    89:         return []
    90: 
    91:     threshold = _quantile(atrs, atr_quantile)
    92:     selected = [row for row in candidates if row["atr"] >= threshold]
    93:     selected.sort(key=lambda r: r["atr"], reverse=True)
    94:     return selected[:top_n]
    95: 
    96: 
    97: __all__ = ["select_active_pairs"]
    98: 


## scalper/selection/scanner.py (last modified: 2025-08-23 20:57:14)
     1: """Utilities for scanning tradable pairs on the exchange."""
     2: 
     3: from __future__ import annotations
     4: 
     5: from typing import Any, Dict, List
     6: 
     7: 
     8: def scan_pairs(
     9:     client: Any,
    10:     *,
    11:     volume_min: float = 5_000_000,
    12:     max_spread_bps: float = 5.0,
    13:     min_hourly_vol: float = 0.0,
    14:     top_n: int = 40,
    15: ) -> List[Dict[str, Any]]:
    16:     """Return pairs satisfying basic liquidity and volatility filters.
    17: 
    18:     Parameters
    19:     ----------
    20:     client: Any
    21:         Client instance exposing ``get_ticker`` and ``get_kline`` methods.
    22:     volume_min: float, optional
    23:         Minimum 24h volume required to keep a pair.
    24:     max_spread_bps: float, optional
    25:         Maximum allowed bid/ask spread expressed in basis points.
    26:     min_hourly_vol: float, optional
    27:         Minimum volatility over the last hour expressed as ``(high - low) /
    28:         close``.  When set to ``0`` the filter is disabled.
    29:     top_n: int, optional
    30:         Limit the number of returned pairs.
    31:     """
    32: 
    33:     tick = client.get_ticker()
    34:     data = tick.get("data") if isinstance(tick, dict) else []
    35:     if not isinstance(data, list):
    36:         data = [data]
    37: 
    38:     eligible: List[Dict[str, Any]] = []
    39: 
    40:     for row in data:
    41:         sym = row.get("symbol")
    42:         if not sym:
    43:             continue
    44:         try:
    45:             vol = float(row.get("volume", 0))
    46:             bid = float(row.get("bidPrice", 0))
    47:             ask = float(row.get("askPrice", 0))
    48:         except (TypeError, ValueError):
    49:             continue
    50:         if vol < volume_min or bid <= 0 or ask <= 0:
    51:             continue
    52:         spread_bps = (ask - bid) / ((ask + bid) / 2.0) * 10_000
    53:         if spread_bps >= max_spread_bps:
    54:             continue
    55: 
    56:         if min_hourly_vol > 0:
    57:             k = client.get_kline(sym, interval="Min60")
    58:             kdata = k.get("data") if isinstance(k, dict) else {}
    59:             highs = kdata.get("high", [])
    60:             lows = kdata.get("low", [])
    61:             closes = kdata.get("close", [])
    62:             if not highs or not lows or not closes:
    63:                 continue
    64:             try:
    65:                 h = float(highs[-1])
    66:                 l = float(lows[-1])
    67:                 c = float(closes[-1])
    68:             except (TypeError, ValueError):
    69:                 continue
    70:             hourly_vol = (h - l) / c if c else 0.0
    71:             if hourly_vol < min_hourly_vol:
    72:                 continue
    73: 
    74:         eligible.append(row)
    75: 
    76:     eligible.sort(key=lambda r: float(r.get("volume", 0)), reverse=True)
    77:     return eligible[:top_n]
    78: 
    79: 
    80: __all__ = ["scan_pairs"]
    81: 


## scalper/selfcheck.py (last modified: 2025-08-23 20:57:14)
     1: # scalper/selfcheck.py
     2: from __future__ import annotations
     3: import os, sys, importlib, traceback
     4: from pathlib import Path
     5: 
     6: NOTEBOOKS = Path("/notebooks")
     7: REPO = (NOTEBOOKS / "scalp") if NOTEBOOKS.exists() else Path(__file__).resolve().parents[2]
     8: 
     9: def _mask(val: str) -> str:
    10:     if not val: return ""
    11:     return (val[:3] + "…" + val[-3:]) if len(val) > 6 else "********"
    12: 
    13: def _try_import(modname: str):
    14:     try:
    15:         m = importlib.import_module(modname)
    16:         return True, m
    17:     except Exception:
    18:         return False, traceback.format_exc()
    19: 
    20: def preflight(verbose: bool = False) -> list[str]:
    21:     """
    22:     Retourne la liste des 'issues' trouvées (vide si tout est OK).
    23:     Ne lève pas d'exception. N'écrit que de l'info lisible.
    24:     """
    25:     issues: list[str] = []
    26:     # s'assurer que le repo est bien dans sys.path
    27:     if str(REPO) not in sys.path:
    28:         sys.path.insert(0, str(REPO))
    29: 
    30:     print("=== SCALPER PREFLIGHT ===")
    31:     print(f"[i] Repo: {REPO}")
    32:     print(f"[i] Python: {sys.version.split()[0]}")
    33: 
    34:     # backtest API
    35:     ok, mod = _try_import("scalper.backtest")
    36:     if not ok:
    37:         print("[✗] Import scalper.backtest KO")
    38:         if verbose: print(mod)  # ici 'mod' contient la trace
    39:         issues.append("backtest import")
    40:     else:
    41:         has_single = hasattr(mod, "run_single")
    42:         has_multi  = hasattr(mod, "run_multi")
    43:         print(f"[✓] scalper.backtest: run_single={has_single} run_multi={has_multi}")
    44:         if not (has_single and has_multi):
    45:             issues.append("backtest API incomplète")
    46: 
    47:     # trade_utils
    48:     ok, mod = _try_import("scalper.trade_utils")
    49:     if not ok:
    50:         print("[✗] Import scalper.trade_utils KO")
    51:         if verbose: print(mod)
    52:         issues.append("trade_utils import")
    53:     else:
    54:         print(f"[✓] scalper.trade_utils: compute_position_size={'compute_position_size' in dir(mod)}")
    55: 
    56:     # fees
    57:     ok, mod = _try_import("scalper.exchange.fees")
    58:     if not ok:
    59:         print("[✗] Import scalper.exchange.fees KO")
    60:         if verbose: print(mod)
    61:         issues.append("fees import")
    62:     else:
    63:         need = {"get_fee", "load_bitget_fees"}
    64:         miss = [n for n in need if not hasattr(mod, n)]
    65:         if miss: issues.append("fees API manquante: " + ",".join(miss))
    66:         print("[✓] scalper.exchange.fees OK")
    67: 
    68:     # notify/commands/backtest_telegram/orchestrator
    69:     for name, required in [
    70:         ("scalper.live.notify", ("build_notifier_and_stream",)),
    71:         ("scalper.live.commands", ("CommandHandler",)),
    72:         ("scalper.live.backtest_telegram", ("handle_backtest_command",)),
    73:         ("scalper.live.orchestrator", ("run_orchestrator", "Orchestrator")),
    74:     ]:
    75:         ok, mod = _try_import(name)
    76:         if not ok:
    77:             print(f"[✗] Import {name} KO")
    78:             if verbose: print(mod)
    79:             issues.append(f"{name} import")
    80:         else:
    81:             miss = [a for a in required if not hasattr(mod, a)]
    82:             if miss: issues.append(f"{name} API manquante: {','.join(miss)}")
    83:             print(f"[✓] {name} OK")
    84: 
    85:     # ENV (masqué)
    86:     tg_t = os.getenv("TELEGRAM_BOT_TOKEN", "")
    87:     tg_c = os.getenv("TELEGRAM_CHAT_ID", "")
    88:     gu   = os.getenv("GIT_USER", "")
    89:     gt   = os.getenv("GIT_TOKEN", "")
    90:     print("\n-- ENV --")
    91:     print(f"  TELEGRAM_BOT_TOKEN: {_mask(tg_t)} {'(ABSENT)' if not tg_t else ''}")
    92:     print(f"  TELEGRAM_CHAT_ID  : {_mask(tg_c)} {'(ABSENT)' if not tg_c else ''}")
    93:     print(f"  GIT_USER          : {gu or '(ABSENT)'}")
    94:     print(f"  GIT_TOKEN         : {_mask(gt)} {'(ABSENT)' if not gt else ''}")
    95: 
    96:     # Data
    97:     data_dir = (REPO / "data")
    98:     print("\n-- DATA --")
    99:     if data_dir.exists():
   100:         csvs = list(data_dir.glob("*.csv"))
   101:         print(f"  {len(csvs)} CSV trouvé(s) dans data/ (OK si tu backtestes via CSV)")
   102:     else:
   103:         print("  data/ absent (OK si loader API)")
   104: 
   105:     return issues
   106: 
   107: def preflight_or_die(verbose: bool = False) -> None:
   108:     issues = preflight(verbose=verbose)
   109:     if issues:
   110:         print("\n[✗] Préflight a détecté des problèmes :")
   111:         for it in issues: print("   -", it)
   112:         print("\nConseils :")
   113:         print(" - Vérifie les fichiers remplacés (backtest/__init__.py, trade_utils.py, exchange/fees.py).")
   114:         print(" - Évite d'importer optimize/walkforward dans backtest/__init__.py.")
   115:         print(" - Charge /notebooks/.env si TELEGRAM/GIT sont absents (source /notebooks/.env).")
   116:         raise SystemExit(1)
   117:     print("\n[✓] Préflight OK — démarrage du bot.")

## scalper/services/__init__.py (last modified: 2025-08-23 20:57:14)


## scalper/services/data_cache.py (last modified: 2025-08-23 20:57:14)
     1: # scalper/services/data_cache.py
     2: from __future__ import annotations
     3: 
     4: import asyncio
     5: import csv
     6: import os
     7: import time
     8: from typing import Iterable, List, Optional, Tuple, Dict
     9: 
    10: # ---------------------------------------------------------------------
    11: # Réglages via env (valeurs sûres par défaut)
    12: # ---------------------------------------------------------------------
    13: DATA_DIR = os.getenv("DATA_DIR", "/notebooks/data")           # dossier PERSISTANT (hors-git)
    14: CSV_MAX_AGE = int(os.getenv("CSV_MAX_AGE_SECONDS", "0"))      # 0 = auto (en fonction du TF)
    15: CSV_MIN_ROWS = int(os.getenv("CSV_MIN_ROWS", "200"))          # minimum de lignes attendues
    16: STALE_FACTOR = float(os.getenv("CSV_STALE_FACTOR", "6"))      # âge max = STALE_FACTOR * tf_sec
    17: PREFETCH_CONC = int(os.getenv("CSV_PREFETCH_CONC", "4"))      # concurrence préchauffage
    18: 
    19: os.makedirs(DATA_DIR, exist_ok=True)
    20: 
    21: 
    22: # ---------------------------------------------------------------------
    23: # Helpers
    24: # ---------------------------------------------------------------------
    25: def parse_timeframe_to_seconds(tf: str) -> int:
    26:     tf = tf.strip().lower()
    27:     unit = tf[-1]
    28:     try:
    29:         n = int(tf[:-1])
    30:     except Exception as e:
    31:         raise ValueError(f"timeframe invalide: {tf}") from e
    32:     if unit == "m":
    33:         return n * 60
    34:     if unit == "h":
    35:         return n * 3600
    36:     if unit == "d":
    37:         return n * 86400
    38:     raise ValueError(f"timeframe invalide: {tf}")
    39: 
    40: 
    41: def csv_path(symbol: str, timeframe: str) -> str:
    42:     return os.path.join(DATA_DIR, f"{symbol}-{timeframe}.csv")
    43: 
    44: 
    45: def read_csv_ohlcv(path: str) -> List[Tuple[int, float, float, float, float, float]]:
    46:     rows: List[Tuple[int, float, float, float, float, float]] = []
    47:     if not os.path.exists(path):
    48:         return rows
    49:     with open(path, "r", newline="") as f:
    50:         r = csv.reader(f)
    51:         header = next(r, None)  # accepte avec ou sans header
    52:         for line in r:
    53:             if not line:
    54:                 continue
    55:             ts, o, h, l, c, v = line[:6]
    56:             rows.append((int(ts), float(o), float(h), float(l), float(c), float(v)))
    57:     return rows
    58: 
    59: 
    60: def write_csv_ohlcv(path: str, data: Iterable[Tuple[int, float, float, float, float, float]]) -> None:
    61:     first = not os.path.exists(path)
    62:     os.makedirs(os.path.dirname(path), exist_ok=True)
    63:     with open(path, "a", newline="") as f:
    64:         w = csv.writer(f)
    65:         if first:
    66:             w.writerow(["timestamp", "open", "high", "low", "close", "volume"])
    67:         for row in data:
    68:             w.writerow(row)
    69: 
    70: 
    71: def last_ts(rows: List[Tuple[int, float, float, float, float, float]]) -> Optional[int]:
    72:     return rows[-1][0] if rows else None
    73: 
    74: 
    75: # ---------------------------------------------------------------------
    76: # Fetch CCXT paginé
    77: # ---------------------------------------------------------------------
    78: async def ccxt_fetch_ohlcv_all(
    79:     exchange,
    80:     symbol: str,
    81:     timeframe: str,
    82:     since_ms: Optional[int],
    83:     limit: int = 1000,
    84: ) -> List[Tuple[int, float, float, float, float, float]]:
    85:     """
    86:     Récupère OHLCV par pages (limit 1000) depuis since_ms jusqu'à ~now.
    87:     Retourne une liste triée/dédupliquée.
    88:     """
    89:     out: List[Tuple[int, float, float, float, float, float]] = []
    90:     tf_ms = parse_timeframe_to_seconds(timeframe) * 1000
    91:     now_ms = exchange.milliseconds() if hasattr(exchange, "milliseconds") else int(time.time() * 1000)
    92: 
    93:     cursor = since_ms or (now_ms - 200 * tf_ms)
    94:     while True:
    95:         batch = await exchange.fetch_ohlcv(symbol, timeframe=timeframe, since=cursor, limit=limit)
    96:         if not batch:
    97:             break
    98:         for ts, o, h, l, c, v in batch:
    99:             out.append((int(ts), float(o), float(h), float(l), float(c), float(v)))
   100:         next_cursor = batch[-1][0] + tf_ms
   101:         if next_cursor <= cursor:
   102:             break
   103:         cursor = next_cursor
   104:         if cursor >= now_ms + (2 * tf_ms):
   105:             break
   106:         await asyncio.sleep(getattr(exchange, "rateLimit", 200) / 1000)
   107: 
   108:     out.sort(key=lambda x: x[0])
   109:     dedup: List[Tuple[int, float, float, float, float, float]] = []
   110:     seen = set()
   111:     for row in out:
   112:         if row[0] in seen:
   113:             continue
   114:         seen.add(row[0])
   115:         dedup.append(row)
   116:     return dedup
   117: 
   118: 
   119: # ---------------------------------------------------------------------
   120: # Cache manager
   121: # ---------------------------------------------------------------------
   122: async def ensure_symbol_csv_cache(
   123:     exchange,
   124:     symbol: str,
   125:     timeframe: str,
   126:     min_rows: int = CSV_MIN_ROWS,
   127: ) -> str:
   128:     """
   129:     Garantit qu'un CSV OHLCV récent existe pour (symbol, timeframe).
   130:     Crée/append si nécessaire. Retourne le chemin.
   131:     """
   132:     path = csv_path(symbol, timeframe)
   133:     rows = read_csv_ohlcv(path)
   134:     tf_sec = parse_timeframe_to_seconds(timeframe)
   135:     tf_ms = tf_sec * 1000
   136:     now_ms = int(time.time() * 1000)
   137: 
   138:     # âge max
   139:     max_age = CSV_MAX_AGE if CSV_MAX_AGE > 0 else int(tf_sec * STALE_FACTOR)
   140: 
   141:     need_full = False
   142:     need_append = False
   143: 
   144:     if not rows:
   145:         need_full = True
   146:     else:
   147:         last = last_ts(rows) or 0
   148:         age_sec = max(0, (now_ms - last) // 1000)
   149:         if age_sec > max_age or len(rows) < min_rows:
   150:             need_append = True
   151: 
   152:     if need_full:
   153:         since = now_ms - (tf_ms * 2000)  # ~2000 bougies
   154:         fresh = await ccxt_fetch_ohlcv_all(exchange, symbol, timeframe, since_ms=since)
   155:         if len(fresh) < min_rows:
   156:             since = now_ms - (tf_ms * 5000)
   157:             fresh = await ccxt_fetch_ohlcv_all(exchange, symbol, timeframe, since_ms=since)
   158:         if os.path.exists(path):
   159:             os.remove(path)
   160:         write_csv_ohlcv(path, fresh)
   161:         return path
   162: 
   163:     if need_append:
   164:         since = (last_ts(rows) or now_ms - (tf_ms * 2000)) + tf_ms
   165:         fresh = await ccxt_fetch_ohlcv_all(exchange, symbol, timeframe, since_ms=since)
   166:         if fresh:
   167:             write_csv_ohlcv(path, fresh)
   168: 
   169:     return path
   170: 
   171: 
   172: async def prewarm_csv_cache(exchange, symbols: Iterable[str], timeframe: str) -> Dict[str, str]:
   173:     """
   174:     Prépare le cache pour plusieurs symboles (concurrence limitée).
   175:     Retourne {symbol: path}.
   176:     """
   177:     sem = asyncio.Semaphore(PREFETCH_CONC)
   178:     result: Dict[str, str] = {}
   179: 
   180:     async def _one(sym: str):
   181:         async with sem:
   182:             p = await ensure_symbol_csv_cache(exchange, sym, timeframe)
   183:             result[sym] = p
   184: 
   185:     await asyncio.gather(*[_one(s) for s in symbols])
   186:     return result

## scalper/services/order_service.py (last modified: 2025-08-23 20:57:14)
     1: from __future__ import annotations
     2: from dataclasses import dataclass
     3: from typing import Any, Dict, Optional, Protocol
     4: from scalper.trade_utils import extract_available_balance
     5: 
     6: 
     7: @dataclass
     8: class OrderCaps:
     9:     min_trade_usdt: float = 5.0
    10:     leverage: float = 1.0
    11: 
    12: 
    13: @dataclass
    14: class OrderRequest:
    15:     symbol: str
    16:     side: str
    17:     price: float
    18:     sl: float
    19:     tp: Optional[float]
    20:     risk_pct: float
    21: 
    22: 
    23: @dataclass
    24: class OrderResult:
    25:     accepted: bool
    26:     reason: str = ""
    27:     payload: Dict[str, Any] = None
    28:     order_id: Optional[str] = None
    29:     status: Optional[str] = None
    30:     avg_price: Optional[float] = None
    31:     filled_qty: Optional[float] = None
    32: 
    33: 
    34: class Exchange(Protocol):
    35:     def get_assets(self) -> Dict[str, Any]: ...
    36:     def get_ticker(self, symbol: Optional[str] = None) -> Dict[str, Any]: ...
    37:     def place_order(
    38:         self,
    39:         symbol: str,
    40:         side: str,
    41:         quantity: float,
    42:         order_type: str,
    43:         price: Optional[float] = None,
    44:         stop_loss: Optional[float] = None,
    45:         take_profit: Optional[float] = None,
    46:     ) -> Dict[str, Any]: ...
    47: 
    48: 
    49: class OrderService:
    50:     def __init__(self, exchange: Exchange, caps: OrderCaps = OrderCaps()):
    51:         self.exchange = exchange
    52:         self.caps = caps
    53: 
    54:     @staticmethod
    55:     def _abs(x: float) -> float:
    56:         return -x if x < 0 else x
    57: 
    58:     def _calc_qty(self, equity_usdt: float, price: float, sl: float, risk_pct: float) -> float:
    59:         dist = self._abs(price - sl)
    60:         if dist <= 0:
    61:             return 0.0
    62:         risk_usdt = max(0.0, equity_usdt * risk_pct)
    63:         return 0.0 if price <= 0 else (risk_usdt / dist)
    64: 
    65:     def prepare_and_place(self, equity_usdt: float, req: OrderRequest) -> OrderResult:
    66:         qty = self._calc_qty(equity_usdt, req.price, req.sl, req.risk_pct)
    67:         if qty <= 0:
    68:             return OrderResult(False, "invalid_size")
    69:         notional = qty * req.price
    70:         if notional < self.caps.min_trade_usdt:
    71:             return OrderResult(False, "under_min_notional")
    72:         assets = self.exchange.get_assets()
    73:         available = extract_available_balance(assets)
    74:         required_margin = notional / max(1.0, self.caps.leverage)
    75:         if available < required_margin:
    76:             return OrderResult(False, "insufficient_margin")
    77:         side = "BUY" if req.side == "long" else "SELL"
    78:         out = self.exchange.place_order(
    79:             symbol=req.symbol, side=side, quantity=qty,
    80:             order_type="limit", price=req.price,
    81:             stop_loss=req.sl, take_profit=req.tp
    82:         )
    83:         # extraire infos utiles
    84:         oid = None; status = None; avg = None; filled = None
    85:         try:
    86:             data = out.get("data") if isinstance(out, dict) else out
    87:             if isinstance(data, dict):
    88:                 oid = str(data.get("orderId") or data.get("ordId") or data.get("id") or "")
    89:                 status = (data.get("status") or data.get("state") or "new").lower()
    90:                 avg = float(data.get("avgPrice", data.get("avgPx", 0)) or 0)
    91:                 filled = float(data.get("filledQty", data.get("fillSz", 0)) or 0)
    92:         except Exception:
    93:             pass
    94:         return OrderResult(True, "", out, oid, status, avg, filled)


## scalper/services/utils.py (last modified: 2025-08-23 20:57:14)
     1: # scalper/services/utils.py
     2: from __future__ import annotations
     3: import asyncio
     4: from typing import Callable, Any
     5: 
     6: 
     7: class NullNotifier:
     8:     async def send(self, _msg: str) -> None:
     9:         return
    10: 
    11: 
    12: async def heartbeat_task(running_getter: Callable[[], bool], notifier: Any, period: float = 30.0) -> None:
    13:     if notifier is None:
    14:         notifier = NullNotifier()
    15:     try:
    16:         while running_getter():
    17:             await notifier.send("heartbeat alive")
    18:             await asyncio.sleep(period)
    19:     except asyncio.CancelledError:
    20:         pass
    21: 
    22: 
    23: async def log_stats_task(
    24:     notifier: Any,
    25:     ticks_getter: Callable[[], int],
    26:     symbols_getter: Callable[[], list[str]],
    27:     period: float = 30.0,
    28: ) -> None:
    29:     if notifier is None:
    30:         notifier = NullNotifier()
    31:     last = 0
    32:     try:
    33:         while True:
    34:             total = int(ticks_getter() or 0)
    35:             delta = total - last
    36:             last = total
    37:             syms = symbols_getter() or []
    38:             msg = f"[stats] ticks_total={total} (+{delta} /30s) | pairs=" + ",".join(syms)
    39:             print(msg)
    40:             await notifier.send(msg)
    41:             await asyncio.sleep(period)
    42:     except asyncio.CancelledError:
    43:         pass

## scalper/signals/__init__.py (last modified: 2025-08-23 20:57:14)
     1: # scalper/signals/__init__.py
     2: from .factory import load_signal, available_strategies
     3: 
     4: __all__ = ["load_signal", "available_strategies"]

## scalper/signals/current.py (last modified: 2025-08-23 20:57:14)
     1: # scalper/signals/current.py
     2: from __future__ import annotations
     3: 
     4: # Wrapper pour utiliser la stratégie live actuelle en mode "plugin"
     5: from scalper.strategy import generate_signal as _generate_signal
     6: 
     7: def generate_signal(**kwargs):
     8:     """
     9:     Expose la même signature que scalper.strategy.generate_signal.
    10:     Sert d’adaptateur pour la factory.
    11:     """
    12:     return _generate_signal(**kwargs)

## scalper/signals/factory.py (last modified: 2025-08-23 20:57:14)
     1: # scalper/signals/factory.py
     2: from __future__ import annotations
     3: 
     4: import importlib
     5: import importlib.util
     6: from typing import Callable, Dict, Optional
     7: 
     8: SignalFn = Callable[..., object]
     9: 
    10: # Mapping symbolique -> module (tu peux en ajouter librement)
    11: _REGISTRY: Dict[str, str] = {
    12:     # Stratégie "actuelle" (renvoie scalper.strategy.generate_signal)
    13:     "current": "scalper.signals.current",
    14: 
    15:     # Exemples de plugins (crée les fichiers si tu veux les utiliser)
    16:     "ema_cross": "scalper.signals.ema_cross",
    17:     "vwap_break": "scalper.signals.vwap_break",
    18: }
    19: 
    20: def _module_exists(modname: str) -> bool:
    21:     return importlib.util.find_spec(modname) is not None
    22: 
    23: def load_signal(name: str, *, default: str = "current") -> SignalFn:
    24:     """
    25:     Charge et retourne une fonction `generate_signal` pour la stratégie `name`.
    26:     Si le module n'existe pas, on retombe sur `default` (courant: 'current').
    27:     """
    28:     target = _REGISTRY.get(name, _REGISTRY.get(default, "scalper.signals.current"))
    29:     if not _module_exists(target):
    30:         # fallback direct sur 'current'
    31:         target = _REGISTRY.get(default, "scalper.signals.current")
    32: 
    33:     mod = importlib.import_module(target)
    34:     fn = getattr(mod, "generate_signal", None)
    35:     if not callable(fn):
    36:         # dernier filet de sécurité : stratégie live directe
    37:         from scalper.strategy import generate_signal as live_generate
    38:         return live_generate
    39:     return fn
    40: 
    41: def available_strategies() -> Dict[str, str]:
    42:     """
    43:     Retourne {nom: 'ok'/'missing'} pour afficher ce qui est disponible.
    44:     """
    45:     out: Dict[str, str] = {}
    46:     for name, mod in _REGISTRY.items():
    47:         out[name] = "ok" if _module_exists(mod) else "missing"
    48:     return out

## scalper/signals/generator.py (last modified: 2025-08-23 20:57:14)
     1: from __future__ import annotations
     2: 
     3: from typing import Any, Dict, List, Optional
     4: 
     5: import pandas as pd
     6: 
     7: from data.indicators import compute_all
     8: 
     9: __all__ = ["generate_signal"]
    10: 
    11: 
    12: def _quality_from_score(score: float) -> str:
    13:     if score >= 0.8:
    14:         return "A"
    15:     if score >= 0.5:
    16:         return "B"
    17:     return "C"
    18: 
    19: 
    20: def generate_signal(
    21:     df: pd.DataFrame,
    22:     *,
    23:     trend_tf: Optional[pd.DataFrame] = None,
    24:     confirm_tf: Optional[pd.DataFrame] = None,
    25:     atr_mult: float = 1.0,
    26:     trailing: bool = False,
    27:     **_: Any,
    28: ) -> Optional[Dict[str, Any]]:
    29:     """Generate a trading signal with confluence scoring.
    30: 
    31:     Parameters
    32:     ----------
    33:     df: pd.DataFrame
    34:         Primary timeframe OHLCV data.
    35:     trend_tf: pd.DataFrame, optional
    36:         Higher timeframe used for trend filtering.
    37:     confirm_tf: pd.DataFrame, optional
    38:         Lower timeframe used for confirmation.
    39:     atr_mult: float, optional
    40:         Multiplier applied to ATR for stop/target calculation.
    41:     trailing: bool, optional
    42:         When ``True`` include a ``trail`` distance (ATR * ``atr_mult``).
    43: 
    44:     Returns
    45:     -------
    46:     dict | None
    47:         Dictionary describing the signal or ``None`` if no trade setup exists.
    48:     """
    49: 
    50:     if df is None or len(df) < 2:
    51:         return None
    52: 
    53:     df = compute_all(df)
    54:     last = df.iloc[-1]
    55: 
    56:     conditions: List[bool] = []
    57:     reasons: List[str] = []
    58:     direction: Optional[str] = None
    59: 
    60:     # --- Basic trend via EMAs ----------------------------------------------
    61:     if last["close"] > last["ema20"] > last["ema50"]:
    62:         direction = "long"
    63:         reasons.append("price_above_ema")
    64:         conditions.append(True)
    65:     elif last["close"] < last["ema20"] < last["ema50"]:
    66:         direction = "short"
    67:         reasons.append("price_below_ema")
    68:         conditions.append(True)
    69:     else:
    70:         conditions.append(False)
    71:         return None
    72: 
    73:     # --- RSI ---------------------------------------------------------------
    74:     if direction == "long":
    75:         cond = last["rsi"] > 55
    76:         if cond:
    77:             reasons.append("rsi_bullish")
    78:         conditions.append(cond)
    79:     else:
    80:         cond = last["rsi"] < 45
    81:         if cond:
    82:             reasons.append("rsi_bearish")
    83:         conditions.append(cond)
    84: 
    85:     # --- MACD --------------------------------------------------------------
    86:     if direction == "long":
    87:         cond = last["macd"] > last["macd_signal"]
    88:         if cond:
    89:             reasons.append("macd_bullish")
    90:         conditions.append(cond)
    91:     else:
    92:         cond = last["macd"] < last["macd_signal"]
    93:         if cond:
    94:             reasons.append("macd_bearish")
    95:         conditions.append(cond)
    96: 
    97:     # --- OBV momentum ------------------------------------------------------
    98:     if len(df) >= 2:
    99:         obv_up = df["obv"].iloc[-1] > df["obv"].iloc[-2]
   100:         if obv_up:
   101:             reasons.append("obv_trending")
   102:         conditions.append(obv_up)
   103: 
   104:     # --- Trend timeframe filter -------------------------------------------
   105:     if trend_tf is not None and len(trend_tf) >= 2:
   106:         tdf = compute_all(trend_tf)
   107:         ema50 = tdf["ema50"]
   108:         slope = ema50.iloc[-1] - ema50.iloc[-2]
   109:         if direction == "long":
   110:             cond = slope > 0
   111:             if cond:
   112:                 reasons.append("trend_up")
   113:             conditions.append(cond)
   114:         else:
   115:             cond = slope < 0
   116:             if cond:
   117:                 reasons.append("trend_down")
   118:             conditions.append(cond)
   119: 
   120:     # --- Confirmation timeframe filter ------------------------------------
   121:     if confirm_tf is not None and len(confirm_tf) > 0:
   122:         cdf = compute_all(confirm_tf)
   123:         rsi = cdf["rsi"].iloc[-1]
   124:         if direction == "long":
   125:             cond = rsi > 50
   126:             if cond:
   127:                 reasons.append("confirm_rsi_bullish")
   128:             conditions.append(cond)
   129:         else:
   130:             cond = rsi < 50
   131:             if cond:
   132:                 reasons.append("confirm_rsi_bearish")
   133:             conditions.append(cond)
   134: 
   135:     score = (
   136:         sum(1 for c in conditions if c) / len(conditions) if conditions else 0.0
   137:     )
   138:     quality = _quality_from_score(score)
   139: 
   140:     atr = last.get("atr")
   141:     if pd.isna(atr) or atr == 0:
   142:         return None
   143: 
   144:     entry = float(last["close"])
   145:     if direction == "long":
   146:         sl = entry - atr * atr_mult
   147:         tp = entry + atr * atr_mult * 2
   148:     else:
   149:         sl = entry + atr * atr_mult
   150:         tp = entry - atr * atr_mult * 2
   151: 
   152:     result: Dict[str, Any] = {
   153:         "direction": direction,
   154:         "entry": entry,
   155:         "sl": sl,
   156:         "tp": tp,
   157:         "score": round(score, 3),
   158:         "reasons": reasons,
   159:         "quality": quality,
   160:     }
   161: 
   162:     if trailing:
   163:         result["trail"] = atr * atr_mult
   164: 
   165:     return result


## scalper/strategy.py (last modified: 2025-08-23 20:57:14)
     1: """Core trading strategy components for scalping EMA/VWAP/RSI/ATR.
     2: 
     3: This module implements a minimal but functional version of the strategy
     4: outlined in the project specification.  The focus is on pure Python
     5: implementations so the logic can easily be unit tested without requiring
     6: external services or heavy third‑party dependencies.
     7: 
     8: The strategy is deliberately stateless; functions operate on passed data and
     9: return simple data structures.  This makes it easy to plug the logic into
    10: real‑time trading loops or backtest engines.
    11: """
    12: 
    13: from __future__ import annotations
    14: 
    15: from dataclasses import dataclass
    16: from typing import Sequence, List, Dict, Optional, Tuple, Any
    17: 
    18: from .metrics import calc_rsi, calc_atr, calc_pnl_pct, calc_macd
    19: from .risk import calc_position_size
    20: 
    21: # ---------------------------------------------------------------------------
    22: # Helpers
    23: # ---------------------------------------------------------------------------
    24: 
    25: def ema(series: Sequence[float], window: int) -> List[float]:
    26:     """Return the exponential moving average of *series*.
    27: 
    28:     The first value is the raw input to remain consistent with most trading
    29:     platforms.  ``window`` must be positive; when it equals ``1`` the input is
    30:     returned unchanged.
    31:     """
    32: 
    33:     if window <= 1 or not series:
    34:         return list(series)
    35:     k = 2.0 / (window + 1.0)
    36:     out: List[float] = [float(series[0])]
    37:     prev = out[0]
    38:     for x in series[1:]:
    39:         prev = float(x) * k + prev * (1.0 - k)
    40:         out.append(prev)
    41:     return out
    42: 
    43: def vwap(highs: Sequence[float], lows: Sequence[float],
    44:          closes: Sequence[float], volumes: Sequence[float]) -> float:
    45:     """Compute the volume weighted average price (VWAP).
    46: 
    47:     Parameters
    48:     ----------
    49:     highs, lows, closes, volumes: Sequence[float]
    50:         Matching sequences for the period considered.
    51:     """
    52: 
    53:     tp_vol = 0.0
    54:     vol_sum = 0.0
    55:     for h, low, c, v in zip(highs, lows, closes, volumes):
    56:         tp = (h + low + c) / 3.0
    57:         tp_vol += tp * v
    58:         vol_sum += v
    59:     return tp_vol / vol_sum if vol_sum else 0.0
    60: 
    61: def obv(closes: Sequence[float], volumes: Sequence[float]) -> List[float]:
    62:     """Return the On Balance Volume (OBV) series."""
    63: 
    64:     if not closes:
    65:         return []
    66:     out: List[float] = [0.0]
    67:     for i in range(1, len(closes)):
    68:         if closes[i] > closes[i - 1]:
    69:             out.append(out[-1] + volumes[i])
    70:         elif closes[i] < closes[i - 1]:
    71:             out.append(out[-1] - volumes[i])
    72:         else:
    73:             out.append(out[-1])
    74:     return out
    75: 
    76: 
    77: def cross(last_fast: float, last_slow: float, prev_fast: float, prev_slow: float) -> int:
    78:     """Detect a crossing between two series.
    79: 
    80:     Returns ``1`` for a bullish crossover, ``-1`` for a bearish crossover and
    81:     ``0`` otherwise.
    82:     """
    83: 
    84:     if prev_fast <= prev_slow and last_fast > last_slow:
    85:         return 1
    86:     if prev_fast >= prev_slow and last_fast < last_slow:
    87:         return -1
    88:     return 0
    89: 
    90: 
    91: def order_book_imbalance(bid_vol: float, ask_vol: float) -> float:
    92:     """Compute order book imbalance.
    93: 
    94:     The value is normalised between ``-1`` and ``1`` where positive numbers
    95:     indicate bid dominance.  ``0`` is returned when both volumes are zero.
    96:     """
    97: 
    98:     total = bid_vol + ask_vol
    99:     return (bid_vol - ask_vol) / total if total else 0.0
   100: 
   101: 
   102: def swing_levels(
   103:     highs: Sequence[float], lows: Sequence[float], lookback: int
   104: ) -> Tuple[float, float]:
   105:     """Return the most recent swing high and swing low.
   106: 
   107:     ``lookback`` defines how many completed candles are inspected.  The current
   108:     candle is excluded to avoid look‑ahead bias.
   109:     """
   110: 
   111:     if len(highs) < lookback + 1 or len(lows) < lookback + 1:
   112:         return highs[-1], lows[-1]
   113:     high = max(highs[-lookback - 1 : -1])
   114:     low = min(lows[-lookback - 1 : -1])
   115:     return high, low
   116: 
   117: # ---------------------------------------------------------------------------
   118: # Pair selection
   119: # ---------------------------------------------------------------------------
   120: 
   121: # The first and second level pair selection helpers now live in
   122: # :mod:`scalper.selection`.  They are re-exported here for backward compatibility
   123: # and to keep the public API unchanged.
   124: from .selection.scanner import scan_pairs  # noqa: E402
   125: from .selection.momentum import select_active_pairs  # noqa: E402
   126: 
   127: # ---------------------------------------------------------------------------
   128: # Signal generation
   129: # ---------------------------------------------------------------------------
   130: 
   131: @dataclass
   132: class Signal:
   133:     """Trading signal with risk parameters."""
   134: 
   135:     symbol: str
   136:     side: int  # 1 for long, -1 for short
   137:     entry: float
   138:     sl: float
   139:     tp1: float
   140:     tp2: float
   141:     qty: float = 0.0
   142:     score: Optional[float] = None
   143:     quality: Optional[float] = None
   144:     reasons: Optional[List[str]] = None
   145: 
   146:     def __post_init__(self) -> None:  # pragma: no cover - simple coercion
   147:         if isinstance(self.side, str):
   148:             self.side = 1 if self.side.lower() in {"long", "buy", "1", "true"} else -1
   149: 
   150:     @property
   151:     def price(self) -> float:
   152:         return self.entry
   153: 
   154: 
   155: def _generate_signal(
   156:     symbol: str,
   157:     ohlcv: Dict[str, Sequence[float]],
   158:     *,
   159:     equity: float,
   160:     risk_pct: float,
   161:     ohlcv_15m: Optional[Dict[str, Sequence[float]]] = None,
   162:     ohlcv_1h: Optional[Dict[str, Sequence[float]]] = None,
   163:     order_book: Optional[Dict[str, float]] = None,
   164:     tick_ratio_buy: Optional[float] = None,
   165:     atr_disable_pct: float = 0.2,
   166:     atr_reduce_pct: float = 2.0,
   167:     swing_lookback: int = 5,
   168:     macd_fast: int = 12,
   169:     macd_slow: int = 26,
   170:     macd_signal: int = 9,
   171:     trend_ema_period: int = 200,
   172: ) -> Optional[Signal]:
   173:     """Return a trading :class:`Signal` if conditions are met.
   174: 
   175:     ``ohlcv`` must contain ``open``, ``high``, ``low``, ``close`` and ``volume``
   176:     sequences ordered from oldest to newest.  The function checks the following
   177:     rules:
   178: 
   179:     * price positioned relative to VWAP and EMA20/EMA50 trend
   180:     * RSI(14) crossing key levels (40/60)
   181:     * OBV rising or high short‑term volume
   182:     * Multi time frame confirmation (H1 EMA50 slope, RSI15 >/< 50)
   183:     * Micro‑structure breakout of last swing high/low
   184:     * MACD trend filter
   185:     * Long‑term trend via configurable EMA filter
   186:     * Order book imbalance and tape filters
   187:     * Dynamic ATR‑based stop‑loss and take‑profit
   188:     * Position sizing via ``calc_position_size``
   189:     """
   190: 
   191:     closes = [float(x) for x in ohlcv.get("close", [])]
   192:     highs = [float(x) for x in ohlcv.get("high", [])]
   193:     lows = [float(x) for x in ohlcv.get("low", [])]
   194:     vols = [float(x) for x in ohlcv.get("volume", [])]
   195:     if len(closes) < 60 or len(highs) != len(lows) or len(closes) != len(highs):
   196:         return None
   197: 
   198:     price = closes[-1]
   199:     ema20 = ema(closes, 20)
   200:     ema50 = ema(closes, 50)
   201:     ema_trend = ema(closes, trend_ema_period)
   202:     v = vwap(highs, lows, closes, vols)
   203:     obv_series = obv(closes, vols)
   204:     obv_rising = obv_series[-1] > obv_series[-2]
   205:     vol_last3 = sum(vols[-3:])
   206:     vol_ma20 = sum(vols[-20:]) / 20.0
   207:     vol_rising = vol_last3 > vol_ma20
   208: 
   209:     macd_val, macd_sig, _ = calc_macd(
   210:         closes, fast=macd_fast, slow=macd_slow, signal=macd_signal
   211:     )
   212: 
   213:     # Multi timeframe filters -------------------------------------------------
   214:     trend_dir = 0  # 1 = long only, -1 = short only, 0 = neutral
   215:     if ohlcv_1h:
   216:         h_closes = [float(x) for x in ohlcv_1h.get("close", [])]
   217:         if len(h_closes) >= 52:
   218:             h_ema50 = ema(h_closes, 50)
   219:             if len(h_ema50) >= 2:
   220:                 slope = h_ema50[-1] - h_ema50[-2]
   221:                 if slope > 0:
   222:                     trend_dir = 1
   223:                 elif slope < 0:
   224:                     trend_dir = -1
   225: 
   226:     rsi_15 = None
   227:     if ohlcv_15m:
   228:         m_closes = [float(x) for x in ohlcv_15m.get("close", [])]
   229:         if len(m_closes) >= 15:
   230:             rsi_15 = calc_rsi(m_closes, 14)
   231: 
   232:     # RSI crossing logic (5m)
   233:     rsi_curr = calc_rsi(closes[-15:], 14)
   234:     rsi_prev = calc_rsi(closes[-16:-1], 14)
   235: 
   236:     atr = calc_atr(highs, lows, closes, 14)
   237:     atr_pct = atr / price * 100.0 if price else 0.0
   238:     if atr_pct < atr_disable_pct:
   239:         return None
   240:     size_mult = 0.5 if atr_pct > atr_reduce_pct else 1.0
   241: 
   242:     sl_dist = 0.5 * atr
   243:     tp1_dist = 1.0 * atr
   244:     tp2_dist = 1.5 * atr
   245: 
   246:     swing_high, swing_low = swing_levels(highs, lows, swing_lookback)
   247: 
   248:     obi_ok_long = obi_ok_short = True
   249:     if order_book is not None:
   250:         bid = float(order_book.get("bid_vol_aggreg", 0))
   251:         ask = float(order_book.get("ask_vol_aggreg", 0))
   252:         obi = order_book_imbalance(bid, ask)
   253:         obi_ok_long = obi > 0.1
   254:         obi_ok_short = obi < -0.1
   255: 
   256:     tick_ok_long = tick_ratio_buy is None or tick_ratio_buy > 0.55
   257:     tick_ok_short = tick_ratio_buy is None or tick_ratio_buy < 0.45
   258: 
   259:     def _size(dist: float) -> float:
   260:         return calc_position_size(equity, risk_pct, dist) * size_mult
   261:     weights = {
   262:         "ema": 15.0,
   263:         "macd": 15.0,
   264:         "vwap": 15.0,
   265:         "rsi": 15.0,
   266:         "obv": 10.0,
   267:         "swing": 10.0,
   268:         "atr": 20.0,
   269:     }
   270: 
   271:     atr_score = min(atr_pct / atr_reduce_pct, 1.0) * weights["atr"]
   272: 
   273:     long_score = atr_score
   274:     long_reasons: List[str] = []
   275:     if price > v:
   276:         long_score += weights["vwap"]
   277:         long_reasons.append("vwap")
   278:     if ema20[-1] > ema50[-1]:
   279:         long_score += weights["ema"]
   280:         long_reasons.append("ema")
   281:     if rsi_prev <= 40 < rsi_curr:
   282:         long_score += weights["rsi"]
   283:         long_reasons.append("rsi")
   284:     if macd_val > macd_sig:
   285:         long_score += weights["macd"]
   286:         long_reasons.append("macd")
   287:     if obv_rising or vol_rising:
   288:         long_score += weights["obv"]
   289:         long_reasons.append("obv")
   290:     if price > swing_high:
   291:         long_score += weights["swing"]
   292:         long_reasons.append("swing")
   293: 
   294:     short_score = atr_score
   295:     short_reasons: List[str] = []
   296:     if price < v:
   297:         short_score += weights["vwap"]
   298:         short_reasons.append("vwap")
   299:     if ema20[-1] < ema50[-1]:
   300:         short_score += weights["ema"]
   301:         short_reasons.append("ema")
   302:     if rsi_prev >= 60 > rsi_curr:
   303:         short_score += weights["rsi"]
   304:         short_reasons.append("rsi")
   305:     if macd_val < macd_sig:
   306:         short_score += weights["macd"]
   307:         short_reasons.append("macd")
   308:     if obv_series[-1] < obv_series[-2] or vol_rising:
   309:         short_score += weights["obv"]
   310:         short_reasons.append("obv")
   311:     if price < swing_low:
   312:         short_score += weights["swing"]
   313:         short_reasons.append("swing")
   314: 
   315:     side: Optional[str] = None
   316:     score: float = 0.0
   317:     reasons: List[str] = []
   318:     if (
   319:         long_score >= short_score
   320:         and long_score > 0
   321:         and macd_val > macd_sig
   322:         and obi_ok_long
   323:         and tick_ok_long
   324:         and trend_dir >= 0
   325:         and price > ema_trend[-1]
   326:     ):
   327:         side = "long"
   328:         score = long_score
   329:         reasons = long_reasons
   330:         sl = price - sl_dist
   331:         tp1 = price + tp1_dist
   332:         tp2 = price + tp2_dist
   333:     elif (
   334:         short_score > long_score
   335:         and short_score > 0
   336:         and macd_val < macd_sig
   337:         and obi_ok_short
   338:         and tick_ok_short
   339:         and trend_dir <= 0
   340:         and price < ema_trend[-1]
   341:     ):
   342:         side = "short"
   343:         score = short_score
   344:         reasons = short_reasons
   345:         sl = price + sl_dist
   346:         tp1 = price - tp1_dist
   347:         tp2 = price - tp2_dist
   348:     else:
   349:         return None
   350: 
   351:     qty = _size(sl_dist)
   352:     return Signal(symbol, side, price, sl, tp1, tp2, qty, score, score, reasons)
   353: 
   354: 
   355: def generate_signal(*args, **kwargs) -> Optional[Signal]:
   356:     if "config" in kwargs:
   357:         config = kwargs.pop("config")
   358:         symbol = kwargs.pop("symbol", None)
   359:         ohlcv = kwargs.pop("ohlcv", None)
   360:         if ohlcv is None:
   361:             raise TypeError("ohlcv argument required")
   362:         return _generate_signal(
   363:             symbol or ohlcv.get("symbol", ""),
   364:             ohlcv,
   365:             equity=kwargs.pop("equity", 0.0),
   366:             risk_pct=getattr(config, "RISK_PCT", 0.0),
   367:             **kwargs,
   368:         )
   369:     return _generate_signal(*args, **kwargs)
   370: 
   371: # ---------------------------------------------------------------------------
   372: # Backtesting utilities
   373: # ---------------------------------------------------------------------------
   374: 
   375: def max_drawdown(equity_curve: Sequence[float]) -> float:
   376:     peak = equity_curve[0]
   377:     mdd = 0.0
   378:     for x in equity_curve:
   379:         if x > peak:
   380:             peak = x
   381:         dd = (peak - x) / peak * 100.0
   382:         if dd > mdd:
   383:             mdd = dd
   384:     return mdd
   385: 
   386: def backtest(
   387:     trades: Sequence[Dict[str, Any]],
   388:     *,
   389:     equity_start: float = 1_000.0,
   390:     fee_rate: float = 0.0,
   391: ) -> Dict[str, float]:
   392:     """Evaluate a list of trade dictionaries.
   393: 
   394:     Each trade must provide ``symbol``, ``entry``, ``exit``, ``side`` and may
   395:     optionally include ``duration`` in minutes.  Results are aggregated into
   396:     common performance metrics to quickly evaluate the strategy.
   397:     """
   398: 
   399:     equity = equity_start
   400:     equity_curve = [equity]
   401:     pnl_pct_list: List[float] = []
   402:     wins = losses = 0
   403:     win_sum = loss_sum = 0.0
   404:     total_duration = 0.0
   405: 
   406:     for t in trades:
   407:         pnl_pct = calc_pnl_pct(t["entry"], t["exit"], t["side"], fee_rate)
   408:         pnl_pct_list.append(pnl_pct)
   409:         if pnl_pct >= 0:
   410:             wins += 1
   411:             win_sum += pnl_pct
   412:         else:
   413:             losses += 1
   414:             loss_sum += pnl_pct
   415:         equity *= 1 + pnl_pct / 100.0
   416:         equity_curve.append(equity)
   417:         total_duration += float(t.get("duration", 0.0))
   418: 
   419:     pnl_pct_total = sum(pnl_pct_list)
   420:     pnl_usdt = equity - equity_start
   421:     profit_factor = (win_sum / abs(loss_sum)) if loss_sum else float("inf")
   422:     winrate = wins / len(trades) * 100.0 if trades else 0.0
   423:     mdd = max_drawdown(equity_curve)
   424:     avg_trade_time = total_duration / len(trades) if trades else 0.0
   425:     exposure = total_duration  # in minutes, callers can normalise if desired
   426:     # Sharpe ratio based on per-trade returns
   427:     if len(pnl_pct_list) > 1:
   428:         mean = sum(pnl_pct_list) / len(pnl_pct_list)
   429:         var = sum((r - mean) ** 2 for r in pnl_pct_list) / (len(pnl_pct_list) - 1)
   430:         sharpe = mean / (var ** 0.5) if var > 0 else 0.0
   431:     else:
   432:         sharpe = 0.0
   433: 
   434:     return {
   435:         "pnl_usdt": pnl_usdt,
   436:         "pnl_pct": pnl_pct_total,
   437:         "profit_factor": profit_factor,
   438:         "winrate": winrate,
   439:         "max_drawdown": mdd,
   440:         "avg_trade_time": avg_trade_time,
   441:         "exposure": exposure,
   442:         "sharpe": sharpe,
   443:     }


## scalper/trade_utils.py (last modified: 2025-08-23 20:57:14)
     1: # scalper/trade_utils.py
     2: from __future__ import annotations
     3: 
     4: from typing import Optional
     5: 
     6: 
     7: def compute_position_size(
     8:     equity: float,
     9:     price: float,
    10:     risk_pct: float,
    11:     *,
    12:     symbol: Optional[str] = None,
    13:     min_qty: float = 0.0,
    14:     max_leverage: float = 1.0,
    15: ) -> float:
    16:     """
    17:     Sizing simple: position notionnelle = equity * risk_pct * max_leverage
    18:     qty = notionnel / price
    19:     - min_qty : borne basse éventuelle (0 pour ignorer)
    20:     - max_leverage : si tu veux simuler un levier (1 par défaut)
    21:     """
    22:     equity = float(max(0.0, equity))
    23:     price = float(max(1e-12, price))
    24:     risk_pct = float(max(0.0, risk_pct))
    25:     notionnel = equity * risk_pct * max_leverage
    26:     qty = notionnel / price
    27:     if min_qty > 0 and qty < min_qty:
    28:         return 0.0
    29:     return float(qty)

## scalper/version.py (last modified: 2025-08-23 20:57:14)
     1: """Utilities for managing the Scalp bot version."""
     2: 
     3: from __future__ import annotations
     4: 
     5: from pathlib import Path
     6: import re
     7: 
     8: import subprocess
     9: 
    10: 
    11: # Path to the VERSION file within the package
    12: _VERSION_FILE = Path(__file__).resolve().parent / "VERSION"
    13: _VERSION_RE = re.compile(r"^(\d+)\.(\d+)\.(\d+)$")
    14: 
    15: 
    16: def get_version() -> str:
    17:     """Return the current version of the bot.
    18: 
    19:     If the VERSION file does not exist the default version ``0.0.0`` is
    20:     returned.
    21:     """
    22:     if not _VERSION_FILE.exists():
    23:         return "0.0.0"
    24:     return _VERSION_FILE.read_text().strip()
    25: 
    26: 
    27: def _parse(version: str) -> tuple[int, int, int]:
    28:     match = _VERSION_RE.match(version)
    29:     if not match:
    30:         raise ValueError(f"Invalid version: {version!r}")
    31:     return tuple(int(x) for x in match.groups())
    32: 
    33: 
    34: def bump_version(part: str = "patch") -> str:
    35:     """Bump the version stored in the VERSION file.
    36: 
    37:     Parameters
    38:     ----------
    39:     part:
    40:         Which component to increment. Accepted values are ``"major"``,
    41:         ``"minor"`` and ``"patch"`` (default).
    42:     """
    43:     major, minor, patch = _parse(get_version())
    44:     if part == "major":
    45:         major += 1
    46:         minor = 0
    47:         patch = 0
    48:     elif part == "minor":
    49:         minor += 1
    50:         patch = 0
    51: 
    52:     elif part == "patch":
    53:         patch += 1
    54:     else:
    55:         raise ValueError(f"Unknown part: {part}")
    56:     new_version = f"{major}.{minor}.{patch}"
    57:     _VERSION_FILE.write_text(f"{new_version}\n")
    58:     return new_version
    59: 
    60: 
    61: def bump_version_from_message(message: str) -> str:
    62:     """Bump the version according to a commit message.
    63: 
    64:     ``message`` is evaluated using a tiny subset of the Conventional
    65:     Commits spec. Messages starting with ``feat`` bump the *minor*
    66:     version, messages whose header ends with ``!`` or contain
    67:     ``BREAKING CHANGE`` bump the *major* version. All other messages
    68:     bump the *patch* component.
    69:     """
    70: 
    71:     header = message.strip().splitlines()[0].lower()
    72:     lower = message.lower()
    73:     type_part = header.split(":")[0]
    74:     if "!" in type_part or "breaking change" in lower:
    75:         part = "major"
    76:     elif type_part.startswith("feat"):
    77:         part = "minor"
    78:     else:
    79:         part = "patch"
    80:     return bump_version(part)
    81: 
    82: 
    83: def bump_version_from_git() -> str:
    84:     """Read the latest git commit message and bump the version accordingly."""
    85:     try:
    86:         message = subprocess.check_output(
    87:             ["git", "log", "-1", "--pretty=%B"], text=True
    88:         ).strip()
    89:     except Exception:
    90:         message = ""
    91:     return bump_version_from_message(message)
    92: 
    93: 
    94: if __name__ == "__main__":
    95:     print(bump_version_from_git())


## scalper/ws.py (last modified: 2025-08-23 20:57:14)
     1: """Minimal websocket manager with heartbeat and auto-resubscribe.
     2: 
     3: This module provides a light-weight framework to maintain a realtime
     4: connection to an exchange.  The actual network layer is expected to be
     5: supplied by the caller via ``connect`` and ``subscribe`` callbacks.  The
     6: manager handles retrying failed connections and periodically invoking the
     7: ``subscribe`` callback as a heartbeat.  This keeps the code fully testable
     8: without opening real network sockets.
     9: """
    10: from __future__ import annotations
    11: 
    12: import asyncio
    13: import logging
    14: from typing import Awaitable, Callable, Optional
    15: 
    16: 
    17: class WebsocketManager:
    18:     """Maintain a websocket connection with heartbeat and retry."""
    19: 
    20:     def __init__(
    21:         self,
    22:         connect: Callable[[], Awaitable[None]],
    23:         subscribe: Callable[[], Awaitable[None]],
    24:         *,
    25:         heartbeat_interval: float = 30.0,
    26:         max_retries: int = 3,
    27:     ) -> None:
    28:         self._connect = connect
    29:         self._subscribe = subscribe
    30:         self.heartbeat_interval = heartbeat_interval
    31:         self.max_retries = max_retries
    32:         self._heartbeat_task: Optional[asyncio.Task] = None
    33: 
    34:     async def run(self) -> None:
    35:         """Open the connection retrying on failure."""
    36:         retries = 0
    37:         while True:
    38:             try:
    39:                 await self._connect()
    40:                 await self._subscribe()
    41:                 self._heartbeat_task = asyncio.create_task(self._heartbeat())
    42:                 return
    43:             except Exception as exc:  # pragma: no cover - network errors
    44:                 logging.error("websocket connect failed: %s", exc)
    45:                 retries += 1
    46:                 if retries > self.max_retries:
    47:                     raise
    48:                 await asyncio.sleep(1)
    49: 
    50:     async def _heartbeat(self) -> None:
    51:         """Send periodic heartbeats and resubscribe on failure."""
    52:         while True:
    53:             await asyncio.sleep(self.heartbeat_interval)
    54:             try:
    55:                 await self._subscribe()
    56:             except Exception as exc:  # pragma: no cover - network errors
    57:                 logging.warning("websocket heartbeat failed: %s", exc)
    58:                 await self.run()
    59:                 break
    60: 
    61:     async def stop(self) -> None:
    62:         """Cancel the heartbeat task if it is running."""
    63:         task = self._heartbeat_task
    64:         if task and not task.done():
    65:             task.cancel()
    66:             try:
    67:                 await task
    68:             except BaseException:  # pragma: no cover - cancellation
    69:                 pass
    70:         self._heartbeat_task = None


## sitecustomize.py (last modified: 2025-08-23 20:57:14)
     1: # sitecustomize.py
     2: """
     3: Ce fichier est importé automatiquement par Python au démarrage, si présent sur sys.path.
     4: On l'utilise pour lancer un préflight de 'scalper' avant l'exécution du bot,
     5: sans modifier bot.py. Désactivable via SKIP_PREFLIGHT=1.
     6: """
     7: 
     8: import os
     9: 
    10: if os.getenv("SKIP_PREFLIGHT", "0") not in ("1", "true", "yes"):
    11:     try:
    12:         # Optionnel: charger /notebooks/.env si présent
    13:         try:
    14:             from dotenv import load_dotenv  # pip install python-dotenv si besoin
    15:             load_dotenv("/notebooks/.env")
    16:         except Exception:
    17:             pass
    18: 
    19:     except Exception:
    20:         pass
    21: 
    22:     try:
    23:         from scalper.selfcheck import preflight_or_die
    24:         preflight_or_die(verbose=False)
    25:     except SystemExit:
    26:         # le préflight a signalé un problème -> on laisse l'arrêt se propager
    27:         raise
    28:     except Exception as e:
    29:         # On ne bloque pas le démarrage si le selfcheck lui-même plante,
    30:         # mais on affiche une alerte claire.
    31:         print(f"[sitecustomize] Avertissement: selfcheck non exécuté ({e})")

## tests/conftest.py (last modified: 2025-08-23 20:57:14)
     1: """Test configuration and shared fixtures."""
     2: 
     3: import sys
     4: import types
     5: from pathlib import Path
     6: 
     7: 
     8: # Ensure the project root is importable so tests can ``import bot``.
     9: ROOT = Path(__file__).resolve().parents[1]
    10: sys.path.insert(0, str(ROOT))
    11: 
    12: 
    13: # Provide a dummy ``requests`` module so ``bot.py`` doesn't attempt to install
    14: # the real dependency during test collection. Individual tests patch the
    15: # functions they need (``request``/``post``/``get``).
    16: sys.modules.setdefault(
    17:     "requests",
    18:     types.SimpleNamespace(HTTPError=Exception, request=None, post=None, get=None),
    19: )
    20: 


## tests/test_analyse_risque.py (last modified: 2025-08-23 20:57:14)
     1: import os
     2: import sys
     3: import types
     4: 
     5: sys.path.append(os.path.dirname(os.path.dirname(__file__)))
     6: sys.modules['requests'] = types.SimpleNamespace(
     7:     request=lambda *a, **k: None,
     8:     post=lambda *a, **k: None,
     9:     HTTPError=Exception,
    10: )
    11: 
    12: from bot import analyse_risque  # noqa: E402
    13: 
    14: 
    15: def make_contract_detail():
    16:     return {
    17:         "data": [
    18:             {
    19:                 "symbol": "BTC_USDT",
    20:                 "contractSize": 0.01,
    21:                 "volUnit": 1,
    22:                 "minVol": 1,
    23:             }
    24:         ]
    25:     }
    26: 
    27: 
    28: def test_analyse_risque_limits_and_leverage():
    29:     contract_detail = make_contract_detail()
    30:     # Risk level 1: leverage halved, limit 1 position
    31:     open_pos = [{"symbol": "BTC_USDT", "side": "long"}]
    32:     vol, lev = analyse_risque(contract_detail, open_pos, 1000, 50000, 0.01, 10,
    33:                                symbol="BTC_USDT", side="long", risk_level=1)
    34:     assert lev == 5
    35:     assert vol == 0  # already one long position
    36: 
    37:     # Risk level 2: base leverage, limit 3 positions
    38:     open_pos = [
    39:         {"symbol": "BTC_USDT", "side": "long"},
    40:         {"symbol": "BTC_USDT", "side": "long"},
    41:         {"symbol": "BTC_USDT", "side": "long"},
    42:     ]
    43:     vol, lev = analyse_risque(contract_detail, open_pos, 1000, 50000, 0.01, 10,
    44:                                symbol="BTC_USDT", side="long", risk_level=2)
    45:     assert lev == 10
    46:     assert vol == 0
    47: 
    48:     # Risk level 3: leverage doubled, no existing position
    49:     open_pos = []
    50:     vol, lev = analyse_risque(contract_detail, open_pos, 1000, 50000, 0.01, 10,
    51:                                symbol="BTC_USDT", side="long", risk_level=3)
    52:     assert lev == 20
    53:     assert vol == 1


## tests/test_backtest.py (last modified: 2025-08-23 20:57:14)
     1: import pytest
     2: 
     3: import bot
     4: 
     5: 
     6: def test_backtest_trades():
     7:     trades = [
     8:         {"symbol": "AAA", "entry": 100.0, "exit": 110.0, "side": 1},
     9:         {"symbol": "BBB", "entry": 100.0, "exit": 90.0, "side": -1},
    10:     ]
    11:     pnl = bot.backtest_trades(trades, fee_rate=0.001)
    12:     # Both trades: 10% - 0.2% fee = 9.8% each
    13:     assert pnl == pytest.approx(19.6)


## tests/test_backtest_multi.py (last modified: 2025-08-23 20:57:14)
     1: import csv
     2: import random
     3: from datetime import datetime, timedelta, timezone
     4: from pathlib import Path
     5: 
     6: import pytest
     7: 
     8: from scalper.backtest.run_multi import run_backtest_multi
     9: from scalper.strategy import Signal
    10: 
    11: 
    12: def make_csv(tmp_path: Path, symbol: str, timeframe: str = "1m") -> None:
    13:     start = datetime(2024, 1, 1, tzinfo=timezone.utc)
    14:     filename = tmp_path / f"{symbol.replace('/', '')}-{timeframe}.csv"
    15:     with open(filename, "w", newline="") as fh:
    16:         writer = csv.writer(fh)
    17:         writer.writerow(["timestamp", "open", "high", "low", "close", "volume"])
    18:         for i in range(200):
    19:             ts = int((start + timedelta(minutes=i)).timestamp() * 1000)
    20:             price = 100 + i
    21:             writer.writerow([ts, price, price * 1.02, price * 0.995, price, 1])
    22: 
    23: 
    24: def simple_signal(symbol, ohlcv, equity, risk_pct, **kwargs):
    25:     closes = ohlcv["close"]
    26:     if len(closes) < 10:
    27:         return None
    28:     price = closes[-1]
    29:     sl = price * 0.99
    30:     tp = price * 1.01
    31:     qty = equity * risk_pct / (price - sl)
    32:     return Signal(symbol, "long", price, sl, tp, tp * 1.01, qty, score=1.0, reasons=["test"])
    33: 
    34: 
    35: def random_signal(symbol, ohlcv, equity, risk_pct, **kwargs):
    36:     if len(ohlcv["close"]) < 10 or random.random() > 0.3:
    37:         return None
    38:     price = ohlcv["close"][-1]
    39:     sl = price * 0.99
    40:     tp = price * 1.01
    41:     qty = equity * risk_pct / (price - sl)
    42:     return Signal(symbol, "long", price, sl, tp, tp * 1.01, qty)
    43: 
    44: 
    45: def tiny_qty_signal(symbol, ohlcv, equity, risk_pct, **kwargs):
    46:     closes = ohlcv["close"]
    47:     if len(closes) < 10:
    48:         return None
    49:     price = closes[-1]
    50:     sl = price * 0.99
    51:     tp = price * 1.01
    52:     return Signal(symbol, "long", price, sl, tp, tp * 1.01, 0.00005)
    53: 
    54: 
    55: def find_row(summary, symbol):
    56:     for row in summary:
    57:         if row["symbol"] == symbol:
    58:             return row
    59:     raise KeyError(symbol)
    60: 
    61: 
    62: def test_csv_multi_pairs(tmp_path, monkeypatch):
    63:     for sym in ["BTC/USDT", "ETH/USDT"]:
    64:         make_csv(tmp_path, sym)
    65:     monkeypatch.setattr("scalper.strategy.generate_signal", simple_signal)
    66:     monkeypatch.setattr("backtest.engine.generate_signal", simple_signal)
    67:     out = tmp_path / "out"
    68:     summary, trades = run_backtest_multi(
    69:         symbols=["BTC/USDT", "ETH/USDT"],
    70:         exchange="csv",
    71:         timeframe="1m",
    72:         csv_dir=str(tmp_path),
    73:         fee_rate=0.0,
    74:         slippage_bps=0.0,
    75:         risk_pct=0.01,
    76:         initial_equity=1000,
    77:         leverage=1.0,
    78:         paper_constraints=True,
    79:         seed=42,
    80:         out_dir=str(out),
    81:         plot=False,
    82:     )
    83:     btc_trades = [t for t in trades if t["symbol"] == "BTC/USDT"]
    84:     eth_trades = [t for t in trades if t["symbol"] == "ETH/USDT"]
    85:     assert len(btc_trades) > 0 and len(eth_trades) > 0
    86:     assert find_row(summary, "BTC/USDT")["pnl_usdt"] > 0
    87:     total = find_row(summary, "TOTAL")["pnl_usdt"]
    88:     assert pytest.approx(total) == find_row(summary, "BTC/USDT")["pnl_usdt"] + find_row(summary, "ETH/USDT")["pnl_usdt"]
    89:     # files
    90:     assert (out / "report_summary.csv").exists()
    91:     assert (out / "report_trades.csv").exists()
    92:     assert (out / "equity_curve_total.csv").exists()
    93:     assert (out / "equity_curve_BTC_USDT.csv").exists()
    94:     # columns in trades
    95:     for col in ["entry_time", "exit_time", "symbol", "side", "entry", "exit", "pnl_pct", "pnl_usdt"]:
    96:         assert col in trades[0]
    97: 
    98: 
    99: def test_fee_slippage(tmp_path, monkeypatch):
   100:     make_csv(tmp_path, "BTC/USDT")
   101:     monkeypatch.setattr("scalper.strategy.generate_signal", simple_signal)
   102:     monkeypatch.setattr("backtest.engine.generate_signal", simple_signal)
   103:     summary1, _ = run_backtest_multi(
   104:         symbols=["BTC/USDT"],
   105:         exchange="csv",
   106:         timeframe="1m",
   107:         csv_dir=str(tmp_path),
   108:         fee_rate=0.0,
   109:         slippage_bps=0.0,
   110:         out_dir=str(tmp_path / "o1"),
   111:     )
   112:     summary2, _ = run_backtest_multi(
   113:         symbols=["BTC/USDT"],
   114:         exchange="csv",
   115:         timeframe="1m",
   116:         csv_dir=str(tmp_path),
   117:         fee_rate=0.01,
   118:         slippage_bps=100,
   119:         out_dir=str(tmp_path / "o2"),
   120:     )
   121:     pnl1 = find_row(summary1, "TOTAL")["pnl_usdt"]
   122:     pnl2 = find_row(summary2, "TOTAL")["pnl_usdt"]
   123:     assert pnl2 < pnl1
   124: 
   125: 
   126: def test_paper_constraints(tmp_path, monkeypatch):
   127:     make_csv(tmp_path, "BTC/USDT")
   128:     monkeypatch.setattr("scalper.strategy.generate_signal", tiny_qty_signal)
   129:     monkeypatch.setattr("backtest.engine.generate_signal", tiny_qty_signal)
   130:     summary, trades = run_backtest_multi(
   131:         symbols=["BTC/USDT"],
   132:         exchange="csv",
   133:         timeframe="1m",
   134:         csv_dir=str(tmp_path),
   135:         paper_constraints=True,
   136:         out_dir=str(tmp_path / "o"),
   137:     )
   138:     assert all(t["qty"] >= 0.001 for t in trades)
   139:     assert all(abs((t["qty"] * 10000) % 1) < 1e-9 for t in trades)
   140:     assert all(t["entry"] * t["qty"] >= 5 - 1e-9 for t in trades)
   141: 
   142: 
   143: def test_seed_reproducible(tmp_path, monkeypatch):
   144:     make_csv(tmp_path, "BTC/USDT")
   145:     monkeypatch.setattr("scalper.strategy.generate_signal", random_signal)
   146:     monkeypatch.setattr("backtest.engine.generate_signal", random_signal)
   147:     s1, t1 = run_backtest_multi(
   148:         symbols=["BTC/USDT"],
   149:         exchange="csv",
   150:         timeframe="1m",
   151:         csv_dir=str(tmp_path),
   152:         seed=7,
   153:         out_dir=str(tmp_path / "o1"),
   154:     )
   155:     s2, t2 = run_backtest_multi(
   156:         symbols=["BTC/USDT"],
   157:         exchange="csv",
   158:         timeframe="1m",
   159:         csv_dir=str(tmp_path),
   160:         seed=7,
   161:         out_dir=str(tmp_path / "o2"),
   162:     )
   163:     assert t1 == t2
   164:     assert s1 == s2


## tests/test_backtest_position.py (last modified: 2025-08-23 20:57:14)
     1: import os
     2: import sys
     3: import pytest
     4: 
     5: sys.path.append(os.path.dirname(os.path.dirname(__file__)))
     6: 
     7: from scalper.metrics import backtest_position
     8: 
     9: 
    10: def test_backtest_position_long():
    11:     prices = [100.0, 110.0, 120.0]
    12:     assert backtest_position(prices, 0, 2, 1) is True
    13: 
    14: 
    15: def test_backtest_position_short():
    16:     prices = [100.0, 90.0, 80.0]
    17:     assert backtest_position(prices, 0, 2, -1) is True
    18: 
    19: 
    20: def test_backtest_position_incoherent():
    21:     prices = [100.0, 110.0, 120.0]
    22:     assert backtest_position(prices, 0, 2, -1) is False
    23: 
    24: 
    25: def test_backtest_position_bad_indices():
    26:     prices = [100.0, 110.0]
    27:     with pytest.raises(ValueError):
    28:         backtest_position(prices, 1, 0, 1)


## tests/test_bitget_futures_pairs.py (last modified: 2025-08-23 20:57:14)
     1: import json
     2: from pathlib import Path
     3: from typing import Any, Dict
     4: 
     5: import pytest
     6: 
     7: import bitget_futures_pairs as bfp
     8: 
     9: 
    10: class DummyResponse:
    11:     def __init__(self, status: int, payload: Dict[str, Any]):
    12:         self.status_code = status
    13:         self._payload = payload
    14:         self.text = json.dumps(payload)
    15: 
    16:     def json(self):
    17:         return self._payload
    18: 
    19: 
    20: def test_fetch_contracts_success(monkeypatch):
    21:     payload = {"code": "00000", "data": [{"symbol": "BTCUSDT"}]}
    22: 
    23:     def fake_get(url, params=None, timeout=0):
    24:         return DummyResponse(200, payload)
    25: 
    26:     monkeypatch.setattr(bfp, "requests", type("R", (), {"get": staticmethod(fake_get)})())
    27:     contracts = bfp.fetch_contracts("USDT-FUTURES")
    28:     assert contracts == payload["data"]
    29: 
    30: 
    31: def test_fetch_contracts_error(monkeypatch):
    32:     payload = {"code": "10001"}
    33: 
    34:     def fake_get(url, params=None, timeout=0):
    35:         return DummyResponse(200, payload)
    36: 
    37:     monkeypatch.setattr(bfp, "requests", type("R", (), {"get": staticmethod(fake_get)})())
    38:     with pytest.raises(RuntimeError):
    39:         bfp.fetch_contracts("USDT-FUTURES")
    40: 
    41: 
    42: def test_normalize_rows():
    43:     contracts = [
    44:         {
    45:             "symbol": "BTCUSDT",
    46:             "baseCoin": "BTC",
    47:             "quoteCoin": "USDT",
    48:             "symbolType": "perpetual",
    49:             "symbolStatus": "normal",
    50:             "maxLever": "50",
    51:             "minLever": "1",
    52:             "minTradeNum": "0.001",
    53:             "sizeMultiplier": "1",
    54:             "pricePlace": "2",
    55:             "volumePlace": "3",
    56:             "launchTime": 0,
    57:             "deliveryTime": 0,
    58:         }
    59:     ]
    60:     rows = bfp.normalize_rows("USDT-FUTURES", contracts)
    61:     assert rows[0]["symbol"] == "BTCUSDT"
    62:     assert rows[0]["productType"] == "USDT-FUTURES"
    63: 
    64: 
    65: def test_write_csv(tmp_path: Path):
    66:     path = tmp_path / "pairs.csv"
    67:     bfp.write_csv([], str(path))
    68:     assert path.exists()
    69:     content = path.read_text().splitlines()
    70:     assert content[0].startswith("productType,")


## tests/test_bot_place_order_caps.py (last modified: 2025-08-23 20:57:14)
     1: import os
     2: import sys
     3: import types
     4: sys.path.append(os.path.dirname(os.path.dirname(__file__)))
     5: sys.modules['requests'] = types.ModuleType('requests')
     6: 
     7: from bot import attempt_entry, Signal
     8: 
     9: 
    10: class DummyClient:
    11:     def __init__(self):
    12:         self.last_order = None
    13: 
    14:     def place_order(self, *args, **kwargs):  # pragma: no cover - simple store
    15:         self.last_order = (args, kwargs)
    16:         return {"code": "00000"}
    17: 
    18: 
    19: class DummyRisk:
    20:     def __init__(self, pct):
    21:         self.risk_pct = pct
    22: 
    23: 
    24: def _detail():
    25:     return {
    26:         "data": [
    27:             {
    28:                 "symbol": "BTC_USDT",
    29:                 "contractSize": 0.001,
    30:                 "volUnit": 1,
    31:                 "minVol": 1,
    32:                 "minTradeUSDT": 5,
    33:             }
    34:         ]
    35:     }
    36: 
    37: 
    38: def test_attempt_entry_respects_caps(monkeypatch):
    39:     captured = {}
    40: 
    41:     def fake_notify(event, payload):
    42:         captured[event] = payload
    43: 
    44:     monkeypatch.setattr("bot.notify", fake_notify)
    45:     client = DummyClient()
    46:     sig = Signal("BTC_USDT", "long", 10000, 9900, 10100, 10200, 1, score=80)
    47:     rm = DummyRisk(0.02)
    48:     equity = 100
    49:     available = 2.2  # just enough for 1 contract with buffer
    50:     params = attempt_entry(
    51:         client,
    52:         _detail(),
    53:         sig,
    54:         equity_usdt=equity,
    55:         available_usdt=available,
    56:         cfg={"LEVERAGE": 10},
    57:         risk_mgr=rm,
    58:         user_risk_level=1,
    59:     )
    60:     assert client.last_order is not None
    61:     assert params["vol"] >= 1
    62:     opened = captured["position_opened"]
    63:     assert opened["notional_usdt"] >= 5
    64:     assert opened["vol"] >= 1
    65: 
    66: 
    67: def test_attempt_entry_insufficient_margin(monkeypatch):
    68:     captured = {}
    69: 
    70:     def fake_notify(event, payload):
    71:         captured[event] = payload
    72: 
    73:     monkeypatch.setattr("bot.notify", fake_notify)
    74:     client = DummyClient()
    75:     sig = Signal("BTC_USDT", "long", 10000, 9900, 10100, 10200, 1, score=80)
    76:     rm = DummyRisk(0.02)
    77:     equity = 100
    78:     available = 1.0  # below required margin
    79:     params = attempt_entry(
    80:         client,
    81:         _detail(),
    82:         sig,
    83:         equity_usdt=equity,
    84:         available_usdt=available,
    85:         cfg={"LEVERAGE": 10},
    86:         risk_mgr=rm,
    87:         user_risk_level=1,
    88:     )
    89:     assert client.last_order is None
    90:     assert params["vol"] == 0
    91:     assert captured["order_blocked"]["reason"].startswith("volume reduced")
    92: 
    93: 
    94: def test_attempt_entry_under_min_trade(monkeypatch):
    95:     captured = {}
    96: 
    97:     def fake_notify(event, payload):
    98:         captured[event] = payload
    99: 
   100:     monkeypatch.setattr("bot.notify", fake_notify)
   101:     client = DummyClient()
   102:     sig = Signal("BTC_USDT", "long", 10000, 9900, 10100, 10200, 1, score=80)
   103:     rm = DummyRisk(0.02)
   104:     detail = {
   105:         "data": [
   106:             {
   107:                 "symbol": "BTC_USDT",
   108:                 "contractSize": 0.001,
   109:                 "volUnit": 1,
   110:                 "minVol": 1,
   111:                 "minTradeUSDT": 50,
   112:             }
   113:         ]
   114:     }
   115:     equity = 100
   116:     available = 100
   117:     params = attempt_entry(
   118:         client,
   119:         detail,
   120:         sig,
   121:         equity_usdt=equity,
   122:         available_usdt=available,
   123:         cfg={"LEVERAGE": 10},
   124:         risk_mgr=rm,
   125:         user_risk_level=1,
   126:     )
   127:     assert client.last_order is None
   128:     assert params["vol"] == 0
   129:     assert captured["order_blocked"]["reason"].startswith("volume reduced")


## tests/test_bot_update.py (last modified: 2025-08-23 20:57:14)
     1: import logging
     2: import bot
     3: 
     4: 
     5: def test_update_displays_pairs(monkeypatch, caplog):
     6:     def fake_send(client, top_n=40):
     7:         assert (client, top_n) == ("cli", 5)
     8:         return {"green": "BTC", "orange": "ETH", "red": "XRP"}
     9: 
    10:     monkeypatch.setattr(bot, "send_selected_pairs", fake_send)
    11:     with caplog.at_level(logging.INFO):
    12:         payload = bot.update("cli", top_n=5)
    13:     assert payload["green"] == "BTC"
    14:     assert "Listing ok" in caplog.text
    15: 
    16: 
    17: def test_update_survives_errors(monkeypatch, caplog):
    18:     """``update`` should never raise even if pair selection fails."""
    19: 
    20:     def boom(client, top_n=40):  # pragma: no cover - simulated failure
    21:         raise RuntimeError("network down")
    22: 
    23:     monkeypatch.setattr(bot, "send_selected_pairs", boom)
    24:     with caplog.at_level(logging.INFO):
    25:         payload = bot.update("cli", top_n=5)
    26: 
    27:     # The function returns an empty payload and logs the error, but still logs
    28:     # the "Listing ok" acknowledgement so callers can proceed.
    29:     assert payload == {}
    30:     assert "network down" in caplog.text
    31:     assert "Listing ok" in caplog.text
    32: 


## tests/test_break_even_stop.py (last modified: 2025-08-23 20:57:14)
     1: from scalper.trade_utils import break_even_stop
     2: 
     3: 
     4: def test_break_even_stop_long() -> None:
     5:     sl = break_even_stop("long", entry_price=100, current_price=110, atr=5, sl=95)
     6:     assert sl == 100
     7:     sl = break_even_stop("long", entry_price=100, current_price=102, atr=5, sl=95)
     8:     assert sl == 95
     9: 
    10: 
    11: def test_break_even_stop_short() -> None:
    12:     sl = break_even_stop("short", entry_price=100, current_price=90, atr=5, sl=105)
    13:     assert sl == 100
    14:     sl = break_even_stop("short", entry_price=100, current_price=97, atr=5, sl=105)
    15:     assert sl == 105


## tests/test_calc_pnl_pct.py (last modified: 2025-08-23 20:57:14)
     1: import os
     2: import sys
     3: import pytest
     4: sys.path.append(os.path.dirname(os.path.dirname(__file__)))
     5: 
     6: from scalper.metrics import calc_pnl_pct
     7: 
     8: 
     9: def test_calc_pnl_pct_long():
    10:     assert calc_pnl_pct(100.0, 110.0, 1) == 10.0
    11: 
    12: def test_calc_pnl_pct_short():
    13:     assert calc_pnl_pct(100.0, 90.0, -1) == 10.0
    14: 
    15: 
    16: def test_calc_pnl_pct_with_fee():
    17:     # 10% move minus 0.1%*2 fees = 9.8%
    18:     assert calc_pnl_pct(100.0, 110.0, 1, fee_rate=0.001) == pytest.approx(9.8)


## tests/test_check_config.py (last modified: 2025-08-23 20:57:14)
     1: import logging
     2: from bot import check_config
     3: 
     4: 
     5: def test_check_config_only_logs_critical_missing(monkeypatch, caplog):
     6:     monkeypatch.delenv("BITGET_ACCESS_KEY", raising=False)
     7:     monkeypatch.delenv("BITGET_SECRET_KEY", raising=False)
     8:     monkeypatch.delenv("NOTIFY_URL", raising=False)
     9:     with caplog.at_level(logging.INFO):
    10:         check_config()
    11:     messages = [r.getMessage() for r in caplog.records]
    12:     assert any("BITGET_ACCESS_KEY" in m for m in messages)
    13:     assert any("BITGET_SECRET_KEY" in m for m in messages)
    14:     assert all("NOTIFY_URL" not in m for m in messages)
    15: 
    16: 
    17: def test_check_config_does_not_log_present_keys(monkeypatch, caplog):
    18:     monkeypatch.setenv("BITGET_ACCESS_KEY", "abcdef")
    19:     monkeypatch.setenv("BITGET_SECRET_KEY", "abcdef")
    20:     monkeypatch.setenv("BITGET_PASSPHRASE", "abcdef")
    21:     with caplog.at_level(logging.INFO):
    22:         check_config()
    23:     assert caplog.records == []


## tests/test_cli.py (last modified: 2025-08-23 20:57:14)
     1: """Tests for the command line interface defined in :mod:`cli`."""
     2: 
     3: from __future__ import annotations
     4: 
     5: import cli
     6: 
     7: 
     8: def test_opt_invokes_parallel_optimization(monkeypatch):
     9:     """The ``opt`` command should call ``run_parallel_optimization``."""
    10: 
    11:     called = {}
    12: 
    13:     def fake_run(pairs, tf, jobs):  # pragma: no cover - executed via CLI
    14:         called["args"] = (pairs, tf, jobs)
    15: 
    16:     monkeypatch.setattr(cli, "run_parallel_optimization", fake_run)
    17:     cli.main(["opt", "--pairs", "BTCUSDT", "ETHUSDT", "--tf", "1h", "--jobs", "4"])
    18:     assert called["args"] == (["BTCUSDT", "ETHUSDT"], "1h", 4)
    19: 
    20: 
    21: def test_walkforward_invokes_analysis(monkeypatch):
    22:     """The ``walkforward`` command calls ``run_walkforward_analysis``."""
    23: 
    24:     called = {}
    25: 
    26:     def fake_run(pair, tf, splits, train_ratio):  # pragma: no cover
    27:         called["args"] = (pair, tf, splits, train_ratio)
    28: 
    29:     monkeypatch.setattr(cli, "run_walkforward_analysis", fake_run)
    30:     cli.main(
    31:         [
    32:             "walkforward",
    33:             "--pair",
    34:             "BTCUSDT",
    35:             "--tf",
    36:             "1m",
    37:             "--splits",
    38:             "3",
    39:             "--train-ratio",
    40:             "0.8",
    41:         ]
    42:     )
    43:     assert called["args"] == ("BTCUSDT", "1m", 3, 0.8)
    44: 
    45: 
    46: def test_live_invokes_async_pipeline(monkeypatch):
    47:     """The ``live`` command must execute the async pipeline via ``asyncio.run``."""
    48: 
    49:     called = {}
    50: 
    51:     async def fake_live(pairs, tfs):  # pragma: no cover - executed asynchronously
    52:         called["args"] = (pairs, list(tfs))
    53: 
    54:     monkeypatch.setattr(cli, "run_live_pipeline", fake_live)
    55:     cli.main(["live", "--pairs", "BTCUSDT", "ETHUSDT", "--tfs", "1m", "1h"])
    56:     assert called["args"] == (["BTCUSDT", "ETHUSDT"], ["1m", "1h"])
    57: 
    58: 
    59: def test_bump_version_invokes_helper(monkeypatch):
    60:     """The ``bump-version`` command calls ``bump_version_from_git``."""
    61: 
    62:     called = {}
    63: 
    64:     def fake_bump():  # pragma: no cover - executed via CLI
    65:         called["called"] = True
    66:         return "0.1.0"
    67: 
    68:     monkeypatch.setattr(cli, "bump_version_from_git", fake_bump)
    69:     cli.main(["bump-version"])
    70:     assert called["called"] is True
    71: 


## tests/test_client.py (last modified: 2025-08-23 20:57:14)
     1: import json
     2: import hmac
     3: import hashlib
     4: import base64
     5: import pytest
     6: import bot
     7: from bot import BitgetFuturesClient
     8: 
     9: 
    10: @pytest.fixture(autouse=True)
    11: def no_log_event(monkeypatch):
    12:     monkeypatch.setattr(bot, "log_event", lambda *a, **k: None)
    13: 
    14: 
    15: def test_private_request_get_signature(monkeypatch):
    16:     client = BitgetFuturesClient("key", "secret", "https://test")
    17:     monkeypatch.setattr(BitgetFuturesClient, "_ms", staticmethod(lambda: 1000))
    18: 
    19:     called = {}
    20: 
    21:     def fake_request(method, url, headers=None, timeout=None):
    22:         called["method"] = method
    23:         called["url"] = url
    24:         called["headers"] = headers
    25: 
    26:         class Resp:
    27:             def raise_for_status(self):
    28:                 pass
    29: 
    30:             def json(self):
    31:                 return {"success": True}
    32: 
    33:         return Resp()
    34: 
    35:     monkeypatch.setattr(bot.requests, "request", fake_request)
    36: 
    37:     resp = client._private_request("GET", "/api/test", params={"b": "2", "a": "1"})
    38:     assert resp["success"] is True
    39:     qs = "a=1&b=2"
    40:     prehash = f"1000GET/api/test?{qs}"
    41:     expected = base64.b64encode(
    42:         hmac.new(b"secret", prehash.encode(), hashlib.sha256).digest()
    43:     ).decode()
    44:     assert called["headers"]["ACCESS-SIGN"] == expected
    45:     assert called["headers"]["ACCESS-KEY"] == "key"
    46:     assert called["headers"]["ACCESS-TIMESTAMP"] == "1000"
    47:     assert called["headers"]["ACCESS-RECV-WINDOW"] == "30"
    48:     assert called["url"] == "https://test/api/test?a=1&b=2"
    49: 
    50: 
    51: def test_private_request_post_signature(monkeypatch):
    52:     client = BitgetFuturesClient("key", "secret", "https://test")
    53:     monkeypatch.setattr(BitgetFuturesClient, "_ms", staticmethod(lambda: 1000))
    54: 
    55:     called = {}
    56: 
    57:     def fake_post(url, data=None, headers=None, timeout=None):
    58:         called["url"] = url
    59:         called["data"] = data
    60:         called["headers"] = headers
    61: 
    62:         class Resp:
    63:             def raise_for_status(self):
    64:                 pass
    65: 
    66:             def json(self):
    67:                 return {"success": True}
    68: 
    69:         return Resp()
    70: 
    71:     monkeypatch.setattr(bot.requests, "post", fake_post)
    72: 
    73:     resp = client._private_request("POST", "/api/test", body={"a": 1, "b": 2})
    74:     assert resp["success"] is True
    75:     body = json.dumps({"a": 1, "b": 2}, separators=(",", ":"), ensure_ascii=False)
    76:     prehash = f"1000POST/api/test{body}"
    77:     expected = base64.b64encode(
    78:         hmac.new(b"secret", prehash.encode(), hashlib.sha256).digest()
    79:     ).decode()
    80:     assert called["headers"]["ACCESS-SIGN"] == expected
    81:     assert called["headers"]["ACCESS-KEY"] == "key"
    82:     assert called["headers"]["ACCESS-TIMESTAMP"] == "1000"
    83:     assert called["headers"]["ACCESS-RECV-WINDOW"] == "30"
    84:     assert called["data"].decode("utf-8") == body
    85:     assert called["url"] == "https://test/api/test"
    86: 
    87: 
    88: def test_private_request_http_error(monkeypatch):
    89:     client = BitgetFuturesClient("key", "secret", "https://test")
    90:     monkeypatch.setattr(BitgetFuturesClient, "_ms", staticmethod(lambda: 1000))
    91: 
    92:     class Resp:
    93:         status_code = 418
    94: 
    95:         def raise_for_status(self):
    96:             raise bot.requests.HTTPError("teapot")
    97: 
    98:         def json(self):
    99:             return {"unused": True}
   100: 
   101:     monkeypatch.setattr(bot.requests, "request", lambda *a, **k: Resp())
   102: 
   103:     resp = client._private_request("GET", "/api/test")
   104:     assert resp["success"] is False
   105:     assert resp["status_code"] == 418
   106:     assert "teapot" in resp["error"]
   107: 
   108: 
   109: def test_get_assets_normalization(monkeypatch):
   110:     client = BitgetFuturesClient("key", "secret", "https://test")
   111: 
   112:     called = {}
   113: 
   114:     def fake_private(self, method, path, params=None, body=None):
   115:         called["method"] = method
   116:         called["path"] = path
   117:         called["params"] = params
   118:         return {"code": "00000", "data": [{"marginCoin": "usdt", "equity": "1"}]}
   119: 
   120:     monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)
   121: 
   122:     assets = client.get_assets()
   123: 
   124:     assert assets["success"] is True
   125:     usdt = assets.get("data", [])[0]
   126:     assert usdt["currency"].upper() == "USDT"
   127:     assert usdt["equity"] == 1.0
   128:     assert called["params"] == {"productType": "USDT-FUTURES", "marginCoin": "USDT"}
   129: 
   130: 
   131: def test_get_assets_equity_fallback(monkeypatch):
   132:     client = BitgetFuturesClient("key", "secret", "https://test")
   133: 
   134:     def fake_private(self, method, path, params=None, body=None):
   135:         return {"code": "00000", "data": [{"marginCoin": "USDT", "available": "2"}]}
   136: 
   137:     monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)
   138: 
   139:     assets = client.get_assets()
   140:     usdt = assets.get("data", [])[0]
   141:     assert usdt["currency"] == "USDT"
   142:     assert usdt["equity"] == 2.0
   143: 
   144: 
   145: def test_get_assets_prefers_available(monkeypatch):
   146:     """When both equity and available are returned, available should win."""
   147:     client = BitgetFuturesClient("key", "secret", "https://test")
   148: 
   149:     def fake_private(self, method, path, params=None, body=None):
   150:         return {
   151:             "code": "00000",
   152:             "data": [
   153:                 {
   154:                     "marginCoin": "USDT",
   155:                     "equity": "5",
   156:                     "available": "1",
   157:                 }
   158:             ],
   159:         }
   160: 
   161:     monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)
   162: 
   163:     assets = client.get_assets()
   164:     usdt = assets.get("data", [])[0]
   165:     assert usdt["equity"] == 1.0
   166: 
   167: 
   168: 
   169: def test_get_assets_zero_available(monkeypatch):
   170:     """Zero available balance should propagate as zero equity."""
   171:     client = BitgetFuturesClient("key", "secret", "https://test")
   172: 
   173:     def fake_private(self, method, path, params=None, body=None):
   174:         return {
   175:             "code": "00000",
   176:             "data": [
   177:                 {
   178:                     "marginCoin": "USDT",
   179:                     "available": "0",
   180:                     "equity": "5",
   181:                 }
   182:             ],
   183:         }
   184: 
   185:     monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)
   186: 
   187:     assets = client.get_assets()
   188:     usdt = assets.get("data", [])[0]
   189:     assert usdt["equity"] == 0.0
   190: 
   191: 
   192: def test_get_assets_available_balance(monkeypatch):
   193:     """Support alternative ``availableBalance`` field name."""
   194:     client = BitgetFuturesClient("key", "secret", "https://test")
   195: 
   196:     def fake_private(self, method, path, params=None, body=None):
   197:         return {
   198:             "code": "00000",
   199:             "data": [{"marginCoin": "USDT", "availableBalance": "3.5"}],
   200:         }
   201: 
   202:     monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)
   203: 
   204:     assets = client.get_assets()
   205:     usdt = assets.get("data", [])[0]
   206:     assert usdt["equity"] == 3.5
   207: 
   208: 
   209: def test_get_ticker_normalization(monkeypatch):
   210:     client = BitgetFuturesClient("key", "secret", "https://test")
   211: 
   212:     called = {}
   213: 
   214:     def fake_get(url, params=None, timeout=None):
   215:         called["url"] = url
   216:         called["params"] = params
   217: 
   218:         class Resp:
   219:             def raise_for_status(self):
   220:                 pass
   221: 
   222:             def json(self):
   223:                 return {
   224:                     "data": {
   225:                         "instId": "BTCUSDT",
   226:                         "lastPr": "1",
   227:                         "bestBidPrice": "0.9",
   228:                         "bestAskPrice": "1.1",
   229:                         "usdtVolume": "100",
   230:                     }
   231:                 }
   232: 
   233:         return Resp()
   234: 
   235:     monkeypatch.setattr(bot.requests, "get", fake_get, raising=False)
   236: 
   237:     ticker = client.get_ticker("BTC_USDT")
   238: 
   239:     assert ticker["success"] is True
   240:     data = ticker["data"][0]
   241:     assert data["symbol"] == "BTCUSDT"
   242:     assert data["lastPrice"] == "1"
   243:     assert data["bidPrice"] == "0.9"
   244:     assert data["askPrice"] == "1.1"
   245:     assert data["volume"] == 100.0
   246:     assert called["params"] == {"symbol": "BTCUSDT", "productType": "USDT-FUTURES"}
   247: 
   248: 
   249: def test_http_client_context_manager(monkeypatch):
   250:     import sys
   251:     import importlib
   252:     sys.modules.pop('requests', None)
   253:     real_requests = importlib.import_module('requests')
   254:     sys.modules['requests'] = real_requests
   255:     import scalper.client as http_client
   256:     importlib.reload(http_client)
   257: 
   258:     closed = {"count": 0}
   259: 
   260:     class DummySession:
   261:         def mount(self, *a, **k):
   262:             pass
   263: 
   264:         def request(self, *a, **k):
   265:             class Resp:
   266:                 def raise_for_status(self):
   267:                     pass
   268: 
   269:                 def json(self):
   270:                     return {}
   271: 
   272:                 text = "{}"
   273: 
   274:             return Resp()
   275: 
   276:         def close(self):
   277:             closed["count"] += 1
   278: 
   279:     monkeypatch.setattr(http_client.requests, "Session", lambda: DummySession())
   280: 
   281:     http = http_client.HttpClient("http://example.com")
   282:     http.close()
   283:     assert closed["count"] == 1
   284: 
   285:     closed["count"] = 0
   286:     with http_client.HttpClient("http://example.com") as hc:
   287:         hc.request("GET", "/")
   288:     assert closed["count"] == 1
   289: 
   290: 
   291: def test_get_kline_query_params(monkeypatch):
   292:     """Ensure ``get_kline`` hits the correct endpoint and passes symbol as a
   293:     query parameter. The previous implementation embedded the symbol in the
   294:     path which resulted in a 404 from Bitget."""
   295: 
   296:     client = BitgetFuturesClient("key", "secret", "https://test")
   297: 
   298:     called = {}
   299: 
   300:     def fake_get(url, params=None, timeout=None):
   301:         called["url"] = url
   302:         called["params"] = params
   303: 
   304:         class Resp:
   305:             def raise_for_status(self):
   306:                 pass
   307: 
   308:             def json(self):
   309:                 return {"data": []}
   310: 
   311:         return Resp()
   312: 
   313:     # Some tests replace ``bot.requests`` with a lightweight namespace that
   314:     # doesn't define ``get``. ``raising=False`` ensures the attribute is added
   315:     # even if missing so we can observe the call.
   316:     monkeypatch.setattr(bot.requests, "get", fake_get, raising=False)
   317: 
   318:     client.get_kline("BTC_USDT", interval="Min1")
   319: 
   320:     assert called["url"].endswith("/api/v2/mix/market/candles")
   321:     assert called["params"] == {
   322:         "symbol": "BTCUSDT",
   323:         "productType": "USDT-FUTURES",
   324:         "granularity": "1m",
   325:     }
   326: 
   327: 
   328: def test_get_open_orders_endpoint(monkeypatch):
   329:     client = BitgetFuturesClient("key", "secret", "https://test", paper_trade=False)
   330: 
   331:     called = {}
   332: 
   333:     def fake_private(self, method, path, params=None, body=None):
   334:         called["method"] = method
   335:         called["path"] = path
   336:         called["params"] = params
   337:         return {"success": True}
   338: 
   339:     monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)
   340: 
   341:     client.get_open_orders("BTCUSDT_UMCBL")
   342: 
   343:     assert called["path"] == "/api/v2/mix/order/orders-pending"
   344:     assert called["params"] == {
   345:         "productType": "USDT-FUTURES",
   346:         "symbol": "BTCUSDT",
   347:     }
   348: 
   349: 
   350: def test_product_type_alias():
   351:     client = BitgetFuturesClient("key", "secret", "https://test", product_type="umcbl")
   352:     assert client.product_type == "USDT-FUTURES"
   353: 
   354: 
   355: def test_get_contract_detail_endpoint(monkeypatch):
   356:     client = BitgetFuturesClient("key", "secret", "https://test")
   357: 
   358:     called = {}
   359: 
   360:     def fake_get(url, params=None, timeout=None):
   361:         called["url"] = url
   362:         called["params"] = params
   363: 
   364:         class Resp:
   365:             status_code = 200
   366: 
   367:             def raise_for_status(self):
   368:                 pass
   369: 
   370:             def json(self):
   371:                 return {"data": []}
   372: 
   373:         return Resp()
   374: 
   375:     monkeypatch.setattr(bot.requests, "get", fake_get, raising=False)
   376: 
   377:     client.get_contract_detail("BTCUSDT_UMCBL")
   378: 
   379:     assert called["url"].endswith("/api/v2/mix/market/contracts")
   380:     assert called["params"] == {
   381:         "productType": "USDT-FUTURES",
   382:         "symbol": "BTCUSDT",
   383:     }
   384: 
   385: 
   386: def test_cancel_all_endpoint(monkeypatch):
   387:     client = BitgetFuturesClient("key", "secret", "https://test", paper_trade=False)
   388: 
   389:     called = {}
   390: 
   391:     def fake_private(self, method, path, params=None, body=None):
   392:         called["method"] = method
   393:         called["path"] = path
   394:         called["params"] = params
   395:         called["body"] = body
   396:         return {"success": True}
   397: 
   398:     monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)
   399: 
   400:     client.cancel_all("BTCUSDT_UMCBL", margin_coin="USDT")
   401: 
   402:     assert called["method"] == "POST"
   403:     assert called["path"] == "/api/v2/mix/order/cancel-all-orders"
   404:     assert called["params"] is None
   405:     assert called["body"] == {
   406:         "productType": "USDT-FUTURES",
   407:         "symbol": "BTCUSDT",
   408:         "marginCoin": "USDT",
   409:     }
   410: 
   411: 
   412: def test_place_order_endpoint(monkeypatch):
   413:     client = BitgetFuturesClient("key", "secret", "https://test", paper_trade=False)
   414: 
   415:     called = {}
   416: 
   417:     monkeypatch.setattr(BitgetFuturesClient, "_get_contract_precision", lambda self, symbol: (0, 0))
   418: 
   419:     def fake_private(self, method, path, params=None, body=None):
   420:         called["method"] = method
   421:         called["path"] = path
   422:         called["body"] = body
   423:         return {"success": True}
   424: 
   425:     monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)
   426: 
   427:     resp = client.place_order("BTCUSDT_UMCBL", side=1, vol=1, order_type=1)
   428: 
   429:     assert resp["success"] is True
   430:     assert called["method"] == "POST"
   431:     assert called["path"] == "/api/v2/mix/order/place-order"
   432:     body = called["body"]
   433:     assert body["symbol"] == "BTCUSDT"
   434:     assert body["marginCoin"] == "USDT"
   435:     assert body["marginMode"] == "crossed"
   436:     assert body["side"] == "buy"
   437:     assert body["posSide"] == "long"
   438:     assert "reduceOnly" not in body
   439:     assert body["posMode"] == "hedge_mode"
   440: 
   441: 
   442: @pytest.mark.parametrize(
   443:     "code, side_str, pos_side",
   444:     [
   445:         (4, "sell", "long"),
   446:         (2, "buy", "short"),
   447:     ],
   448: )
   449: def test_place_order_close_positions(monkeypatch, code, side_str, pos_side):
   450:     client = BitgetFuturesClient("key", "secret", "https://test", paper_trade=False)
   451: 
   452:     monkeypatch.setattr(BitgetFuturesClient, "_get_contract_precision", lambda self, symbol: (0, 0))
   453: 
   454:     called = {}
   455: 
   456:     def fake_private(self, method, path, params=None, body=None):
   457:         called["body"] = body
   458:         return {"success": True}
   459: 
   460:     monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)
   461: 
   462:     client.place_order("BTCUSDT_UMCBL", side=code, vol=1, order_type=1)
   463: 
   464:     body = called["body"]
   465:     assert body["side"] == side_str
   466:     assert body["posSide"] == pos_side
   467:     assert "reduceOnly" not in body
   468: 
   469: 
   470: def test_place_order_precision(monkeypatch):
   471:     client = BitgetFuturesClient("key", "secret", "https://test", paper_trade=False)
   472: 
   473:     monkeypatch.setattr(BitgetFuturesClient, "_get_contract_precision", lambda self, symbol: (2, 3))
   474: 
   475:     called = {}
   476: 
   477:     def fake_private(self, method, path, params=None, body=None):
   478:         called["body"] = body
   479:         return {"success": True}
   480: 
   481:     monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)
   482: 
   483:     client.place_order(
   484:         "BTCUSDT_UMCBL", side=1, vol=1.23456, order_type=1, price=1234.5678
   485:     )
   486: 
   487:     assert called["body"]["price"] == 1234.57
   488:     assert called["body"]["size"] == 1.235
   489: 
   490: 
   491: def test_margin_cap_skips_order(monkeypatch):
   492:     client = BitgetFuturesClient("key", "secret", "https://test", paper_trade=False)
   493:     called = {}
   494: 
   495:     def fake_private(method, path, **kwargs):
   496:         called["path"] = path
   497:         return {"code": "00000"}
   498: 
   499:     monkeypatch.setattr(client, "_private_request", fake_private)
   500:     contract_detail = {
   501:         "data": {
   502:             "symbol": "BTCUSDT_UMCBL",
   503:             "contractSize": 1,
   504:             "volUnit": 1,
   505:             "minVol": 1,
   506:             "minTradeUSDT": 5,
   507:         }
   508:     }
   509:     price = 100.0
   510:     available = 0.5
   511:     vol = bot.compute_position_size(
   512:         contract_detail,
   513:         equity_usdt=available,
   514:         price=price,
   515:         risk_pct=1.0,
   516:         leverage=10,
   517:         symbol="BTCUSDT_UMCBL",
   518:         available_usdt=available,
   519:     )
   520:     if vol > 0:
   521:         client.place_order(
   522:             "BTCUSDT_UMCBL", side=1, vol=vol, order_type=1, price=price, leverage=10
   523:         )
   524:     assert called == {}
   525: 
   526: 
   527: def test_margin_cap_reduces_volume(monkeypatch):
   528:     client = BitgetFuturesClient("key", "secret", "https://test", paper_trade=False)
   529:     called = {}
   530: 
   531:     def fake_private(method, path, **kwargs):
   532:         called["body"] = kwargs.get("body")
   533:         return {"code": "00000"}
   534: 
   535:     monkeypatch.setattr(client, "_private_request", fake_private)
   536:     contract_detail = {
   537:         "data": {
   538:             "symbol": "BTCUSDT_UMCBL",
   539:             "contractSize": 1,
   540:             "volUnit": 1,
   541:             "minVol": 1,
   542:             "minTradeUSDT": 5,
   543:         }
   544:     }
   545:     price = 10.0
   546:     vol_theoretical = bot.compute_position_size(
   547:         contract_detail,
   548:         equity_usdt=100,
   549:         price=price,
   550:         risk_pct=1.0,
   551:         leverage=10,
   552:         symbol="BTCUSDT_UMCBL",
   553:     )
   554:     available = 20.0
   555:     vol_final = bot.compute_position_size(
   556:         contract_detail,
   557:         equity_usdt=available,
   558:         price=price,
   559:         risk_pct=1.0,
   560:         leverage=10,
   561:         symbol="BTCUSDT_UMCBL",
   562:         available_usdt=available,
   563:     )
   564:     assert vol_final < vol_theoretical
   565:     client.place_order(
   566:         "BTCUSDT_UMCBL", side=1, vol=vol_final, order_type=1, price=price, leverage=10
   567:     )
   568:     assert called["body"]["size"] == vol_final
   569: 
   570: def test_get_open_orders_paper_trade(monkeypatch):
   571:     client = BitgetFuturesClient("key", "secret", "https://test", paper_trade=True)
   572: 
   573:     called = {"count": 0}
   574: 
   575:     def fake_private(*a, **k):
   576:         called["count"] += 1
   577:         return {"success": True}
   578: 
   579:     monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)
   580: 
   581:     resp = client.get_open_orders("BTCUSDT_UMCBL")
   582: 
   583:     assert resp["success"] is True
   584:     assert resp["data"] == []
   585:     assert called["count"] == 0
   586: 
   587: 
   588: def test_cancel_all_paper_trade(monkeypatch):
   589:     client = BitgetFuturesClient("key", "secret", "https://test", paper_trade=True)
   590: 
   591:     called = {"count": 0}
   592: 
   593:     def fake_private(*a, **k):
   594:         called["count"] += 1
   595:         return {"success": True}
   596: 
   597:     monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)
   598: 
   599:     resp = client.cancel_all("BTCUSDT_UMCBL", margin_coin="USDT")
   600: 
   601:     assert resp["success"] is True
   602:     assert called["count"] == 0
   603: 
   604: 
   605: def test_get_kline_transforms_data(monkeypatch):
   606:     client = BitgetFuturesClient("key", "secret", "https://test")
   607: 
   608:     def fake_get(url, params=None, timeout=None):
   609:         class Resp:
   610:             def raise_for_status(self):
   611:                 pass
   612: 
   613:             def json(self):
   614:                 return {
   615:                     "data": [
   616:                         ["1", "2", "3", "1", "2", "10", "20"],
   617:                         ["2", "3", "4", "2", "3", "11", "21"],
   618:                     ]
   619:                 }
   620: 
   621:         return Resp()
   622: 
   623:     monkeypatch.setattr(bot.requests, "get", fake_get, raising=False)
   624: 
   625:     data = client.get_kline("BTC_USDT", interval="1m")
   626:     kdata = data["data"]
   627:     assert kdata["open"] == [2.0, 3.0]
   628:     assert kdata["high"] == [3.0, 4.0]
   629:     assert kdata["low"] == [1.0, 2.0]
   630:     assert kdata["close"] == [2.0, 3.0]
   631:     assert kdata["volume"] == [10.0, 11.0]
   632:     assert kdata["quoteVolume"] == [20.0, 21.0]


## tests/test_compute_position_size.py (last modified: 2025-08-23 20:57:14)
     1: import os
     2: import sys
     3: import types
     4: import pytest
     5: 
     6: sys.path.append(os.path.dirname(os.path.dirname(__file__)))
     7: sys.modules["requests"] = types.ModuleType("requests")
     8: import bot  # noqa: E402
     9: from bot import compute_position_size  # noqa: E402
    10: 
    11: 
    12: def test_compute_position_size_basic():
    13:     contract_detail = {
    14:         "data": [
    15:             {
    16:                 "symbol": "BTC_USDT",
    17:                 "contractSize": 0.01,
    18:                 "volUnit": 1,
    19:                 "minVol": 1,
    20:             }
    21:         ]
    22:     }
    23:     vol = compute_position_size(contract_detail, equity_usdt=1000, price=50000,
    24:                                 risk_pct=0.01, leverage=10, symbol="BTC_USDT")
    25:     assert vol == 1
    26: 
    27: 
    28: def test_compute_position_size_symbol_not_found():
    29:     contract_detail = {"data": [{"symbol": "ETH_USDT", "contractSize": 0.1}]}
    30:     with pytest.raises(ValueError):
    31:         compute_position_size(contract_detail, equity_usdt=1000, price=500,
    32:                                 risk_pct=0.01, leverage=10, symbol="BTC_USDT")
    33: 
    34: 
    35: def test_compute_position_size_invalid_price():
    36:     contract_detail = {
    37:         "data": [
    38:             {
    39:                 "symbol": "BTC_USDT",
    40:                 "contractSize": 0.01,
    41:                 "volUnit": 1,
    42:                 "minVol": 1,
    43:             }
    44:         ]
    45:     }
    46:     vol = compute_position_size(
    47:         contract_detail,
    48:         equity_usdt=1000,
    49:         price=0,
    50:         risk_pct=0.01,
    51:         leverage=10,
    52:         symbol="BTC_USDT",
    53:     )
    54:     assert vol == 0
    55: 
    56: 
    57: def test_compute_position_size_respects_equity():
    58:     contract_detail = {
    59:         "data": [
    60:             {
    61:                 "symbol": "BTC_USDT",
    62:                 "contractSize": 1,
    63:                 "volUnit": 1,
    64:                 "minVol": 1,
    65:             }
    66:         ]
    67:     }
    68:     vol = compute_position_size(
    69:         contract_detail,
    70:         equity_usdt=5,
    71:         price=100,
    72:         risk_pct=0.01,
    73:         leverage=10,
    74:         symbol="BTC_USDT",
    75:     )
    76:     assert vol == 0
    77: 
    78: 
    79: def test_compute_position_size_leaves_fee_buffer():
    80:     contract_detail = {
    81:         "data": [
    82:             {
    83:                 "symbol": "BTC_USDT",
    84:                 "contractSize": 1,
    85:                 "volUnit": 1,
    86:                 "minVol": 1,
    87:             }
    88:         ]
    89:     }
    90:     vol = compute_position_size(
    91:         contract_detail,
    92:         equity_usdt=100,
    93:         price=100,
    94:         risk_pct=1.0,
    95:         leverage=1,
    96:         symbol="BTC_USDT",
    97:     )
    98:     assert vol == 0
    99: 
   100: 
   101: def test_compute_position_size_under_min_notional_returns_zero():
   102:     contract_detail = {
   103:         "data": [
   104:             {
   105:                 "symbol": "PI_USDT",
   106:                 "contractSize": 1,
   107:                 "volUnit": 1,
   108:                 "minVol": 1,
   109:                 "minTradeUSDT": 5,
   110:             }
   111:         ]
   112:     }
   113:     vol = compute_position_size(
   114:         contract_detail,
   115:         equity_usdt=100,
   116:         price=0.5,
   117:         risk_pct=0.0001,
   118:         leverage=20,
   119:         symbol="PI_USDT",
   120:     )
   121:     assert vol == 0
   122: 
   123: 
   124: def test_compute_position_size_cap_by_available():
   125:     contract_detail = {
   126:         "data": [
   127:             {
   128:                 "symbol": "BTC_USDT",
   129:                 "contractSize": 1,
   130:                 "volUnit": 2,
   131:                 "minVol": 2,
   132:                 "minTradeUSDT": 5,
   133:             }
   134:         ]
   135:     }
   136:     vol = compute_position_size(
   137:         contract_detail,
   138:         equity_usdt=100,
   139:         price=10,
   140:         risk_pct=0.5,
   141:         leverage=10,
   142:         symbol="BTC_USDT",
   143:         available_usdt=0.5,
   144:     )
   145:     assert vol == 0
   146:     vol = compute_position_size(
   147:         contract_detail,
   148:         equity_usdt=100,
   149:         price=10,
   150:         risk_pct=0.5,
   151:         leverage=10,
   152:         symbol="BTC_USDT",
   153:         available_usdt=10,
   154:     )
   155:     assert vol == 8
   156:     fee_rate = max(bot.CONFIG.get("FEE_RATE", 0.0), 0.001)
   157:     required = (10 * 1 * vol / 10 + fee_rate * 10 * 1 * vol) * 1.03
   158:     assert required <= 10


## tests/test_compute_position_size_cap.py (last modified: 2025-08-23 20:57:14)
     1: import os
     2: import sys
     3: import types
     4: import pytest
     5: 
     6: sys.path.append(os.path.dirname(os.path.dirname(__file__)))
     7: sys.modules['requests'] = types.ModuleType('requests')
     8: 
     9: from bot import compute_position_size, CONFIG
    10: 
    11: 
    12: def _detail(vol_unit=1, min_vol=1, min_trade=5):
    13:     return {
    14:         "data": [
    15:             {
    16:                 "symbol": "BTC_USDT",
    17:                 "contractSize": 0.001,
    18:                 "volUnit": vol_unit,
    19:                 "minVol": min_vol,
    20:                 "minTradeUSDT": min_trade,
    21:             }
    22:         ]
    23:     }
    24: 
    25: 
    26: def test_volume_zero_when_available_low():
    27:     detail = _detail()
    28:     vol = compute_position_size(
    29:         detail,
    30:         equity_usdt=1000,
    31:         price=10000,
    32:         risk_pct=0.01,
    33:         leverage=10,
    34:         symbol="BTC_USDT",
    35:         available_usdt=0.5,
    36:     )
    37:     assert vol == 0
    38: 
    39: 
    40: def test_margin_close_to_available():
    41:     detail = _detail()
    42:     CONFIG["FEE_RATE"] = 0.001
    43:     available = 1.05
    44:     vol = compute_position_size(
    45:         detail,
    46:         equity_usdt=1000,
    47:         price=10000,
    48:         risk_pct=1,
    49:         leverage=10,
    50:         symbol="BTC_USDT",
    51:         available_usdt=available,
    52:     )
    53:     assert vol == 1
    54:     notional = 10000 * 0.001 * vol
    55:     fee = max(CONFIG.get("FEE_RATE", 0.0), 0.001) * notional
    56:     required = (notional / 10 + fee) * 1.03
    57:     assert required == pytest.approx(available, rel=0.05)
    58: 
    59: 
    60: def test_respects_units_and_minimums():
    61:     detail = _detail(vol_unit=2, min_vol=2, min_trade=5)
    62:     vol = compute_position_size(
    63:         detail,
    64:         equity_usdt=1000,
    65:         price=1000,
    66:         risk_pct=1,
    67:         leverage=5,
    68:         symbol="BTC_USDT",
    69:         available_usdt=1000,
    70:     )
    71:     assert vol % 2 == 0 and vol >= 2


## tests/test_dynamic_allocation.py (last modified: 2025-08-23 20:57:14)
     1: import math
     2: from scalper.risk import adjust_risk_pct
     3: 
     4: 
     5: def test_adjust_risk_pct_increase_decrease():
     6:     base = 0.01
     7:     assert adjust_risk_pct(base, win_streak=2, loss_streak=0) > base
     8:     assert adjust_risk_pct(base, win_streak=0, loss_streak=2) < base
     9: 
    10: 
    11: def test_adjust_risk_pct_bounds():
    12:     assert math.isclose(
    13:         adjust_risk_pct(0.05, win_streak=2, loss_streak=0, max_pct=0.05), 0.05
    14:     )
    15:     assert math.isclose(
    16:         adjust_risk_pct(0.001, win_streak=0, loss_streak=2, min_pct=0.001), 0.001
    17:     )


## tests/test_effective_leverage.py (last modified: 2025-08-23 20:57:14)
     1: import pytest
     2: from scalper.trade_utils import effective_leverage
     3: 
     4: 
     5: def test_effective_leverage_basic():
     6:     lev = effective_leverage(
     7:         entry_price=100.0,
     8:         liquidation_price=90.0,
     9:         position_margin=10.0,
    10:         position_size=1.0,
    11:     )
    12:     assert lev == pytest.approx(10.0)
    13: 
    14: 
    15: def test_effective_leverage_estimated_margin():
    16:     lev = effective_leverage(
    17:         entry_price=200.0,
    18:         liquidation_price=180.0,
    19:         position_margin=0.0,
    20:         position_size=2.0,
    21:     )
    22:     # price diff 20 * size 2 -> margin 40; notional 400
    23:     assert lev == pytest.approx(10.0)
    24: 
    25: 
    26: def test_effective_leverage_short_position():
    27:     lev = effective_leverage(
    28:         entry_price=100.0,
    29:         liquidation_price=110.0,
    30:         position_margin=10.0,
    31:         position_size=-1.5,
    32:     )
    33:     assert lev == pytest.approx(15.0)
    34: 
    35: 
    36: def test_effective_leverage_invalid():
    37:     assert effective_leverage(0, 0, 0, 0) == 0.0


## tests/test_env_loading.py (last modified: 2025-08-23 20:57:14)
     1: """Tests for loading environment variables from ``notebook/.env``."""
     2: 
     3: from __future__ import annotations
     4: 
     5: import importlib
     6: import os
     7: import sys
     8: from pathlib import Path
     9: 
    10: 
    11: def test_parent_env_loaded(tmp_path, monkeypatch) -> None:
    12:     """Module should load variables from ``notebook/.env`` if present."""
    13: 
    14:     notebook = tmp_path / "notebook"
    15:     spot = notebook / "spot"
    16:     spot.mkdir(parents=True)
    17:     bitget_bot = spot / "bitget_bot.py"
    18:     bitget_bot.write_text("")
    19:     env_file = notebook / ".env"
    20:     env_file.write_text("BITGET_ACCESS_KEY=from_env\n")
    21: 
    22:     old = os.environ.pop("BITGET_ACCESS_KEY", None)
    23:     monkeypatch.setattr(sys, "argv", [str(bitget_bot)])
    24:     import scalp
    25: 
    26:     importlib.reload(scalp)
    27: 
    28:     try:
    29:         assert os.getenv("BITGET_ACCESS_KEY") == "from_env"
    30:     finally:
    31:         env_file.unlink(missing_ok=True)
    32:         if old is None:
    33:             os.environ.pop("BITGET_ACCESS_KEY", None)
    34:         else:
    35:             os.environ["BITGET_ACCESS_KEY"] = old


## tests/test_grid_search.py (last modified: 2025-08-23 20:57:14)
     1: import json
     2: import random
     3: 
     4: import pytest
     5: 
     6: from scalper.backtest import grid_search
     7: 
     8: 
     9: def test_build_grid_sampling():
    10:     param_lists = {
    11:         "timeframe": ["1m", "5m", "15m"],
    12:         "score_min": [50, 55, 60],
    13:         "atr_min_ratio": [0.0015, 0.002, 0.003],
    14:     }
    15:     combos = grid_search.build_param_grid(param_lists, grid_max=6)
    16:     assert len(combos) == 6
    17:     tfs = {c["timeframe"] for c in combos}
    18:     assert {"1m", "5m", "15m"}.issubset(tfs)
    19: 
    20: 
    21: def test_run_grid_search_with_mock(tmp_path):
    22:     calls = []
    23: 
    24:     def fake_run_backtest_multi(**kwargs):
    25:         tf = kwargs.get("timeframe")
    26:         risk = kwargs.get("risk_pct")
    27:         # fabricate metrics based on params
    28:         pf = {"1m": 1.5, "5m": 3.0}[tf]
    29:         pf += risk  # tiny variation
    30:         metrics = {
    31:             "symbol": "TOTAL",
    32:             "pnl_usdt": 100 * risk,
    33:             "profit_factor": pf,
    34:             "max_drawdown_pct": 5.0 if tf == "1m" else 3.0,
    35:             "winrate_pct": 50.0,
    36:             "trades": 40 if tf == "1m" else 30,
    37:         }
    38:         calls.append((tf, risk))
    39:         return [metrics], []
    40: 
    41:     param_lists = {
    42:         "timeframe": ["1m", "5m"],
    43:         "risk_pct": [0.005, 0.01],
    44:     }
    45:     base_params = {
    46:         "timeframe": "1m",
    47:         "risk_pct": 0.005,
    48:     }
    49:     out_dir = tmp_path / "grid"
    50:     grid_search.run_grid_search(
    51:         symbols=["BTC/USDT"],
    52:         exchange="csv",
    53:         base_params=base_params,
    54:         param_lists=param_lists,
    55:         grid_max=4,
    56:         csv_dir="/dev/null",
    57:         out_dir=str(out_dir),
    58:         run_func=fake_run_backtest_multi,
    59:     )
    60:     best = json.loads((out_dir / "best_config.json").read_text())
    61:     # best PF should be timeframe 5m risk 0.01
    62:     assert best["params"]["timeframe"] == "5m"
    63:     assert best["params"]["risk_pct"] == 0.01
    64:     assert len(calls) == 4
    65: 
    66: 
    67: def test_parse_hours():
    68:     assert grid_search.parse_hours("7-11,13-17") == [7, 8, 9, 10, 11, 13, 14, 15, 16, 17]
    69: 
    70: 
    71: def test_deterministic_results(tmp_path):
    72:     def fake_run_backtest_multi(**kwargs):
    73:         # metrics vary with global random state
    74:         pf = random.uniform(1.0, 3.0)
    75:         metrics = {
    76:             "symbol": "TOTAL",
    77:             "pnl_usdt": random.uniform(-10, 10),
    78:             "profit_factor": pf,
    79:             "max_drawdown_pct": random.uniform(1, 5),
    80:             "winrate_pct": 50.0,
    81:             "trades": random.randint(10, 50),
    82:         }
    83:         return [metrics], []
    84: 
    85:     param_lists = {"timeframe": ["1m", "5m"]}
    86:     base_params = {"timeframe": "1m"}
    87:     out_dir = tmp_path / "grid"
    88:     res1 = grid_search.run_grid_search(
    89:         symbols=["BTC/USDT"],
    90:         exchange="csv",
    91:         base_params=base_params,
    92:         param_lists=param_lists,
    93:         grid_max=2,
    94:         csv_dir="/dev/null",
    95:         out_dir=str(out_dir),
    96:         seed=42,
    97:         run_func=fake_run_backtest_multi,
    98:     )
    99:     best1 = json.loads((out_dir / "best_config.json").read_text())
   100:     # run again
   101:     out_dir2 = tmp_path / "grid2"
   102:     res2 = grid_search.run_grid_search(
   103:         symbols=["BTC/USDT"],
   104:         exchange="csv",
   105:         base_params=base_params,
   106:         param_lists=param_lists,
   107:         grid_max=2,
   108:         csv_dir="/dev/null",
   109:         out_dir=str(out_dir2),
   110:         seed=42,
   111:         run_func=fake_run_backtest_multi,
   112:     )
   113:     best2 = json.loads((out_dir2 / "best_config.json").read_text())
   114:     assert best1 == best2
   115:     # also ensure results object same best params
   116:     assert res1[0].params == res2[0].params


## tests/test_heat_score.py (last modified: 2025-08-23 20:57:14)
     1: from scalper.pairs import heat_score, select_top_heat_pairs, decorrelate_pairs
     2: 
     3: 
     4: def test_heat_score_value():
     5:     assert heat_score(2.0, 100.0) == 200.0
     6:     assert heat_score(2.0, 100.0, news=True) == 400.0
     7: 
     8: 
     9: def test_select_and_decorrelate_pairs():
    10:     pairs = [
    11:         {"symbol": "A", "volatility": 2, "volume": 100, "news": True},
    12:         {"symbol": "B", "volatility": 1, "volume": 200, "news": False},
    13:         {"symbol": "C", "volatility": 1.5, "volume": 150, "news": False},
    14:         {"symbol": "D", "volatility": 3, "volume": 50, "news": True},
    15:     ]
    16:     top = select_top_heat_pairs(pairs, top_n=3)
    17:     assert len(top) == 3
    18:     corr = {"A": {"B": 0.9}, "B": {"A": 0.9}, "C": {}, "D": {}}
    19:     selected = decorrelate_pairs(pairs, corr, threshold=0.8, top_n=3)
    20:     syms = {p["symbol"] for p in selected}
    21:     assert not ("A" in syms and "B" in syms)


## tests/test_indicators.py (last modified: 2025-08-23 20:57:14)
     1: 
     2: 
     3: import os
     4: import sys
     5: import pytest
     6: sys.path.append(os.path.dirname(os.path.dirname(__file__)))
     7: 
     8: 
     9: 
    10: 
    11: from scalper.metrics import calc_rsi, calc_atr, calc_macd
    12: 
    13: 
    14: def test_calc_rsi_uptrend():
    15:     prices = list(range(1, 16))  # strictly increasing
    16:     assert calc_rsi(prices, period=14) == pytest.approx(100.0)
    17: 
    18: 
    19: def test_calc_rsi_downtrend():
    20:     prices = list(range(15, 0, -1))  # strictly decreasing
    21:     assert calc_rsi(prices, period=14) == pytest.approx(0.0)
    22: 
    23: 
    24: 
    25: def test_calc_rsi_flat():
    26:     prices = [1.0] * 15  # no movement
    27:     assert calc_rsi(prices, period=14) == pytest.approx(50.0)
    28: 
    29: 
    30: 
    31:     highs = [10, 11, 12, 13, 14]
    32:     lows = [9, 10, 11, 12, 13]
    33:     closes = [9.5, 10.5, 11.5, 12.5, 13.5]
    34:     assert calc_atr(highs, lows, closes, period=3) == pytest.approx(1.5)
    35: 
    36: 
    37: def test_calc_macd_trend():
    38:     prices = list(range(1, 60))
    39:     macd, signal, hist = calc_macd(prices)
    40:     assert macd > signal
    41:     assert hist > 0
    42: 
    43: 
    44: def test_calc_macd_flat():
    45:     prices = [100.0] * 60
    46:     macd, signal, hist = calc_macd(prices)
    47:     assert macd == pytest.approx(0.0)
    48:     assert signal == pytest.approx(0.0)
    49:     assert hist == pytest.approx(0.0)
    50: 
    51: 
    52: 
    53: @pytest.mark.parametrize("prices, period", [([1, 2, 3], 0), ([1, 2, 3], 5)])
    54: def test_calc_rsi_invalid_inputs(prices, period):
    55:     with pytest.raises(ValueError):
    56:         calc_rsi(prices, period=period)
    57: 
    58: 
    59: @pytest.mark.parametrize(
    60:     "highs, lows, closes, period",
    61:     [
    62:         ([1, 2, 3], [1, 2], [1, 2, 3], 2),
    63:         ([1, 2], [1, 1], [1, 1], 3),
    64:     ],
    65: )
    66: def test_calc_atr_invalid_inputs(highs, lows, closes, period):
    67:     with pytest.raises(ValueError):
    68:         calc_atr(highs, lows, closes, period=period)
    69: 


## tests/test_min_qty_rules.py (last modified: 2025-08-23 20:57:14)
     1: import os
     2: import sys
     3: import types
     4: 
     5: sys.path.append(os.path.dirname(os.path.dirname(__file__)))
     6: sys.modules['requests'] = types.ModuleType('requests')
     7: 
     8: from bot import _apply_contract_checks
     9: 
    10: 
    11: def _detail():
    12:     return {
    13:         "data": [
    14:             {
    15:                 "symbol": "BTC_USDT",
    16:                 "contractSize": 1,
    17:                 "volUnit": 5,
    18:                 "minVol": 10,
    19:                 "minTradeUSDT": 5,
    20:             }
    21:         ]
    22:     }
    23: 
    24: 
    25: def test_min_qty_floor_and_validation():
    26:     detail = _detail()
    27:     vol, N, req = _apply_contract_checks(1, 13, 10, 100, detail, "BTC_USDT")
    28:     assert vol == 10
    29:     vol2, N2, req2 = _apply_contract_checks(1, 7, 10, 100, detail, "BTC_USDT")
    30:     assert vol2 == 0


## tests/test_notifier.py (last modified: 2025-08-23 20:57:14)
     1: import scalper.notifier as notifier
     2: 
     3: 
     4: def test_notify_skips_without_targets(monkeypatch):
     5:     called = False
     6: 
     7:     def fake_post(url, json=None, timeout=5):  # pragma: no cover - fallback
     8:         nonlocal called
     9:         called = True
    10: 
    11:     monkeypatch.delenv("NOTIFY_URL", raising=False)
    12:     monkeypatch.delenv("TELEGRAM_BOT_TOKEN", raising=False)
    13:     monkeypatch.delenv("TELEGRAM_CHAT_ID", raising=False)
    14:     monkeypatch.setattr(notifier.requests, "post", fake_post)
    15:     notifier.notify("test", {"foo": 1})
    16:     assert called is False
    17: 
    18: 
    19: def test_notify_posts_http(monkeypatch):
    20:     payload = {}
    21: 
    22:     def fake_post(url, json=None, timeout=5):
    23:         payload["url"] = url
    24:         payload["json"] = json
    25:         payload["timeout"] = timeout
    26: 
    27:     monkeypatch.delenv("TELEGRAM_BOT_TOKEN", raising=False)
    28:     monkeypatch.delenv("TELEGRAM_CHAT_ID", raising=False)
    29:     monkeypatch.setenv("NOTIFY_URL", "http://example.com")
    30:     monkeypatch.setattr(notifier.requests, "post", fake_post)
    31:     notifier.notify("evt", {"bar": 2})
    32:     assert payload["url"] == "http://example.com"
    33:     assert payload["json"]["event"] == "evt"
    34:     assert payload["json"]["bar"] == 2
    35: 
    36: 
    37: def test_notify_posts_telegram(monkeypatch):
    38:     payload = {}
    39: 
    40:     def fake_post(url, json=None, timeout=5):
    41:         payload["url"] = url
    42:         payload["json"] = json
    43:         payload["timeout"] = timeout
    44: 
    45:     monkeypatch.delenv("NOTIFY_URL", raising=False)
    46:     monkeypatch.setenv("TELEGRAM_BOT_TOKEN", "abc")
    47:     monkeypatch.setenv("TELEGRAM_CHAT_ID", "123")
    48:     monkeypatch.setattr(notifier.requests, "post", fake_post)
    49: 
    50:     notifier.notify("evt", {"bar": 2})
    51: 
    52:     assert payload["url"] == "https://api.telegram.org/botabc/sendMessage"
    53:     assert payload["json"]["chat_id"] == "123"
    54:     assert "evt" in payload["json"]["text"]
    55: 
    56: 
    57: def test_notify_posts_both(monkeypatch):
    58:     calls = []
    59: 
    60:     def fake_post(url, json=None, timeout=5):
    61:         calls.append({"url": url, "json": json, "timeout": timeout})
    62: 
    63:     monkeypatch.setenv("NOTIFY_URL", "http://example.com")
    64:     monkeypatch.setenv("TELEGRAM_BOT_TOKEN", "abc")
    65:     monkeypatch.setenv("TELEGRAM_CHAT_ID", "123")
    66:     monkeypatch.setattr(notifier.requests, "post", fake_post)
    67: 
    68:     notifier.notify("evt", {"bar": 2})
    69: 
    70:     assert len(calls) == 2
    71:     urls = {c["url"] for c in calls}
    72:     assert "http://example.com" in urls
    73:     assert "https://api.telegram.org/botabc/sendMessage" in urls
    74: 
    75: 
    76: def test_notify_skips_telegram_for_pair_list(monkeypatch):
    77:     calls = []
    78: 
    79:     def fake_post(url, json=None, timeout=5):
    80:         calls.append(url)
    81: 
    82:     monkeypatch.setenv("NOTIFY_URL", "http://example.com")
    83:     monkeypatch.setenv("TELEGRAM_BOT_TOKEN", "abc")
    84:     monkeypatch.setenv("TELEGRAM_CHAT_ID", "123")
    85:     monkeypatch.setattr(notifier.requests, "post", fake_post)
    86: 
    87:     notifier.notify("pair_list", {"pairs": "BTC"})
    88: 
    89:     # Only the generic webhook should be called, not Telegram
    90:     assert calls == ["http://example.com"]
    91: 
    92: 
    93: def test_format_text_open_position():
    94:     payload = {
    95:         "symbol": "BTCUSDT",
    96:         "side": "short",
    97:         "price": 18350,
    98:         "vol": 37,
    99:         "contract_size": 1,
   100:         "notional_usdt": 120.5,
   101:         "leverage": 5,
   102:         "required_margin_usdt": 25.3,
   103:         "available_usdt": 134,
   104:         "risk_level_user": 3,
   105:         "signal_level": 2,
   106:         "risk_color": "🟡",
   107:         "risk_pct_eff": 0.01,
   108:         "fee_rate": 0.001,
   109:     }
   110:     text = notifier._format_text("position_opened", payload)
   111:     lines = text.splitlines()
   112: 
   113:     assert lines[0] == "🟡 Ouvre short BTC"
   114:     assert lines[1] == "Notional: 120.5 USDT   Levier: x5"
   115:     assert lines[2] == "Marge estimée: 25.3 USDT (dispo: 134 USDT)"
   116:     assert lines[3] == "Risque: lvl 2/3 (risk_pct=1.0000%)"
   117:     assert lines[4] == "Prix: 18350   Vol: 37 (cs=1)"
   118: 
   119: 
   120: def test_format_text_closed_position():
   121:     payload = {
   122:         "symbol": "BTCUSDT",
   123:         "side": "short",
   124:         "entry_price": 18350,
   125:         "exit_price": 18328,
   126:         "vol": 37,
   127:         "contract_size": 1,
   128:         "notional_entry_usdt": 120.5,
   129:         "notional_exit_usdt": 120.3,
   130:         "fees_usdt": 0.03,
   131:         "pnl_usdt": 0.84,
   132:         "pnl_pct_on_margin": 3.25,
   133:         "leverage": 5,
   134:         "risk_color": "🟡",
   135:         "fee_rate": 0.001,
   136:     }
   137:     text = notifier._format_text("position_closed", payload)
   138:     lines = text.splitlines()
   139:     assert lines[0] == "Ferme short BTC 🟡"
   140:     assert lines[1] == "PnL net: +0.84 USDT (frais: 0.03)"
   141:     assert lines[2] == "% sur marge: 3.25%"
   142:     assert lines[3] == "Entrée: 18350  Sortie: 18328"
   143:     assert lines[4] == "Vol: 37  Notional: in 120.5 → out 120.3 USDT"
   144: 
   145: 
   146: def test_format_text_pair_list_and_start():
   147:     assert notifier._format_text("bot_started") == "🤖 Bot démarré"
   148:     text = notifier._format_text(
   149:         "pair_list", {"green": "AAA", "orange": "BBB", "red": "CCC"}
   150:     )
   151:     assert text == "Listing ok"
   152: 
   153: 
   154: def test_format_pair_list_helper():
   155:     payload = {"green": "AAA", "orange": "BBB", "red": "CCC"}
   156:     text = notifier._format_pair_list(payload)
   157:     assert text == "Listing ok"
   158: 
   159: 
   160: def test_format_position_event_helper():
   161:     payload = {
   162:         "symbol": "BTCUSDT",
   163:         "side": "short",
   164:         "price": 18350,
   165:         "vol": 37,
   166:         "contract_size": 1,
   167:         "notional_usdt": 120.5,
   168:         "leverage": 5,
   169:         "required_margin_usdt": 25.3,
   170:         "available_usdt": 134,
   171:         "risk_level_user": 3,
   172:         "signal_level": 2,
   173:         "risk_color": "🟡",
   174:         "risk_pct_eff": 0.01,
   175:         "fee_rate": 0.001,
   176:     }
   177:     text = notifier._format_position_event("position_opened", payload)
   178:     assert text.splitlines()[0] == "🟡 Ouvre short BTC"
   179: 
   180: 


## tests/test_notional_and_pnl_units.py (last modified: 2025-08-23 20:57:14)
     1: import os, sys, types, pytest
     2: sys.path.append(os.path.dirname(os.path.dirname(__file__)))
     3: sys.modules['requests'] = types.ModuleType('requests')
     4: 
     5: from scalper.trade_utils import (
     6:     get_contract_size,
     7:     notional as calc_notional,
     8:     required_margin as calc_required_margin,
     9:     compute_pnl_usdt,
    10:     compute_pnl_with_fees,
    11: )
    12: 
    13: 
    14: def _detail():
    15:     return {"data": [{"symbol": "BTC_USDT", "contractSize": 0.001}]}
    16: 
    17: 
    18: def test_notional_and_pnl_units():
    19:     detail = _detail()
    20:     cs = get_contract_size(detail, "BTC_USDT")
    21:     N = calc_notional(10000, 2, cs)
    22:     assert N == pytest.approx(10000 * 0.001 * 2)
    23:     margin = calc_required_margin(N, 10, 0.001, buffer=0.0)
    24:     assert margin == pytest.approx(N / 10 + 0.001 * N)
    25:     pnl = compute_pnl_usdt(detail, 10000, 10100, 2, 1, symbol="BTC_USDT")
    26:     assert pnl == pytest.approx((10100 - 10000) * 0.001 * 2)
    27:     pnl_net, pct = compute_pnl_with_fees(
    28:         detail, 10000, 10100, 2, 1, 10, 0.001, symbol="BTC_USDT"
    29:     )
    30:     gross = (10100 - 10000) * cs * 2
    31:     fees = 0.001 * (calc_notional(10000, 2, cs) + calc_notional(10100, 2, cs))
    32:     expected = gross - fees
    33:     expected_pct = expected / (N / 10) * 100
    34:     assert pnl_net == pytest.approx(expected)
    35:     assert pct == pytest.approx(expected_pct)


## tests/test_pair_selection.py (last modified: 2025-08-23 20:57:14)
     1: import bot
     2: 
     3: 
     4: def test_get_trade_pairs():
     5:     class Client:
     6:         def get_ticker(self, symbol=None):
     7:             return {
     8:                 "success": True,
     9:                 "data": [
    10:                     {"symbol": "BTC_USDT"},
    11:                     {"symbol": "ETH_USDT"},
    12:                 ],
    13:             }
    14: 
    15:     pairs = bot.get_trade_pairs(Client())
    16:     assert [p["symbol"] for p in pairs] == ["BTC_USDT", "ETH_USDT"]
    17: 
    18: 
    19: def test_select_top_pairs():
    20:     class Client:
    21:         def get_ticker(self, symbol=None):
    22:             return {
    23:                 "success": True,
    24:                 "data": [
    25:                     {"symbol": "A", "volume": "1"},
    26:                     {"symbol": "B", "volume": "3"},
    27:                     {"symbol": "C", "volume": "2"},
    28:                 ],
    29:             }
    30: 
    31:     top = bot.select_top_pairs(Client(), top_n=2)
    32:     assert [p["symbol"] for p in top] == ["B", "C"]
    33: 
    34: 
    35: def test_select_top_pairs_default_count():
    36:     class Client:
    37:         def get_ticker(self, symbol=None):
    38:             data = []
    39:             for i in range(100):
    40:                 data.append({"symbol": str(i), "volume": str(i)})
    41:             return {"success": True, "data": data}
    42: 
    43:     top = bot.select_top_pairs(Client())
    44:     assert len(top) == 40
    45: 
    46: 
    47: def test_filter_trade_pairs():
    48:     class Client:
    49:         def get_ticker(self, symbol=None):
    50:             return {
    51:                 "success": True,
    52:                 "data": [
    53:                     {
    54:                         "symbol": "AAA",
    55:                         "volume": "6000000",
    56:                         "bidPrice": "100",
    57:                         "askPrice": "100.03",
    58:                     },  # spread ~3 bps
    59:                     {
    60:                         "symbol": "BBB",
    61:                         "volume": "10000000",
    62:                         "bidPrice": "50",
    63:                         "askPrice": "50.1",
    64:                     },  # spread ~200 bps
    65:                     {
    66:                         "symbol": "CCC",
    67:                         "volume": "7000000",
    68:                         "bidPrice": "10",
    69:                         "askPrice": "10.01",
    70:                     },  # spread ~100 bps
    71:                     {
    72:                         "symbol": "DDD",
    73:                         "volume": "4000000",
    74:                         "bidPrice": "20",
    75:                         "askPrice": "20.01",
    76:                     },  # volume trop faible
    77:                 ],
    78:             }
    79: 
    80:     pairs = bot.filter_trade_pairs(
    81:         Client(),
    82:         volume_min=5_000_000,
    83:         max_spread_bps=5,
    84:     )
    85:     assert [p["symbol"] for p in pairs] == ["AAA"]
    86: 
    87: 
    88: def test_find_trade_positions(monkeypatch):
    89:     class Client:
    90:         def __init__(self):
    91:             self.data = {
    92:                 "AAA": {"data": {"close": [1, 2, 3]}},
    93:                 "BBB": {"data": {"close": [3, 2, 1]}},
    94:             }
    95: 
    96:         def get_kline(self, symbol, interval="1m"):
    97:             return self.data[symbol]
    98: 
    99:     pairs = [
   100:         {"symbol": "AAA", "lastPrice": "1"},
   101:         {"symbol": "BBB", "lastPrice": "1"},
   102:     ]
   103: 
   104:     monkeypatch.setattr(bot, "ema", lambda series, window: series)
   105: 
   106:     def fake_cross(last_fast, last_slow, prev_fast, prev_slow):
   107:         if last_fast > prev_fast:
   108:             return 1
   109:         if last_fast < prev_fast:
   110:             return -1
   111:         return 0
   112: 
   113:     monkeypatch.setattr(bot, "cross", fake_cross)
   114: 
   115:     signals = bot.find_trade_positions(Client(), pairs, ema_fast_n=1, ema_slow_n=1)
   116:     assert signals == [
   117:         {"symbol": "AAA", "signal": "long", "price": 1.0},
   118:         {"symbol": "BBB", "signal": "short", "price": 1.0},
   119:     ]


## tests/test_pairs.py (last modified: 2025-08-23 20:57:14)
     1: import bot
     2: 
     3: 
     4: def test_send_selected_pairs(monkeypatch):
     5:     sent = {}
     6: 
     7:     def fake_notify(event, payload=None):
     8:         sent["event"] = event
     9:         sent["payload"] = payload
    10: 
    11:     monkeypatch.setattr(bot, "notify", fake_notify)
    12:     monkeypatch.setattr(
    13:         bot,
    14:         "filter_trade_pairs",
    15:         lambda client, top_n=120: [
    16:             {"symbol": "WIFUSDT", "volume": 10},
    17:             {"symbol": "WIFUSDT", "volume": 9},
    18:             {"symbol": "BTCUSD", "volume": 8},
    19:             {"symbol": "BTCUSDT", "volume": 7},
    20:             {"symbol": "DOGEUSDT", "volume": 6},
    21:             {"symbol": "ETHUSDC", "volume": 5},
    22:             {"symbol": "ETHUSDT", "volume": 4},
    23:         ],
    24:     )
    25: 
    26:     monkeypatch.setitem(bot.CONFIG, "ALLOWED_SYMBOLS", ["BTCUSDT", "ETHUSDT"])
    27: 
    28:     payload = bot.send_selected_pairs(object(), top_n=4)
    29: 
    30:     assert sent["event"] == "pair_list"
    31:     assert sent["payload"]["green"] == "BTC"
    32:     assert sent["payload"]["orange"] == "ETH"
    33:     assert "red" not in sent["payload"]
    34:     assert payload == sent["payload"]
    35: 
    36: 
    37: def test_send_selected_pairs_no_whitelist(monkeypatch):
    38:     sent = {}
    39: 
    40:     def fake_notify(event, payload=None):
    41:         sent["payload"] = payload
    42: 
    43:     monkeypatch.setattr(bot, "notify", fake_notify)
    44:     monkeypatch.setattr(
    45:         bot,
    46:         "filter_trade_pairs",
    47:         lambda client, top_n=120: [
    48:             {"symbol": "AAAUSDT", "volume": 10},
    49:             {"symbol": "BBBUSD", "volume": 9},
    50:             {"symbol": "CCCUSDC", "volume": 8},
    51:             {"symbol": "DDDUSDT", "volume": 7},
    52:         ],
    53:     )
    54:     monkeypatch.setitem(bot.CONFIG, "ALLOWED_SYMBOLS", [])
    55: 
    56:     payload = bot.send_selected_pairs(object(), top_n=4)
    57: 
    58:     assert payload == sent["payload"]
    59:     assert payload["green"] == "AAA"
    60:     assert payload["orange"] == "BBB"
    61:     assert payload["red"] == "CCC, DDD"
    62: 
    63: 
    64: def test_filter_trade_pairs_all_pairs(monkeypatch):
    65:     class DummyClient:
    66:         def get_ticker(self):
    67:             return {
    68:                 "data": [
    69:                     {"symbol": "BTCUSDT", "volume": 100, "bidPrice": 1, "askPrice": 1.0001},
    70:                     {"symbol": "ETHUSDT", "volume": 90, "bidPrice": 1, "askPrice": 1.0001},
    71:                 ]
    72:             }
    73: 
    74:     client = DummyClient()
    75:     res = bot.filter_trade_pairs(client, volume_min=0, max_spread_bps=10, top_n=5)
    76:     assert [r["symbol"] for r in res] == ["BTCUSDT", "ETHUSDT"]
    77: 


## tests/test_risk_manager.py (last modified: 2025-08-23 20:57:14)
     1: from scalp import RiskManager
     2: 
     3: 
     4: def test_kill_switch_triggered() -> None:
     5:     rm = RiskManager(max_daily_loss_pct=2.0, max_positions=1, risk_pct=0.01)
     6:     rm.record_trade(-1.0)
     7:     rm.record_trade(-1.5)
     8:     assert rm.kill_switch is True
     9: 
    10: 
    11: def test_profit_kill_switch_triggered() -> None:
    12:     rm = RiskManager(
    13:         max_daily_loss_pct=10.0,
    14:         max_daily_profit_pct=3.0,
    15:         max_positions=1,
    16:         risk_pct=0.01,
    17:     )
    18:     rm.record_trade(1.5)
    19:     rm.record_trade(1.6)
    20:     assert rm.kill_switch is True
    21: 
    22: 
    23: def test_pause_and_can_open() -> None:
    24:     rm = RiskManager(max_daily_loss_pct=10.0, max_positions=1, risk_pct=0.01)
    25:     rm.record_trade(-0.5)
    26:     rm.record_trade(-0.6)
    27:     rm.record_trade(-0.7)
    28:     assert rm.pause_duration() == 15 * 60
    29:     rm.record_trade(-0.8)
    30:     rm.record_trade(-0.9)
    31:     assert rm.pause_duration() == 60 * 60
    32:     assert rm.can_open(0) is True
    33:     assert rm.can_open(1) is False
    34: 
    35: 
    36: def test_risk_pct_scaling() -> None:
    37:     rm = RiskManager(max_daily_loss_pct=10.0, max_positions=1, risk_pct=0.01)
    38:     rm.record_trade(1.0)
    39:     rm.record_trade(1.0)
    40:     assert rm.risk_pct > 0.01
    41:     rm.record_trade(-1.0)
    42:     rm.record_trade(-1.0)
    43:     assert rm.risk_pct < 0.01


## tests/test_risk_utils.py (last modified: 2025-08-23 20:57:14)
     1: import pytest
     2: 
     3: from scalper.risk import calc_risk_amount, calc_position_size
     4: 
     5: 
     6: def test_calc_risk_amount_basic():
     7:     assert calc_risk_amount(1000, 0.01) == 10.0
     8: 
     9: 
    10: def test_calc_position_size_basic():
    11:     # risk_amount = 1000 * 0.01 = 10; position size = 10 / 50 = 0.2
    12:     assert calc_position_size(1000, 0.01, 50) == 0.2
    13: 
    14: 
    15: @pytest.mark.parametrize("equity,risk_pct", [
    16:     (0, 0.01),
    17:     (-100, 0.01),
    18:     (1000, 0),
    19:     (1000, -0.1),
    20:     (1000, 1.5),
    21: ])
    22: def test_calc_risk_amount_invalid(equity, risk_pct):
    23:     with pytest.raises(ValueError):
    24:         calc_risk_amount(equity, risk_pct)
    25: 
    26: 
    27: @pytest.mark.parametrize("stop_distance", [0, -1])
    28: def test_calc_position_size_invalid_stop(stop_distance):
    29:     with pytest.raises(ValueError):
    30:         calc_position_size(1000, 0.01, stop_distance)


## tests/test_signal_risk.py (last modified: 2025-08-23 20:57:14)
     1: import types
     2: import os
     3: import sys
     4: 
     5: sys.path.append(os.path.dirname(os.path.dirname(__file__)))
     6: sys.modules['requests'] = types.ModuleType('requests')
     7: 
     8: from bot import (
     9:     map_score_to_sig_level,
    10:     compute_risk_params,
    11:     prepare_order,
    12:     Signal,
    13:     CONFIG,
    14: )
    15: 
    16: 
    17: class DummyRisk:
    18:     def __init__(self, pct: float) -> None:
    19:         self.risk_pct = pct
    20: 
    21: 
    22: def _contract_detail():
    23:     return {
    24:         "data": [
    25:             {
    26:                 "symbol": "BTC_USDT",
    27:                 "contractSize": 0.001,
    28:                 "volUnit": 1,
    29:                 "minVol": 1,
    30:                 "minTradeUSDT": 5,
    31:             }
    32:         ]
    33:     }
    34: 
    35: 
    36: def test_score_to_level_mapping():
    37:     assert map_score_to_sig_level(10) == 1
    38:     assert map_score_to_sig_level(35) == 2
    39:     assert map_score_to_sig_level(69.9) == 2
    40:     assert map_score_to_sig_level(70) == 3
    41: 
    42: 
    43: def test_risk_tables():
    44:     rp, lev, cap = compute_risk_params(2, 3, 0.01, 20)
    45:     assert rp == 0.01 * 1.25
    46:     assert lev == int(20 * 0.75)
    47:     assert cap == 0.55
    48:     rp2, lev2, cap2 = compute_risk_params(3, 1, 0.01, 20)
    49:     assert rp2 == 0.01 * 1.0
    50:     assert lev2 == int(20 * 0.5)
    51:     assert cap2 == 0.35
    52: 
    53: 
    54: def test_notional_cap():
    55:     rm = DummyRisk(0.05)
    56:     sig = Signal("BTC_USDT", "long", 10000, 9900, 10100, 10200, 1, score=80)
    57:     available = 1000
    58:     params = prepare_order(
    59:         sig,
    60:         _contract_detail(),
    61:         equity_usdt=available,
    62:         available_usdt=available,
    63:         base_leverage=10,
    64:         risk_mgr=rm,
    65:         user_risk_level=2,
    66:     )
    67:     assert params["notional"] <= params["cap_ratio"] * available + 1e-6


## tests/test_slippage.py (last modified: 2025-08-23 20:57:14)
     1: from scalper.trade_utils import marketable_limit_price
     2: 
     3: 
     4: def test_marketable_limit_price_buy_sell():
     5:     price_buy = marketable_limit_price("buy", best_bid=9.9, best_ask=10.0, slippage=0.001)
     6:     assert price_buy == 10.0 * 1.001
     7:     price_sell = marketable_limit_price("sell", best_bid=9.9, best_ask=10.0, slippage=0.001)
     8:     assert price_sell == 9.9 * (1 - 0.001)


## tests/test_strategy_v2.py (last modified: 2025-08-23 20:57:14)
     1: import pytest
     2: 
     3: from scalp import strategy
     4: from scalper.trade_utils import trailing_stop, should_scale_in, timeout_exit
     5: 
     6: 
     7: def make_ohlcv(n=60, start=100, step=1):
     8:     closes = [start + i * step for i in range(n)]
     9:     highs = [c + 1 for c in closes]
    10:     lows = [c - 1 for c in closes]
    11:     vols = [1 for _ in closes]
    12:     return {"open": closes, "high": highs, "low": lows, "close": closes, "volume": vols}
    13: 
    14: 
    15: def test_generate_signal_atr_adaptation(monkeypatch):
    16:     base = make_ohlcv(step=2)
    17:     ohlcv_15 = make_ohlcv(n=15, step=2)
    18:     ohlcv_1h = make_ohlcv(step=2)
    19: 
    20:     # patches for deterministic RSI values
    21:     rsi_vals = iter([60, 41, 39])
    22:     monkeypatch.setattr(strategy, "calc_rsi", lambda *args, **kwargs: next(rsi_vals))
    23:     monkeypatch.setattr(strategy, "calc_position_size", lambda equity, risk, dist: 100)
    24:     # low ATR -> signal disabled
    25:     monkeypatch.setattr(strategy, "calc_atr", lambda *args, **kwargs: 0.1)
    26:     sig = strategy.generate_signal(
    27:         "AAA",
    28:         base,
    29:         equity=1_000,
    30:         risk_pct=0.01,
    31:         ohlcv_15m=ohlcv_15,
    32:         ohlcv_1h=ohlcv_1h,
    33:         order_book={"bid_vol_aggreg": 120, "ask_vol_aggreg": 80},
    34:         tick_ratio_buy=0.6,
    35:     )
    36:     assert sig is None
    37: 
    38:     # high ATR -> size reduced
    39:     rsi_vals = iter([60, 41, 39])
    40:     monkeypatch.setattr(strategy, "calc_rsi", lambda *args, **kwargs: next(rsi_vals))
    41:     monkeypatch.setattr(strategy, "calc_atr", lambda *args, **kwargs: 5.0)
    42:     sig = strategy.generate_signal(
    43:         "AAA",
    44:         base,
    45:         equity=1_000,
    46:         risk_pct=0.01,
    47:         ohlcv_15m=ohlcv_15,
    48:         ohlcv_1h=ohlcv_1h,
    49:         order_book={"bid_vol_aggreg": 120, "ask_vol_aggreg": 80},
    50:         tick_ratio_buy=0.6,
    51:     )
    52:     assert sig and sig.side == "long"
    53:     assert sig.qty == 50
    54: 
    55: 
    56: def test_generate_signal_short_with_filters(monkeypatch):
    57:     base = make_ohlcv(start=200, step=-2)
    58:     ohlcv_15 = make_ohlcv(n=15, start=200, step=-2)
    59:     ohlcv_1h = make_ohlcv(start=200, step=-2)
    60: 
    61:     rsi_vals = iter([40, 59, 61])
    62:     monkeypatch.setattr(strategy, "calc_rsi", lambda *args, **kwargs: next(rsi_vals))
    63:     monkeypatch.setattr(strategy, "calc_position_size", lambda equity, risk, dist: 100)
    64:     monkeypatch.setattr(strategy, "calc_atr", lambda *args, **kwargs: 1.0)
    65: 
    66:     sig = strategy.generate_signal(
    67:         "AAA",
    68:         base,
    69:         equity=1_000,
    70:         risk_pct=0.01,
    71:         ohlcv_15m=ohlcv_15,
    72:         ohlcv_1h=ohlcv_1h,
    73:         order_book={"bid_vol_aggreg": 80, "ask_vol_aggreg": 120},
    74:         tick_ratio_buy=0.4,
    75:     )
    76:     assert sig and sig.side == "short"
    77:     assert sig.qty == 100
    78: 
    79: 
    80: def test_trailing_and_timeout():
    81:     # trailing stop
    82:     sl = trailing_stop("long", current_price=110, atr=10, sl=90)
    83:     assert sl == pytest.approx(102.5)
    84:     # scaling
    85:     assert should_scale_in(100, 105, 100, 10, "long") is True
    86:     assert should_scale_in(100, 95, 100, 10, "short") is True
    87:     # timeout
    88:     # before the progress window no exit should be triggered
    89:     assert not timeout_exit(0, 10 * 60, 100, 99, "long", progress_min=15, timeout_min=30)
    90:     # after ``progress_min`` minutes without favourable movement we close
    91:     assert timeout_exit(0, 20 * 60, 100, 99, "long", progress_min=15, timeout_min=30)
    92: 
    93: 
    94: def test_generate_signal_macd_filter(monkeypatch):
    95:     base = make_ohlcv(step=2)
    96:     ohlcv_15 = make_ohlcv(n=15, step=2)
    97:     ohlcv_1h = make_ohlcv(step=2)
    98: 
    99:     rsi_vals = iter([60, 41, 39])
   100:     monkeypatch.setattr(strategy, "calc_rsi", lambda *args, **kwargs: next(rsi_vals))
   101:     monkeypatch.setattr(strategy, "calc_position_size", lambda equity, risk, dist: 100)
   102:     monkeypatch.setattr(strategy, "calc_atr", lambda *args, **kwargs: 1.0)
   103:     monkeypatch.setattr(strategy, "calc_macd", lambda *args, **kwargs: (-1.0, 0.0, -1.0))
   104: 
   105:     sig = strategy.generate_signal(
   106:         "AAA",
   107:         base,
   108:         equity=1_000,
   109:         risk_pct=0.01,
   110:         ohlcv_15m=ohlcv_15,
   111:         ohlcv_1h=ohlcv_1h,
   112:         order_book={"bid_vol_aggreg": 120, "ask_vol_aggreg": 80},
   113:         tick_ratio_buy=0.6,
   114:     )
   115:     assert sig is None
   116: 
   117: 
   118: 
   119: def test_generate_signal_trend_ema_filter(monkeypatch):
   120:     base = make_ohlcv(step=2)
   121:     ohlcv_15 = make_ohlcv(n=15, step=2)
   122:     ohlcv_1h = make_ohlcv(step=2)
   123: 
   124:     rsi_vals = iter([60, 41, 39])
   125:     monkeypatch.setattr(strategy, "calc_rsi", lambda *args, **kwargs: next(rsi_vals))
   126:     monkeypatch.setattr(strategy, "calc_position_size", lambda equity, risk, dist: 100)
   127:     monkeypatch.setattr(strategy, "calc_atr", lambda *args, **kwargs: 1.0)
   128: 
   129:     orig_ema = strategy.ema
   130: 
   131:     def fake_ema(series, window):
   132:         if window == 200:
   133:             return [x + 1000 for x in orig_ema(series, window)]
   134:         return orig_ema(series, window)
   135: 
   136:     monkeypatch.setattr(strategy, "ema", fake_ema)
   137: 
   138:     sig = strategy.generate_signal(
   139:         "AAA",
   140:         base,
   141:         equity=1_000,
   142:         risk_pct=0.01,
   143:         ohlcv_15m=ohlcv_15,
   144:         ohlcv_1h=ohlcv_1h,
   145:         order_book={"bid_vol_aggreg": 120, "ask_vol_aggreg": 80},
   146:         tick_ratio_buy=0.6,
   147:         trend_ema_period=200,
   148:     )
   149:     assert sig is None
   150:     

## tests/test_telegram_bot.py (last modified: 2025-08-23 20:57:14)
     1: from scalper.telegram_bot import TelegramBot
     2: 
     3: 
     4: class DummyClient:
     5: 
     6:     def __init__(self):
     7:         self.closed = []
     8:         self.closed_all = False
     9: 
    10: 
    11:     def get_assets(self):
    12:         return {"data": [{"currency": "USDT", "equity": 123.45}]}
    13: 
    14:     def get_positions(self):
    15:         return {
    16:             "data": [
    17:                 {
    18:                     "symbol": "BTC_USDT",
    19:                     "side": "long",
    20:                     "vol": 2,
    21:                     "pnl_usd": 1.0,
    22:                     "pnl_pct": 5.0,
    23:                 }
    24:             ]
    25:         }
    26: 
    27:     def close_position(self, sym):
    28:         self.closed.append(sym)
    29: 
    30:     def close_all_positions(self):
    31:         self.closed_all = True
    32: 
    33: 
    34: 
    35: class DummyRiskMgr:
    36: 
    37:     def __init__(self):
    38:         self.reset_called = False
    39:         self.max_positions = 1
    40:         self.risk_pct = 0.01
    41: 
    42:     def reset_day(self):
    43:         self.reset_called = True
    44: 
    45: 
    46: class DummyRequests:
    47:     def __init__(self):
    48:         self.posts = []
    49: 
    50:     def post(self, url, json=None, timeout=5):
    51:         self.posts.append((url, json))
    52: 
    53:     def get(self, url, params=None, timeout=5):  # pragma: no cover - unused
    54:         return type("R", (), {"json": lambda self: {}, "raise_for_status": lambda self: None})()
    55: 
    56: 
    57: def make_bot(config=None, requests_module=None):
    58:     cfg = {"RISK_LEVEL": 2, "MAX_POSITIONS": 1}
    59:     if config:
    60:         cfg.update(config)
    61:     if requests_module is None:
    62:         requests_module = DummyRequests()
    63:     return TelegramBot("t", "1", DummyClient(), cfg, DummyRiskMgr(), requests_module=requests_module)
    64: 
    65: 
    66: def test_handle_balance():
    67:     bot = make_bot()
    68: 
    69:     resp, kb = bot.handle_callback("balance", 0.0)
    70:     assert "123.45" in resp
    71:     assert kb == bot.main_keyboard
    72: 
    73: 
    74: 
    75: def test_handle_positions():
    76:     bot = make_bot()
    77:     resp, _ = bot.handle_callback("positions", 0.0)
    78:     assert "BTC" in resp
    79:     assert "PnL" in resp
    80: 
    81: 
    82: def test_handle_positions_zero_pnl():
    83:     bot = make_bot()
    84: 
    85:     def zero_positions():
    86:         return {
    87:             "data": [
    88:                 {
    89:                     "symbol": "BTC_USDT",
    90:                     "side": "long",
    91:                     "vol": 1,
    92:                     "pnl_usd": 0.0,
    93:                     "pnl_pct": 0.0,
    94:                 }
    95:             ]
    96:         }
    97: 
    98:     bot.client.get_positions = zero_positions
    99:     resp, _ = bot.handle_callback("positions", 0.0)
   100:     assert "PnL: 0.00 USDT" in resp
   101: 
   102: 
   103: 
   104: def test_handle_pnl():
   105:     bot = make_bot()
   106:     resp, _ = bot.handle_callback("pnl", 5.0)
   107: 
   108:     assert "5.00" in resp
   109: 
   110: 
   111: def test_handle_risk_change():
   112:     bot = make_bot()
   113: 
   114:     resp, kb = bot.handle_callback("risk_red", 0.0)
   115:     assert "3" in resp
   116:     assert bot.config["RISK_LEVEL"] == 3
   117:     assert kb == bot.main_keyboard
   118: 
   119: 
   120: def test_risk_menu():
   121:     bot = make_bot()
   122:     resp, kb = bot.handle_callback("risk", 0.0)
   123:     assert "risque" in resp.lower()
   124:     assert kb == bot.risk_keyboard
   125: 
   126: 
   127: 
   128: def test_stop_menu_and_actions():
   129:     bot = make_bot()
   130:     resp, kb = bot.handle_callback("stop", 0.0)
   131:     assert any(
   132:         btn["callback_data"] == "stop_BTC_USDT" for row in kb for btn in row
   133:     )
   134:     assert any(btn["callback_data"] == "stop_all" for row in kb for btn in row)
   135:     resp, _ = bot.handle_callback("stop_BTC_USDT", 0.0)
   136:     assert "fermée" in resp.lower()
   137:     assert bot.client.closed == ["BTC_USDT"]
   138:     resp, _ = bot.handle_callback("stop_all", 0.0)
   139:     assert bot.client.closed_all is True
   140: 
   141: 
   142: def test_handle_unknown():
   143:     bot = make_bot()
   144:     resp, kb = bot.handle_callback("foobar", 0.0)
   145:     assert resp is None
   146:     assert kb is None
   147: 
   148: 
   149: def test_reset_all():
   150:     bot = make_bot()
   151:     resp, kb = bot.handle_callback("reset_all", 0.0)
   152:     assert "réinitialisés" in resp.lower()
   153:     assert bot.risk_mgr.reset_called is True
   154:     assert bot.client.closed_all is True
   155:     assert kb == bot.settings_keyboard
   156: 
   157: 
   158: def test_shutdown_bot():
   159:     bot = make_bot()
   160:     resp, kb = bot.handle_callback("shutdown", 0.0)
   161:     assert "arrêt" in resp.lower()
   162:     assert bot.stop_requested is True
   163:     assert kb == bot.main_keyboard
   164: 
   165: 
   166: def test_start_sends_menu():
   167:     req = DummyRequests()
   168:     make_bot(requests_module=req)
   169:     assert req.posts
   170:     text = req.posts[0][1]["text"]
   171:     assert "Solde" in text and "PnL session" in text
   172:     assert "Positions max" in text
   173:     assert "Risque actuel" in text
   174: 
   175: 
   176: def test_settings_menu_and_reset_risk():
   177:     bot = make_bot()
   178:     resp, kb = bot.handle_callback("settings", 0.0)
   179:     assert "réglages" in resp.lower()
   180:     assert kb == bot.settings_keyboard
   181:     resp, kb = bot.handle_callback("reset_risk", 0.0)
   182:     assert "risque" in resp.lower()
   183:     assert bot.risk_mgr.reset_called is True
   184:     assert kb == bot.settings_keyboard
   185: 
   186: 
   187: def test_update_button(monkeypatch):
   188:     bot = make_bot()
   189:     called = {}
   190: 
   191:     def fake_update():
   192:         called["called"] = True
   193: 
   194:     bot.update_pairs = fake_update
   195:     resp, kb = bot.handle_callback("update", 0.0)
   196:     assert called["called"] is True
   197:     assert "mise à jour" in resp.lower()
   198:     assert kb == bot.main_keyboard
   199: 
   200: 
   201: def test_maxpos_menu_and_change():
   202:     bot = make_bot()
   203:     resp, kb = bot.handle_callback("maxpos", 0.0)
   204:     assert "nombre" in resp.lower()
   205:     assert kb == bot.maxpos_keyboard
   206:     resp, kb = bot.handle_callback("maxpos_3", 0.0)
   207:     assert "3" in resp
   208:     assert bot.config["MAX_POSITIONS"] == 3
   209:     assert bot.risk_mgr.max_positions == 3
   210:     assert kb == bot.main_keyboard
   211: 
   212: 
   213: def test_stop_no_positions():
   214:     bot = make_bot()
   215:     bot.client.get_positions = lambda: {"data": []}
   216:     resp, kb = bot.handle_callback("stop", 0.0)
   217:     assert "aucune crypto" in resp.lower()
   218:     assert kb == bot.settings_keyboard
   219: 


## tests/test_utils.py (last modified: 2025-08-23 20:57:14)
     1: import pytest
     2: from bot import ema, cross, compute_position_size, CONFIG
     3: from scalper.trade_utils import extract_available_balance
     4: 
     5: 
     6: def test_ema_basic():
     7:     data = [1, 2, 3, 4, 5]
     8:     result = ema(data, 3)
     9:     assert result == pytest.approx([1, 1.5, 2.25, 3.125, 4.0625])
    10: 
    11: 
    12: def test_cross_up_down_none():
    13:     assert cross(3, 2, 1, 2) == 1  # up cross
    14:     assert cross(0.5, 1, 2, 1) == -1  # down cross
    15:     assert cross(2, 2, 2, 2) == 0  # no cross
    16: 
    17: 
    18: def test_compute_position_size():
    19:     detail = {
    20:         "data": [
    21:             {
    22:                 "symbol": CONFIG["SYMBOL"],
    23:                 "contractSize": 0.001,
    24:                 "volUnit": 1,
    25:                 "minVol": 1,
    26:             }
    27:         ]
    28:     }
    29:     vol = compute_position_size(detail, equity_usdt=100.0, price=20000.0,
    30:                                 risk_pct=0.01, leverage=5)
    31:     assert vol == 1
    32: 
    33: 
    34: def test_compute_position_size_missing_symbol():
    35:     with pytest.raises(ValueError):
    36:         compute_position_size({"data": []}, 100.0, 1.0, 0.01, 5)
    37: 
    38: 
    39: def test_extract_available_balance_fallback():
    40:     assets = {
    41:         "data": [
    42:             {
    43:                 "currency": "USDT",
    44:                 "available": 0,
    45:                 "cashBalance": "150.5",
    46:                 "equity": "200",
    47:             }
    48:         ]
    49:     }
    50:     assert extract_available_balance(assets) == 150.5
    51: 
    52: 
    53: def test_extract_available_balance_equity_only():
    54:     assets = {
    55:         "data": [
    56:             {
    57:                 "currency": "USDT",
    58:                 "equity": "42",
    59:             }
    60:         ]
    61:     }
    62:     assert extract_available_balance(assets) == 42.0
    63: 
    64: 
    65: def test_extract_available_balance_zero_available_returns_zero():
    66:     assets = {
    67:         "data": [
    68:             {
    69:                 "currency": "USDT",
    70:                 "available": 0,
    71:                 "availableBalance": 0,
    72:                 "equity": "42",
    73:             }
    74:         ]
    75:     }
    76:     assert extract_available_balance(assets) == 0.0


## tests/test_version.py (last modified: 2025-08-23 20:57:14)
     1: import pytest
     2: from scalp import version
     3: 
     4: 
     5: def test_get_version(monkeypatch, tmp_path):
     6:     vfile = tmp_path / "VERSION"
     7:     vfile.write_text("1.2.3")
     8:     monkeypatch.setattr(version, "_VERSION_FILE", vfile)
     9:     assert version.get_version() == "1.2.3"
    10: 
    11: 
    12: def test_bump_version(monkeypatch, tmp_path):
    13:     vfile = tmp_path / "VERSION"
    14: 
    15:     vfile.write_text("0.1.2\n")
    16:     monkeypatch.setattr(version, "_VERSION_FILE", vfile)
    17:     assert version.bump_version("minor") == "0.2.0"
    18:     assert vfile.read_text().strip() == "0.2.0"
    19: 
    20: 
    21: def test_bump_version_invalid_part(monkeypatch, tmp_path):
    22:     vfile = tmp_path / "VERSION"
    23:     vfile.write_text("0.1.0\n")
    24:     monkeypatch.setattr(version, "_VERSION_FILE", vfile)
    25:     with pytest.raises(ValueError):
    26:         version.bump_version("foo")
    27: 
    28: 
    29: def test_bump_from_message(monkeypatch, tmp_path):
    30:     vfile = tmp_path / "VERSION"
    31:     vfile.write_text("1.0.0\n")
    32:     monkeypatch.setattr(version, "_VERSION_FILE", vfile)
    33:     assert version.bump_version_from_message("feat: add x") == "1.1.0"
    34:     assert version.bump_version_from_message("fix: bug") == "1.1.1"
    35:     assert version.bump_version_from_message("feat!: major change") == "2.0.0"
    36: 


## tests/test_walk_forward.py (last modified: 2025-08-23 20:57:14)
     1: from scalper.backtest import walk_forward_windows
     2: 
     3: 
     4: def test_walk_forward_windows():
     5:     data = list(range(10))
     6:     windows = list(walk_forward_windows(data, train=4, test=2))
     7:     assert windows == [
     8:         ([0, 1, 2, 3], [4, 5]),
     9:         ([2, 3, 4, 5], [6, 7]),
    10:         ([4, 5, 6, 7], [8, 9]),
    11:     ]


## tests/test_ws.py (last modified: 2025-08-23 20:57:14)
     1: import asyncio
     2: 
     3: from scalper.ws import WebsocketManager
     4: 
     5: 
     6: def test_websocket_manager_stop():
     7:     async def connect():
     8:         return None
     9: 
    10:     async def subscribe():
    11:         return None
    12: 
    13:     ws = WebsocketManager(connect, subscribe, heartbeat_interval=0.01)
    14: 
    15:     async def run_and_stop():
    16:         await ws.run()
    17:         assert ws._heartbeat_task is not None
    18:         await ws.stop()
    19:         assert ws._heartbeat_task is None
    20: 
    21:     asyncio.run(run_and_stop())


## tg_diag.py (last modified: 2025-08-23 20:57:14)
     1: # tg_diag.py
     2: import asyncio, os, aiohttp
     3: 
     4: TOKEN = os.getenv("TELEGRAM_TOKEN", "")
     5: CHAT  = os.getenv("TELEGRAM_CHAT_ID", "")
     6: 
     7: async def main():
     8:     if not TOKEN or not CHAT:
     9:         print("❌ Manque TELEGRAM_TOKEN ou TELEGRAM_CHAT_ID dans l'env.")
    10:         return
    11:     url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
    12:     payload = {"chat_id": CHAT, "text": "🔎 Test Telegram OK ?"}
    13:     try:
    14:         async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=15)) as s:
    15:             async with s.post(url, json=payload) as r:
    16:                 body = await r.text()
    17:                 print("HTTP:", r.status)
    18:                 print("Body:", body[:500])
    19:     except Exception as e:
    20:         print("❌ Exception:", repr(e))
    21: 
    22: if __name__ == "__main__":
    23:     asyncio.run(main())



--------------------------------------------------------------------------------
FILE: dumps/DUMP_20250824-112618.txt
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
FILE: init.py
--------------------------------------------------------------------------------
#!/usr/bin/env python3
"""Install all project dependencies.

Run this script once to install every ``requirements*.txt`` file found in the
repository as well as the packages needed for the test suite.  All subsequent
invocations of the bot or its submodules will then share the same Python
environment with the required dependencies available.
"""

from __future__ import annotations

import subprocess
import sys
from pathlib import Path


def install_packages(*args: str) -> None:
    """Install packages using pip for the current Python interpreter."""
    cmd = [sys.executable, "-m", "pip", "install", *args]
    subprocess.check_call(cmd)


def main() -> None:
    repo_root = Path(__file__).resolve().parent

    # Install from any requirements*.txt file across the repository so that
    # sub-packages with their own dependency lists are also covered.
    for req in sorted(repo_root.rglob("requirements*.txt")):
        install_packages("-r", str(req))

    # Ensure test dependencies are available
    install_packages("pytest")


if __name__ == "__main__":
    main()


--------------------------------------------------------------------------------
FILE: pytest.ini
--------------------------------------------------------------------------------
[pytest]
addopts = -q


--------------------------------------------------------------------------------
FILE: requirements-dev.txt
--------------------------------------------------------------------------------
pytest


--------------------------------------------------------------------------------
FILE: requirements.txt
--------------------------------------------------------------------------------
requests
python-dotenv
pydantic==1.10.15 ; python_version < "3.11"

# pydantic v1 déjà pin si environnement ancien
# rien à ajouter ici pour market_data (pas de nouvelle dépendance)


--------------------------------------------------------------------------------
FILE: resultat.log
--------------------------------------------------------------------------------
.................................................................................................                        [100%]
97 passed in 0.42s


--------------------------------------------------------------------------------
FILE: scalper/VERSION
--------------------------------------------------------------------------------
0.3.0



--------------------------------------------------------------------------------
FILE: scalper/__init__.py
--------------------------------------------------------------------------------
# Rend le dossier 'scalper' importable comme package.
__all__ = ["live", "signals", "core"]

--------------------------------------------------------------------------------
FILE: scalper/adapters/__init__.py
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
FILE: scalper/adapters/bitget.py
--------------------------------------------------------------------------------
# scalp/adapters/bitget.py
from __future__ import annotations
from typing import Any, Dict, List, Optional
import inspect, os
import requests

# Client bas-niveau fourni par le repo
from scalper.bitget_client import BitgetFuturesClient as _Base


def _to_float(x, default: float = 0.0) -> float:
    try:
        return float(x)
    except Exception:
        return default


def _select_base_url() -> str:
    env = os.environ.get("BITGET_BASE_URL")
    if env:
        return env
    paper = os.environ.get("PAPER_TRADE", "true").lower() in ("1", "true", "yes", "on")
    return "https://api-testnet.bitget.com" if paper else "https://api.bitget.com"


class BitgetFuturesClient(_Base):
    """
    Adaptateur Bitget:
      - __init__ dynamique (passe seulement les kwargs que le client accepte)
      - Normalisations robustes: assets, ticker(s), positions, fills
    """

    # --------------------- INIT dynamique ---------------------
    def __init__(self, *args: Any, **kwargs: Any) -> None:
        """
        Accepte indifféremment:
          api_key/apiKey/access_key/accessKey/key
          api_secret/apiSecret/secret/secret_key/secretKey
          passphrase/password/api_passphrase/apiPassphrase
          base_url/baseUrl/host/endpoint (ou auto)
        On n'envoie au client de base que les noms présents dans sa signature.
        """
        user_kwargs = dict(kwargs)

        # Collecte des valeurs possibles (tous alias)
        incoming_key = (
            user_kwargs.pop("api_key", None)
            or user_kwargs.pop("apiKey", None)
            or user_kwargs.pop("access_key", None)
            or user_kwargs.pop("accessKey", None)
            or user_kwargs.pop("key", None)
            or user_kwargs.pop("API_KEY", None)
        )
        incoming_secret = (
            user_kwargs.pop("api_secret", None)
            or user_kwargs.pop("apiSecret", None)
            or user_kwargs.pop("secret_key", None)
            or user_kwargs.pop("secretKey", None)
            or user_kwargs.pop("secret", None)
            or user_kwargs.pop("API_SECRET", None)
        )
        incoming_pass = (
            user_kwargs.pop("passphrase", None)
            or user_kwargs.pop("password", None)
            or user_kwargs.pop("api_passphrase", None)
            or user_kwargs.pop("apiPassphrase", None)
        )
        incoming_base = (
            user_kwargs.pop("base_url", None)
            or user_kwargs.pop("baseUrl", None)
            or user_kwargs.pop("host", None)
            or user_kwargs.pop("endpoint", None)
            or _select_base_url()
        )

        # Signature réelle du client bas-niveau
        sig = inspect.signature(_Base.__init__)
        param_names = set(sig.parameters.keys())  # ex: {'self','access_key','secret_key','passphrase','base_url',...}

        def pick_name(cands: List[str]) -> Optional[str]:
            for c in cands:
                if c in param_names:
                    return c
            return None

        # Noms réellement supportés
        key_name = pick_name(["api_key", "apiKey", "access_key", "accessKey", "key"])
        sec_name = pick_name(["api_secret", "apiSecret", "secret_key", "secretKey", "secret"])
        pas_name = pick_name(["passphrase", "password", "api_passphrase", "apiPassphrase"])
        base_name = pick_name(["base_url", "baseUrl", "host", "endpoint"])
        req_mod_name = "requests_module" if "requests_module" in param_names else None

        # Construire kwargs à transmettre (une seule fois par nom)
        base_kwargs: Dict[str, Any] = {}
        if key_name and incoming_key is not None:
            base_kwargs[key_name] = incoming_key
        if sec_name and incoming_secret is not None:
            base_kwargs[sec_name] = incoming_secret
        if pas_name and incoming_pass is not None:
            base_kwargs[pas_name] = incoming_pass
        if base_name:
            base_kwargs[base_name] = incoming_base
        if req_mod_name:
            base_kwargs[req_mod_name] = requests

        # Ne transmettre aucun doublon : si user_kwargs contient un nom supporté
        # qui n'a pas été défini ci-dessus, on le relaie.
        for k, v in list(user_kwargs.items()):
            if k in param_names and k not in base_kwargs:
                base_kwargs[k] = v

        # Appel propre, 100% mots-clés (évite “missing positional arg” et “multiple values”)
        super().__init__(**base_kwargs)

    # --------------------- COMPTES / ASSETS ---------------------
    def get_assets(self) -> Dict[str, Any]:
        raw = super().get_assets()
        data = raw.get("data") or raw.get("result") or raw.get("assets") or []
        norm: List[Dict[str, Any]] = []
        for a in data:
            currency = a.get("currency") or a.get("marginCoin") or a.get("coin") or "USDT"
            equity = _to_float(a.get("equity", a.get("usdtEquity", a.get("totalEquity", 0))))
            available = _to_float(a.get("available", a.get("availableBalance", a.get("availableUSDT", 0))))
            norm.append({"currency": currency, "equity": equity, "available": available, **a})
        return {"success": True, "data": norm}

    # ------------------------ TICKER(S) -------------------------
    def get_ticker(self, symbol: Optional[str] = None) -> Dict[str, Any]:
        """
        Normalise vers liste d'objets: {symbol,lastPrice,bidPrice,askPrice,volume}
        Tolère top-level dict/list et items dict/list.
        """
        try:
            raw: Any = super().get_ticker(symbol) if symbol else super().get_tickers()
        except Exception as e:
            return {"success": False, "error": repr(e), "data": []}

        items: List[Any] = []
        if isinstance(raw, dict):
            d = raw.get("data")
            if symbol and isinstance(d, dict):
                items = [d]
            else:
                items = d or raw.get("result") or raw.get("tickers") or []
        elif isinstance(raw, (list, tuple)):
            items = list(raw)

        norm: List[Dict[str, Any]] = []
        for t in items:
            if isinstance(t, dict):
                s = (t.get("symbol") or t.get("instId") or t.get("instrumentId") or "").replace("_", "")
                last_ = t.get("lastPrice", t.get("last", t.get("close", t.get("markPrice", 0))))
                bid_ = t.get("bidPrice", t.get("bestBidPrice", t.get("bestBid", t.get("buyOne", last_))))
                ask_ = t.get("askPrice", t.get("bestAskPrice", t.get("bestAsk", t.get("sellOne", last_))))
                vol_usdt = t.get("usdtVolume", t.get("quoteVolume", t.get("turnover24h", None)))
                vol_base = t.get("baseVolume", t.get("volume", t.get("size24h", 0)))
                volume = _to_float(vol_usdt if vol_usdt is not None else vol_base)
                norm.append({
                    "symbol": s,
                    "lastPrice": _to_float(last_),
                    "bidPrice": _to_float(bid_),
                    "askPrice": _to_float(ask_),
                    "volume": volume
                })
            else:
                seq = list(t)
                if len(seq) >= 5:
                    first_ts = isinstance(seq[0], (int, float)) and seq[0] > 10**10
                    if first_ts:
                        close = _to_float(seq[4]); vol = _to_float(seq[5] if len(seq) > 5 else 0.0)
                    else:
                        close = _to_float(seq[3]); vol = _to_float(seq[4] if len(seq) > 4 else 0.0)
                else:
                    close = _to_float(seq[-1] if seq else 0.0); vol = 0.0
                s = (symbol or "").replace("_", "")
                norm.append({"symbol": s, "lastPrice": close, "bidPrice": close, "askPrice": close, "volume": vol})

        return {"success": True, "data": norm}

    # --------------- POSITIONS / ORDRES / FILLS -----------------
    def get_open_positions(self, symbol: Optional[str] = None) -> Dict[str, Any]:
        raw: Dict[str, Any] = super().get_positions() if hasattr(super(), "get_positions") else {}
        items = raw.get("data") or raw.get("result") or raw.get("positions") or []
        out: List[Dict[str, Any]] = []
        for p in items:
            s = (p.get("symbol") or p.get("instId") or "").replace("_", "")
            if symbol and s != symbol:
                continue
            side = (p.get("holdSide") or p.get("posSide") or p.get("side") or "").lower()
            qty = _to_float(p.get("size", p.get("holdAmount", p.get("total", 0))))
            avg = _to_float(p.get("avgOpenPrice", p.get("avgPrice", p.get("entryPrice", 0))))
            out.append({"symbol": s, "side": side, "qty": qty, "avgEntryPrice": avg})
        return {"success": True, "data": out}

    def get_fills(self, symbol: str, order_id: Optional[str] = None, limit: int = 100) -> Dict[str, Any]:
        raw: Dict[str, Any] = super().get_fills(symbol=symbol) if hasattr(super(), "get_fills") else {}
        items = raw.get("data") or raw.get("result") or []
        out: List[Dict[str, Any]] = []
        for f in items[:limit]:
            s = (f.get("symbol") or f.get("instId") or "").replace("_", "")
            if s != symbol:
                continue
            if order_id and str(f.get("orderId") or f.get("ordId") or "") != str(order_id):
                continue
            out.append({
                "orderId": str(f.get("orderId") or f.get("ordId") or ""),
                "tradeId": str(f.get("tradeId") or f.get("fillId") or f.get("execId") or ""),
                "price": _to_float(f.get("price", f.get("fillPx", 0))),
                "qty": _to_float(f.get("size", f.get("fillSz", 0))),
                "fee": _to_float(f.get("fee", f.get("fillFee", 0))),
                "ts": int(f.get("ts", f.get("time", 0))),
            })
        return {"success": True, "data": out}

    def cancel_order(self, symbol: str, order_id: str) -> Dict[str, Any]:
        raw = super().cancel_order(symbol=symbol, orderId=order_id) if hasattr(super(), "cancel_order") else {}
        ok = bool(raw.get("success", True)) if isinstance(raw, dict) else True
        return {"success": ok, "data": {"orderId": order_id}}

--------------------------------------------------------------------------------
FILE: scalper/adapters/bitget_fetch.py
--------------------------------------------------------------------------------
# scalper/adapters/bitget_fetch.py
from __future__ import annotations

import asyncio
import inspect
import os
from typing import Any, Optional

BT_DEBUG = int(os.getenv("BT_DEBUG", "0") or "0")

def _log(msg: str) -> None:
    if BT_DEBUG:
        print(f"[bt.debug] {msg}", flush=True)

_TF_TO_SECS = {
    "1m": 60, "3m": 180, "5m": 300, "15m": 900, "30m": 1800,
    "1h": 3600, "4h": 14400, "1d": 86400,
}
_TF_TO_MIX = {  # granularity pour mix (docs Bitget)
    "1m": "1min", "3m": "3min", "5m": "5min", "15m": "15min",
    "30m": "30min", "1h": "1h", "4h": "4h", "1d": "1day",
}
_TF_TO_SPOT = {  # period pour spot (docs Bitget)
    "1m": "1min", "3m": "3min", "5m": "5min", "15m": "15min",
    "30m": "30min", "1h": "1hour", "4h": "4hour", "1d": "1day",
}

def _await_if_needed(val: Any) -> Any:
    if inspect.isawaitable(val):
        try:
            asyncio.get_running_loop()
        except RuntimeError:
            return asyncio.run(val)
        else:
            fut = asyncio.run_coroutine_threadsafe(val, asyncio.get_running_loop())
            return fut.result()
    return val

class BitgetFetchAdapter:
    """
    Adaptateur qui fournit une méthode CCXT-like:
      fetch_ohlcv(symbol, timeframe='5m', since=None, limit=1000)
    au-dessus d'un client Bitget existant (sync ou async).
    """
    def __init__(self, client: Any, *, market_hint: str | None = None):
        self.client = client
        self.market_hint = (market_hint or "").lower() or None
        _log(f"BitgetFetchAdapter attaché sur {type(client).__name__} (market_hint={self.market_hint})")
        if hasattr(client, "fetch_ohlcv") and callable(getattr(client, "fetch_ohlcv")):
            _log("Client expose déjà fetch_ohlcv → adaptation inutile (utilisation directe).")

    @staticmethod
    def _possible_methods(client: Any) -> list[str]:
        names = dir(client)
        base = [
            "fetch_ohlcv",
            "get_candlesticks", "candlesticks", "get_candles", "candles",
            "klines", "get_klines", "kline",
            "mix_get_candles", "mix_candles",
            "spot_get_candles", "spot_candles",
            "market_candles", "public_candles",
        ]
        # + heuristique: tout ce qui contient candle/kline
        extra = [n for n in names if ("candle" in n.lower() or "kline" in n.lower()) and callable(getattr(client, n))]
        out = []
        for n in base + extra:
            if n in names and callable(getattr(client, n)) and n not in out:
                out.append(n)
        _log(f"Méthodes candidates détectées: {out or '(aucune)'}")
        return out

    @staticmethod
    def _sym_variants(sym: str) -> list[str]:
        s = sym.upper()
        out = [s]
        if not s.endswith("_UMCBL"):
            out.append(f"{s}_UMCBL")
        if not s.endswith("_SPBL"):
            out.append(f"{s}_SPBL")
        _log(f"Variantes symbole testées: {out}")
        return out

    @staticmethod
    def _param_variants(timeframe: str, market_hint: Optional[str]) -> list[dict]:
        secs = _TF_TO_SECS.get(timeframe, 300)
        mix = _TF_TO_MIX.get(timeframe, "5min")
        spot = _TF_TO_SPOT.get(timeframe, "5min")
        variants = []
        if market_hint == "mix":
            variants.append({"granularity": mix})
        if market_hint == "spot":
            variants.append({"period": spot})
        variants += [
            {"timeframe": timeframe},
            {"interval": timeframe},
            {"k": secs},
            {"granularity": mix},
            {"period": spot},
        ]
        _log(f"Variantes params testées pour tf={timeframe}: {variants}")
        return variants

    @staticmethod
    def _normalize_rows(raw: Any) -> list[list[float]]:
        import pandas as pd  # local import
        if raw is None:
            raise ValueError("OHLCV vide")
        if isinstance(raw, dict) and "data" in raw:
            raw = raw["data"]
        if isinstance(raw, (list, tuple)) and raw and isinstance(raw[0], (list, tuple)):
            out = []
            for r in raw:
                ts = int(str(r[0]))
                o, h, l, c, v = map(float, (r[1], r[2], r[3], r[4], r[5]))
                out.append([ts, o, h, l, c, v])
            return out
        if "pandas" in str(type(raw)):
            df = raw
            if "timestamp" in df.columns:
                df["timestamp"] = pd.to_datetime(df["timestamp"], utc=True, infer_datetime_format=True)
                df = df.set_index("timestamp").sort_index()
            df = df[["open", "high", "low", "close", "volume"]]
            return [[int(ts.value // 10**6), *map(float, row)] for ts, row in df.itertuples()]
        raise ValueError(f"Format OHLCV inattendu: {type(raw)}")

    def fetch_ohlcv(self, symbol: str, timeframe: str = "5m", since: Any | None = None, limit: int = 1000):
        methods = self._possible_methods(self.client)
        if not methods:
            raise AttributeError("Aucune méthode OHLCV trouvée sur le client Bitget")

        last_err: Exception | None = None
        for mname in methods:
            fn = getattr(self.client, mname)
            for sym in self._sym_variants(symbol):
                for par in self._param_variants(timeframe, self.market_hint):
                    kwargs = dict(par)
                    kwargs.setdefault("symbol", sym)
                    kwargs.setdefault("limit", limit)
                    if since is not None:
                        kwargs.setdefault("since", since)
                    try:
                        _log(f"→ Essai {mname}(kwargs={kwargs})")
                        res = _await_if_needed(fn(**kwargs))
                        rows = self._normalize_rows(res)
                        if rows:
                            unit = "ms" if rows and rows[0][0] > 10_000_000_000 else "s"
                            first = rows[0][0]; last = rows[-1][0]
                            _log(f"✓ OK via {mname} {sym} {par} | n={len(rows)} | "
                                 f"t0={first} {unit}, t1={last} {unit}")
                            return rows
                    except TypeError as e:
                        _log(f"TypeError {mname} {sym} {par}: {e}")
                        last_err = e
                    except Exception as e:
                        _log(f"Erreur {mname} {sym} {par}: {e}")
                        last_err = e
        raise last_err or RuntimeError("Impossible d'obtenir l'OHLCV via le client Bitget")

def ensure_bitget_fetch(exchange: Any, *, market_hint: str | None = None) -> Any:
    """Renvoie l'exchange si fetch_ohlcv existe, sinon un wrapper qui l’implémente. Log debug si BT_DEBUG=1."""
    if hasattr(exchange, "fetch_ohlcv") and callable(getattr(exchange, "fetch_ohlcv")):
        _log("exchange.fetch_ohlcv() déjà présent.")
        return exchange
    _log("exchange.fetch_ohlcv() absent → usage BitgetFetchAdapter.")
    return BitgetFetchAdapter(exchange, market_hint=market_hint)

--------------------------------------------------------------------------------
FILE: scalper/adapters/market_data.py
--------------------------------------------------------------------------------
# scalper/backtest/market_data.py
from __future__ import annotations

import os
from pathlib import Path
from typing import Any

import pandas as pd

BT_DEBUG = int(os.getenv("BT_DEBUG", "0") or "0")

def _log(msg: str) -> None:
    if BT_DEBUG:
        print(f"[bt.debug] {msg}", flush=True)

def _csv_path(data_dir: str | Path, symbol: str, timeframe: str) -> Path:
    root = Path(data_dir)
    root.mkdir(parents=True, exist_ok=True)
    tf = timeframe.replace(":", "")
    return root / f"{symbol}-{tf}.csv"

def _read_csv(path: Path) -> pd.DataFrame:
    _log(f"lecture CSV: {path}")
    df = pd.read_csv(path)
    ts_col = next((c for c in df.columns if c.lower() in ("ts", "timestamp", "time", "date")), None)
    if ts_col is None:
        raise ValueError("Colonne temps introuvable (timestamp/time/date)")
    df = df.rename(columns={ts_col: "timestamp"})
    df["timestamp"] = pd.to_datetime(df["timestamp"], utc=True, infer_datetime_format=True)
    df = df.set_index("timestamp").sort_index()
    _log(f"→ CSV ok, n={len(df)}, t0={df.index.min()}, t1={df.index.max()}")
    return df

def _write_csv(path: Path, df: pd.DataFrame) -> None:
    tmp = df.reset_index().rename(columns={"index": "timestamp"})
    if "timestamp" not in tmp.columns:
        tmp = tmp.rename(columns={"index": "timestamp"})
    tmp.to_csv(path, index=False)
    _log(f"écrit CSV: {path} (n={len(df)})")

def fetch_ohlcv_via_exchange(exchange: Any, symbol: str, timeframe: str, *, limit: int = 1000) -> pd.DataFrame:
    _log(f"fetch via exchange.fetch_ohlcv: symbol={symbol} tf={timeframe} limit={limit}")
    raw = exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=limit)  # peut être sync ou adapté
    # Normalisation minimaliste (liste de listes)
    rows = []
    for r in raw:
        ts = int(r[0])
        unit = "ms" if ts > 10_000_000_000 else "s"
        ts = pd.to_datetime(ts, unit=unit, utc=True)
        rows.append([ts, float(r[1]), float(r[2]), float(r[3]), float(r[4]), float(r[5])])
    df = pd.DataFrame(rows, columns=["timestamp", "open", "high", "low", "close", "volume"]).set_index("timestamp").sort_index()
    _log(f"→ exchange ok, n={len(df)}, t0={df.index.min()}, t1={df.index.max()}")
    return df

def hybrid_loader_from_exchange(exchange: Any, data_dir: str = "data", *, api_limit: int = 1000):
    """
    Loader hybride:
      1) lit data/<SYMBOL>-<TF>.csv si présent,
      2) sinon fetch via exchange.fetch_ohlcv, puis écrit le CSV en cache.
    """
    def load(symbol: str, timeframe: str, start: str | None, end: str | None) -> pd.DataFrame:
        path = _csv_path(data_dir, symbol, timeframe)
        if path.exists():
            df = _read_csv(path)
            src = "csv"
        else:
            df = fetch_ohlcv_via_exchange(exchange, symbol, timeframe, limit=api_limit)
            _write_csv(path, df)
            src = "exchange"
        if start:
            df = df.loc[pd.Timestamp(start, tz="UTC") :]
        if end:
            df = df.loc[: pd.Timestamp(end, tz="UTC")]
        _log(f"loader -> {symbol} {timeframe} (src={src}) n={len(df)} "
             f"range=[{df.index.min()} .. {df.index.max()}]")
        return df
    return load

--------------------------------------------------------------------------------
FILE: scalper/backtest/__init__.py
--------------------------------------------------------------------------------
# scalper/backtest/__init__.py
from .runner import (
    BTCfg, BTConfig,        # BTConfig = alias rétro-compat
    run_multi, run_single,  # mêmes signatures async
    save_results,           # no-op compat
)
from .cache import (
    ensure_csv_cache, csv_path, read_csv_ohlcv, dump_validation_report,
    tf_to_seconds,
)

--------------------------------------------------------------------------------
FILE: scalper/backtest/cache.py
--------------------------------------------------------------------------------
# scalper/backtest/cache.py
from __future__ import annotations

import csv
import json
import os
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Tuple, Iterable, Optional

# ---------------- Timeframe utils ----------------

_TF_SECONDS = {
    "1m": 60, "3m": 180, "5m": 300, "15m": 900, "30m": 1800,
    "1h": 3600, "2h": 7200, "4h": 14400, "6h": 21600, "12h": 43200,
    "1d": 86400, "3d": 259200, "1w": 604800,
}

def tf_to_seconds(tf: str) -> int:
    tf = tf.strip().lower()
    if tf not in _TF_SECONDS:
        raise ValueError(f"Timeframe inconnu: {tf}")
    return _TF_SECONDS[tf]

# ---------------- Fraîcheur cible par TF ----------------

_DEFAULT_MAX_AGE = {
    # règle empirique (peut être surchargée par ENV)
    "1m": 2 * 3600,        # 2h
    "3m": 4 * 3600,        # 4h
    "5m": 12 * 3600,       # 12h
    "15m": 24 * 3600,      # 24h
    "30m": 36 * 3600,      # 36h
    "1h": 3 * 86400,       # 3 jours
    "2h": 5 * 86400,       # 5 jours
    "4h": 10 * 86400,      # 10 jours
    "6h": 15 * 86400,      # 15 jours
    "12h": 20 * 86400,     # 20 jours
    "1d": 3 * 86400,       # 3 jours (ok si 2 jours comme tu voulais)
    "3d": 10 * 86400,
    "1w": 30 * 86400,
}

def max_age_for_tf(tf: str) -> int:
    """Autorise override ENV via BACKTEST_MAX_AGE_<TF> (en secondes)."""
    tf = tf.lower()
    env_key = f"BACKTEST_MAX_AGE_{tf.replace('m','M').replace('h','H').replace('d','D').replace('w','W')}"
    if env_key in os.environ:
        try:
            return int(os.environ[env_key])
        except Exception:
            pass
    return _DEFAULT_MAX_AGE.get(tf, 7 * 86400)

# ---------------- CSV I/O ----------------

def data_dir() -> Path:
    d = Path(os.getenv("DATA_DIR", "data"))
    d.mkdir(parents=True, exist_ok=True)
    return d

def csv_path(symbol: str, tf: str) -> Path:
    return data_dir() / f"{symbol.upper()}-{tf}.csv"

def read_csv_ohlcv(path: Path) -> List[List[float]]:
    out: List[List[float]] = []
    if not path.exists():
        return out
    with path.open("r", newline="") as f:
        r = csv.reader(f)
        header = next(r, None)
        for row in r:
            # columns: timestamp,open,high,low,close,volume
            try:
                ts, o, h, l, c, v = row[:6]
                out.append([int(ts), float(o), float(h), float(l), float(c), float(v)])
            except Exception:
                continue
    return out

def write_csv_ohlcv(path: Path, rows: Iterable[Iterable[float]]) -> None:
    new_file = not path.exists()
    with path.open("w", newline="") as f:
        w = csv.writer(f)
        w.writerow(["timestamp","open","high","low","close","volume"])
        for r in rows:
            w.writerow(r)

# ---------------- Validation / Chargement / Fetch ----------------

@dataclass
class CacheInfo:
    symbol: str
    tf: str
    path: Path
    exists: bool
    fresh: bool
    last_ts: Optional[int] = None
    rows: int = 0

def _is_fresh(last_ts: Optional[int], tf: str) -> bool:
    if not last_ts:
        return False
    age = int(time.time()) - int(last_ts / 1000)
    return age <= max_age_for_tf(tf)

def inspect_csv(symbol: str, tf: str) -> CacheInfo:
    p = csv_path(symbol, tf)
    if not p.exists():
        return CacheInfo(symbol, tf, p, exists=False, fresh=False)
    rows = read_csv_ohlcv(p)
    last_ts = rows[-1][0] if rows else None
    return CacheInfo(symbol, tf, p, exists=True, fresh=_is_fresh(last_ts, tf), last_ts=last_ts, rows=len(rows))

async def fetch_ohlcv_via_exchange(exchange, symbol: str, tf: str, limit: int) -> List[List[float]]:
    # exchange: objet CCXT-like fourni par le live (déjà configuré Bitget)
    return await exchange.fetch_ohlcv(symbol=symbol, timeframe=tf, limit=limit)

async def ensure_csv_for_symbol(exchange, symbol: str, tf: str, limit: int) -> Tuple[CacheInfo, List[List[float]]]:
    info = inspect_csv(symbol, tf)
    if info.exists and info.fresh:
        data = read_csv_ohlcv(info.path)
        return info, data

    # fetch & persist
    data = await fetch_ohlcv_via_exchange(exchange, symbol, tf, limit=limit)
    if data:
        write_csv_ohlcv(info.path, data)
        info = inspect_csv(symbol, tf)  # refresh stats
    return info, data

async def ensure_csv_cache(exchange, symbols: List[str], tf: str, limit: int) -> Dict[str, List[List[float]]]:
    """Vérifie le cache CSV et (re)charge depuis l'exchange si nécessaire."""
    out: Dict[str, List[List[float]]] = {}
    for s in symbols:
        info, rows = await ensure_csv_for_symbol(exchange, s, tf, limit)
        out[s] = rows
    return out

def dump_validation_report(symbols: List[str], tf: str, out_path: Path) -> None:
    report = []
    for s in symbols:
        info = inspect_csv(s, tf)
        report.append({
            "symbol": s,
            "tf": tf,
            "path": str(info.path),
            "exists": info.exists,
            "fresh": info.fresh,
            "last_ts": info.last_ts,
            "rows": info.rows,
            "max_age": max_age_for_tf(tf),
        })
    out_path.parent.mkdir(parents=True, exist_ok=True)
    out_path.write_text(json.dumps(report, indent=2))

--------------------------------------------------------------------------------
FILE: scalper/backtest/cli.py
--------------------------------------------------------------------------------
from __future__ import annotations

import argparse
from scalper.backtest.runner import run_multi, csv_loader_factory

def create_parser() -> argparse.ArgumentParser:
    p = argparse.ArgumentParser(prog="backtest", description="Backtest multi symboles / multi timeframes")
    p.add_argument("--symbols", required=True, help="Liste, ex: BTCUSDT,ETHUSDT,SOLUSDT")
    p.add_argument("--timeframes", required=True, help="Liste, ex: 1m,5m,15m")
    p.add_argument("--data-dir", default="data", help="Répertoire CSV OHLCV")
    p.add_argument("--out-dir", default="result", help="Répertoire de sortie")
    p.add_argument("--cash", type=float, default=10_000.0)
    p.add_argument("--risk", type=float, default=0.005, help="risk_pct par trade (0.005 = 0.5%)")
    p.add_argument("--slippage-bps", type=float, default=1.5)
    return p

def main(argv: list[str] | None = None) -> int:
    p = create_parser()
    a = p.parse_args(argv)
    symbols = [s.strip().upper() for s in a.symbols.split(",") if s.strip()]
    tfs = [t.strip() for t in a.timeframes.split(",") if t.strip()]
    loader = csv_loader_factory(a.data_dir)
    run_multi(
        symbols=symbols,
        timeframes=tfs,
        loader=loader,
        out_dir=a.out_dir,
        initial_cash=a.cash,
        risk_pct=a.risk,
        slippage_bps=a.slippage_bps,
    )
    print(f"✅ Backtests terminés → {a.out_dir}/ (equity_curve/trades/fills/metrics/summary)")
    return 0

if __name__ == "__main__":
    raise SystemExit(main())

--------------------------------------------------------------------------------
FILE: scalper/backtest/engine.py
--------------------------------------------------------------------------------
# scalper/backtest/engine.py
from __future__ import annotations
from typing import Any, Dict, List, Optional, Tuple
import csv
import os
from dataclasses import dataclass
from scalper.strategy.factory import resolve_signal_fn
from scalper.core.signal import Signal
from scalper.backtest.position_sizing import position_size_from_signal, fees_cost

@dataclass
class Trade:
    symbol: str
    timeframe: str
    side: str
    entry_ts: int
    exit_ts: int
    entry: float
    exit: float
    qty: float
    pnl: float
    pnl_after_fees: float
    reasons: str

def _read_csv(path: str) -> Dict[str, List[float]]:
    cols = ("timestamp","open","high","low","close","volume")
    out = {k: [] for k in cols}
    with open(path, "r", newline="", encoding="utf-8") as f:
        r = csv.DictReader(f)
        for row in r:
            for k in cols:
                out[k].append(float(row[k]))
    return out

def _slice(d: Dict[str, List[float]], end_idx: int) -> Dict[str, List[float]]:
    return {k: v[: end_idx + 1] for k, v in d.items()}

class BacktestEngine:
    def __init__(
        self,
        *,
        symbol: str,
        timeframe: str,
        data: Dict[str, List[float]],
        equity_start: float = 1_000.0,
        risk_pct: float = 0.01,
        fees_bps: float = 6.0,
        warmup: int = 230,
        strategies_cfg: Dict[str, Any],
        data_1h: Optional[Dict[str, List[float]]] = None,
    ):
        self.symbol = symbol.upper()
        self.tf = timeframe
        self.data = data
        self.data_1h = data_1h
        self.equity = float(equity_start)
        self.start_equity = float(equity_start)
        self.risk_pct = float(risk_pct)
        self.fees_bps = float(fees_bps)
        self.warmup = int(warmup)
        self.cfg = strategies_cfg
        self.trades: List[Trade] = []
        self.signals_rows: List[Dict[str, Any]] = []
        self.signal_fn = resolve_signal_fn(self.symbol, self.tf, self.cfg)

    def run(self) -> Tuple[float, List[Trade]]:
        n = len(self.data["close"])
        pos_open: Optional[Signal] = None
        pos_qty: float = 0.0
        entry_idx: int = -1

        for i in range(self.warmup, n):
            window = _slice(self.data, i)
            window_1h = _slice(self.data_1h, self._map_1h_index(i)) if self.data_1h else None

            sig = self.signal_fn(
                symbol=self.symbol, timeframe=self.tf, ohlcv=window,
                equity=self.equity, risk_pct=self.risk_pct, ohlcv_1h=window_1h,
            )
            if sig:
                self.signals_rows.append(sig.as_dict())

            if pos_open is None and sig is not None:
                qty = position_size_from_signal(self.equity, sig, self.risk_pct * max(0.25, sig.quality))
                if qty <= 0:
                    continue
                pos_open, pos_qty, entry_idx = sig, qty, i
                continue

            if pos_open is not None:
                hi = self.data["high"][i]
                lo = self.data["low"][i]
                exit_price: Optional[float] = None
                tp1 = pos_open.tp1 or pos_open.entry
                tp2 = pos_open.tp2 or pos_open.entry
                half_closed = False
                be = pos_open.entry

                if pos_open.side == "long":
                    if lo <= pos_open.sl:
                        exit_price = pos_open.sl
                    elif hi >= tp1:
                        pnl_half = (tp1 - pos_open.entry) * (pos_qty * 0.5)
                        fees = fees_cost(tp1 * (pos_qty * 0.5), self.fees_bps)
                        self.equity += pnl_half - fees
                        pos_qty *= 0.5
                        half_closed = True
                        pos_open.sl = be
                    if hi >= tp2:
                        exit_price = tp2
                else:
                    if hi >= pos_open.sl:
                        exit_price = pos_open.sl
                    elif lo <= tp1:
                        pnl_half = (pos_open.entry - tp1) * (pos_qty * 0.5)
                        fees = fees_cost(tp1 * (pos_qty * 0.5), self.fees_bps)
                        self.equity += pnl_half - fees
                        pos_qty *= 0.5
                        half_closed = True
                        pos_open.sl = be
                    if lo <= tp2:
                        exit_price = tp2

                if exit_price is None and half_closed:
                    continue

                if exit_price is not None:
                    pnl = (exit_price - pos_open.entry) * pos_qty if pos_open.side == "long" else (pos_open.entry - exit_price) * pos_qty
                    fees = fees_cost(exit_price * pos_qty, self.fees_bps)
                    pnl_after = pnl - fees
                    self.equity += pnl_after

                    tr = Trade(
                        symbol=self.symbol, timeframe=self.tf, side=pos_open.side,
                        entry_ts=int(self.data["timestamp"][entry_idx]), exit_ts=int(self.data["timestamp"][i]),
                        entry=pos_open.entry, exit=exit_price, qty=pos_qty,
                        pnl=pnl, pnl_after_fees=pnl_after, reasons="|".join(pos_open.reasons),
                    )
                    self.trades.append(tr)
                    pos_open, pos_qty, entry_idx = None, 0.0, -1

        return self.equity, self.trades

    def _map_1h_index(self, i_main: int) -> int:
        if not self.data_1h:
            return 0
        ts = self.data["timestamp"][i_main]
        arr = self.data_1h["timestamp"]
        j = 0
        while j + 1 < len(arr) and arr[j + 1] <= ts:
            j += 1
        return j

    # --- E/S helpers ---
    @staticmethod
    def load_csv(path: str) -> Dict[str, List[float]]:
        if not os.path.isfile(path):
            raise FileNotFoundError(f"CSV OHLCV introuvable: {path}")
        return _read_csv(path)

    def save_results(self, out_dir: str = "backtest_out") -> None:
        os.makedirs(out_dir, exist_ok=True)
        if self.signals_rows:
            sig_path = os.path.join(out_dir, f"signals_{self.symbol}_{self.tf}.csv")
            keys = sorted(self.signals_rows[0].keys())
            with open(sig_path, "w", newline="", encoding="utf-8") as f:
                import csv
                w = csv.DictWriter(f, fieldnames=keys)
                w.writeheader()
                for row in self.signals_rows:
                    w.writerow(row)
        if self.trades:
            tr_path = os.path.join(out_dir, f"trades_{self.symbol}_{self.tf}.csv")
            with open(tr_path, "w", newline="", encoding="utf-8") as f:
                import csv
                w = csv.writer(f)
                w.writerow(["symbol","timeframe","side","entry_ts","exit_ts","entry","exit","qty","pnl","pnl_after_fees","reasons"])
                for t in self.trades:
                    w.writerow([t.symbol,t.timeframe,t.side,t.entry_ts,t.exit_ts,t.entry,t.exit,t.qty,t.pnl,t.pnl_after_fees,t.reasons])

    def summary(self) -> Dict[str, float]:
        eq = self.equity
        ret = (eq / self.start_equity - 1.0) * 100.0
        n = len(self.trades)
        wins = sum(1 for t in self.trades if t.pnl_after_fees > 0)
        winrate = (wins / n * 100.0) if n else 0.0
        return {"equity_end": eq, "return_pct": ret, "trades": float(n), "winrate_pct": winrate}

--------------------------------------------------------------------------------
FILE: scalper/backtest/grid_search.py
--------------------------------------------------------------------------------
"""Grid-search express module to evaluate hyperparameter combinations.

This module builds combinations of strategy and engine parameters, runs the
existing multi symbol backtester for each combination, collects key metrics and
selects the best configuration according to:

1. Profit factor (descending)
2. Maximum drawdown percentage (ascending)
3. Net PnL in USDT (descending)
4. Number of trades (ascending)

Results are written under ``result/grid`` by default and a short summary is
printed to the console.
"""
from __future__ import annotations

from dataclasses import dataclass
import csv
import json
import os
import random
from itertools import product
from typing import Any, Callable, Dict, Iterable, List, Sequence

# ---------------------------------------------------------------------------
# Utilities
# ---------------------------------------------------------------------------


def parse_hours(hours: str) -> List[int]:
    """Parse hours specification like ``"7-11,13-17"`` into a list of ints.

    Each comma separated element can either be a single hour (``"8"``) or a
    range ``"7-11"`` which is inclusive.  Returned hours are sorted and unique.
    """

    if not hours:
        return []
    result: List[int] = []
    for part in hours.split(","):
        part = part.strip()
        if not part:
            continue
        if "-" in part:
            start_s, end_s = part.split("-", 1)
            start, end = int(start_s), int(end_s)
            result.extend(range(start, end + 1))
        else:
            result.append(int(part))
    return sorted(set(result))


# Order of parameters used throughout the module and in CSV output
PARAM_KEYS = [
    "timeframe",
    "score_min",
    "atr_min_ratio",
    "rr_min",
    "risk_pct",
    "slippage_bps",
    "fee_rate",
    "cooldown_secs",
    "hours",
]

# Default values used if a parameter is not provided in the grid
DEFAULTS = {
    "score_min": 55,
    "atr_min_ratio": 0.002,
    "rr_min": 1.2,
    "risk_pct": 0.01,
    "slippage_bps": 2,
    "fee_rate": 0.001,
    "cooldown_secs": 300,
    "hours": "7-11,13-17",
}


@dataclass
class GridResult:
    params: Dict[str, Any]
    metrics: Dict[str, float]


def _ensure_list(val: Sequence[Any] | Any) -> List[Any]:
    if isinstance(val, (list, tuple, set)):
        return list(val)
    return [val]


def build_param_grid(param_lists: Dict[str, Sequence[Any]], grid_max: int) -> List[Dict[str, Any]]:
    """Return a list of parameter combinations.

    ``param_lists`` maps parameter names to a sequence of values.  Missing keys
    fall back to ``DEFAULTS``.  The resulting cartesian product is uniformly
    sampled to ``grid_max`` elements when necessary while trying to maintain a
    variety of timeframes and ``atr_min_ratio`` values.
    """

    lists: Dict[str, List[Any]] = {}
    for key in PARAM_KEYS:
        if key == "timeframe":
            # timeframe must be explicitly provided; default empty -> "1m"
            vals = param_lists.get(key) or ["1m"]
        else:
            vals = param_lists.get(key)
            if not vals:
                default = DEFAULTS[key]
                vals = [default]
        lists[key] = _ensure_list(vals)

    combos: List[Dict[str, Any]] = [
        dict(zip(PARAM_KEYS, values)) for values in product(*(lists[k] for k in PARAM_KEYS))
    ]

    # Uniform sampling if exceeding grid_max
    if len(combos) > grid_max:
        step = len(combos) / float(grid_max)
        sampled = []
        for i in range(grid_max):
            idx = int(round(i * step))
            if idx >= len(combos):
                idx = len(combos) - 1
            sampled.append(combos[idx])
        # ensure each timeframe appears at least once
        wanted_tfs = set(lists["timeframe"])
        present_tfs = {c["timeframe"] for c in sampled}
        missing = list(wanted_tfs - present_tfs)
        if missing:
            for tf in missing:
                for c in combos:
                    if c["timeframe"] == tf and c not in sampled:
                        sampled.append(c)
                        break
            sampled = sampled[:grid_max]
        combos = sampled
    return combos


# ---------------------------------------------------------------------------
# Core runner
# ---------------------------------------------------------------------------


def run_grid_search(
    *,
    symbols: Sequence[str],
    exchange: str,
    base_params: Dict[str, Any],
    param_lists: Dict[str, Sequence[Any]],
    grid_max: int = 12,
    csv_dir: str | None = None,
    initial_equity: float = 1000.0,
    leverage: float = 1.0,
    paper_constraints: bool = True,
    seed: int | None = None,
    out_dir: str = "./result/grid",
    match_exchange_semantics: bool = False,  # placeholder for compatibility
    run_func: Callable[..., Any] | None = None,
) -> List[GridResult]:
    """Execute grid search across parameter combinations.

    ``base_params`` provides default single values for parameters. ``param_lists``
    contains the grid specifications from CLI (already parsed into sequences).
    ``run_func`` should have the same signature as :func:`run_backtest_multi`.
    """

    if seed is not None:
        random.seed(seed)

    if run_func is None:  # avoid circular import at module load
        from .run_multi import run_backtest_multi  # late import

        run_func = run_backtest_multi

    # merge lists with defaults
    full_lists: Dict[str, Sequence[Any]] = {}
    for k in PARAM_KEYS:
        if k == "timeframe":
            full_lists[k] = param_lists.get(k) or [base_params.get("timeframe", "1m")]
        else:
            if param_lists.get(k) is not None:
                full_lists[k] = param_lists[k]
            else:
                full_lists[k] = [base_params.get(k, DEFAULTS[k])]

    combos = build_param_grid(full_lists, grid_max)

    results: List[GridResult] = []
    os.makedirs(out_dir, exist_ok=True)

    for combo in combos:
        # Build parameters for backtester
        tf = combo["timeframe"]
        fee = float(combo["fee_rate"])
        slip = float(combo["slippage_bps"])
        risk = float(combo["risk_pct"])

        summary, _trades = run_func(
            symbols=list(symbols),
            exchange=exchange,
            timeframe=tf,
            csv_dir=csv_dir,
            fee_rate=fee,
            slippage_bps=slip,
            risk_pct=risk,
            initial_equity=initial_equity,
            leverage=leverage,
            paper_constraints=paper_constraints,
            seed=seed,
            out_dir=os.path.join(out_dir, "tmp"),
            plot=False,
            dry_run=True,
        )
        total = next((r for r in summary if r.get("symbol") == "TOTAL"), summary[-1])
        metrics = {
            "pnl_usdt": float(total.get("pnl_usdt", 0.0)),
            "profit_factor": float(total.get("profit_factor", 0.0)),
            "max_dd_pct": float(total.get("max_drawdown_pct", 0.0)),
            "winrate_pct": float(total.get("winrate_pct", 0.0)),
            "trades": float(total.get("trades", 0.0)),
            "final_equity": initial_equity + float(total.get("pnl_usdt", 0.0)),
        }
        results.append(GridResult(params=combo, metrics=metrics))

    # sort results
    results.sort(
        key=lambda r: (
            -r.metrics["profit_factor"],
            r.metrics["max_dd_pct"],
            -r.metrics["pnl_usdt"],
            r.metrics["trades"],
        )
    )

    # console output -------------------------------------------------------
    print(
        f"Grid-search express ({len(results)} combinaisons testées, top trié par PF↓ puis MaxDD%↑)"
    )
    header = (
        f"{'timeframe':<8} {'PF':>6} {'MaxDD%':>8} {'PnL':>8} {'Trades':>8}"
    )
    print(header)
    for r in results[:10]:
        m = r.metrics
        print(
            f"{r.params['timeframe']:<8} {m['profit_factor']:>6.2f} {m['max_dd_pct']:>8.2f} {m['pnl_usdt']:>8.2f} {int(m['trades']):>8}"
        )

    # write csv ------------------------------------------------------------
    csv_cols = PARAM_KEYS + [
        "pnl_usdt",
        "profit_factor",
        "max_dd_pct",
        "winrate_pct",
        "trades",
        "final_equity",
    ]
    with open(os.path.join(out_dir, "grid_results.csv"), "w", newline="") as fh:
        writer = csv.DictWriter(fh, fieldnames=csv_cols)
        writer.writeheader()
        for r in results:
            row = {**r.params, **r.metrics}
            writer.writerow(row)

    best = results[0]
    with open(os.path.join(out_dir, "best_config.json"), "w", encoding="utf8") as fh:
        json.dump({"params": best.params, "metrics": best.metrics}, fh, indent=2)

    # markdown summary -----------------------------------------------------
    md_path = os.path.join(out_dir, "grid_summary.md")
    with open(md_path, "w", encoding="utf8") as fh:
        fh.write(
            "| timeframe | PF | MaxDD% | PnL | trades |\n|---|---|---|---|---|\n"
        )
        for r in results[:10]:
            m = r.metrics
            fh.write(
                f"| {r.params['timeframe']} | {m['profit_factor']:.2f} | {m['max_dd_pct']:.2f} | {m['pnl_usdt']:.2f} | {int(m['trades'])} |\n"
            )

    # optional scatter plot ------------------------------------------------
    try:  # pragma: no cover - optional dependency
        import matplotlib.pyplot as plt

        pf = [r.metrics["profit_factor"] for r in results]
        dd = [r.metrics["max_dd_pct"] for r in results]
        trades = [r.metrics["trades"] for r in results]
        tfs = [r.params["timeframe"] for r in results]
        colors = {tf: i for i, tf in enumerate(sorted(set(tfs)))}
        c = [colors[tf] for tf in tfs]
        plt.figure(figsize=(6, 4))
        plt.scatter(dd, pf, c=c, s=[max(10, t) for t in trades], alpha=0.7)
        plt.xlabel("MaxDD%")
        plt.ylabel("Profit Factor")
        plt.title("PF vs MaxDD")
        plt.savefig(os.path.join(out_dir, "pf_vs_dd.png"))
        plt.close()
    except Exception:  # pragma: no cover
        pass

    return results


__all__ = ["run_grid_search", "build_param_grid", "parse_hours", "GridResult"]


--------------------------------------------------------------------------------
FILE: scalper/backtest/loader_csv.py
--------------------------------------------------------------------------------
# scalper/backtest/loader_csv.py
from __future__ import annotations

import csv
from typing import Dict, List

from scalper.services.data_cache import csv_path

# Format de sortie : liste de bougies [ts, open, high, low, close, volume]
def load_ohlcv_csv(symbol: str, timeframe: str) -> List[List[float]]:
    path = csv_path(symbol, timeframe)
    rows: List[List[float]] = []
    with open(path, "r") as f:
        r = csv.DictReader(f)
        for row in r:
            rows.append([
                int(row["timestamp"]),
                float(row["open"]),
                float(row["high"]),
                float(row["low"]),
                float(row["close"]),
                float(row["volume"]),
            ])
    rows.sort(key=lambda x: x[0])
    return rows


def load_many(symbols: List[str], timeframe: str) -> Dict[str, List[List[float]]]:
    out: Dict[str, List[List[float]]] = {}
    for s in symbols:
        out[s] = load_ohlcv_csv(s, timeframe)
    return out

--------------------------------------------------------------------------------
FILE: scalper/backtest/market_data.py
--------------------------------------------------------------------------------
from __future__ import annotations

import json
import os
import time
from pathlib import Path
from typing import Any, Iterable, Optional, Sequence, Tuple
from urllib.request import Request, urlopen
from urllib.error import URLError, HTTPError

import pandas as pd

# ============================================================================
# Logs & utilitaires
# ============================================================================
BT_DEBUG = int(os.getenv("BT_DEBUG", "0") or "0")
def _log(msg: str) -> None:
    if BT_DEBUG:
        print(f"[bt.debug] {msg}", flush=True)

def _now_ms() -> int:
    return int(time.time() * 1000)

def _tf_to_seconds(tf: str) -> int:
    tf = tf.lower().strip()
    table = {"1m":60,"3m":180,"5m":300,"15m":900,"30m":1800,"1h":3600,"4h":14400,"1d":86400}
    if tf not in table:
        raise ValueError(f"Timeframe non supporté: {tf}")
    return table[tf]

def _parse_duration(s: str) -> int:
    """
    '90s','15m','2h','3d' -> secondes
    """
    s = s.strip().lower()
    if s.endswith("s"): return int(float(s[:-1]))
    if s.endswith("m"): return int(float(s[:-1])*60)
    if s.endswith("h"): return int(float(s[:-1])*3600)
    if s.endswith("d"): return int(float(s[:-1])*86400)
    return int(float(s))  # secondes

# ============================================================================
# Politique de fraîcheur (par défaut + overrides via ENV)
# ============================================================================
def _default_max_age_seconds(tf: str) -> int:
    """
    Règles par défaut (conservatrices) :
      - 1m..15m : 2 × TF  (ex: 5m -> 10m)
      - 30m     : 1h
      - 1h      : 6h
      - 4h      : 24h
      - 1d      : 3d
    """
    tf = tf.lower()
    if tf in ("1m","3m","5m","15m"):
        return 2 * _tf_to_seconds(tf)
    if tf == "30m":
        return 3600
    if tf == "1h":
        return 6*3600
    if tf == "4h":
        return 24*3600
    if tf == "1d":
        return 3*86400
    raise ValueError(tf)

def _max_age_seconds(tf: str) -> int:
    """
    Overrides possibles (au choix) :
      - CSV_MAX_AGE_MULT=NN → NN × TF  (ex: 50 pour 1m => 50 minutes)
      - CSV_MAX_AGE_5m="45m" (prioritaire si présent)
      - CSV_MAX_AGE_DEFAULT="2h" (fallback global)
    """
    tfk = tf.lower().replace(":", "")
    env_spec = os.getenv(f"CSV_MAX_AGE_{tfk}")
    if env_spec:
        return _parse_duration(env_spec)
    mult = os.getenv("CSV_MAX_AGE_MULT")
    if mult:
        return int(float(mult) * _tf_to_seconds(tf))
    g = os.getenv("CSV_MAX_AGE_DEFAULT")
    if g:
        return _parse_duration(g)
    return _default_max_age_seconds(tf)

# ============================================================================
# CSV helpers + validation
# ============================================================================
def _data_dir(default: str = "data") -> Path:
    root = Path(os.getenv("DATA_DIR", default))
    root.mkdir(parents=True, exist_ok=True)
    return root

def _csv_path(symbol: str, timeframe: str) -> Path:
    tf = timeframe.replace(":", "")
    return _data_dir() / f"{symbol}-{tf}.csv"

def _rows_to_df(rows: Iterable[Iterable[float]]) -> pd.DataFrame:
    rows = list(rows)
    if not rows:
        raise ValueError("OHLCV vide")
    unit = "ms" if rows[0][0] > 10_000_000_000 else "s"
    df = pd.DataFrame(rows, columns=["ts","open","high","low","close","volume"])
    df["timestamp"] = pd.to_datetime(df["ts"], unit=unit, utc=True)
    return df.drop(columns=["ts"]).set_index("timestamp").sort_index()

def _read_csv(path: Path) -> pd.DataFrame:
    df = pd.read_csv(path)
    # tolère quelques variations de colonnes
    cols = {c.lower(): c for c in df.columns}
    ts_col = cols.get("timestamp") or cols.get("time") or cols.get("date") or cols.get("ts")
    if not ts_col:
        raise ValueError("Colonne temps absente (timestamp/time/date/ts)")
    rename = {ts_col: "timestamp"}
    for c in ("open","high","low","close","volume"):
        if c not in cols:
            raise ValueError(f"Colonne manquante: {c}")
        rename[cols[c]] = c
    df = df.rename(columns=rename)
    df["timestamp"] = pd.to_datetime(df["timestamp"], utc=True, infer_datetime_format=True)
    df = df[["timestamp","open","high","low","close","volume"]].sort_values("timestamp")
    df = df.drop_duplicates("timestamp")
    df = df.set_index("timestamp")
    return df

def _write_csv(path: Path, df: pd.DataFrame) -> None:
    out = df.reset_index().rename(columns={"index": "timestamp"})
    out.to_csv(path, index=False)

def _is_csv_fresh_and_valid(path: Path, timeframe: str, *, min_rows: int = 100) -> Tuple[bool, str]:
    """
    Retourne (ok, reason). ok=True si le CSV est utilisable:
      - schéma valide
      - assez de lignes
      - fraîcheur < seuil selon TF
    """
    if not path.exists():
        return False, "absent"
    try:
        df = _read_csv(path)
    except Exception as e:
        return False, f"invalid({e})"
    if len(df) < min_rows:
        return False, f"too_few_rows({len(df)}<{min_rows})"
    # Fraîcheur
    last_ts = int(df.index.max().timestamp())
    age_s = int(time.time()) - last_ts
    max_age = _max_age_seconds(timeframe)
    if age_s > max_age:
        return False, f"stale({age_s}s>{max_age}s)"
    # Monotonicité (échantillon)
    if not df.index.is_monotonic_increasing:
        return False, "not_monotonic"
    return True, "ok"

# ============================================================================
# Fallback réseau (CCXT d'abord, HTTP sinon)
# ============================================================================
def _ensure_ccxt() -> Any | None:
    try:
        import ccxt  # type: ignore
        return ccxt
    except Exception:
        return None

def _fetch_via_ccxt(symbol: str, timeframe: str, limit: int = 1000) -> Optional[pd.DataFrame]:
    ccxt = _ensure_ccxt()
    if not ccxt:
        _log("ccxt indisponible")
        return None
    ex = ccxt.bitget({"enableRateLimit": True, "options": {"defaultType": "swap"}})
    ex.load_markets()
    base = symbol.upper()
    if not base.endswith("USDT"):
        raise ValueError("symbol doit finir par USDT (ex: BTCUSDT)")
    coin = base[:-4]
    candidates = [f"{coin}/USDT:USDT", f"{coin}/USDT"]  # perp puis spot
    for ccxt_sym in candidates:
        try:
            rows = ex.fetch_ohlcv(ccxt_sym, timeframe=timeframe, limit=limit)
            if rows:
                return _rows_to_df(sorted(rows, key=lambda r: r[0]))
        except Exception as e:
            _log(f"ccxt fail {ccxt_sym}: {e}")
            continue
    return None

# === (facultatif) HTTP Bitget v1 minimal ===
_GRAN_MIX = {"1m":"1min","3m":"3min","5m":"5min","15m":"15min","30m":"30min","1h":"1h","4h":"4h","1d":"1day"}
_PERIOD_SPOT = {"1m":"1min","3m":"3min","5m":"5min","15m":"15min","30m":"30min","1h":"1hour","4h":"4hour","1d":"1day"}

def _http_get(url: str, timeout: int = 20) -> dict | list:
    req = Request(url, headers={"User-Agent":"backtest-marketdata/1.0"})
    with urlopen(req, timeout=timeout) as resp:
        return json.loads(resp.read().decode("utf-8"))

def _normalize_http_rows(payload: dict | list) -> list[list[float]]:
    rows = payload.get("data") if isinstance(payload, dict) else payload
    if not isinstance(rows, list):
        raise ValueError(f"Réponse inattendue: {payload}")
    out = []
    for r in rows:
        ts = int(str(r[0])); o,h,l,c,v = map(float,(r[1],r[2],r[3],r[4],r[5]))
        out.append([ts,o,h,l,c,v])
    out.sort(key=lambda x:x[0])
    return out

def _fetch_via_http(symbol: str, timeframe: str, limit: int = 1000) -> Optional[pd.DataFrame]:
    tf = timeframe.lower()
    g = _GRAN_MIX.get(tf); p = _PERIOD_SPOT.get(tf)
    if not (g and p):
        return None
    # mix umcbl puis spot spbl, paramètres minimum (v1)
    trials = [
        f"https://api.bitget.com/api/mix/v1/market/candles?symbol={symbol}_UMCBL&granularity={g}&limit={limit}",
        f"https://api/bitget.com/api/mix/v1/market/candles?symbol={symbol}&granularity={g}&limit={limit}",
        f"https://api.bitget.com/api/spot/v1/market/candles?symbol={symbol}_SPBL&period={p}&limit={limit}",
        f"https://api.bitget.com/api/spot/v1/market/candles?symbol={symbol}&period={p}&limit={limit}",
    ]
    for url in trials:
        try:
            payload = _http_get(url)
            if isinstance(payload, dict) and "code" in payload and str(payload["code"]) != "00000" and "data" not in payload:
                raise RuntimeError(f"Bitget error {payload.get('code')}: {payload.get('msg')}")
            rows = _normalize_http_rows(payload)
            if rows:
                return _rows_to_df(rows)
        except Exception as e:
            _log(f"HTTP fail: {url} -> {e}")
            continue
    return None

# ============================================================================
# API publique utilisée par l’orchestrateur/backtest
# ============================================================================
def fetch_ohlcv_best(symbol: str, timeframe: str, *, limit: int = 1000) -> pd.DataFrame:
    """
    Tente d’abord CCXT (si présent), sinon HTTP v1. Lève si tout échoue.
    """
    df = _fetch_via_ccxt(symbol, timeframe, limit=limit)
    if df is not None:
        _log(f"source=ccxt  n={len(df)}")
        return df
    df = _fetch_via_http(symbol, timeframe, limit=limit)
    if df is not None:
        _log(f"source=http  n={len(df)}")
        return df
    raise RuntimeError(f"Aucune source OHLCV pour {symbol} {timeframe}")

def hybrid_loader(
    data_dir: str = "data",
    *,
    use_cache_first: bool = True,
    min_rows: int = 100,
    refill_if_stale: bool = True,
    network_limit: int = 1000,
):
    """
    Loader smart :
      1) si CSV présent ET frais/valide → le renvoie
      2) sinon, si refill_if_stale → recharge (CCXT>HTTP) puis écrit CSV
      3) sinon → lève
    """
    os.environ.setdefault("DATA_DIR", data_dir)

    def load(symbol: str, timeframe: str, start: str | None, end: str | None) -> pd.DataFrame:
        path = _csv_path(symbol, timeframe)

        if use_cache_first:
            ok, why = _is_csv_fresh_and_valid(path, timeframe, min_rows=min_rows)
            if ok:
                _log(f"CSV OK: {path}")
                df = _read_csv(path)
            else:
                _log(f"CSV non utilisable ({why}): {path}")
                if not refill_if_stale:
                    raise RuntimeError(f"CSV invalide et recharge désactivée: {path} ({why})")
                df = fetch_ohlcv_best(symbol, timeframe, limit=network_limit)
                _write_csv(path, df)
        else:
            df = fetch_ohlcv_best(symbol, timeframe, limit=network_limit)
            _write_csv(path, df)

        # Fenêtrage temporel si demandé (timestamps UTC)
        if start:
            df = df.loc[pd.Timestamp(start, tz="UTC") :]
        if end:
            df = df.loc[: pd.Timestamp(end, tz="UTC")]
        return df

    return load

--------------------------------------------------------------------------------
FILE: scalper/backtest/metrics.py
--------------------------------------------------------------------------------
from __future__ import annotations
import math
from dataclasses import dataclass
from typing import List, Dict

@dataclass
class Trade:
    ts: int
    side: str
    entry: float
    exit: float
    pnl_abs: float
    pnl_pct: float
    dur_min: float

def equity_to_drawdown(equity: List[float]) -> float:
    peak = -1e18; maxdd = 0.0
    for v in equity:
        if v > peak: peak = v
        dd = 0.0 if peak == 0 else (peak - v) / peak
        if dd > maxdd: maxdd = dd
    return maxdd

def sharpe(returns: List[float], rf: float = 0.0, period_per_year: int = 365*24*12) -> float:
    # returns: per-bar (ex: par 5m) log or simple; ici simple
    if not returns: return 0.0
    mean = sum(returns)/len(returns)
    var = sum((r-mean)**2 for r in returns)/max(1, len(returns)-1)
    std = math.sqrt(var) if var>0 else 0.0
    if std == 0: return 0.0
    return (mean - rf) / std * math.sqrt(period_per_year)

def summarize(trades: List[Trade], equity: List[float], bar_returns: List[float], start_ts: int, end_ts: int) -> Dict:
    wins = [t for t in trades if t.pnl_abs > 0]
    losses = [t for t in trades if t.pnl_abs < 0]
    wr = len(wins)/len(trades) if trades else 0.0
    gross_win = sum(t.pnl_abs for t in wins)
    gross_loss = abs(sum(t.pnl_abs for t in losses))
    pf = (gross_win / gross_loss) if gross_loss > 0 else float('inf') if gross_win > 0 else 0.0
    mdd = equity_to_drawdown(equity)
    shp = sharpe(bar_returns)
    expectancy = (gross_win - gross_loss) / max(1, len(trades))
    n_years = max(1e-9, (end_ts - start_ts) / (365*24*3600*1000))
    cagr = (equity[-1]/equity[0])**(1/n_years) - 1 if equity and equity[0] > 0 else 0.0
    score = (wr*0.2) + (min(pf,3.0)/3.0*0.3) + (max(0.0,1.0-mdd)*0.3) + (max(0.0, min(shp/3,1.0))*0.2)
    return {
        "trades": len(trades),
        "winrate": wr, "pf": pf, "maxdd": mdd, "sharpe": shp,
        "expectancy": expectancy, "cagr": cagr, "score": score,
        "equity_start": equity[0] if equity else None,
        "equity_end": equity[-1] if equity else None,
    }

--------------------------------------------------------------------------------
FILE: scalper/backtest/optimize.py
--------------------------------------------------------------------------------
from __future__ import annotations

"""Parameter sweep utilities for strategy optimisation.

This module performs a grid search over a parameter space in parallel.  It
tries to use :mod:`ray` for distributed execution when available and falls
back to :mod:`multiprocessing` otherwise.
"""

import itertools
import json
import multiprocessing as mp
import os
from typing import Any, Dict, Iterable, List, Sequence

try:  # Optional dependency
    import ray  # type: ignore
except Exception:  # pragma: no cover - ray is optional
    ray = None

from scalper.backtest import backtest_trades


# ---------------------------------------------------------------------------
# Parameter space
# ---------------------------------------------------------------------------

def param_space_default() -> Dict[str, Sequence[Any]]:
    """Return the default parameter search space.

    The keys correspond to strategy parameters while the values are iterables
    of possible settings.  The defaults represent a small but representative
    grid and can be overridden by callers.
    """

    return {
        "ema_fast": [10, 20, 30],
        "ema_slow": [50, 100, 200],
        "rsi_period": [14, 21],
        "atr_period": [14, 21],
    }


def _param_grid(space: Dict[str, Iterable[Any]]) -> List[Dict[str, Any]]:
    """Expand *space* into a list of parameter combinations."""

    keys = list(space)
    values = [space[k] for k in keys]
    return [dict(zip(keys, combo)) for combo in itertools.product(*values)]


# ---------------------------------------------------------------------------
# Evaluation
# ---------------------------------------------------------------------------

def eval_params_one(grid_item: Dict[str, Any]) -> Dict[str, Any]:
    """Run a backtest for a single parameter combination.

    ``grid_item`` contains the parameter values along with optional ``trades``
    to evaluate.  The function returns a copy of the parameters augmented with
    the computed PnL under the key ``pnl``.
    """

    params = dict(grid_item)
    trades = params.pop("trades", [])
    fee_rate = params.pop("fee_rate", None)
    pnl = backtest_trades(trades, fee_rate=fee_rate)
    params["pnl"] = pnl
    return params


# ---------------------------------------------------------------------------
# Orchestration
# ---------------------------------------------------------------------------

def run_param_sweep(space: Dict[str, Iterable[Any]] | None = None, *, jobs: int | None = None) -> List[Dict[str, Any]]:
    """Evaluate the full parameter grid in parallel and return results."""

    space = space or param_space_default()
    grid = _param_grid(space)

    # Determine execution backend
    use_ray = False
    if ray is not None:
        try:  # pragma: no cover - depends on ray
            ray.init(ignore_reinit_error=True)
            use_ray = True
        except Exception:
            use_ray = False

    if use_ray:
        remote_eval = ray.remote(eval_params_one)  # type: ignore
        futures = [remote_eval.remote(g) for g in grid]
        results = ray.get(futures)
    else:
        jobs = jobs or int(os.getenv("OPT_JOBS", "0")) or mp.cpu_count()
        with mp.Pool(processes=jobs) as pool:
            results = pool.map(eval_params_one, grid)

    return results


def optimize(space: Dict[str, Iterable[Any]] | None = None, *, outfile: str = "opt_results.json", jobs: int | None = None) -> List[Dict[str, Any]]:
    """High level helper executing the sweep and saving aggregated results."""

    results = run_param_sweep(space, jobs=jobs)
    with open(outfile, "w", encoding="utf8") as fh:
        json.dump(results, fh, indent=2, sort_keys=True)
    return results


def main() -> None:  # pragma: no cover - convenience CLI
    optimize()


if __name__ == "__main__":  # pragma: no cover
    main()


--------------------------------------------------------------------------------
FILE: scalper/backtest/position_sizing.py
--------------------------------------------------------------------------------
# scalper/backtest/position_sizing.py
from __future__ import annotations
from scalper.core.signal import Signal

def position_size_from_signal(equity: float, sig: Signal, risk_pct: float) -> float:
    """
    Taille = (equity * risk_pct) / |entry - sl|
    Retourne la QUANTITÉ (unités de la crypto).
    """
    risk = max(1e-12, abs(sig.entry - sig.sl))
    cash_at_risk = max(0.0, equity) * max(0.0, risk_pct)
    return max(0.0, cash_at_risk / risk)

def fees_cost(notional: float, bps: float) -> float:
    return abs(notional) * (bps / 10000.0)

--------------------------------------------------------------------------------
FILE: scalper/backtest/run_multi.py
--------------------------------------------------------------------------------
# annulé

--------------------------------------------------------------------------------
FILE: scalper/backtest/runner.py
--------------------------------------------------------------------------------
# scalper/backtest/runner.py
from __future__ import annotations
import argparse
import os
from typing import Dict, List
from scalper.strategy.factory import load_strategies_cfg
from scalper.backtest.engine import BacktestEngine

def run_once(
    symbol: str,
    timeframe: str,
    csv_path: str,
    strategies_cfg_path: str = "scalper/config/strategies.yml",
    csv_1h_path: str = "",
    equity: float = 1000.0,
    risk: float = 0.01,
    fees_bps: float = 6.0,
) -> Dict[str, float]:
    cfg = load_strategies_cfg(strategies_cfg_path)
    data = BacktestEngine.load_csv(csv_path)
    data_1h = BacktestEngine.load_csv(csv_1h_path) if csv_1h_path and os.path.isfile(csv_1h_path) else None

    eng = BacktestEngine(
        symbol=symbol, timeframe=timeframe, data=data, data_1h=data_1h,
        equity_start=equity, risk_pct=risk, fees_bps=fees_bps, strategies_cfg=cfg,
    )
    eng.run()
    eng.save_results()
    return eng.summary()

def main():
    ap = argparse.ArgumentParser(description="Runner Backtest (point d'entrée unique)")
    ap.add_argument("--symbol", required=True, help="ex: BTCUSDT")
    ap.add_argument("--tf", required=True, help="ex: 5m, 1h")
    ap.add_argument("--csv", required=True, help="CSV OHLCV principal (timestamp,open,high,low,close,volume)")
    ap.add_argument("--csv_1h", default="", help="CSV 1h (optionnel) pour filtre MTF")
    ap.add_argument("--cfg", default="scalper/config/strategies.yml", help="config stratégies (YAML/JSON)")
    ap.add_argument("--equity", type=float, default=1000.0)
    ap.add_argument("--risk", type=float, default=0.01)
    ap.add_argument("--fees_bps", type=float, default=6.0)
    args = ap.parse_args()

    summary = run_once(
        symbol=args.symbol, timeframe=args.tf, csv_path=args.csv,
        strategies_cfg_path=args.cfg, csv_1h_path=args.csv_1h,
        equity=args.equity, risk=args.risk, fees_bps=args.fees_bps,
    )
    print("== Résumé ==")
    print(summary)

if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
FILE: scalper/backtest/walkforward.py
--------------------------------------------------------------------------------
from __future__ import annotations

from itertools import product
from statistics import mean, stdev
from typing import Dict, Iterable, Optional

from ..strategy import max_drawdown


def _sharpe(returns: Iterable[float]) -> float:
    vals = list(returns)
    if not vals:
        return 0.0
    mu = mean(vals)
    if len(vals) > 1:
        sd = stdev(vals)
    else:
        sd = 0.0
    return mu / sd if sd > 0 else 0.0


def _stability(equity: Iterable[float]) -> float:
    curve = list(equity)
    n = len(curve)
    if n < 2:
        return 0.0
    x = list(range(n))
    x_mean = sum(x) / n
    y_mean = sum(curve) / n
    ss_tot = sum((y - y_mean) ** 2 for y in curve)
    denom = sum((xi - x_mean) ** 2 for xi in x)
    if denom == 0 or ss_tot == 0:
        return 0.0
    b = sum((xi - x_mean) * (yi - y_mean) for xi, yi in zip(x, curve)) / denom
    a = y_mean - b * x_mean
    ss_res = sum((yi - (a + b * xi)) ** 2 for xi, yi in zip(x, curve))
    return 1 - ss_res / ss_tot


def walk_forward(
    df,
    splits: int = 5,
    train_ratio: float = 0.7,
    params: Optional[Dict[str, Iterable]] = None,
) -> Dict[str, float]:
    """Perform walk-forward optimisation and evaluation.

    Parameters
    ----------
    df:
        DataFrame containing per-period percentage returns. The first column is
        used when a dedicated ``"returns"`` column is not found.
    splits:
        Number of walk-forward test windows.
    train_ratio:
        Proportion of the data used for training in the initial window.
    params:
        Optional parameter grid. If provided, columns in ``df`` matching each
        parameter combination are evaluated and the best Sharpe ratio on the
        training window is selected. When ``None``, the first column is used.
    """

    if df.empty:
        return {"sharpe": 0.0, "mdd": 0.0, "pnl": 0.0, "stability": 0.0}

    returns_col = "returns" if "returns" in df.columns else df.columns[0]
    data = df.copy()

    n = len(data)
    train_len = max(1, int(n * train_ratio))
    test_len = max(1, (n - train_len) // splits) if splits else max(1, n - train_len)

    sharpe_list = []
    mdd_list = []
    pnl_list = []
    stability_list = []

    from . import walk_forward_windows

    indices = list(range(n))

    for tr_idx, te_idx in walk_forward_windows(indices, train_len, test_len):
        train_df = data.iloc[tr_idx]
        test_df = data.iloc[te_idx]

        # Parameter optimisation based on Sharpe ratio
        if params:
            best_col = None
            best_score = float("-inf")
            keys, values = zip(*params.items()) if params else ([], [])
            for combo in product(*values):
                col_name = "_".join(f"{k}={v}" for k, v in zip(keys, combo))
                if col_name not in data.columns:
                    continue
                score = _sharpe(train_df[col_name])
                if score > best_score:
                    best_score = score
                    best_col = col_name
            series = test_df[best_col] if best_col else test_df[returns_col]
        else:
            series = test_df[returns_col]

        sharpe_list.append(_sharpe(series))
        equity = (1 + series / 100.0).cumprod()
        mdd_list.append(max_drawdown(equity))
        pnl_list.append((equity.iloc[-1] - 1) * 100 if len(equity) else 0.0)
        stability_list.append(_stability(equity))

    count = len(sharpe_list) or 1
    mean_sharpe = sum(sharpe_list) / count
    mean_mdd = sum(mdd_list) / count
    mean_pnl = sum(pnl_list) / count
    mean_stability = sum(stability_list) / count

    return {
        "sharpe": mean_sharpe,
        "mdd": mean_mdd,
        "pnl": mean_pnl,
        "stability": mean_stability,
    }


--------------------------------------------------------------------------------
FILE: scalper/bitget_client.py
--------------------------------------------------------------------------------
import json
import logging
import time
import hmac
import hashlib
import base64
import uuid
from typing import Any, Dict, List, Optional

import requests


# Mapping of deprecated v1 product type identifiers to the new v2 names
_PRODUCT_TYPE_ALIASES = {
    "UMCBL": "USDT-FUTURES",
    "DMCBL": "USDC-FUTURES",
    "CMCBL": "COIN-FUTURES",
}

# Granularity aliases from v1 to v2 nomenclature
_GRANULARITY_ALIASES = {
    "MIN1": "1m",
    "MIN3": "3m",
    "MIN5": "5m",
    "MIN15": "15m",
    "MIN30": "30m",
    "HOUR1": "1H",
    "HOUR4": "4H",
    "HOUR12": "12H",
    "DAY1": "1D",
    "WEEK1": "1W",
}


# Default margin coin for each product type. Some authenticated endpoints
# require ``marginCoin`` in addition to ``productType``; supplying a sensible
# default avoids ``400 Bad Request`` responses when the caller does not provide
# it explicitly.
_DEFAULT_MARGIN_COIN = {
    "USDT-FUTURES": "USDT",
    "USDC-FUTURES": "USDC",
}


class BitgetFuturesClient:
    """Lightweight REST client for Bitget LAPI v2 futures endpoints."""

    def __init__(
        self,
        access_key: str,
        secret_key: str,
        base_url: str,
        *,
        product_type: str = "USDT-FUTURES",
        recv_window: int = 30,
        paper_trade: bool = True,
        requests_module: Any = requests,
        log_event: Optional[Any] = None,
        passphrase: Optional[str] = None,
    ) -> None:
        self.ak = access_key
        self.sk = secret_key
        self.base = base_url.rstrip("/")
        pt = product_type.upper()
        self.product_type = _PRODUCT_TYPE_ALIASES.get(pt, pt)
        self.recv_window = recv_window
        self.paper_trade = paper_trade
        self.requests = requests_module
        self.log_event = log_event or (lambda *a, **k: None)
        self.passphrase = passphrase
        if not self.ak or not self.sk or self.ak == "A_METTRE" or self.sk == "B_METTRE":
            logging.warning(
                "\u26a0\ufe0f Cl\u00e9s API non d\u00e9finies. Le mode r\u00e9el ne fonctionnera pas.",
            )
        # Cache for contract precision details to avoid repeated network calls
        self._contract_cache: Dict[str, Dict[str, Any]] = {}

    # ------------------------------------------------------------------
    # Helpers
    # ------------------------------------------------------------------
    @staticmethod
    def _ms() -> int:
        return int(time.time() * 1000)

    @staticmethod
    def _urlencode_sorted(params: Dict[str, Any]) -> str:
        if not params:
            return ""
        items = []
        for k in sorted(params.keys()):
            v = "" if params[k] is None else str(params[k])
            items.append(f"{k}={v}")
        return "&".join(items)

    def _sign(self, prehash: str) -> str:
        """Return a base64-encoded HMAC SHA256 signature."""
        digest = hmac.new(self.sk.encode(), prehash.encode(), hashlib.sha256).digest()
        return base64.b64encode(digest).decode()

    def _headers(self, signature: str, timestamp: int) -> Dict[str, str]:
        headers = {
            "ACCESS-KEY": self.ak,
            "ACCESS-SIGN": signature,
            "ACCESS-TIMESTAMP": str(timestamp),
            "ACCESS-RECV-WINDOW": str(self.recv_window),
            "Content-Type": "application/json",
        }
        if self.passphrase:
            headers["ACCESS-PASSPHRASE"] = self.passphrase
        return headers

    def _format_symbol(self, symbol: str) -> str:
        """Return ``symbol`` formatted for Bitget API.

        The v2 endpoints expect the trading pair without any product type
        suffix (``BTCUSDT``). Older configurations may provide symbols like
        ``BTC_USDT`` or ``BTCUSDT_UMCBL``; these are normalised by removing the
        separators and any trailing product type string (legacy or v2).
        """

        if not symbol:
            return symbol

        sym = symbol.replace("_", "").upper()
        # Strip product type suffix if present (e.g. BTCUSDTUMCBL)
        if sym.endswith(self.product_type):
            sym = sym[: -len(self.product_type)]
        else:
            for old in _PRODUCT_TYPE_ALIASES.keys():
                if sym.endswith(old):
                    sym = sym[: -len(old)]
                    break
        return sym

    def _product_type(self, pt: Optional[str] = None) -> str:
        """Normalise ``pt`` to a valid v2 product type identifier."""
        key = (pt or self.product_type or "").upper()
        return _PRODUCT_TYPE_ALIASES.get(key, key)

    # ------------------------------------------------------------------
    # Public endpoints
    # ------------------------------------------------------------------
    def get_contract_detail(self, symbol: Optional[str] = None) -> Dict[str, Any]:
        """Return futures contract information.

        The previous implementation queried ``/contract-detail`` which does not
        exist on Bitget's v2 API and resulted in a 404 error.  The correct
        endpoint is ``/contracts`` with the symbol supplied as a query
        parameter."""

        url = f"{self.base}/api/v2/mix/market/contracts"
        params: Dict[str, Any] = {"productType": self.product_type}
        if symbol:
            params["symbol"] = self._format_symbol(symbol)
        r = self.requests.get(url, params=params, timeout=15)
        if r.status_code == 404:  # pragma: no cover - depends on network
            logging.error("Contract detail introuvable pour %s", symbol)
            return {"success": False, "code": 404, "data": None}
        r.raise_for_status()
        return r.json()

    # ------------------------------------------------------------------
    def _get_contract_precision(self, symbol: str) -> tuple[int, int]:
        """Return price and volume precision for ``symbol``.

        Results are cached to minimise HTTP requests. If the contract
        information cannot be retrieved, ``(0, 0)`` is returned.
        """
        sym = self._format_symbol(symbol)
        info = self._contract_cache.get(sym)
        if info is None:
            detail = self.get_contract_detail(sym)
            try:
                data = detail.get("data", [])
                if isinstance(data, list) and data:
                    info = data[0]
                else:
                    info = {}
            except Exception:
                info = {}
            self._contract_cache[sym] = info
        price_place = int(info.get("pricePlace") or 0)
        volume_place = int(info.get("volumePlace") or 0)
        return price_place, volume_place

    def get_kline(
        self,
        symbol: str,
        interval: str = "1m",
        start: Optional[int] = None,
        end: Optional[int] = None,
    ) -> Dict[str, Any]:
        # Endpoint expects the trading pair in query parameters rather than
        # encoded in the path. Using ``/candles/{symbol}`` results in a 404
        # response from Bitget. See: https://api.bitget.com/api/v2/mix/market/candles
        url = f"{self.base}/api/v2/mix/market/candles"
        interval_norm = _GRANULARITY_ALIASES.get(interval.replace("_", "").upper(), interval)
        params: Dict[str, Any] = {
            "symbol": self._format_symbol(symbol),
            "productType": self.product_type,
            "granularity": interval_norm,
        }
        if start is not None:
            params["startTime"] = int(start)
        if end is not None:
            params["endTime"] = int(end)
        r = self.requests.get(url, params=params, timeout=15)
        r.raise_for_status()
        data = r.json()

        rows = data.get("data") if isinstance(data, dict) else None
        if isinstance(rows, list) and rows and isinstance(rows[0], list):
            cols = {"ts": [], "open": [], "high": [], "low": [], "close": [], "volume": [], "quoteVolume": []}
            for row in rows:
                if len(row) < 7:
                    continue
                try:
                    ts, op, hi, lo, cl, vol, qv = row[:7]
                    cols["ts"].append(int(ts))
                    cols["open"].append(float(op))
                    cols["high"].append(float(hi))
                    cols["low"].append(float(lo))
                    cols["close"].append(float(cl))
                    cols["volume"].append(float(vol))
                    cols["quoteVolume"].append(float(qv))
                except (TypeError, ValueError):
                    continue
            data["data"] = cols
        elif isinstance(rows, list):
            data["data"] = {"ts": [], "open": [], "high": [], "low": [], "close": [], "volume": [], "quoteVolume": []}
        return data

    def get_ticker(self, symbol: Optional[str] = None) -> Dict[str, Any]:
        if symbol:
            url = f"{self.base}/api/v2/mix/market/ticker"
            params = {
                "symbol": self._format_symbol(symbol),
                "productType": self.product_type,
            }
        else:
            url = f"{self.base}/api/v2/mix/market/tickers"
            params = {"productType": self.product_type}
        r = self.requests.get(url, params=params, timeout=15)
        r.raise_for_status()
        return r.json()

    # ------------------------------------------------------------------
    # Private endpoints
    # ------------------------------------------------------------------
    def _private_request(
        self,
        method: str,
        path: str,
        *,
        params: Optional[Dict[str, Any]] = None,
        body: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        method = method.upper()
        ts = self._ms()

        if method in ("GET", "DELETE"):
            qs = self._urlencode_sorted(params or {})
            req_path = path + (f"?{qs}" if qs else "")
            sig = self._sign(f"{ts}{method}{req_path}")
            headers = self._headers(sig, ts)
            url = f"{self.base}{req_path}"
            r = self.requests.request(method, url, headers=headers, timeout=20)
        elif method == "POST":
            qs = self._urlencode_sorted(params or {})
            req_path = path + (f"?{qs}" if qs else "")
            body_str = json.dumps(body or {}, separators=(",", ":"), ensure_ascii=False)
            sig = self._sign(f"{ts}{method}{req_path}{body_str}")
            headers = self._headers(sig, ts)
            url = f"{self.base}{req_path}"
            r = self.requests.post(
                url,
                data=body_str.encode("utf-8"),
                headers=headers,
                timeout=20,
            )
        else:
            raise ValueError("M\u00e9thode non support\u00e9e")

        resp_text = getattr(r, "text", "")
        try:
            data = r.json()
        except Exception:
            data = {
                "success": False,
                "error": resp_text,
                "status_code": getattr(r, "status_code", None),
            }

        status = getattr(r, "status_code", 0)
        if status >= 400:
            code = str(data.get("code")) if isinstance(data, dict) else ""
            if code == "22001":
                logging.info("Aucun ordre à annuler (%s %s)", method, path)
            else:
                try:
                    r.raise_for_status()
                except Exception as e:
                    if not resp_text:
                        resp_text = getattr(r, "text", "") or str(e)
                logging.error(
                    "Erreur HTTP/JSON %s %s -> %s %s",
                    method,
                    path,
                    status,
                    resp_text,
                )
                if isinstance(data, dict):
                    data.setdefault("success", False)
                    data.setdefault("status_code", status)
                    data.setdefault("error", resp_text)

        self.log_event(
            "http_private",
            {"method": method, "path": path, "params": params, "body": body, "response": data},
        )
        return data

    # Accounts & positions -------------------------------------------------
    def get_assets(self, margin_coin: Optional[str] = None) -> Dict[str, Any]:
        if self.paper_trade:
            return {
                "success": True,
                "code": 0,
                "data": [
                    {
                        "currency": "USDT",
                        "equity": 100.0,
                    }
                ],
            }

        params = {"productType": self.product_type}
        if margin_coin is None:
            margin_coin = _DEFAULT_MARGIN_COIN.get(self.product_type)
        if margin_coin:
            params["marginCoin"] = margin_coin
        data = self._private_request(
            "GET", "/api/v2/mix/account/accounts", params=params
        )
        if isinstance(data, dict):
            data.setdefault("success", str(data.get("code")) == "00000")
        try:
            for row in data.get("data", []):
                if "currency" not in row and row.get("marginCoin"):
                    row["currency"] = str(row["marginCoin"]).upper()
                chosen = None
                for key in ("available", "cashBalance", "equity", "usdtEquity"):
                    val = row.get(key)
                    if val is not None:
                        chosen = val
                        break
                if chosen is not None:
                    row["equity"] = chosen
                try:
                    row["equity"] = float(row["equity"])
                except Exception:
                    pass
        except Exception:  # pragma: no cover - best effort
            pass
        return data

    def get_positions(self, product_type: Optional[str] = None) -> Dict[str, Any]:
        if self.paper_trade:
            return {"success": True, "code": 0, "data": []}
        data = self._private_request(
            "GET",
            "/api/v2/mix/position/all-position",
            params={"productType": self._product_type(product_type)},
        )
        try:
            positions = data.get("data", [])
            filtered = []
            for pos in positions:
                vol = pos.get("vol")
                try:
                    if vol is not None and float(vol) > 0:
                        filtered.append(pos)
                except (TypeError, ValueError):
                    continue
            data["data"] = filtered
        except Exception:  # pragma: no cover - best effort
            pass
        return data

    def get_open_orders(self, symbol: Optional[str] = None) -> Dict[str, Any]:
        if self.paper_trade:
            return {"success": True, "code": 0, "data": []}
        params: Dict[str, Any] = {"productType": self.product_type}
        if symbol:
            params["symbol"] = self._format_symbol(symbol)
        return self._private_request("GET", "/api/v2/mix/order/orders-pending", params=params)

    # Account configuration -------------------------------------------------
    def set_position_mode_one_way(self, symbol: str, product_type: Optional[str] = None) -> Dict[str, Any]:
        body = {
            "productType": self._product_type(product_type),
            "symbol": self._format_symbol(symbol),
            "posMode": "one_way_mode",
        }
        return self._private_request("POST", "/api/v2/mix/account/set-position-mode", body=body)

    def set_leverage(
        self,
        symbol: str,
        product_type: Optional[str] = None,
        margin_coin: str = "USDT",
        leverage: int = 1,
    ) -> Dict[str, Any]:
        body = {
            "symbol": self._format_symbol(symbol),
            "productType": self._product_type(product_type),
            "marginCoin": margin_coin,
            "leverage": int(leverage),
        }
        return self._private_request(
            "POST", "/api/v2/mix/account/set-leverage", body=body
        )

    def place_market_order_one_way(
        self,
        symbol: str,
        side: str,
        size: float,
        product_type: Optional[str] = None,
        margin_coin: str = "USDT",
        *,
        time_in_force: str = "normal",
    ) -> Dict[str, Any]:
        side = side.lower()
        if side not in {"buy", "sell"}:
            raise ValueError("side must be 'buy' or 'sell'")
        body = {
            "symbol": self._format_symbol(symbol),
            "productType": self._product_type(product_type),
            "marginCoin": margin_coin,
            "marginMode": "crossed",
            "posMode": "one_way_mode",
            "orderType": "market",
            "side": side,
            "size": str(size),
            "timeInForceValue": time_in_force,
            "clientOid": str(uuid.uuid4())[:32],
        }
        return self._private_request(
            "POST", "/api/v2/mix/order/place-order", body=body
        )

    # Orders ---------------------------------------------------------------
    def place_order(
        self,
        symbol: str,
        side: int,
        vol: int,
        order_type: int,
        *,
        price: Optional[float] = None,
        open_type: int = 1,
        leverage: Optional[int] = None,
        position_id: Optional[int] = None,
        external_oid: Optional[str] = None,
        stop_loss: Optional[float] = None,
        take_profit: Optional[float] = None,
        position_mode: Optional[int] = None,
        margin_coin: Optional[str] = None,
        time_in_force: str = "normal",
    ) -> Dict[str, Any]:
        """Submit an order.

        This helper keeps backward compatibility with the older numeric
        parameters used by the bot while translating them to the string based
        fields required by Bitget's v2 API.
        """
        if self.paper_trade:
            logging.info(
                "PAPER_TRADE=True -> ordre simul\u00e9: side=%s vol=%s type=%s price=%s",
                side,
                vol,
                order_type,
                price,
            )
            return {
                "success": True,
                "paperTrade": True,
                "simulated": {
                    "symbol": symbol,
                    "side": side,
                    "vol": vol,
                    "type": order_type,
                    "price": price,
                    "openType": open_type,
                    "leverage": leverage,
                    "stopLossPrice": stop_loss,
                    "takeProfitPrice": take_profit,
                },
            }

        # ------------------------------------------------------------------
        # Parameter mapping
        # ------------------------------------------------------------------
        side_map = {
            1: ("buy", "long"),
            2: ("buy", "short"),
            3: ("sell", "short"),
            4: ("sell", "long"),
        }
        if isinstance(side, int):
            mapped = side_map.get(side)
            if not mapped:
                raise ValueError(f"Invalid side value: {side}")
            side_str, pos_side = mapped
        else:
            side_str = str(side)
            pos_side = None

        order_map = {1: "market", 2: "limit", 3: "post_only", 4: "fok", 5: "limit"}
        if isinstance(order_type, int):
            order_str = order_map.get(order_type)
            if order_str is None:
                order_str = "limit" if price is not None else "market"
        else:
            order_str = str(order_type)

        margin_mode = "crossed" if int(open_type) == 1 else "isolated"

        if margin_coin is None:
            margin_coin = _DEFAULT_MARGIN_COIN.get(self.product_type)

        # ------------------------------------------------------------------
        # Precision handling
        # ------------------------------------------------------------------
        try:
            price_place, volume_place = self._get_contract_precision(symbol)
        except Exception:  # pragma: no cover - best effort
            price_place = volume_place = 0
        if price is not None:
            price = round(float(price), price_place)
        if vol is not None:
            vol = round(float(vol), volume_place)

        body = {
            "symbol": self._format_symbol(symbol),
            "productType": self.product_type,
            "marginMode": margin_mode,
            "orderType": order_str,
            "side": side_str,
            "size": vol,
            "timeInForceValue": time_in_force,
        }
        if pos_side is not None:
            body["posSide"] = pos_side
        if margin_coin:
            body["marginCoin"] = margin_coin
        if price is not None:
            body["price"] = float(price)
        if leverage is not None:
            body["leverage"] = int(leverage)
        if position_id is not None:
            body["positionId"] = int(position_id)
        if external_oid:
            body["clientOid"] = str(external_oid)[:32]
        else:
            body["clientOid"] = str(uuid.uuid4())[:32]
        if stop_loss is not None:
            body["stopLossPrice"] = float(stop_loss)
        if take_profit is not None:
            body["takeProfitPrice"] = float(take_profit)
        if position_mode is not None:
            body["posMode"] = "one_way_mode" if int(position_mode) == 1 else "hedge_mode"
        elif pos_side is not None:
            body["posMode"] = "hedge_mode"

        return self._private_request("POST", "/api/v2/mix/order/place-order", body=body)

    def cancel_order(self, order_ids: List[int]) -> Dict[str, Any]:
        if self.paper_trade:
            logging.info(
                "PAPER_TRADE=True -> annulation simulée: order_ids=%s", order_ids
            )
            return {"success": True, "code": 0}
        return self._private_request(
            "POST", "/api/v2/mix/order/cancel-order", body={"orderIds": order_ids}
        )

    def cancel_all(
        self,
        symbol: Optional[str] = None,
        margin_coin: Optional[str] = None,
    ) -> Dict[str, Any]:
        if self.paper_trade:
            logging.info(
                "PAPER_TRADE=True -> annulation simulée de tous les ordres"
            )
            return {"success": True, "code": 0}
        body = {"productType": self.product_type}
        if symbol:
            body["symbol"] = self._format_symbol(symbol)
        if margin_coin is None:
            margin_coin = _DEFAULT_MARGIN_COIN.get(self.product_type)
        if margin_coin:
            body["marginCoin"] = margin_coin
        return self._private_request(
            "POST", "/api/v2/mix/order/cancel-all-orders", body=body
        )

    def close_position(
        self,
        symbol: str,
        size: Optional[int] = None,
        hold_side: Optional[str] = None,
    ) -> Dict[str, Any]:
        """Close an open position for ``symbol``.

        Parameters
        ----------
        symbol:
            Trading symbol to close.
        size:
            Optional number of contracts to close. If omitted the entire
            position is closed.
        hold_side:
            Optional side (``"long"``/``"short"``) to close when ``size`` is
            specified. If not provided the exchange will infer it.
        """

        if self.paper_trade:
            logging.info(
                "PAPER_TRADE=True -> fermeture simulée de la position %s", symbol
            )
            return {"success": True, "code": 0}

        body = {"symbol": self._format_symbol(symbol)}
        if size is not None:
            body["size"] = int(size)
        if hold_side:
            body["holdSide"] = hold_side

        body["productType"] = self.product_type
        return self._private_request(
            "POST", "/api/v2/mix/position/close-position", body=body
        )

    def close_all_positions(self, product_type: Optional[str] = None) -> Dict[str, Any]:
        """Close all open positions."""
        results = []
        try:
            for pos in self.get_positions(product_type).get("data", []):
                sym = pos.get("symbol")
                if sym:
                    results.append(self.close_position(sym))
        except Exception as exc:  # pragma: no cover - best effort
            logging.error("Erreur fermeture de toutes les positions: %s", exc)
        return {"success": True, "data": results}


--------------------------------------------------------------------------------
FILE: scalper/client.py
--------------------------------------------------------------------------------
import logging
from typing import Any, Dict, Optional

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry


class HTTPError(RuntimeError):
    """Raised when an HTTP request fails"""


class HttpClient:
    """Simple HTTP client with persistent session and retry logic.

    The client exposes a :py:meth:`close` method and implements the context
    manager protocol so it can be used with ``with`` statements to ensure
    that the underlying :class:`requests.Session` is properly closed.
    """

    def __init__(
        self,
        base_url: str,
        *,
        timeout: float = 10.0,
        max_retries: int = 3,
        backoff_factor: float = 0.3,
        status_forcelist: Optional[list[int]] = None,
    ) -> None:
        self.base_url = base_url.rstrip("/")
        self.timeout = timeout
        self.session = requests.Session()
        retry = Retry(
            total=max_retries,
            backoff_factor=backoff_factor,
            status_forcelist=status_forcelist or [429, 500, 502, 503, 504],
            allowed_methods=[
                "HEAD",
                "GET",
                "OPTIONS",
                "POST",
                "PUT",
                "DELETE",
                "PATCH",
            ],
        )
        adapter = HTTPAdapter(max_retries=retry)
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)

    def close(self) -> None:
        """Close the underlying :class:`requests.Session`."""
        self.session.close()

    # ------------------------------------------------------------------
    # Context manager support
    # ------------------------------------------------------------------
    def __enter__(self) -> "HttpClient":
        return self

    def __exit__(self, exc_type, exc, tb) -> None:  # type: ignore[override]
        self.close()

    def request(
        self,
        method: str,
        path: str,
        *,
        params: Optional[Dict[str, Any]] = None,
        json: Optional[Dict[str, Any]] = None,
        headers: Optional[Dict[str, str]] = None,
    ) -> Dict[str, Any]:
        """Perform an HTTP request and return JSON data.

        Errors during the request raise ``HTTPError``. If the response cannot
        be decoded as JSON, a dictionary describing the issue is returned.
        """
        url = f"{self.base_url}{path}"
        try:
            resp = self.session.request(
                method,
                url,
                params=params,
                json=json,
                headers=headers,
                timeout=self.timeout,
            )
            resp.raise_for_status()
        except requests.RequestException as exc:  # network or HTTP errors
            msg = f"HTTP error calling {url}: {exc}"
            logging.error(msg)
            raise HTTPError(msg) from exc

        try:
            return resp.json()
        except ValueError:  # invalid JSON
            msg = "Invalid JSON in response"
            logging.error("%s for %s: %s", msg, url, resp.text)
            return {"success": False, "error": msg, "text": resp.text}


--------------------------------------------------------------------------------
FILE: scalper/config/__init__.py
--------------------------------------------------------------------------------
from .loader import load_settings
__all__ = ['load_settings']


--------------------------------------------------------------------------------
FILE: scalper/config/loader.py
--------------------------------------------------------------------------------
# scalp/config/loader.py
from __future__ import annotations
import os, json
from typing import Any, Dict, Tuple

# YAML est recommandé, mais on fallback proprement si PyYAML n'est pas installé
try:
    import yaml  # type: ignore
except Exception:
    yaml = None  # fallback JSON si besoin

# dotenv (facultatif) pour charger un .env automatiquement
try:
    from dotenv import load_dotenv  # type: ignore
except Exception:
    load_dotenv = None

# ---------------- Utils ----------------

def _parse_bool(x: Any, default: bool = False) -> bool:
    if isinstance(x, bool): return x
    s = str(x).strip().lower()
    if s in ("1","true","yes","y","on"): return True
    if s in ("0","false","no","n","off",""): return False
    return default

def _parse_float(x: Any, default: float | None = None) -> float | None:
    try: return float(x)
    except Exception: return default

def _parse_int(x: Any, default: int | None = None) -> int | None:
    try: return int(str(x).strip())
    except Exception: return default

def _parse_csv(x: Any) -> list[str]:
    if x is None: return []
    if isinstance(x, (list, tuple)): return [str(v).strip() for v in x if str(v).strip()]
    return [t.strip() for t in str(x).replace(" ", "").split(",") if t.strip()]

def _read_yaml(path: str) -> Dict[str, Any]:
    if not os.path.exists(path): return {}
    with open(path, "r", encoding="utf-8") as f:
        if yaml:
            return yaml.safe_load(f) or {}
        # fallback JSON si quelqu’un met du JSON dans config.yml (rare mais safe)
        try:
            return json.load(f)
        except Exception:
            raise RuntimeError(f"Impossible de lire {path}: installe PyYAML (`pip install pyyaml`) ou fournis du JSON valide.")

def _merge_dict(a: Dict[str, Any], b: Dict[str, Any]) -> Dict[str, Any]:
    # shallow merge suffisant ici (structure plate)
    out = dict(a)
    out.update({k: v for k, v in b.items() if v is not None})
    return out

# ---------------- Public API ----------------

def load_settings(
    config_path: str = "config.yml",
    config_local_path: str = "config.local.yml",
) -> Tuple[Dict[str, Any], Dict[str, Any]]:
    """
    Retourne (config_runtime, secrets) :
      - config_runtime : paramètres de stratégie / exécution (OK pour versionner)
      - secrets        : clés API & tokens (NE PAS versionner)
    Priorité : config.yml < config.local.yml < ENV (non sensibles)
    Secrets proviennent EXCLUSIVEMENT de l'ENV (.env)
    """
    # 1) .env (pour secrets & env non sensibles). Faculatif.
    if load_dotenv is not None:
        load_dotenv(override=False)

    # 2) Charge YAML (config.yml + override local)
    base = _read_yaml(config_path)
    local = _read_yaml(config_local_path)
    cfg = _merge_dict(base, local)

    # 3) Overlay ENV **non sensibles** (permet de surcharger sans toucher au YAML)
    env_overlay: Dict[str, Any] = {}
    # Verbosité
    env_overlay["QUIET"] = _parse_bool(os.getenv("QUIET", cfg.get("QUIET", 0)), bool(cfg.get("QUIET", 0)))
    env_overlay["PRINT_OHLCV_SAMPLE"] = _parse_bool(os.getenv("PRINT_OHLCV_SAMPLE", cfg.get("PRINT_OHLCV_SAMPLE", 0)),
                                                    bool(cfg.get("PRINT_OHLCV_SAMPLE", 0)))
    # Runtime / Stratégie
    env_overlay["TIMEFRAME"] = os.getenv("TIMEFRAME", cfg.get("TIMEFRAME", "5m"))
    env_overlay["CASH"] = _parse_float(os.getenv("CASH", cfg.get("CASH", 10000)), cfg.get("CASH", 10000))
    env_overlay["RISK_PCT"] = _parse_float(os.getenv("RISK_PCT", cfg.get("RISK_PCT", 0.5)), cfg.get("RISK_PCT", 0.5))
    env_overlay["SLIPPAGE_BPS"] = _parse_float(os.getenv("SLIPPAGE_BPS", cfg.get("SLIPPAGE_BPS", 0)), cfg.get("SLIPPAGE_BPS", 0))
    # Watchlist
    env_overlay["WATCHLIST_MODE"] = os.getenv("WATCHLIST_MODE", cfg.get("WATCHLIST_MODE", "static"))
    env_overlay["WATCHLIST_LOCAL_CONC"] = _parse_int(
        os.getenv("WATCHLIST_LOCAL_CONC", cfg.get("WATCHLIST_LOCAL_CONC", 4)), cfg.get("WATCHLIST_LOCAL_CONC", 4)
    )
    env_overlay["TOP_SYMBOLS"] = _parse_csv(os.getenv("TOP_SYMBOLS", cfg.get("TOP_SYMBOLS")))
    env_overlay["TOP_CANDIDATES"] = _parse_csv(os.getenv("TOP_CANDIDATES", cfg.get("TOP_CANDIDATES")))
    # Caps (optionnel) : on accepte YAML (dict) ou ENV JSON
    caps_env = os.getenv("CAPS_JSON")
    if caps_env:
        try:
            env_overlay["CAPS"] = json.loads(caps_env)
        except Exception:
            env_overlay["CAPS"] = cfg.get("CAPS", {})
    else:
        env_overlay["CAPS"] = cfg.get("CAPS", {})

    # 4) Secrets UNIQUEMENT via ENV (jamais via YAML)
    secrets = {
        "BITGET_API_KEY": os.getenv("BITGET_API_KEY", ""),
        "BITGET_API_SECRET": os.getenv("BITGET_API_SECRET", ""),
        "BITGET_API_PASSWORD": os.getenv("BITGET_API_PASSWORD", ""),
        "BITGET_USE_TESTNET": _parse_bool(os.getenv("BITGET_USE_TESTNET", os.getenv("BITGET_TESTNET", "1")), True),
        "BITGET_PRODUCT": os.getenv("BITGET_PRODUCT", "umcbl"),
        "TELEGRAM_BOT_TOKEN": os.getenv("TELEGRAM_BOT_TOKEN", ""),
        "TELEGRAM_CHAT_ID": os.getenv("TELEGRAM_CHAT_ID", ""),
    }

    # 5) Runtime normalisé pour l’orchestrateur
    runtime = {
        "quiet": bool(env_overlay["QUIET"]),
        "print_sample": bool(env_overlay["PRINT_OHLCV_SAMPLE"]),
        "timeframe": str(env_overlay["TIMEFRAME"]),
        "cash": float(env_overlay["CASH"]),
        "risk_pct": float(env_overlay["RISK_PCT"]),
        "slippage_bps": float(env_overlay["SLIPPAGE_BPS"]),
        "watchlist_mode": str(env_overlay["WATCHLIST_MODE"]),
        "watchlist_local_conc": int(env_overlay["WATCHLIST_LOCAL_CONC"]),
        "top_symbols": env_overlay["TOP_SYMBOLS"],          # list[str]
        "top_candidates": env_overlay["TOP_CANDIDATES"],    # list[str]
        "caps": env_overlay["CAPS"],                        # dict
        # rempli au boot par les frais Bitget
        "fees_by_symbol": {}, 
    }

    return runtime, secrets
    

--------------------------------------------------------------------------------
FILE: scalper/config/strategies.yml
--------------------------------------------------------------------------------
# scalper/config/strategies.yml
default: current
by_timeframe:
  "1m": current
  "5m": current
  "15m": current
  "1h": current
by_symbol:
  BTCUSDT:
    "1m": current
    "5m": current
  ETHUSDT:
    "5m": current


--------------------------------------------------------------------------------
FILE: scalper/core/indicators.py
--------------------------------------------------------------------------------
# scalper/core/indicators.py
from __future__ import annotations
from typing import Sequence, Tuple, List

def _to_list(x: Sequence[float]) -> List[float]:
    return list(map(float, x))

def ema(series: Sequence[float], period: int) -> List[float]:
    s = _to_list(series)
    if period <= 1 or len(s) == 0:
        return s[:]
    k = 2.0 / (period + 1.0)
    out = [s[0]]
    for i in range(1, len(s)):
        out.append(s[i] * k + out[-1] * (1.0 - k))
    return out

def sma(series: Sequence[float], period: int) -> List[float]:
    s = _to_list(series)
    out: List[float] = []
    acc = 0.0
    for i, v in enumerate(s):
        acc += v
        if i >= period:
            acc -= s[i - period]
        out.append(acc / min(i + 1, period))
    return out

def rsi(closes: Sequence[float], period: int = 14) -> List[float]:
    c = _to_list(closes)
    if len(c) < 2:
        return [50.0] * len(c)
    gains = [0.0]
    losses = [0.0]
    for i in range(1, len(c)):
        ch = c[i] - c[i - 1]
        gains.append(max(ch, 0.0))
        losses.append(max(-ch, 0.0))
    avg_gain = sma(gains, period)
    avg_loss = sma(losses, period)
    out = []
    for g, l in zip(avg_gain, avg_loss):
        if l == 0:
            out.append(100.0)
        else:
            rs = g / l
            out.append(100.0 - (100.0 / (1.0 + rs)))
    return out

def macd(closes: Sequence[float], fast: int = 12, slow: int = 26, signal: int = 9) -> Tuple[List[float], List[float], List[float]]:
    c = _to_list(closes)
    ema_fast = ema(c, fast)
    ema_slow = ema(c, slow)
    macd_line = [f - s for f, s in zip(ema_fast, ema_slow)]
    signal_line = ema(macd_line, signal)
    hist = [m - s for m, s in zip(macd_line, signal_line)]
    return macd_line, signal_line, hist

def atr(highs: Sequence[float], lows: Sequence[float], closes: Sequence[float], period: int = 14) -> List[float]:
    h, l, c = _to_list(highs), _to_list(lows), _to_list(closes)
    if not h:
        return []
    trs = [h[0] - l[0]]
    for i in range(1, len(h)):
        tr = max(h[i] - l[i], abs(h[i] - c[i - 1]), abs(l[i] - c[i - 1]))
        trs.append(tr)
    return ema(trs, period)

def obv(closes: Sequence[float], volumes: Sequence[float]) -> List[float]:
    c, v = _to_list(closes), _to_list(volumes)
    out = [0.0]
    for i in range(1, len(c)):
        if c[i] > c[i - 1]:
            out.append(out[-1] + v[i])
        elif c[i] < c[i - 1]:
            out.append(out[-1] - v[i])
        else:
            out.append(out[-1])
    return out

def vwap(highs: Sequence[float], lows: Sequence[float], closes: Sequence[float], volumes: Sequence[float]) -> List[float]:
    h, l, c, v = _to_list(highs), _to_list(lows), _to_list(closes), _to_list(volumes)
    out: List[float] = []
    cum_tp_vol = 0.0
    cum_vol = 0.0
    for hi, lo, cl, vol in zip(h, l, c, v):
        tp = (hi + lo + cl) / 3.0
        cum_tp_vol += tp * vol
        cum_vol += max(vol, 1e-12)
        out.append(cum_tp_vol / cum_vol)
    return out

def slope(series: Sequence[float], lookback: int = 5) -> List[float]:
    s = _to_list(series)
    out: List[float] = []
    for i in range(len(s)):
        if i < lookback:
            out.append(0.0)
        else:
            denom = abs(s[i - lookback]) if abs(s[i - lookback]) > 1e-12 else 1e-12
            out.append((s[i] - s[i - lookback]) / denom)
    return out

--------------------------------------------------------------------------------
FILE: scalper/core/signal.py
--------------------------------------------------------------------------------
# scalper/core/signal.py
from __future__ import annotations
from dataclasses import dataclass, field
from typing import List, Optional, Literal, Dict, Any

Side = Literal["long", "short"]

@dataclass
class Signal:
    symbol: str
    timeframe: str
    side: Side
    entry: float
    sl: float
    tp1: Optional[float] = None
    tp2: Optional[float] = None
    qty: Optional[float] = None
    score: float = 0.0          # 0..1 (ou entier, normalisé au besoin)
    quality: float = 0.0        # 0..1
    reasons: List[str] = field(default_factory=list)
    timestamp: Optional[int] = None  # ms epoch de la bougie de déclenchement
    extra: Dict[str, Any] = field(default_factory=dict)

    def risk_per_unit(self) -> float:
        return abs(self.entry - self.sl)

    def as_dict(self) -> Dict[str, Any]:
        d = {
            "symbol": self.symbol, "timeframe": self.timeframe, "side": self.side,
            "entry": self.entry, "sl": self.sl, "tp1": self.tp1, "tp2": self.tp2,
            "qty": self.qty, "score": self.score, "quality": self.quality,
            "timestamp": self.timestamp, "reasons": "|".join(self.reasons),
        }
        d.update(self.extra or {})
        return d

--------------------------------------------------------------------------------
FILE: scalper/exchange/__init__.py
--------------------------------------------------------------------------------
# Rend le sous-package exchanges importable
__all__ = ["bitget"]

--------------------------------------------------------------------------------
FILE: scalper/exchange/bitget.py
--------------------------------------------------------------------------------
# scalper/exchange/bitget.py
from __future__ import annotations
import os
import requests
from typing import List, Dict, Any

BASE_URL = "https://api.bitget.com"

# Spot: period strings
_SPOT_PERIOD = {
    "1m": "1min", "3m": "3min", "5m": "5min", "15m": "15min", "30m": "30min",
    "1h": "1hour", "4h": "4hour", "6h": "6hour", "12h": "12hour",
    "1d": "1day", "3d": "3day", "1w": "1week",
}
# Mix: granularity seconds
_MIX_GRAN = {
    "1m": 60, "3m": 180, "5m": 300, "15m": 900, "30m": 1800,
    "1h": 3600, "4h": 14400, "6h": 21600, "12h": 43200,
    "1d": 86400, "3d": 259200, "1w": 604800,
}

def _market_from_symbol(symbol: str) -> str:
    s = symbol.upper()
    if s.endswith("_SPBL"):
        return "spot"
    if s.endswith("_UMCBL"):
        return "umcbl"
    if s.endswith("_DMCBL"):
        return "dmcbl"
    if s.endswith("_CMCBL"):
        return "cmcbl"
    # fallback env / défaut umcbl
    return os.getenv("BITGET_MARKET", "umcbl").lower()

def _product_type(market: str) -> str:
    # valeur attendue par les endpoints mix (umcbl/dmcbl/cmcbl)
    if market in ("umcbl", "dmcbl", "cmcbl"):
        return market
    return "umcbl"

class BitgetExchange:
    """
    Wrapper simple: get_ohlcv(symbol, timeframe, limit) -> [[ts, o, h, l, c, v], ...]
    symbol spot ex: BTCUSDT_SPBL
    symbol perp ex: BTCUSDT_UMCBL / BTCUSD_DMCBL / BTCUSD_CMCBL
    """
    def __init__(self, api_key: str = "", api_secret: str = "", api_passphrase: str = "", timeout: int = 20) -> None:
        self.session = requests.Session()
        self.session.headers.update({"User-Agent": "scalp-bot/1.0"})
        self.timeout = timeout

    def _get(self, path: str, params: Dict[str, Any]) -> Dict[str, Any]:
        url = BASE_URL + path
        r = self.session.get(url, params=params, timeout=self.timeout)
        r.raise_for_status()
        data = r.json()
        # Bitget: {"code":"00000","msg":"success","requestTime":..., "data":[...]}
        if not isinstance(data, dict) or str(data.get("code")) not in ("00000", "0", "200"):
            raise RuntimeError(f"Bitget error payload: {data}")
        return data

    def get_ohlcv(self, symbol: str, timeframe: str = "5m", limit: int = 500) -> List[List[float]]:
        timeframe = timeframe.lower()
        mkt = _market_from_symbol(symbol)

        if mkt == "spot":
            period = _SPOT_PERIOD.get(timeframe)
            if not period:
                raise ValueError(f"timeframe spot non supporté: {timeframe}")
            # Bitget spot: limit max souvent 1000
            lim = max(1, min(int(limit), 1000))
            params = {"symbol": symbol, "period": period, "limit": lim}
            data = self._get("/api/spot/v1/market/candles", params=params)
            rows = data.get("data") or []
            out: List[List[float]] = []
            # Bitget renvoie décroissant -> on inverse
            for r in reversed(rows):
                ts = int(r[0]); o, h, l, c = map(float, r[1:5]); v = float(r[5])
                out.append([ts, o, h, l, c, v])
            return out

        # MIX (umcbl/dmcbl/cmcbl)
        gran = _MIX_GRAN.get(timeframe)
        if not gran:
            raise ValueError(f"timeframe mix non supporté: {timeframe}")

        # Bitget mix: limit max souvent 200, granularity en secondes, productType parfois requis
        lim = max(1, min(int(limit), 200))
        params = {
            "symbol": symbol,
            "granularity": int(gran),
            "limit": lim,
            "productType": _product_type(mkt),
        }

        # essais: candles -> history-candles (certaines régions)
        try:
            data = self._get("/api/mix/v1/market/candles", params=params)
        except requests.HTTPError:
            data = self._get("/api/mix/v1/market/history-candles", params=params)

        rows = data.get("data") or []
        out: List[List[float]] = []
        for r in reversed(rows):
            ts = int(r[0]); o, h, l, c = map(float, r[1:5]); v = float(r[5])
            out.append([ts, o, h, l, c, v])
        return out

--------------------------------------------------------------------------------
FILE: scalper/exchange/bitget_ccxt.py
--------------------------------------------------------------------------------
# scalper/exchange/bitget_ccxt.py
from __future__ import annotations

import asyncio
import csv
import os
import time
from typing import Any, List, Optional

# CCXT async
try:
    import ccxt.async_support as ccxt
except Exception as e:  # noqa: BLE001
    raise RuntimeError("CCXT n'est pas installé. Fais `pip install ccxt`.") from e


def _now_ms() -> int:
    return int(time.time() * 1000)


class BitgetExchange:
    """
    Échange Bitget via CCXT (async) avec cache CSV local.
    - Orienté SPOT pour simplifier (BTCUSDT, ETHUSDT, ...).
    - fetch_ohlcv(symbol, timeframe, limit) -> list[list] façon CCXT:
        [[ts, open, high, low, close, volume], ...]
    """

    def __init__(
        self,
        *,
        api_key: Optional[str] = None,
        secret: Optional[str] = None,
        password: Optional[str] = None,  # Bitget a souvent "password" (API passphrase)
        data_dir: str = "/notebooks/data",
        use_cache: bool = True,
        min_fresh_seconds: int = 0,  # fraicheur minimale requise (0 = on accepte tout)
        spot: bool = True,           # True = SPOT (recommandé ici)
    ) -> None:
        self.data_dir = data_dir
        self.use_cache = use_cache
        self.min_fresh = int(min_fresh_seconds)
        self.spot = spot

        os.makedirs(self.data_dir, exist_ok=True)

        # Instance CCXT (async)
        self.ex = ccxt.bitget({
            "apiKey": api_key or "",
            "secret": secret or "",
            "password": password or "",
            "enableRateLimit": True,
            # CCXT timeframe natif (pas besoin de rajouter des headers…)
        })

        # Pré‑charge les marchés SPOT pour résoudre correctement symboles
        self._markets_task: Optional[asyncio.Task[Any]] = None

    async def _ensure_markets(self) -> None:
        if self._markets_task is None:
            self._markets_task = asyncio.create_task(self.ex.load_markets())
        await self._markets_task

    # ---------- CSV cache ----------
    def _csv_path(self, symbol: str, timeframe: str) -> str:
        safe = symbol.replace("/", "").replace(":", "")
        return os.path.join(self.data_dir, f"{safe}-{timeframe}.csv")

    def _read_cache(self, path: str) -> List[List[float]]:
        if not os.path.exists(path):
            return []
        rows: List[List[float]] = []
        try:
            with open(path, "r", newline="") as f:
                rd = csv.reader(f)
                for r in rd:
                    if not r:
                        continue
                    # ts, o, h, l, c, v
                    try:
                        rows.append([
                            int(r[0]),
                            float(r[1]),
                            float(r[2]),
                            float(r[3]),
                            float(r[4]),
                            float(r[5]),
                        ])
                    except Exception:
                        # on ignore les lignes corrompues
                        continue
        except Exception:
            return []
        return rows

    def _write_cache(self, path: str, data: List[List[float]]) -> None:
        # On ré‑écrit intégralement (simple et sûr)
        tmp = path + ".tmp"
        with open(tmp, "w", newline="") as f:
            wr = csv.writer(f)
            wr.writerows(data)
        os.replace(tmp, path)

    # ---------- API publique pour orchestrateur ----------
    async def fetch_ohlcv(
        self, symbol: str, timeframe: str, limit: int, since: Optional[int] = None
    ) -> List[List[float]]:
        """
        Conformité orchestrateur : signature (symbol, timeframe, limit).
        Retour CCXT OHLCV. Utilise cache si dispo/assez frais, sinon CCXT.
        """
        await self._ensure_markets()

        # Bitget (spot) symbol format CCXT: "BTC/USDT"
        ccxt_symbol = symbol.replace("USDT", "/USDT")
        cache_path = self._csv_path(symbol, timeframe)

        # 1) Cache
        if self.use_cache:
            cached = self._read_cache(cache_path)
            if cached:
                # fraicheur = diff entre maintenant et ts dernière bougie
                last_ts = int(cached[-1][0])
                if self.min_fresh == 0 or (_now_ms() - last_ts) <= self.min_fresh * 1000:
                    # suffisant => on retourne la fin
                    if len(cached) >= limit:
                        return cached[-limit:]
                    # pas assez, on essaiera de compléter via CCXT plus bas
                # sinon: on tentera de rafraîchir plus loin

        # 2) Remote via CCXT
        # CCXT fetch_ohlcv: since=None, limit=…  (since en ms)
        # On demande 'limit' bougies; si cache partiel, on pourra fusionner ensuite.
        params: dict[str, Any] = {}
        if self.spot is True:
            params["type"] = "spot"  # ccxt bitget accepte 'type' pour certain endpoints

        try:
            ohlcv = await self.ex.fetch_ohlcv(ccxt_symbol, timeframe, since=since, limit=limit, params=params)
        except Exception as e:  # noqa: BLE001
            # En cas d’échec remote: si on a du cache, on le renvoie quand même
            cached = self._read_cache(cache_path) if self.use_cache else []
            if cached:
                return cached[-limit:]
            raise RuntimeError(f"Bitget CCXT fetch_ohlcv failed for {symbol} {timeframe}: {e}") from e

        # 3) Merge simple cache + remote et ré‑écrit (sans doublons sur ts)
        if self.use_cache:
            base = self._read_cache(cache_path)
            merged = _merge_ohlcv(base, ohlcv)
            self._write_cache(cache_path, merged)
            # retourne la fin
            return merged[-limit:]

        return ohlcv[-limit:]

    async def close(self) -> None:
        try:
            await self.ex.close()
        except Exception:
            pass


def _merge_ohlcv(a: List[List[float]], b: List[List[float]]) -> List[List[float]]:
    """
    Fusionne deux listes OHLCV par timestamp, en écrasant a par b sur collision.
    """
    if not a:
        return list(b)
    if not b:
        return list(a)

    # index rapide par ts
    by_ts: dict[int, List[float]] = {int(row[0]): row for row in a}
    for row in b:
        by_ts[int(row[0])] = row
    return [by_ts[k] for k in sorted(by_ts)]

--------------------------------------------------------------------------------
FILE: scalper/exchange/fees.py
--------------------------------------------------------------------------------
# scalper/exchange/fees.py
from __future__ import annotations

from typing import Dict, Iterable

# Valeurs par défaut (Bitget spot/futures ~ ordre de grandeur ; sera écrasé quand on charge les frais)
DEFAULT_TAKER_BPS = 6    # 0.06%
DEFAULT_MAKER_BPS = 2    # 0.02%

# Cache local: symbol -> {"taker_bps": int, "maker_bps": int}
_FEES_BY_SYMBOL: Dict[str, Dict[str, float]] = {}


def get_fee(symbol: str, kind: str = "taker") -> float:
    """
    Retourne le fee rate (fraction, ex 0.0006) pour 'symbol' et 'kind' ("taker" ou "maker").
    Utilise le cache alimenté par load_bitget_fees(), sinon valeurs par défaut.
    """
    rec = _FEES_BY_SYMBOL.get(symbol, {"taker_bps": DEFAULT_TAKER_BPS, "maker_bps": DEFAULT_MAKER_BPS})
    bps = rec["taker_bps"] if kind == "taker" else rec["maker_bps"]
    return float(bps) / 10_000.0


async def load_bitget_fees(exchange, symbols: Iterable[str]) -> Dict[str, Dict[str, float]]:
    """
    Tente de charger les frais auprès de l'exchange (type ccxt):
      - fetch_trading_fees(symbols) si dispo
      - sinon fetch_trading_fee(symbol) pour chaque symbole
    Remplit le cache _FEES_BY_SYMBOL avec des BPS (entiers).
    """
    symbols = list(symbols)
    fees: Dict[str, Dict[str, float]] = {}

    try:
        if hasattr(exchange, "fetch_trading_fees"):
            data = await exchange.fetch_trading_fees(symbols)
            for s in symbols:
                d = (data or {}).get(s, {}) or {}
                taker = float(d.get("taker", DEFAULT_TAKER_BPS / 10_000))
                maker = float(d.get("maker", DEFAULT_MAKER_BPS / 10_000))
                fees[s] = {"taker_bps": round(taker * 10_000), "maker_bps": round(maker * 10_000)}
        else:
            for s in symbols:
                try:
                    d = await exchange.fetch_trading_fee(s)
                except Exception:
                    d = {}
                taker = float(d.get("taker", DEFAULT_TAKER_BPS / 10_000))
                maker = float(d.get("maker", DEFAULT_MAKER_BPS / 10_000))
                fees[s] = {"taker_bps": round(taker * 10_000), "maker_bps": round(maker * 10_000)}
    except Exception:
        # fallback: défauts
        for s in symbols:
            fees[s] = {"taker_bps": DEFAULT_TAKER_BPS, "maker_bps": DEFAULT_MAKER_BPS}

    # maj du cache
    _FEES_BY_SYMBOL.update(fees)
    return fees

--------------------------------------------------------------------------------
FILE: scalper/hooks/prewarm_cache.py
--------------------------------------------------------------------------------
# -*- coding: utf-8 -*-
"""
Pré-chauffe léger du cache OHLCV.

Objectif: ne PAS bloquer le lancement. On log juste un statut "warmup OK"
pour chaque symbole, et on s'assure que le dossier data existe.
Si tu veux rebrancher un vrai downloader plus tard, expose simplement une
fonction `prewarm_cache(cfg, symbols, timeframe, out_dir)` avec la même
signature.
"""
from __future__ import annotations
from pathlib import Path
from typing import Iterable


def prewarm_cache(cfg: dict, symbols: Iterable[str], timeframe: str, out_dir: str | Path) -> None:
    out = Path(out_dir)
    out.mkdir(parents=True, exist_ok=True)
    for sym in symbols:
        # Marqueur vide; permet à d’autres services de voir que le symbole est "préparé"
        (out / f"{sym}-{timeframe}.csv").touch(exist_ok=True)
        print(f"[cache] warmup OK for {sym}")

--------------------------------------------------------------------------------
FILE: scalper/live/__init__.py
--------------------------------------------------------------------------------
__all__ = ["orchestrator", "fetcher", "runner"]

--------------------------------------------------------------------------------
FILE: scalper/live/backtest_telegram.py
--------------------------------------------------------------------------------
# scalper/live/backtest_telegram.py
from __future__ import annotations

import asyncio
import os
from typing import List

from scalper.backtest import BTCfg, run_multi
from scalper.services.utils import safe_call

# Exchange CCXT asynchrone pour OHLCV publics (Bitget)
async def _get_exchange():
    try:
        import ccxt.async_support as ccxt  # type: ignore
    except Exception:
        raise RuntimeError("CCXT n'est pas installé. Lance: pip install ccxt")
    return ccxt.bitget()

def _parse_symbols(defaults: List[str]) -> List[str]:
    env = os.getenv("BACKTEST_SYMBOLS", "")
    if env.strip():
        return [s.strip().upper() for s in env.split(",") if s.strip()]
    return defaults

async def handle_backtest_command(notifier, defaults: List[str], timeframe: str = "5m") -> None:
    """Lancé par l'orchestrateur quand l'utilisateur tape /backtest sur Telegram."""
    symbols = _parse_symbols(defaults)
    cash = float(os.getenv("BT_CASH", "10000"))
    risk = float(os.getenv("BT_RISK_PCT", "0.05"))
    slip = float(os.getenv("BT_SLIPPAGE_BPS", "0.0"))
    limit = int(os.getenv("BT_LIMIT", "1500"))

    await notifier.send(
        "🧪 Backtest en cours...\n"
        f"• Symbols: {', '.join(symbols)}\n"
        f"• TF: {timeframe}\n"
        f"• Cash: {cash:,.0f}  • Risk: {risk:0.4f}  • Slippage: {slip:0.1f} bps\n"
        f"• Source: exchange.fetch_ohlcv (adapté) + cache CSV"
    )

    async def _run():
        exchange = await _get_exchange()
        try:
            cfg = BTCfg(symbols=symbols, timeframe=timeframe, cash=cash,
                        risk_pct=risk, slippage_bps=slip, limit=limit)
            res = await run_multi(cfg, exchange)
            await notifier.send(f"✅ Backtest terminé. Résultats: `{res['out_dir']}`")
        finally:
            try:
                await exchange.close()
            except Exception:
                pass

    try:
        await safe_call(_run, label="backtest", max_retry=1)  # 1 tir = si fail on avertit
    except Exception as e:
        await notifier.send(f"⚠️ Backtest : erreur inattendue: {e}")

--------------------------------------------------------------------------------
FILE: scalper/live/commands.py
--------------------------------------------------------------------------------
# scalper/live/commands.py
from __future__ import annotations

import asyncio
from typing import Awaitable, Callable


class CommandHandler:
    """
    Gère les commandes reçues d'un CommandStream (Telegram ou Null).
    Chaque commande est routée vers un callback approprié.
    Les erreurs de callbacks sont capturées pour ne pas tuer l'orchestrateur.
    """

    def __init__(self, notifier, command_stream, status_getter, status_sender):
        self.notifier = notifier
        self.stream = command_stream
        self.status_getter = status_getter
        self.status_sender = status_sender

    async def _safe_call(self, coro: Awaitable[None], err_msg: str) -> None:
        try:
            await coro
        except Exception as e:
            try:
                await self.notifier.send(f"⚠️ {err_msg}: {e}")
            except Exception:
                pass  # on ne propage jamais

    async def run(
        self,
        on_pause: Callable[[], None],
        on_resume: Callable[[], None],
        on_stop: Callable[[], Awaitable[None]] | None,
        on_setup_apply: Callable[[dict], None],
        on_backtest: Callable[[str], Awaitable[None]] | None = None,
    ):
        """
        Boucle asynchrone qui lit les lignes du CommandStream
        et exécute le callback approprié.
        TOUTE exception de callback est absorbée pour ne pas terminer cette task.
        """
        async for line in self.stream:
            txt = (line or "").strip()
            if not txt:
                continue

            try:
                if txt.startswith("/pause"):
                    on_pause()
                    await self.notifier.send("⏸️ Pause.")

                elif txt.startswith("/resume"):
                    on_resume()
                    await self.notifier.send("▶️ Resume.")

                elif txt.startswith("/stop"):
                    if on_stop:
                        await self._safe_call(on_stop(), "Arrêt échoué")

                elif txt.startswith("/status"):
                    snap = self.status_getter()
                    await self.notifier.send(f"ℹ️ {snap}")

                elif txt.startswith("/setup"):
                    await self.notifier.send("🧩 Setup wizard à compléter.")

                elif txt.startswith("/backtest"):
                    if on_backtest:
                        tail = txt[len("/backtest"):].strip()
                        # IMPORTANT : on ne bloque PAS la boucle de commandes.
                        asyncio.create_task(self._safe_call(
                            on_backtest(tail), "Backtest échoué"
                        ))
                        await self.notifier.send("🧪 Backtest lancé en tâche de fond.")
                    else:
                        await self.notifier.send("⚠️ Backtest non disponible.")

                else:
                    await self.notifier.send(
                        "❓ Commandes: /status /pause /resume /stop /setup /backtest"
                    )

            except Exception as e:
                # On protège la boucle quoi qu'il arrive
                try:
                    await self.notifier.send(f"⚠️ Erreur commande: {e}")
                except Exception:
                    pass

--------------------------------------------------------------------------------
FILE: scalper/live/data_utils.py
--------------------------------------------------------------------------------
# scalper/live/data_utils.py
from __future__ import annotations
from typing import Dict, List, Sequence

Cols = ("timestamp", "open", "high", "low", "close", "volume")

def ohlcv_rows_to_dict(rows: Sequence[Sequence[float]]) -> Dict[str, List[float]]:
    """
    Convertit [[ts,o,h,l,c,v], ...] -> dict de listes.
    Tolère float|int|str numériques.
    """
    out: Dict[str, List[float]] = {k: [] for k in Cols}
    for r in rows:
        if len(r) < 6:
            raise ValueError("Ligne OHLCV invalide (6 colonnes attendues).")
        out["timestamp"].append(float(r[0]))
        out["open"].append(float(r[1]))
        out["high"].append(float(r[2]))
        out["low"].append(float(r[3]))
        out["close"].append(float(r[4]))
        out["volume"].append(float(r[5]))
    return out

def ohlcv_df_or_dict_to_dict(obj) -> Dict[str, List[float]]:
    """
    Accepte:
      - pandas.DataFrame avec colonnes Cols
      - dict de listes
    """
    if hasattr(obj, "columns"):
        missing = [c for c in Cols if c not in obj.columns]
        if missing:
            raise ValueError(f"Colonnes OHLCV manquantes: {missing}")
        return {k: [float(x) for x in obj[k].tolist()] for k in Cols}
    if isinstance(obj, dict):
        missing = [c for c in Cols if c not in obj]
        if missing:
            raise ValueError(f"Clés OHLCV manquantes: {missing}")
        return {k: [float(x) for x in obj[k]] for k in Cols}
    raise TypeError("Format OHLCV non supporté (DataFrame ou dict attendu).")

def map_index_secondary(ts_main: float, ts_arr: List[float]) -> int:
    """
    Retourne l'index i du timestamp secondaire le plus proche
    inférieur/égal à ts_main. Recherche linéaire suffisante en live.
    """
    j = 0
    n = len(ts_arr)
    while j + 1 < n and ts_arr[j + 1] <= ts_main:
        j += 1
    return j

--------------------------------------------------------------------------------
FILE: scalper/live/fetcher.py
--------------------------------------------------------------------------------
# scalper/live/fetcher.py
from __future__ import annotations
from typing import Dict, List, Optional, Any

class DataFetcher:
    """
    Récupération OHLCV depuis un client d'exchange.
    Compatible:
      - Wrapper custom: client.get_ohlcv(symbol, timeframe, limit)
      - ccxt direct:    client.fetch_ohlcv(symbol, timeframe=..., limit=...)
    Retour standardisé: dict[str, list[float]] avec clés:
      timestamp, open, high, low, close, volume
    """
    def __init__(self, client: Any) -> None:
        self.client = client
        # Détection des méthodes disponibles
        self._has_get = hasattr(client, "get_ohlcv")
        self._has_fetch = hasattr(client, "fetch_ohlcv")

        if not (self._has_get or self._has_fetch):
            raise AttributeError(
                "Le client exchange doit exposer get_ohlcv(...) ou fetch_ohlcv(...). "
                "Ex: wrapper custom ou objet ccxt.bitget."
            )

    @staticmethod
    def _to_dict(rows: List[List[float]]) -> Dict[str, List[float]]:
        cols = ("timestamp", "open", "high", "low", "close", "volume")
        out = {k: [] for k in cols}
        for r in rows:
            # rows: [ts, open, high, low, close, volume]
            out["timestamp"].append(float(r[0]))
            out["open"].append(float(r[1]))
            out["high"].append(float(r[2]))
            out["low"].append(float(r[3]))
            out["close"].append(float(r[4]))
            out["volume"].append(float(r[5]))
        return out

    def fetch(self, symbol: str, timeframe: str, limit: int = 1500) -> Dict[str, List[float]]:
        if self._has_get:
            rows = self.client.get_ohlcv(symbol=symbol, timeframe=timeframe, limit=limit)
        else:
            # ccxt: fetch_ohlcv(symbol, timeframe=..., limit=...)
            rows = self.client.fetch_ohlcv(symbol, timeframe=timeframe, limit=limit)
        return self._to_dict(rows)

    def try_fetch_1h(self, symbol: str, limit: int = 1500) -> Optional[Dict[str, List[float]]]:
        try:
            if self._has_get:
                rows = self.client.get_ohlcv(symbol=symbol, timeframe="1h", limit=limit)
            else:
                rows = self.client.fetch_ohlcv(symbol, timeframe="1h", limit=limit)
            return self._to_dict(rows)
        except Exception:
            return None

--------------------------------------------------------------------------------
FILE: scalper/live/journal.py
--------------------------------------------------------------------------------
from __future__ import annotations
import os, csv
from typing import Any, Dict, List

class LogWriter:
    """Gestion simple des CSV (création à la volée + append)."""
    def __init__(self, dirpath: str) -> None:
        self.dir = dirpath
        os.makedirs(self.dir, exist_ok=True)

    def init(self, fname: str, headers: List[str]) -> None:
        p = os.path.join(self.dir, fname)
        if not os.path.exists(p):
            with open(p, "w", newline="", encoding="utf-8") as f:
                csv.DictWriter(f, fieldnames=headers).writeheader()

    def row(self, fname: str, row: Dict[str, Any]) -> None:
        p = os.path.join(self.dir, fname)
        with open(p, "a", newline="", encoding="utf-8") as f:
            csv.DictWriter(f, fieldnames=list(row.keys())).writerow(row)

--------------------------------------------------------------------------------
FILE: scalper/live/logs.py
--------------------------------------------------------------------------------
# scalp/live/logs.py
from __future__ import annotations
import os, csv
from typing import Any, List, Dict

class CsvLog:
    def __init__(self, path: str, headers: List[str]):
        self.path = path
        self.headers = headers
        self._ensure_header()

    def _ensure_header(self):
        must_write = not os.path.exists(self.path) or os.path.getsize(self.path) == 0
        os.makedirs(os.path.dirname(self.path), exist_ok=True)
        if must_write:
            with open(self.path, "w", newline="") as f:
                csv.writer(f).writerow(self.headers)

    def write_row(self, row: Dict[str, Any]):
        with open(self.path, "a", newline="") as f:
            w = csv.DictWriter(f, fieldnames=self.headers)
            w.writerow({k: row.get(k, "") for k in self.headers})

--------------------------------------------------------------------------------
FILE: scalper/live/loops/trade.py
--------------------------------------------------------------------------------
# scalp/live/loops/trade.py
from __future__ import annotations
import asyncio, os
from dataclasses import dataclass, field
from typing import Any, Dict, List, Callable

from ...services.utils import safe_call
from ...risk.manager import compute_size

QUIET = int(os.getenv("QUIET", "0") or "0")
PRINT_OHLCV_SAMPLE = int(os.getenv("PRINT_OHLCV_SAMPLE", "0") or "0")

class PositionFSM:
    def __init__(self):
        self.state = "FLAT"
        self.side = "flat"
        self.entry = 0.0
        self.qty = 0.0
    def can_open(self): return self.state == "FLAT"
    def on_open(self, side, entry, qty): self.state, self.side, self.entry, self.qty = "OPEN", side, entry, qty
    def can_close(self): return self.state == "OPEN"
    def on_close(self): self.state, self.side, self.entry, self.qty = "FLAT", "flat", 0.0, 0.0

@dataclass
class SymbolContext:
    symbol: str
    timeframe: str
    ohlcv: List[List[float]] = field(default_factory=list)
    ticks: int = 0
    fsm: PositionFSM = field(default_factory=PositionFSM)

class TradeLoop:
    """
    Boucle par symbole, indépendante de l'orchestrateur.
    """
    def __init__(
        self,
        symbol: str,
        timeframe: str,
        ohlcv_fetch: Callable[..., Any],           # async fn(symbol, timeframe, limit) -> ohlcv
        order_market: Callable[..., Any],          # async fn(symbol, side, qty) -> order dict
        generate_signal: Callable[[List[List[float]], Dict[str, Any]], Dict[str, Any]],
        config: Dict[str, Any],
        mode_getter: Callable[[], str],
        log_signals, log_orders, log_fills,
        tick_counter_add: Callable[[int], None],
    ):
        self.symbol = symbol
        self.timeframe = timeframe
        self.fetch = ohlcv_fetch
        self.order_market = order_market
        self.generate_signal = generate_signal
        self.config = config
        self.get_mode = mode_getter
        self.log_signals = log_signals
        self.log_orders = log_orders
        self.log_fills = log_fills
        self.ctx = SymbolContext(symbol, timeframe)
        self._tick_add = tick_counter_add

        # Risk/frais
        self.risk_pct = float(self.config.get("risk_pct", 0.5))
        self.caps_by_symbol = self.config.get("caps", {})  # dict optionnel
        self.fees_map = self.config.get("fees_by_symbol", {})  # {sym: {"maker_bps":..., "taker_bps":...}}
        self.slippage_bps = float(self.config.get("slippage_bps", 0.0))

    def _bps_for(self, order_type: str = "market") -> float:
        # market -> taker; limit post-only -> maker
        per = self.fees_map.get(self.symbol, {})
        if order_type == "limit":
            return float(per.get("maker_bps", 0.0))
        return float(per.get("taker_bps", 0.0))

    async def run(self, running: Callable[[], bool]):
        lookback = 200
        while running():
            if self.get_mode() != "RUNNING":
                await asyncio.sleep(0.5); continue

            async def _fetch():
                return await self.fetch(self.symbol, timeframe=self.timeframe, limit=lookback+2)
            ohlcv = await safe_call(_fetch, label=f"fetch_ohlcv:{self.symbol}")
            if not ohlcv or len(ohlcv) < lookback+1:
                await asyncio.sleep(1.0); continue

            self.ctx.ohlcv = ohlcv
            self.ctx.ticks += 1
            self._tick_add(1)

            window = ohlcv[-(lookback+1):]
            ts, _o, _h, _l, c, _v = window[-1]

            try:
                sig = self.generate_signal(window, self.config) or {}
            except Exception as e:
                if not QUIET:
                    print(f"[trade:{self.symbol}] generate_signal error: {e}", flush=True)
                await asyncio.sleep(0.5); continue

            side = sig.get("side","flat"); entry = float(sig.get("entry", c)); sl = sig.get("sl"); tp = sig.get("tp")
            self.log_signals.write_row({"ts": ts, "symbol": self.symbol, "side": side, "entry": entry, "sl": sl, "tp": tp, "last": c})

            # --- Entrée (market -> taker)
            if self.ctx.fsm.state == "FLAT" and side in ("long","short"):
                balance = float(self.config.get("cash", 10_000.0))
                qty = compute_size(
                    symbol=self.symbol, price=entry or c, balance_cash=balance,
                    risk_pct=self.risk_pct, caps_by_symbol=self.caps_by_symbol
                )
                if qty > 0:
                    async def _place():
                        return await self.order_market(self.symbol, side, qty)
                    order = await safe_call(_place, label=f"order:{self.symbol}")
                    self.ctx.fsm.on_open(side, entry or c, qty)
                    self.log_orders.write_row({"ts": ts, "symbol": self.symbol, "side": side, "qty": qty,
                                               "status": "placed", "order_id": (order or {}).get("id",""), "note": f"entry taker={self._bps_for('market')}bps"})

            # --- Sortie (market -> taker)
            elif self.ctx.fsm.state == "OPEN" and (side == "flat" or (side in ("long","short") and side != self.ctx.fsm.side)):
                qty = self.ctx.fsm.qty
                exit_side = "sell" if self.ctx.fsm.side == "long" else "buy"
                async def _close():
                    return await self.order_market(self.symbol, exit_side, qty)
                order = await safe_call(_close, label=f"close:{self.symbol}")

                # fill avec slippage + frais (taker)
                price_fill = float(c)
                price_fill *= (1 + (self.slippage_bps/10000.0)) if exit_side == "buy" else (1 - (self.slippage_bps/10000.0))
                self.log_orders.write_row({"ts": ts, "symbol": self.symbol, "side": exit_side, "qty": qty,
                                           "status": "placed", "order_id": (order or {}).get("id",""), "note": f"exit taker={self._bps_for('market')}bps"})
                self.log_fills.write_row({"ts": ts, "symbol": self.symbol, "side": exit_side, "price": price_fill, "qty": qty,
                                          "order_id": (order or {}).get("id","")})
                self.ctx.fsm.on_close()

            if PRINT_OHLCV_SAMPLE and (self.ctx.ticks % 20 == 0) and not QUIET:
                print(f"[{self.symbol}] last={c} ticks={self.ctx.ticks}", flush=True)

            await asyncio.sleep(0.1 if QUIET else 0.01)

--------------------------------------------------------------------------------
FILE: scalper/live/notify.py
--------------------------------------------------------------------------------
# -*- coding: utf-8 -*-
from __future__ import annotations
import os
import asyncio
from dataclasses import dataclass
from typing import AsyncIterator, Optional


@dataclass
class BaseNotifier:
    async def send(self, text: str) -> None:  # pragma: no cover
        print(text)


class NullNotifier(BaseNotifier):
    pass


class TelegramNotifier(BaseNotifier):
    def __init__(self, token: str, chat_id: str, session: Optional[asyncio.AbstractEventLoop]=None):
        import aiohttp  # lazy
        self._token = token
        self._chat = chat_id
        self._session: aiohttp.ClientSession | None = None

    async def _ensure(self):
        import aiohttp
        if self._session is None or self._session.closed:
            self._session = aiohttp.ClientSession()

    async def send(self, text: str) -> None:
        import aiohttp
        await self._ensure()
        # pas de markdown pour éviter les erreurs 400 de parsing
        url = f"https://api.telegram.org/bot{self._token}/sendMessage"
        payload = {"chat_id": self._chat, "text": text, "disable_web_page_preview": True}
        try:
            async with self._session.post(url, json=payload, timeout=20) as r:
                await r.text()  # on ignore la réponse pour rester simple
        except Exception:
            # on fait un fallback silencieux pour ne pas casser le bot
            print("[notify:telegram] send fail (ignored)")

    async def close(self):
        if self._session and not self._session.closed:
            await self._session.close()


class _NullCommands:
    """Itérateur async vide utilisé quand Telegram n'est pas configuré."""
    def __aiter__(self) -> AsyncIterator[str]:
        return self
    async def __anext__(self) -> str:
        await asyncio.sleep(3600)  # jamais
        raise StopAsyncIteration


async def build_notifier_and_commands(config: dict) -> tuple[BaseNotifier, AsyncIterator[str]]:
    """
    Retourne (notifier, command_stream).

    - Si TELEGRAM_BOT_TOKEN et TELEGRAM_CHAT_ID sont présents: TelegramNotifier,
      et un flux (vide) – l’orchestreur n’en a besoin que si on implémente des
      commandes interactives plus tard.
    - Sinon: NullNotifier + flux vide.
    """
    token = os.getenv("TELEGRAM_BOT_TOKEN")
    chat = os.getenv("TELEGRAM_CHAT_ID")
    if token and chat:
        print("[notify] TELEGRAM configured.")
        return TelegramNotifier(token, chat), _NullCommands()
    print("[notify] TELEGRAM not configured -> Null notifier will be used.")
    return NullNotifier(), _NullCommands()

--------------------------------------------------------------------------------
FILE: scalper/live/ohlcv_service.py
--------------------------------------------------------------------------------
from __future__ import annotations
import time
from typing import Any, Dict, List, Optional

try:
    from scalper.adapters.market_data import MarketData
except Exception:
    MarketData = None  # type: ignore

class OhlcvService:
    """Lecture/normalisation OHLCV avec fallback agressifs."""
    def __init__(self, exchange) -> None:
        self.exchange = exchange
        self.md = MarketData(exchange) if MarketData is not None else None

    @staticmethod
    def normalize_rows(rows: Any) -> List[Dict[str, float]]:
        out: List[Dict[str, float]] = []
        if not rows: return out
        for r in rows:
            if isinstance(r, dict):
                ts = int(r.get("ts") or r.get("time") or r.get("timestamp") or 0)
                o = float(r.get("open", 0.0)); h = float(r.get("high", o)); l = float(r.get("low", o)); c = float(r.get("close", o))
                v = float(r.get("volume", r.get("vol", 0.0)))
            else:
                rr = list(r)
                if len(rr) >= 6 and isinstance(rr[0], (int, float)) and rr[0] > 10**10:
                    ts, o, h, l, c = int(rr[0]), float(rr[1]), float(rr[2]), float(rr[3]), float(rr[4]); v = float(rr[5])
                else:
                    o = float(rr[0]) if len(rr) > 0 else 0.0
                    h = float(rr[1]) if len(rr) > 1 else o
                    l = float(rr[2]) if len(rr) > 2 else o
                    c = float(rr[3]) if len(rr) > 3 else o
                    v = float(rr[4]) if len(rr) > 4 else 0.0
                    ts = int(rr[5]) if len(rr) > 5 else 0
            out.append({"ts": ts, "open": o, "high": h, "low": l, "close": c, "volume": v})
        return out

    async def fetch_once(self, symbol: str, interval: str = "1m", limit: int = 100) -> List[Dict[str, float]]:
        # 1) MarketData (si dispo)
        if self.md is not None:
            try:
                d = self.md.get_ohlcv(symbol, interval, limit)
                if isinstance(d, dict) and d.get("success") and d.get("data"):
                    return self.normalize_rows(d["data"])
            except Exception:
                pass

        # 2) Exchange natif
        rows: List[Any] = []
        try:
            data = self.exchange.get_kline(symbol, interval=interval)
        except Exception:
            data = None

        if isinstance(data, dict):
            rows = (
                data.get("data") or data.get("result") or data.get("records") or
                data.get("list") or data.get("items") or data.get("candles") or []
            )
            guard = 0
            while isinstance(rows, dict) and guard < 3:
                rows = (
                    rows.get("data") or rows.get("result") or rows.get("records") or
                    rows.get("list") or rows.get("items") or rows.get("candles") or rows.get("klines") or rows.get("bars") or []
                )
                guard += 1
        elif isinstance(data, (list, tuple)):
            rows = list(data)

        out = self.normalize_rows(rows)[-limit:]
        if out: return out

        # 3) Fallback strict via ticker -> bougie synthétique
        try:
            tkr = self.exchange.get_ticker(symbol)
            items = []
            if isinstance(tkr, dict): items = tkr.get("data") or tkr.get("result") or tkr.get("tickers") or []
            elif isinstance(tkr, (list, tuple)): items = list(tkr)
            if items:
                last = items[0]
                if isinstance(last, dict):
                    p = float(last.get("lastPrice", last.get("close", last.get("markPrice", 0.0))))
                    v = float(last.get("volume", last.get("usdtVolume", last.get("quoteVolume", 0.0))))
                else:
                    seq = list(last); p = float(seq[3] if len(seq) > 3 else seq[-2]); v = float(seq[4] if len(seq) > 4 else seq[-1])
                ts = int(time.time()*1000)
                return [{"ts": ts, "open": p, "high": p, "low": p, "close": p, "volume": v}]
        except Exception:
            pass
        return []

--------------------------------------------------------------------------------
FILE: scalper/live/orchestrator.py
--------------------------------------------------------------------------------
# scalper/live/orchestrator.py
from __future__ import annotations
import time
from typing import List, Tuple, Dict, Any
from scalper.live.fetcher import DataFetcher
from scalper.live.runner import JobRunner

class Orchestrator:
    def __init__(
        self,
        *,
        exchange_client: Any,
        strategies_cfg: Dict[str, Any],
        jobs: List[Tuple[str, str]],   # [(symbol, timeframe)]
        interval_sec: int = 60,
        equity: float = 1000.0,
        risk_pct: float = 0.01,
    ) -> None:
        self.fetcher = DataFetcher(exchange_client)
        self.runner = JobRunner(strategies_cfg, equity, risk_pct)
        self.jobs = [(s.upper(), tf) for s, tf in jobs]
        self.interval = max(5, int(interval_sec))

    def _tick(self) -> None:
        for symbol, tf in self.jobs:
            try:
                data = self.fetcher.fetch(symbol, tf)
                data_1h = self.fetcher.try_fetch_1h(symbol)
                sig = self.runner.run_once(symbol=symbol, timeframe=tf, ohlcv=data, ohlcv_1h=data_1h)
                if sig is None:
                    print(f"[{symbol}/{tf}] Aucun signal.")
                else:
                    d = sig.as_dict()
                    print(f"[{symbol}/{tf}] side={d['side']} entry={d['entry']:.6f} "
                          f"sl={d['sl']:.6f} tp1={d['tp1']:.6f} tp2={d['tp2']:.6f} "
                          f"score={d['score']} q={d['quality']:.2f} :: {d.get('reasons','')}")
            except Exception as e:
                print(f"[{symbol}/{tf}] ERREUR: {e}")

    def loop(self) -> None:
        print(f"[Orchestrator] jobs={self.jobs} interval={self.interval}s")
        while True:
            t0 = time.time()
            self._tick()
            dt = time.time() - t0
            time.sleep(max(0.0, self.interval - dt))

--------------------------------------------------------------------------------
FILE: scalper/live/orders.py
--------------------------------------------------------------------------------
# live/orders.py
from __future__ import annotations
from dataclasses import dataclass
from typing import Any, Optional

from scalper.services.order_service import OrderService, OrderRequest

@dataclass
class OrderResult:
    accepted: bool
    order_id: str | None = None
    status: str | None = None
    reason: str | None = None

class OrderExecutor:
    """
    Fine couche autour d'OrderService + exchange :
      - calcule l'équité USDT
      - place une entrée (risk_pct)
      - récupère les fills (normalisés)
    L'orchestrateur n’appelle plus OrderService directement.
    """

    def __init__(self, order_service: OrderService, exchange: Any, config: Any) -> None:
        self.order_service = order_service
        self.exchange = exchange
        self.config = config

    # ---------- Equity ----------
    def get_equity_usdt(self) -> float:
        equity = 0.0
        try:
            assets = self.exchange.get_assets()
            if isinstance(assets, dict):
                for a in (assets.get("data") or []):
                    if str(a.get("currency")).upper() == "USDT":
                        equity = float(a.get("equity", 0.0))
                        break
        except Exception:
            pass
        return equity

    # ---------- Entrée ----------
    def place_entry(self, *, symbol: str, side: str, price: float,
                    sl: float | None, tp: float | None, risk_pct: float) -> OrderResult:
        """
        side: 'long' | 'short'
        Retourne OrderResult(accepted, order_id, status, reason)
        """
        equity = self.get_equity_usdt()
        req = OrderRequest(symbol=symbol, side=side, price=float(price),
                           sl=(float(sl) if sl else None), tp=(float(tp) if tp else None),
                           risk_pct=float(risk_pct))
        try:
            res = self.order_service.prepare_and_place(equity, req)
            return OrderResult(accepted=bool(getattr(res, "accepted", False)),
                               order_id=getattr(res, "order_id", None),
                               status=getattr(res, "status", None),
                               reason=getattr(res, "reason", None))
        except Exception as e:
            return OrderResult(accepted=False, reason=str(e))

    # ---------- Fills ----------
    def fetch_fills(self, symbol: str, order_id: str | None, limit: int = 50) -> list[dict]:
        """
        Normalise le format en liste de dicts {orderId, tradeId, price, qty, fee}
        """
        try:
            raw = self.exchange.get_fills(symbol, order_id, limit)
        except Exception:
            return []

        items: list = []
        if isinstance(raw, dict):
            items = raw.get("data") or raw.get("result") or raw.get("fills") or []
        elif isinstance(raw, (list, tuple)):
            items = list(raw)

        out: list[dict] = []
        for f in items:
            if isinstance(f, dict):
                out.append({
                    "orderId": f.get("orderId") or f.get("order_id") or "",
                    "tradeId": f.get("tradeId") or f.get("trade_id") or "",
                    "price": float(f.get("price", f.get("fillPrice", 0.0)) or 0.0),
                    "qty": float(f.get("qty", f.get("size", f.get("fillQty", 0.0))) or 0.0),
                    "fee": float(f.get("fee", f.get("fillFee", 0.0)) or 0.0),
                })
            else:
                try:
                    seq = list(f)
                    out.append({
                        "orderId": str(seq[0]) if seq else "",
                        "tradeId": str(seq[1]) if len(seq) > 1 else "",
                        "price": float(seq[2]) if len(seq) > 2 else 0.0,
                        "qty": float(seq[3]) if len(seq) > 3 else 0.0,
                        "fee": float(seq[4]) if len(seq) > 4 else 0.0,
                    })
                except Exception:
                    continue
        return out

--------------------------------------------------------------------------------
FILE: scalper/live/position_fsm.py
--------------------------------------------------------------------------------
# live/position_fsm.py
from __future__ import annotations
from dataclasses import dataclass
from typing import Optional, Dict, Any, List


STATE_FLAT = "FLAT"
STATE_PENDING_ENTRY = "PENDING_ENTRY"
STATE_OPEN = "OPEN"
STATE_PENDING_EXIT = "PENDING_EXIT"


@dataclass
class PositionState:
    symbol: str
    state: str = STATE_FLAT
    order_id: Optional[str] = None
    side: Optional[str] = None   # "long" | "short"
    qty: float = 0.0
    entry: float = 0.0


class PositionFSM:
    """
    FSM ultra-simple par symbole.
    - set_pending_entry(order_id, side)
    - reconcile(open_positions, fills) -> met à jour l'état à partir des données Bitget
    """

    def __init__(self, symbols: List[str]) -> None:
        self._by_symbol: Dict[str, PositionState] = {s: PositionState(s) for s in symbols}

    # -------- API utilisateur --------
    def ensure_symbol(self, symbol: str) -> None:
        if symbol not in self._by_symbol:
            self._by_symbol[symbol] = PositionState(symbol)

    def set_pending_entry(self, symbol: str, order_id: str, side: str) -> None:
        self.ensure_symbol(symbol)
        st = self._by_symbol[symbol]
        st.state = STATE_PENDING_ENTRY
        st.order_id = order_id
        st.side = side

    def mark_pending_exit(self, symbol: str) -> None:
        self.ensure_symbol(symbol)
        st = self._by_symbol[symbol]
        st.state = STATE_PENDING_EXIT

    def force_flat(self, symbol: str) -> None:
        self._by_symbol[symbol] = PositionState(symbol)

    # -------- Lecture --------
    def get(self, symbol: str) -> PositionState:
        self.ensure_symbol(symbol)
        return self._by_symbol[symbol]

    def all(self) -> Dict[str, PositionState]:
        return self._by_symbol

    # -------- Réconciliation --------
    def reconcile(self, open_positions: List[Dict[str, Any]], fills: Dict[str, List[Dict[str, Any]]]) -> None:
        """
        open_positions: liste [{symbol, side, qty, avgEntryPrice}]
        fills: dict symbol -> liste de fills [{orderId, price, qty, ...}]
        """
        # indexer positions ouvertes
        idx_open = {p["symbol"]: p for p in open_positions if float(p.get("qty", 0.0)) > 0.0}

        for sym, st in self._by_symbol.items():
            p = idx_open.get(sym)

            if st.state == STATE_PENDING_ENTRY:
                # si on voit des fills de l'ordre en attente -> OPEN
                f_list = fills.get(sym) or []
                qty_filled = sum(float(f.get("qty", 0.0)) for f in f_list if not st.order_id or str(f.get("orderId")) == str(st.order_id))
                if qty_filled > 0.0 or p:
                    st.state = STATE_OPEN
                    st.qty = float(p.get("qty", qty_filled)) if p else qty_filled
                    st.entry = float(p.get("avgEntryPrice", f_list[0].get("price", 0.0) if f_list else 0.0)) if p else \
                               float(f_list[0].get("price", 0.0)) if f_list else 0.0
            elif st.state == STATE_OPEN:
                # si plus de position ouverte -> FLAT
                if not p:
                    st.state = STATE_FLAT
                    st.order_id = None
                    st.side = None
                    st.qty = 0.0
                    st.entry = 0.0
                else:
                    st.qty = float(p.get("qty", st.qty))
                    st.entry = float(p.get("avgEntryPrice", st.entry))
            elif st.state == STATE_PENDING_EXIT:
                # si plus de position -> FLAT ; sinon reste OPEN
                if not p:
                    st.state = STATE_FLAT
                    st.order_id = None
                    st.side = None
                    st.qty = 0.0
                    st.entry = 0.0
                else:
                    st.state = STATE_OPEN  # pas encore clos
            else:
                # FLAT: si une position apparaît (cas reboot) -> OPEN
                if p:
                    st.state = STATE_OPEN
                    st.qty = float(p.get("qty", 0.0))
                    st.entry = float(p.get("avgEntryPrice", 0.0))

--------------------------------------------------------------------------------
FILE: scalper/live/runner.py
--------------------------------------------------------------------------------
# scalper/live/runner.py
from __future__ import annotations
from typing import Dict, List, Optional
from scalper.signals.factory import resolve_signal_fn

class JobRunner:
    def __init__(self, strategies_cfg: dict, equity: float, risk_pct: float) -> None:
        self.cfg = strategies_cfg
        self.equity = float(equity)
        self.risk = float(risk_pct)

    def run_once(
        self, *, symbol: str, timeframe: str,
        ohlcv: Dict[str, List[float]],
        ohlcv_1h: Optional[Dict[str, List[float]]] = None
    ):
        fn = resolve_signal_fn(symbol, timeframe, self.cfg)
        return fn(
            symbol=symbol, timeframe=timeframe, ohlcv=ohlcv,
            equity=self.equity, risk_pct=self.risk, ohlcv_1h=ohlcv_1h
        )

--------------------------------------------------------------------------------
FILE: scalper/live/setup_wizard.py
--------------------------------------------------------------------------------
from __future__ import annotations
import asyncio, os
from dataclasses import dataclass
from typing import List, Dict, Optional, Callable
from ..signals.factory import load_signal
from ..backtest.runner import BacktestRunner
from .notify import Notifier, CommandStream

@dataclass
class SetupResult:
    strategy: str
    symbols: List[str]
    timeframes: List[str]
    risk_pct: float
    accepted: bool
    summary_path: str

class SetupWizard:
    """
    Wizard interactif Telegram avant lancement des trades.
    Utilise Notifier (send/send_menu) + CommandStream (async iterator).
    """
    def __init__(self, notifier: Notifier, cmd_stream: CommandStream,
                 ohlcv_loader_sync: Callable, out_dir: str = "out_bt_setup",
                 admin_chat_id: Optional[int]=None):
        self.notifier = notifier
        self.cmd_stream = cmd_stream
        self.loader = ohlcv_loader_sync
        self.out_dir = out_dir
        self.admin_chat_id = admin_chat_id

    async def _ask_list(self, prompt: str, choices: List[str], allow_multi=True) -> List[str]:
        await self.notifier.send_menu(prompt, choices)
        async for msg in self.cmd_stream:
            txt = msg.strip()
            if allow_multi and ("," in txt or " " in txt):
                sel = [t.strip() for t in txt.replace(" ", "").split(",") if t.strip()]
                return sel
            if txt.isdigit():
                i = int(txt)-1
                if 0 <= i < len(choices):
                    return [choices[i]]
            if txt in choices:
                return [txt]
            await self.notifier.send("Entrée invalide. Réessaie.")

    async def _ask_value(self, prompt: str, cast: Callable, default):
        await self.notifier.send(f"{prompt} (défaut: {default})")
        async for msg in self.cmd_stream:
            txt = msg.strip()
            if txt == "" or txt.lower() in ("d","defaut","default"):
                return default
            try:
                return cast(txt)
            except Exception:
                await self.notifier.send("Entrée invalide. Réessaie.")

    async def run(self, default_symbols: List[str], default_timeframes: List[str],
                  default_strategy: str="current") -> SetupResult:
        await self.notifier.send("🧪 Validation avant trading : choix strat/symbols/TF → backtest → validation.")
        # 1) stratégie
        strategies = ["current","ema_cross","vwap_break"]
        [strategy] = await self._ask_list("Choisis la stratégie :", strategies, allow_multi=False)

        # 2) symboles
        symbols = await self._ask_list("Sélectionne les symboles :", default_symbols, allow_multi=True)

        # 3) timeframes
        timeframes = await self._ask_list("Sélectionne les timeframes :", default_timeframes, allow_multi=True)

        # 4) risk %
        risk_pct = await self._ask_value("Risk % du solde (ex: 0.5 = 50%)", float, 0.5)

        # 5) période backtest
        start = await self._ask_value("Date de début (YYYY-MM-DD)", str, "2024-01-01")
        end   = await self._ask_value("Date de fin   (YYYY-MM-DD)", str, "2025-08-01")

        # 6) run backtest
        from ..backtest.cli import parse_ts
        start_ms, end_ms = parse_ts(start), parse_ts(end)
        runner = BacktestRunner(self.loader, self.out_dir, strategy,
                                cfg={}, cash=10_000.0, risk_pct=risk_pct, max_conc=6)
        res = await runner.run_all(symbols, timeframes, start_ms, end_ms)

        # 7) résumé
        sum_path = os.path.join(self.out_dir, "metrics.json")
        prop = res["proposal"]
        lines = ["**Proposition** :"]
        for sym, best in prop["per_symbol_best"].items():
            lines.append(f"• {sym}: {best['timeframe']}  score={best['score']:.3f}  PF={best['pf']:.2f}  WR={best['winrate']:.1%}  DD={best['maxdd']:.1%}")
        await self.notifier.send("\n".join(lines) + f"\nFichier: {sum_path}\n✅ Tape **ACCEPTER** pour lancer\n🔁 **MODIFIER** pour relancer\n❌ **ANNULER** pour quitter.")

        # 8) décision
        async for msg in self.cmd_stream:
            t = msg.strip().lower()
            if t in ("accepter","accept","ok","go","start"):
                await self.notifier.send("✅ Validation reçue — passage en RUNNING.")
                return SetupResult(strategy, symbols, timeframes, risk_pct, True, sum_path)
            if t in ("modifier","again","repeat"):
                return await self.run(default_symbols, default_timeframes, default_strategy=strategy)
            if t in ("annuler","cancel","stop"):
                await self.notifier.send("❌ Annulé.")
                return SetupResult(strategy, symbols, timeframes, risk_pct, False, sum_path)

--------------------------------------------------------------------------------
FILE: scalper/live/state_store.py
--------------------------------------------------------------------------------
# live/state_store.py
from __future__ import annotations
import json, os, time, asyncio
from typing import Callable, Dict, Any

class StateStore:
    """
    Persistance légère de l'état (FSM + horodatages) dans un JSON.
    - save_state(snapshot: dict) -> écrit sur disque
    - load_state() -> dict
    - task_autosave(get_snapshot: callable) -> boucle d’auto‑save
    """

    def __init__(self, filepath: str, period_s: float = 10.0) -> None:
        self.filepath = filepath
        self.period_s = period_s
        os.makedirs(os.path.dirname(self.filepath), exist_ok=True)
        self._running = False

    # -------- I/O --------
    def save_state(self, snapshot: Dict[str, Any]) -> None:
        tmp = self.filepath + ".tmp"
        with open(tmp, "w", encoding="utf-8") as f:
            json.dump(snapshot, f, ensure_ascii=False, indent=2)
        os.replace(tmp, self.filepath)

    def load_state(self) -> Dict[str, Any]:
        if not os.path.exists(self.filepath):
            return {}
        try:
            with open(self.filepath, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}

    # -------- Autosave --------
    async def task_autosave(self, get_snapshot: Callable[[], Dict[str, Any]]):
        self._running = True
        while self._running:
            try:
                snap = get_snapshot()
                snap["saved_at"] = int(time.time() * 1000)
                self.save_state(snap)
            except Exception:
                pass
            await asyncio.sleep(self.period_s)

    def stop(self): self._running = False

--------------------------------------------------------------------------------
FILE: scalper/live/telegram_async.py
--------------------------------------------------------------------------------
from __future__ import annotations
import time
import requests
import asyncio
from typing import Optional, Dict, Any, List


class TelegramAsync:
    """
    Client Telegram simple basé sur requests, utilisé de manière non bloquante via asyncio.to_thread.
    Sans nouvelle dépendance.
    """
    def __init__(self, token: Optional[str], chat_id: Optional[str]) -> None:
        self.token = token
        self.chat_id = chat_id
        self.base = f"https://api.telegram.org/bot{token}" if token else None
        self._offset = 0
        self._enabled = bool(token and chat_id)

    def enabled(self) -> bool:
        return self._enabled

    # ---------- sync I/O (appelées via to_thread) ----------
    def _send_message_sync(self, text: str) -> Dict[str, Any]:
        if not self._enabled:
            return {"ok": False, "reason": "disabled"}
        url = f"{self.base}/sendMessage"
        payload = {"chat_id": self.chat_id, "text": text}
        try:
            r = requests.post(url, json=payload, timeout=10)
            return r.json()
        except Exception as e:
            return {"ok": False, "error": repr(e)}

    def _get_updates_sync(self, timeout_s: int = 30) -> Dict[str, Any]:
        if not self._enabled:
            return {"ok": True, "result": []}
        url = f"{self.base}/getUpdates"
        params = {"timeout": timeout_s, "offset": self._offset}
        try:
            r = requests.get(url, params=params, timeout=timeout_s + 5)
            return r.json()
        except Exception as e:
            return {"ok": False, "error": repr(e), "result": []}

    # ---------- async wrappers ----------
    async def send_message(self, text: str) -> None:
        await asyncio.to_thread(self._send_message_sync, text)

    async def poll_commands(self, timeout_s: int = 30) -> List[Dict[str, Any]]:
        data = await asyncio.to_thread(self._get_updates_sync, timeout_s)
        if not data.get("ok"):
            return []
        out = []
        for upd in data.get("result", []):
            self._offset = max(self._offset, int(upd.get("update_id", 0)) + 1)
            msg = upd.get("message") or {}
            text = (msg.get("text") or "").strip()
            if not text:
                continue
            out.append({
                "date": msg.get("date"),
                "chat": str((msg.get("chat") or {}).get("id")),
                "text": text,
                "from": (msg.get("from") or {}).get("username") or (msg.get("from") or {}).get("first_name") or "unknown",
            })
        return out


--------------------------------------------------------------------------------
FILE: scalper/live/watchlist.py
--------------------------------------------------------------------------------
# -*- coding: utf-8 -*-
from __future__ import annotations
from dataclasses import dataclass
from typing import List


@dataclass
class WatchlistManager:
    symbols: List[str]

    @classmethod
    def from_env_or_default(cls) -> "WatchlistManager":
        # Tu peux lire une variable d'env ici si tu veux surcharger
        default = [
            "BTCUSDT","ETHUSDT","SOLUSDT","BNBUSDT","XRPUSDT",
            "DOGEUSDT","ADAUSDT","LTCUSDT","AVAXUSDT","LINKUSDT"
        ]
        return cls(default)

--------------------------------------------------------------------------------
FILE: scalper/logging_utils.py
--------------------------------------------------------------------------------
"""Logging helpers for the Scalp bot."""

from __future__ import annotations

import atexit
import csv
import json
import os
import sqlite3
import time
from pathlib import Path
from typing import Any, Dict, List


def get_jsonl_logger(path: str, max_bytes: int = 0, backup_count: int = 0):
    """Return a callable that logs events as JSON lines.

    Parameters
    ----------
    path: str
        Target file path for JSON lines.
    max_bytes: int, optional
        If >0, rotate the file when its size exceeds this value.
    backup_count: int, optional
        Number of rotated files to keep when ``max_bytes`` is set.
    """
    os.makedirs(os.path.dirname(path), exist_ok=True)
    log_file = open(path, "a", encoding="utf-8")

    def _close_file() -> None:
        try:
            log_file.close()
        except Exception:
            pass

    atexit.register(_close_file)

    def _rotate() -> None:
        nonlocal log_file
        log_file.close()
        for i in range(backup_count - 1, 0, -1):
            src = f"{path}.{i}"
            dst = f"{path}.{i + 1}"
            if os.path.exists(src):
                os.replace(src, dst)
        os.replace(path, f"{path}.1")
        log_file = open(path, "a", encoding="utf-8")

    def _log(event: str, payload: Dict[str, Any]) -> None:
        nonlocal log_file
        payload = dict(payload or {})
        payload["event"] = event
        payload["ts"] = int(time.time() * 1000)
        line = json.dumps(payload, ensure_ascii=False)
        if max_bytes and backup_count > 0:
            if log_file.tell() + len(line) + 1 > max_bytes:
                _rotate()
        log_file.write(line + "\n")
        log_file.flush()

    return _log


class TradeLogger:
    """Helper writing trade information to CSV and SQLite files."""

    fields = [
        "pair",
        "tf",
        "dir",
        "entry",
        "sl",
        "tp",
        "score",
        "reasons",
        "pnl",
    ]

    def __init__(self, csv_path: str, sqlite_path: str) -> None:
        os.makedirs(os.path.dirname(csv_path), exist_ok=True)
        self.csv_path = csv_path
        self.sqlite_path = sqlite_path

        # Ensure CSV has header
        if not os.path.exists(csv_path):
            with open(csv_path, "w", newline="", encoding="utf-8") as f:
                writer = csv.DictWriter(f, fieldnames=self.fields)
                writer.writeheader()

        # Setup SQLite store
        self.conn = sqlite3.connect(sqlite_path)
        cur = self.conn.cursor()
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS trades (
                pair TEXT,
                tf TEXT,
                dir TEXT,
                entry REAL,
                sl REAL,
                tp REAL,
                score REAL,
                reasons TEXT,
                pnl REAL
            )
            """
        )
        self.conn.commit()
        atexit.register(self.conn.close)

    def log(self, data: Dict[str, Any]) -> None:
        row = {k: data.get(k) for k in self.fields}
        with open(self.csv_path, "a", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=self.fields)
            writer.writerow(row)
        cur = self.conn.cursor()
        cur.execute(
            "INSERT INTO trades (pair, tf, dir, entry, sl, tp, score, reasons, pnl) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)",
            (
                row["pair"],
                row["tf"],
                row["dir"],
                row["entry"],
                row["sl"],
                row["tp"],
                row["score"],
                row["reasons"],
                row["pnl"],
            ),
        )
        self.conn.commit()


BASE_DIR = Path(__file__).resolve().parents[2]


def _append_csv(path: Path, fields: List[str], row: Dict[str, Any]) -> None:
    """Append a row to ``path`` creating the file with ``fields`` if needed."""
    path.parent.mkdir(parents=True, exist_ok=True)
    file_exists = path.exists()
    with path.open("a", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=fields)
        if not file_exists:
            writer.writeheader()
        writer.writerow({k: row.get(k) for k in fields})


def log_position(data: Dict[str, Any]) -> None:
    """Log a closed position to ``../positions.csv``."""
    fields = [
        "timestamp",
        "pair",
        "direction",
        "entry",
        "exit",
        "pnl_pct",
        "fee_rate",
        "notes",
    ]
    _append_csv(BASE_DIR / "positions.csv", fields, data)


def log_operation_memo(data: Dict[str, Any]) -> None:
    """Log operation details to ``../operations_memo.csv``."""
    fields = ["timestamp", "pair", "details"]
    _append_csv(BASE_DIR / "operations_memo.csv", fields, data)


--------------------------------------------------------------------------------
FILE: scalper/metrics.py
--------------------------------------------------------------------------------
"""Utility metrics for trading calculations."""

from __future__ import annotations


from typing import Iterable

__all__ = ["calc_pnl_pct", "calc_rsi", "calc_atr", "calc_macd", "backtest_position"]


def calc_pnl_pct(
    entry_price: float, exit_price: float, side: int, fee_rate: float = 0.0
) -> float:
    """Return percentage PnL between entry and exit prices minus fees.


    Parameters
    ----------
    entry_price: float
        Trade entry price (>0).
    exit_price: float
        Trade exit price (>0).
    side: int
        +1 for long, -1 for short.
    fee_rate: float, optional
        Trading fee rate per operation (e.g., 0.0006 for 0.06%). The fee is
        applied twice (entry + exit).
    """
    if entry_price <= 0 or exit_price <= 0:
        raise ValueError("Prices must be positive")
    if side not in (1, -1):
        raise ValueError("side must be +1 (long) or -1 (short)")

    pnl = (exit_price - entry_price) / entry_price * 100.0 * side
    fee_pct = fee_rate * 2 * 100.0  # entrée + sortie
    return pnl - fee_pct


def calc_rsi(prices: Iterable[float], period: int = 14) -> float:
    """Compute the Relative Strength Index (RSI) using Wilder's smoothing.


    Parameters
    ----------
    prices:
        Ordered sequence of closing prices.
    period:
        Number of periods to use for the calculation. Must be positive and the
        length of ``prices`` must be at least ``period + 1``.
    """

    prices_list = [float(p) for p in prices]

    if period <= 0:
        raise ValueError("period must be positive")
    if len(prices_list) < period + 1:

        raise ValueError("len(prices) must be >= period + 1")

    gains: list[float] = []
    losses: list[float] = []
    for i in range(1, period + 1):

        diff = prices_list[i] - prices_list[i - 1]

        if diff >= 0:
            gains.append(diff)
            losses.append(0.0)
        else:
            gains.append(0.0)
            losses.append(-diff)

    avg_gain = sum(gains) / period
    avg_loss = sum(losses) / period

    for i in range(period + 1, len(prices_list)):
        diff = prices_list[i] - prices_list[i - 1]

        gain = max(diff, 0.0)
        loss = max(-diff, 0.0)
        avg_gain = (avg_gain * (period - 1) + gain) / period
        avg_loss = (avg_loss * (period - 1) + loss) / period

    if avg_gain == 0 and avg_loss == 0:
        return 50.0
    if avg_loss == 0:
        return 100.0
    if avg_gain == 0:
        return 0.0
    rs = avg_gain / avg_loss
    return 100.0 - (100.0 / (1.0 + rs))


def calc_atr(
    highs: Iterable[float],
    lows: Iterable[float],
    closes: Iterable[float],
    period: int = 14,
) -> float:
    """Compute the Average True Range (ATR) using Wilder's smoothing.


    Parameters
    ----------
    highs, lows, closes:
        Ordered sequences of high, low and close prices. All sequences must
        have the same length and contain at least ``period + 1`` elements.
    period:
        Number of periods to use for the calculation. Must be positive.
    """

    highs_list = [float(h) for h in highs]
    lows_list = [float(low) for low in lows]
    closes_list = [float(c) for c in closes]

    length = len(highs_list)
    if length != len(lows_list) or length != len(closes_list):

        raise ValueError("Input sequences must have the same length")
    if period <= 0:
        raise ValueError("period must be positive")
    if length < period + 1:
        raise ValueError("Input sequences must have at least period + 1 elements")

    trs: list[float] = []
    for i in range(1, len(highs_list)):
        tr = max(
            highs_list[i] - lows_list[i],
            abs(highs_list[i] - closes_list[i - 1]),
            abs(lows_list[i] - closes_list[i - 1]),
        )
        trs.append(tr)

    atr = sum(trs[:period]) / period
    for tr in trs[period:]:
        atr = (atr * (period - 1) + tr) / period
    return atr


def calc_macd(
    prices: Sequence[float],
    fast: int = 12,
    slow: int = 26,
    signal: int = 9,
) -> tuple[float, float, float]:
    """Return MACD, signal line and histogram values.

    The implementation computes exponential moving averages using Wilder's
    smoothing. ``prices`` must contain at least ``slow + signal`` elements.
    """

    prices_list = [float(p) for p in prices]
    if fast <= 0 or slow <= 0 or signal <= 0:
        raise ValueError("periods must be positive")
    min_len = max(fast, slow) + signal
    if len(prices_list) < min_len:
        raise ValueError("len(prices) must be >= slow + signal")

    def _ema_series(series: Sequence[float], window: int) -> list[float]:
        k = 2.0 / (window + 1.0)
        out = [float(series[0])]
        for x in series[1:]:
            out.append(float(x) * k + out[-1] * (1.0 - k))
        return out

    fast_ema = _ema_series(prices_list, fast)
    slow_ema = _ema_series(prices_list, slow)
    macd_series = [f - s for f, s in zip(fast_ema, slow_ema)]
    signal_series = _ema_series(macd_series, signal)
    macd_val = macd_series[-1]
    signal_val = signal_series[-1]
    hist = macd_val - signal_val
    return macd_val, signal_val, hist


def backtest_position(
    prices: list[float], entry_idx: int, exit_idx: int, side: int
) -> bool:
    """Run a basic backtest to verify a position's coherence.

    Parameters
    ----------
    prices: list[float]
        Sequential list of prices to evaluate.
    entry_idx: int
        Index in ``prices`` where the position is opened.
    exit_idx: int
        Index in ``prices`` where the position is closed (must be > ``entry_idx``).
    side: int
        +1 for long, -1 for short.

    Returns
    -------
    bool
        ``True`` if the resulting PnL is non-negative, meaning the position is
        coherent with the direction of price movement. ``False`` otherwise.
    """
    if side not in (1, -1):
        raise ValueError("side must be +1 (long) or -1 (short)")
    if not (0 <= entry_idx < exit_idx < len(prices)):
        raise ValueError(
            "entry_idx and exit_idx must be valid and entry_idx < exit_idx"
        )

    entry_price = float(prices[entry_idx])
    exit_price = float(prices[exit_idx])
    pnl = calc_pnl_pct(entry_price, exit_price, side)
    return pnl >= 0.0


--------------------------------------------------------------------------------
FILE: scalper/pairs.py
--------------------------------------------------------------------------------
"""Utilities to select trading pairs and detect signals."""
from __future__ import annotations
from typing import Any, Dict, List, Optional, Callable
from scalper.strategy import Signal

from scalper.bot_config import CONFIG
from scalper.strategy import ema as default_ema, cross as default_cross
from scalper.notifier import notify


def get_trade_pairs(client: Any) -> List[Dict[str, Any]]:
    """Return all trading pairs using the client's ``get_ticker`` method."""
    tick = client.get_ticker()
    data = tick.get("data") if isinstance(tick, dict) else []
    if not data:
        return []
    return data if isinstance(data, list) else [data]


def filter_trade_pairs(
    client: Any,
    *,
    volume_min: float = 5_000_000,
    max_spread_bps: float = 5.0,
    top_n: int = 40,
) -> List[Dict[str, Any]]:
    """Filter pairs by volume and spread."""
    pairs = get_trade_pairs(client)
    eligible: List[Dict[str, Any]] = []

    for info in pairs:
        sym = info.get("symbol")
        if not sym:
            continue
        try:
            vol = float(info.get("volume", 0))
        except (TypeError, ValueError):
            continue
        if vol < volume_min:
            continue
        try:
            bid = float(info.get("bidPrice", 0))
            ask = float(info.get("askPrice", 0))
        except (TypeError, ValueError):
            continue
        if bid <= 0 or ask <= 0:
            continue
        spread_bps = (ask - bid) / ((ask + bid) / 2) * 10_000
        if spread_bps >= max_spread_bps:
            continue
        eligible.append(info)

    eligible.sort(key=lambda row: float(row.get("volume", 0)), reverse=True)
    return eligible[:top_n]


def select_top_pairs(client: Any, top_n: int = 40, key: str = "volume") -> List[Dict[str, Any]]:
    """Return ``top_n`` pairs sorted by ``key``."""
    pairs = get_trade_pairs(client)

    def volume(row: Dict[str, Any]) -> float:
        try:
            return float(row.get(key, 0))
        except (TypeError, ValueError):
            return 0.0

    pairs.sort(key=volume, reverse=True)
    return pairs[:top_n]


def _ancienne_impl(
    client: Any,
    pairs: List[Dict[str, Any]],
    *,
    interval: str = "1m",
    ema_fast_n: Optional[int] = None,
    ema_slow_n: Optional[int] = None,
    ema_func=default_ema,
    cross_func=default_cross,
) -> List[Dict[str, Any]]:
    """Original implementation returning dicts."""
    ema_fast_n = ema_fast_n or CONFIG.get("EMA_FAST", 9)
    ema_slow_n = ema_slow_n or CONFIG.get("EMA_SLOW", 21)
    results: List[Dict[str, Any]] = []

    for info in pairs:
        symbol = info.get("symbol")
        if not symbol:
            continue
        k = client.get_kline(symbol, interval=interval)
        closes = k.get("data", {}).get("close", []) if isinstance(k, dict) else []
        if len(closes) < max(ema_fast_n, ema_slow_n) + 2:
            continue
        efull = ema_func(closes, ema_fast_n)
        eslow = ema_func(closes, ema_slow_n)
        signal = cross_func(efull[-1], eslow[-1], efull[-2], eslow[-2])
        if signal == 1:
            price_str = info.get("lastPr") or info.get("lastPrice") or 0.0
            results.append({"symbol": symbol, "signal": "long", "price": float(price_str)})
        elif signal == -1:
            price_str = info.get("lastPr") or info.get("lastPrice") or 0.0
            results.append({"symbol": symbol, "signal": "short", "price": float(price_str)})
    return results


def _to_signal(d: dict) -> Signal:
    side = 1 if d.get("signal") in ("long", "buy", 1, True) else -1
    return Signal(
        symbol=d.get("symbol"),
        side=side,
        entry=float(d.get("price", d.get("entry", 0))),
        sl=float(d.get("sl", 0)),
        tp1=float(d.get("tp1", 0)) or None,
        tp2=float(d.get("tp2", 0)) or None,
        score=d.get("score"),
        quality=d.get("quality"),
        reasons=d.get("reasons", []),
    )


def find_trade_positions(
    client: Any,
    pairs: List[Dict[str, Any]],
    *,
    interval: str = "1m",
    ema_fast_n: Optional[int] = None,
    ema_slow_n: Optional[int] = None,
    ema_func=default_ema,
    cross_func=default_cross,
) -> List[Signal]:
    raw = _ancienne_impl(
        client,
        pairs,
        interval=interval,
        ema_fast_n=ema_fast_n,
        ema_slow_n=ema_slow_n,
        ema_func=ema_func,
        cross_func=cross_func,
    )
    return [_to_signal(x) for x in raw]


def send_selected_pairs(
    client: Any,
    top_n: int = 40,
    *,
    select_fn: Callable[[Any, int], List[Dict[str, Any]]] = select_top_pairs,
    notify_fn: Callable[[str, Optional[Dict[str, Any]]], None] = notify,
) -> Dict[str, str]:
    """Fetch top pairs, drop USD/USDT/USDC duplicates and notify their list.

    Returns the payload sent to ``notify_fn``. The mapping contains the
    comma-separated symbols for each color group (``green``, ``orange`` and
    ``red``) or an empty dictionary when no pairs are available.
    """

    def split_symbol(sym: str) -> tuple[str, str]:
        if "_" in sym:
            left, right = sym.split("_", 1)
            # Legacy style: BTC_USDT
            if len(right) <= 4:
                return left, right
            # Bitget futures style: BTCUSDT_UMCBL
            main = left
            if main.endswith("USDT"):
                return main[:-4], "USDT"
            if main.endswith("USDC"):
                return main[:-4], "USDC"
            if main.endswith("USD"):
                return main[:-3], "USD"
            return main, ""
        if sym.endswith("USDT"):
            return sym[:-4], "USDT"
        if sym.endswith("USDC"):
            return sym[:-4], "USDC"
        if sym.endswith("USD"):
            return sym[:-3], "USD"
        return sym, ""

    pairs = select_fn(client, top_n=top_n * 3)
    allowed = {s.split("_")[0].upper() for s in CONFIG.get("ALLOWED_SYMBOLS", [])}
    by_base: Dict[str, Dict[str, Any]] = {}
    for info in pairs:
        sym = info.get("symbol")
        if not sym:
            continue
        norm_sym = sym.split("_")[0].upper()
        if allowed and norm_sym not in allowed:
            continue
        base, quote = split_symbol(sym)
        existing = by_base.get(base)
        priority = {"USDT": 3, "USDC": 2, "USD": 1}
        if existing is None or priority.get(quote, 0) > priority.get(existing["quote"], 0):
            by_base[base] = {"data": info, "quote": quote}

    unique = sorted(
        (v["data"] for v in by_base.values()),
        key=lambda row: float(row.get("volume", 0)),
        reverse=True,
    )
    symbols: list[str] = []
    for row in unique[:top_n]:
        sym = row.get("symbol")
        if not sym:
            continue
        base, _ = split_symbol(sym)
        symbols.append(base)
    if symbols:
        n = len(symbols)
        third = max(n // 3, 1)
        green = symbols[:third]
        orange = symbols[third : 2 * third]
        red = symbols[2 * third :]
        payload: Dict[str, str] = {}
        if green:
            payload["green"] = ", ".join(green)
        if orange:
            payload["orange"] = ", ".join(orange)
        if red:
            payload["red"] = ", ".join(red)
        notify_fn("pair_list", payload)
        return payload
    return {}


def heat_score(volatility: float, volume: float, news: bool = False) -> float:
    """Return a heat score combining volatility, volume and a news flag."""
    mult = 2.0 if news else 1.0
    return volatility * volume * mult


def select_top_heat_pairs(
    pairs: List[Dict[str, Any]], *, top_n: int = 3
) -> List[Dict[str, Any]]:
    """Return ``top_n`` pairs ranked by ``heat_score``."""

    scored: List[Dict[str, Any]] = []
    for info in pairs:
        try:
            vol = float(info.get("volatility", 0))
            volume = float(info.get("volume", 0))
        except (TypeError, ValueError):
            continue
        score = heat_score(vol, volume, bool(info.get("news")))
        row = dict(info)
        row["heat_score"] = score
        scored.append(row)

    scored.sort(key=lambda r: r["heat_score"], reverse=True)
    return scored[:top_n]


def decorrelate_pairs(
    pairs: List[Dict[str, Any]],
    corr: Dict[str, Dict[str, float]],
    *,
    threshold: float = 0.8,
    top_n: int = 3,
) -> List[Dict[str, Any]]:
    """Return top pairs while avoiding highly correlated symbols.

    ``corr`` is a mapping of pair symbol to correlation with other symbols.  Two
    pairs are considered too correlated when the absolute value of the
    correlation exceeds ``threshold``.
    """

    selected: List[Dict[str, Any]] = []
    for info in select_top_heat_pairs(pairs, top_n=len(pairs)):
        sym = info.get("symbol")
        if not sym:
            continue
        if all(abs(corr.get(sym, {}).get(p["symbol"], 0.0)) < threshold for p in selected):
            selected.append(info)
        if len(selected) >= top_n:
            break
    return selected


--------------------------------------------------------------------------------
FILE: scalper/positions/__init__.py
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
FILE: scalper/positions/state.py
--------------------------------------------------------------------------------
from __future__ import annotations
from dataclasses import dataclass, field
from enum import Enum, auto
from typing import List, Optional
import time

class PositionStatus(Enum):
    IDLE = auto()
    PENDING_ENTRY = auto()
    OPEN = auto()
    PENDING_EXIT = auto()
    CLOSED = auto()

class PositionSide(Enum):
    LONG = 1
    SHORT = -1

@dataclass
class Fill:
    order_id: str
    trade_id: str
    price: float
    qty: float
    fee: float
    ts: int

@dataclass
class PositionState:
    symbol: str
    side: PositionSide
    status: PositionStatus = PositionStatus.IDLE
    entry_order_id: Optional[str] = None
    exit_order_id: Optional[str] = None
    req_qty: float = 0.0
    filled_qty: float = 0.0
    avg_entry_price: float = 0.0
    avg_exit_price: float = 0.0
    sl: Optional[float] = None
    tp: Optional[float] = None
    realized_pnl: float = 0.0
    fees: float = 0.0
    opened_ts: Optional[int] = None
    closed_ts: Optional[int] = None
    fills: List[Fill] = field(default_factory=list)
    last_sync_ts: int = field(default_factory=lambda: int(time.time()*1000))

    def apply_fill_entry(self, f: Fill) -> None:
        self.fills.append(f)
        self.filled_qty += f.qty
        # moyenne pondérée
        notional = self.avg_entry_price * (self.filled_qty - f.qty) + f.price * f.qty
        self.avg_entry_price = notional / max(1e-12, self.filled_qty)
        self.fees += abs(f.fee)
        if self.opened_ts is None:
            self.opened_ts = f.ts
        if self.filled_qty > 1e-12:
            self.status = PositionStatus.OPEN

    def apply_fill_exit(self, f: Fill) -> None:
        self.fills.append(f)
        qty = min(self.filled_qty, f.qty)
        # realized pnl sur la quantité fermée
        if self.side == PositionSide.LONG:
            self.realized_pnl += (f.price - self.avg_entry_price) * qty
        else:
            self.realized_pnl += (self.avg_entry_price - f.price) * qty
        self.fees += abs(f.fee)
        self.filled_qty = max(0.0, self.filled_qty - qty)
        # moyenne de sortie indicative
        closed_q = (self.req_qty - self.filled_qty)
        self.avg_exit_price = ((self.avg_exit_price * (closed_q - qty)) + f.price * qty) / max(1e-12, closed_q)
        if self.filled_qty <= 1e-12:
            self.status = PositionStatus.CLOSED
            self.closed_ts = f.ts



--------------------------------------------------------------------------------
FILE: scalper/risk/__init__.py
--------------------------------------------------------------------------------
# scalp/risk/__init__.py
from .manager import (
    Caps,
    compute_size,
    calc_position_size,  # alias legacy
    RiskManager,         # shim legacy
)

__all__ = ["Caps", "compute_size", "calc_position_size", "RiskManager"]

--------------------------------------------------------------------------------
FILE: scalper/risk/manager.py
--------------------------------------------------------------------------------
# scalp/risk/manager.py
from __future__ import annotations
from dataclasses import dataclass
from typing import Optional, Dict, Any

@dataclass
class Caps:
    min_qty: float = 0.0
    min_notional: float = 0.0
    max_leverage: float = 20.0

def _get_caps(caps_by_symbol: Optional[Dict[str, Any]], symbol: str) -> Caps:
    if not caps_by_symbol:
        return Caps()
    c = caps_by_symbol.get(symbol, {})
    return Caps(
        min_qty=float(c.get("min_qty", 0.0) or 0.0),
        min_notional=float(c.get("min_notional", 0.0) or 0.0),
        max_leverage=float(c.get("max_leverage", 20.0) or 20.0),
    )

def compute_size(
    *,
    symbol: str,
    price: float,
    balance_cash: float,
    risk_pct: float = 0.5,
    caps_by_symbol: Optional[Dict[str, Any]] = None,
) -> float:
    """Sizing robuste avec gardes min_notional / min_qty."""
    price = max(1e-9, float(price))
    balance_cash = max(0.0, float(balance_cash))
    risk_pct = max(0.0, float(risk_pct))

    notionnel = balance_cash * risk_pct
    qty = notionnel / price

    caps = _get_caps(caps_by_symbol, symbol)
    if caps.min_notional > 0 and (qty * price) < caps.min_notional:
        qty = caps.min_notional / price
    if caps.min_qty > 0 and qty < caps.min_qty:
        qty = caps.min_qty
    return max(0.0, qty)

# --- Shims pour compatibilité ancienne API -----------------------------------

def calc_position_size(symbol: str, price: float, balance_cash: float,
                       risk_pct: float = 0.5,
                       caps_by_symbol: Optional[Dict[str, Any]] = None) -> float:
    """Alias legacy → compute_size."""
    return compute_size(
        symbol=symbol, price=price, balance_cash=balance_cash,
        risk_pct=risk_pct, caps_by_symbol=caps_by_symbol
    )

class RiskManager:
    """
    Shim minimal compatible avec l'ancien code:
      rm = RiskManager(risk_pct=0.5, caps_by_symbol={...})
      qty = rm.size(symbol, price, balance_cash)
    """
    def __init__(self, risk_pct: float = 0.5, caps_by_symbol: Optional[Dict[str, Any]] = None):
        self.risk_pct = float(risk_pct)
        self.caps_by_symbol = caps_by_symbol or {}

    def size(self, symbol: str, price: float, balance_cash: float) -> float:
        return compute_size(
            symbol=symbol, price=price, balance_cash=balance_cash,
            risk_pct=self.risk_pct, caps_by_symbol=self.caps_by_symbol
        )

--------------------------------------------------------------------------------
FILE: scalper/selection/__init__.py
--------------------------------------------------------------------------------
"""Pair selection helpers for the Scalp bot.

This package exposes two utilities used during the preparation phase of the
trading strategy:

``scan_pairs``
    Performs the first level market scan by filtering pairs based on volume,
    spread and hourly volatility.

``select_active_pairs``
    Refines a list of pairs by keeping only those showing an EMA20/EMA50
    crossover and a sufficiently high ATR.
"""

from .scanner import scan_pairs
from .momentum import select_active_pairs

__all__ = ["scan_pairs", "select_active_pairs"]



--------------------------------------------------------------------------------
FILE: scalper/selection/momentum.py
--------------------------------------------------------------------------------
"""Utilities to select pairs exhibiting strong momentum."""

from __future__ import annotations

from typing import Any, Dict, List, Sequence

from ..metrics import calc_atr


def ema(series: Sequence[float], window: int) -> List[float]:
    """Simple exponential moving average implementation."""

    if window <= 1 or not series:
        return list(series)
    k = 2.0 / (window + 1.0)
    out: List[float] = [float(series[0])]
    prev = out[0]
    for x in series[1:]:
        prev = float(x) * k + prev * (1.0 - k)
        out.append(prev)
    return out


def cross(last_fast: float, last_slow: float, prev_fast: float, prev_slow: float) -> int:
    """Return 1 if a bullish cross occurred, -1 for bearish, 0 otherwise."""

    if prev_fast <= prev_slow and last_fast > last_slow:
        return 1
    if prev_fast >= prev_slow and last_fast < last_slow:
        return -1
    return 0


def _quantile(values: Sequence[float], q: float) -> float:
    """Return the *q* quantile of *values* (0 <= q <= 1)."""

    if not values:
        return 0.0
    q = min(max(q, 0.0), 1.0)
    vals = sorted(values)
    idx = int((len(vals) - 1) * q)
    return vals[idx]


def select_active_pairs(
    client: Any,
    pairs: Sequence[Dict[str, Any]],
    *,
    interval: str = "Min5",
    ema_fast: int = 20,
    ema_slow: int = 50,
    atr_period: int = 14,
    atr_quantile: float = 0.5,
    top_n: int = 5,
) -> List[Dict[str, Any]]:
    """Return pairs with an EMA crossover and high ATR.

    Only pairs where ``EMA20`` crosses ``EMA50`` on the latest candle are kept.
    Among those candidates, the Average True Range is computed and only pairs
    whose ATR is above the provided quantile are returned.  The resulting
    dictionaries include an ``atr`` key for convenience.
    """

    candidates: List[Dict[str, Any]] = []
    atrs: List[float] = []

    for info in pairs:
        sym = info.get("symbol")
        if not sym:
            continue
        k = client.get_kline(sym, interval=interval)
        kdata = k.get("data") if isinstance(k, dict) else {}
        closes = kdata.get("close", [])
        highs = kdata.get("high", [])
        lows = kdata.get("low", [])
        if len(closes) < max(ema_slow, atr_period) + 2:
            continue
        efast = ema(closes, ema_fast)
        eslow = ema(closes, ema_slow)
        if cross(efast[-1], eslow[-1], efast[-2], eslow[-2]) == 0:
            continue
        atr_val = calc_atr(highs, lows, closes, atr_period)
        row = dict(info)
        row["atr"] = atr_val
        candidates.append(row)
        atrs.append(atr_val)

    if not candidates:
        return []

    threshold = _quantile(atrs, atr_quantile)
    selected = [row for row in candidates if row["atr"] >= threshold]
    selected.sort(key=lambda r: r["atr"], reverse=True)
    return selected[:top_n]


__all__ = ["select_active_pairs"]



--------------------------------------------------------------------------------
FILE: scalper/selection/scanner.py
--------------------------------------------------------------------------------
"""Utilities for scanning tradable pairs on the exchange."""

from __future__ import annotations

from typing import Any, Dict, List


def scan_pairs(
    client: Any,
    *,
    volume_min: float = 5_000_000,
    max_spread_bps: float = 5.0,
    min_hourly_vol: float = 0.0,
    top_n: int = 40,
) -> List[Dict[str, Any]]:
    """Return pairs satisfying basic liquidity and volatility filters.

    Parameters
    ----------
    client: Any
        Client instance exposing ``get_ticker`` and ``get_kline`` methods.
    volume_min: float, optional
        Minimum 24h volume required to keep a pair.
    max_spread_bps: float, optional
        Maximum allowed bid/ask spread expressed in basis points.
    min_hourly_vol: float, optional
        Minimum volatility over the last hour expressed as ``(high - low) /
        close``.  When set to ``0`` the filter is disabled.
    top_n: int, optional
        Limit the number of returned pairs.
    """

    tick = client.get_ticker()
    data = tick.get("data") if isinstance(tick, dict) else []
    if not isinstance(data, list):
        data = [data]

    eligible: List[Dict[str, Any]] = []

    for row in data:
        sym = row.get("symbol")
        if not sym:
            continue
        try:
            vol = float(row.get("volume", 0))
            bid = float(row.get("bidPrice", 0))
            ask = float(row.get("askPrice", 0))
        except (TypeError, ValueError):
            continue
        if vol < volume_min or bid <= 0 or ask <= 0:
            continue
        spread_bps = (ask - bid) / ((ask + bid) / 2.0) * 10_000
        if spread_bps >= max_spread_bps:
            continue

        if min_hourly_vol > 0:
            k = client.get_kline(sym, interval="Min60")
            kdata = k.get("data") if isinstance(k, dict) else {}
            highs = kdata.get("high", [])
            lows = kdata.get("low", [])
            closes = kdata.get("close", [])
            if not highs or not lows or not closes:
                continue
            try:
                h = float(highs[-1])
                l = float(lows[-1])
                c = float(closes[-1])
            except (TypeError, ValueError):
                continue
            hourly_vol = (h - l) / c if c else 0.0
            if hourly_vol < min_hourly_vol:
                continue

        eligible.append(row)

    eligible.sort(key=lambda r: float(r.get("volume", 0)), reverse=True)
    return eligible[:top_n]


__all__ = ["scan_pairs"]



--------------------------------------------------------------------------------
FILE: scalper/selfcheck.py
--------------------------------------------------------------------------------
# scalper/selfcheck.py
from __future__ import annotations
import os, sys, importlib, traceback
from pathlib import Path

NOTEBOOKS = Path("/notebooks")
REPO = (NOTEBOOKS / "scalp") if NOTEBOOKS.exists() else Path(__file__).resolve().parents[2]

def _mask(val: str) -> str:
    if not val: return ""
    return (val[:3] + "…" + val[-3:]) if len(val) > 6 else "********"

def _try_import(modname: str):
    try:
        m = importlib.import_module(modname)
        return True, m
    except Exception:
        return False, traceback.format_exc()

def preflight(verbose: bool = False) -> list[str]:
    """
    Retourne la liste des 'issues' trouvées (vide si tout est OK).
    Ne lève pas d'exception. N'écrit que de l'info lisible.
    """
    issues: list[str] = []
    # s'assurer que le repo est bien dans sys.path
    if str(REPO) not in sys.path:
        sys.path.insert(0, str(REPO))

    print("=== SCALPER PREFLIGHT ===")
    print(f"[i] Repo: {REPO}")
    print(f"[i] Python: {sys.version.split()[0]}")

    # backtest API
    ok, mod = _try_import("scalper.backtest")
    if not ok:
        print("[✗] Import scalper.backtest KO")
        if verbose: print(mod)  # ici 'mod' contient la trace
        issues.append("backtest import")
    else:
        has_single = hasattr(mod, "run_single")
        has_multi  = hasattr(mod, "run_multi")
        print(f"[✓] scalper.backtest: run_single={has_single} run_multi={has_multi}")
        if not (has_single and has_multi):
            issues.append("backtest API incomplète")

    # trade_utils
    ok, mod = _try_import("scalper.trade_utils")
    if not ok:
        print("[✗] Import scalper.trade_utils KO")
        if verbose: print(mod)
        issues.append("trade_utils import")
    else:
        print(f"[✓] scalper.trade_utils: compute_position_size={'compute_position_size' in dir(mod)}")

    # fees
    ok, mod = _try_import("scalper.exchange.fees")
    if not ok:
        print("[✗] Import scalper.exchange.fees KO")
        if verbose: print(mod)
        issues.append("fees import")
    else:
        need = {"get_fee", "load_bitget_fees"}
        miss = [n for n in need if not hasattr(mod, n)]
        if miss: issues.append("fees API manquante: " + ",".join(miss))
        print("[✓] scalper.exchange.fees OK")

    # notify/commands/backtest_telegram/orchestrator
    for name, required in [
        ("scalper.live.notify", ("build_notifier_and_stream",)),
        ("scalper.live.commands", ("CommandHandler",)),
        ("scalper.live.backtest_telegram", ("handle_backtest_command",)),
        ("scalper.live.orchestrator", ("run_orchestrator", "Orchestrator")),
    ]:
        ok, mod = _try_import(name)
        if not ok:
            print(f"[✗] Import {name} KO")
            if verbose: print(mod)
            issues.append(f"{name} import")
        else:
            miss = [a for a in required if not hasattr(mod, a)]
            if miss: issues.append(f"{name} API manquante: {','.join(miss)}")
            print(f"[✓] {name} OK")

    # ENV (masqué)
    tg_t = os.getenv("TELEGRAM_BOT_TOKEN", "")
    tg_c = os.getenv("TELEGRAM_CHAT_ID", "")
    gu   = os.getenv("GIT_USER", "")
    gt   = os.getenv("GIT_TOKEN", "")
    print("\n-- ENV --")
    print(f"  TELEGRAM_BOT_TOKEN: {_mask(tg_t)} {'(ABSENT)' if not tg_t else ''}")
    print(f"  TELEGRAM_CHAT_ID  : {_mask(tg_c)} {'(ABSENT)' if not tg_c else ''}")
    print(f"  GIT_USER          : {gu or '(ABSENT)'}")
    print(f"  GIT_TOKEN         : {_mask(gt)} {'(ABSENT)' if not gt else ''}")

    # Data
    data_dir = (REPO / "data")
    print("\n-- DATA --")
    if data_dir.exists():
        csvs = list(data_dir.glob("*.csv"))
        print(f"  {len(csvs)} CSV trouvé(s) dans data/ (OK si tu backtestes via CSV)")
    else:
        print("  data/ absent (OK si loader API)")

    return issues

def preflight_or_die(verbose: bool = False) -> None:
    issues = preflight(verbose=verbose)
    if issues:
        print("\n[✗] Préflight a détecté des problèmes :")
        for it in issues: print("   -", it)
        print("\nConseils :")
        print(" - Vérifie les fichiers remplacés (backtest/__init__.py, trade_utils.py, exchange/fees.py).")
        print(" - Évite d'importer optimize/walkforward dans backtest/__init__.py.")
        print(" - Charge /notebooks/.env si TELEGRAM/GIT sont absents (source /notebooks/.env).")
        raise SystemExit(1)
    print("\n[✓] Préflight OK — démarrage du bot.")

--------------------------------------------------------------------------------
FILE: scalper/services/__init__.py
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
FILE: scalper/services/data_cache.py
--------------------------------------------------------------------------------
# scalper/services/data_cache.py
from __future__ import annotations

import asyncio
import csv
import os
import time
from typing import Iterable, List, Optional, Tuple, Dict

# ---------------------------------------------------------------------
# Réglages via env (valeurs sûres par défaut)
# ---------------------------------------------------------------------
DATA_DIR = os.getenv("DATA_DIR", "/notebooks/data")           # dossier PERSISTANT (hors-git)
CSV_MAX_AGE = int(os.getenv("CSV_MAX_AGE_SECONDS", "0"))      # 0 = auto (en fonction du TF)
CSV_MIN_ROWS = int(os.getenv("CSV_MIN_ROWS", "200"))          # minimum de lignes attendues
STALE_FACTOR = float(os.getenv("CSV_STALE_FACTOR", "6"))      # âge max = STALE_FACTOR * tf_sec
PREFETCH_CONC = int(os.getenv("CSV_PREFETCH_CONC", "4"))      # concurrence préchauffage

os.makedirs(DATA_DIR, exist_ok=True)


# ---------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------
def parse_timeframe_to_seconds(tf: str) -> int:
    tf = tf.strip().lower()
    unit = tf[-1]
    try:
        n = int(tf[:-1])
    except Exception as e:
        raise ValueError(f"timeframe invalide: {tf}") from e
    if unit == "m":
        return n * 60
    if unit == "h":
        return n * 3600
    if unit == "d":
        return n * 86400
    raise ValueError(f"timeframe invalide: {tf}")


def csv_path(symbol: str, timeframe: str) -> str:
    return os.path.join(DATA_DIR, f"{symbol}-{timeframe}.csv")


def read_csv_ohlcv(path: str) -> List[Tuple[int, float, float, float, float, float]]:
    rows: List[Tuple[int, float, float, float, float, float]] = []
    if not os.path.exists(path):
        return rows
    with open(path, "r", newline="") as f:
        r = csv.reader(f)
        header = next(r, None)  # accepte avec ou sans header
        for line in r:
            if not line:
                continue
            ts, o, h, l, c, v = line[:6]
            rows.append((int(ts), float(o), float(h), float(l), float(c), float(v)))
    return rows


def write_csv_ohlcv(path: str, data: Iterable[Tuple[int, float, float, float, float, float]]) -> None:
    first = not os.path.exists(path)
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "a", newline="") as f:
        w = csv.writer(f)
        if first:
            w.writerow(["timestamp", "open", "high", "low", "close", "volume"])
        for row in data:
            w.writerow(row)


def last_ts(rows: List[Tuple[int, float, float, float, float, float]]) -> Optional[int]:
    return rows[-1][0] if rows else None


# ---------------------------------------------------------------------
# Fetch CCXT paginé
# ---------------------------------------------------------------------
async def ccxt_fetch_ohlcv_all(
    exchange,
    symbol: str,
    timeframe: str,
    since_ms: Optional[int],
    limit: int = 1000,
) -> List[Tuple[int, float, float, float, float, float]]:
    """
    Récupère OHLCV par pages (limit 1000) depuis since_ms jusqu'à ~now.
    Retourne une liste triée/dédupliquée.
    """
    out: List[Tuple[int, float, float, float, float, float]] = []
    tf_ms = parse_timeframe_to_seconds(timeframe) * 1000
    now_ms = exchange.milliseconds() if hasattr(exchange, "milliseconds") else int(time.time() * 1000)

    cursor = since_ms or (now_ms - 200 * tf_ms)
    while True:
        batch = await exchange.fetch_ohlcv(symbol, timeframe=timeframe, since=cursor, limit=limit)
        if not batch:
            break
        for ts, o, h, l, c, v in batch:
            out.append((int(ts), float(o), float(h), float(l), float(c), float(v)))
        next_cursor = batch[-1][0] + tf_ms
        if next_cursor <= cursor:
            break
        cursor = next_cursor
        if cursor >= now_ms + (2 * tf_ms):
            break
        await asyncio.sleep(getattr(exchange, "rateLimit", 200) / 1000)

    out.sort(key=lambda x: x[0])
    dedup: List[Tuple[int, float, float, float, float, float]] = []
    seen = set()
    for row in out:
        if row[0] in seen:
            continue
        seen.add(row[0])
        dedup.append(row)
    return dedup


# ---------------------------------------------------------------------
# Cache manager
# ---------------------------------------------------------------------
async def ensure_symbol_csv_cache(
    exchange,
    symbol: str,
    timeframe: str,
    min_rows: int = CSV_MIN_ROWS,
) -> str:
    """
    Garantit qu'un CSV OHLCV récent existe pour (symbol, timeframe).
    Crée/append si nécessaire. Retourne le chemin.
    """
    path = csv_path(symbol, timeframe)
    rows = read_csv_ohlcv(path)
    tf_sec = parse_timeframe_to_seconds(timeframe)
    tf_ms = tf_sec * 1000
    now_ms = int(time.time() * 1000)

    # âge max
    max_age = CSV_MAX_AGE if CSV_MAX_AGE > 0 else int(tf_sec * STALE_FACTOR)

    need_full = False
    need_append = False

    if not rows:
        need_full = True
    else:
        last = last_ts(rows) or 0
        age_sec = max(0, (now_ms - last) // 1000)
        if age_sec > max_age or len(rows) < min_rows:
            need_append = True

    if need_full:
        since = now_ms - (tf_ms * 2000)  # ~2000 bougies
        fresh = await ccxt_fetch_ohlcv_all(exchange, symbol, timeframe, since_ms=since)
        if len(fresh) < min_rows:
            since = now_ms - (tf_ms * 5000)
            fresh = await ccxt_fetch_ohlcv_all(exchange, symbol, timeframe, since_ms=since)
        if os.path.exists(path):
            os.remove(path)
        write_csv_ohlcv(path, fresh)
        return path

    if need_append:
        since = (last_ts(rows) or now_ms - (tf_ms * 2000)) + tf_ms
        fresh = await ccxt_fetch_ohlcv_all(exchange, symbol, timeframe, since_ms=since)
        if fresh:
            write_csv_ohlcv(path, fresh)

    return path


async def prewarm_csv_cache(exchange, symbols: Iterable[str], timeframe: str) -> Dict[str, str]:
    """
    Prépare le cache pour plusieurs symboles (concurrence limitée).
    Retourne {symbol: path}.
    """
    sem = asyncio.Semaphore(PREFETCH_CONC)
    result: Dict[str, str] = {}

    async def _one(sym: str):
        async with sem:
            p = await ensure_symbol_csv_cache(exchange, sym, timeframe)
            result[sym] = p

    await asyncio.gather(*[_one(s) for s in symbols])
    return result

--------------------------------------------------------------------------------
FILE: scalper/services/order_service.py
--------------------------------------------------------------------------------
from __future__ import annotations
from dataclasses import dataclass
from typing import Any, Dict, Optional, Protocol
from scalper.trade_utils import extract_available_balance


@dataclass
class OrderCaps:
    min_trade_usdt: float = 5.0
    leverage: float = 1.0


@dataclass
class OrderRequest:
    symbol: str
    side: str
    price: float
    sl: float
    tp: Optional[float]
    risk_pct: float


@dataclass
class OrderResult:
    accepted: bool
    reason: str = ""
    payload: Dict[str, Any] = None
    order_id: Optional[str] = None
    status: Optional[str] = None
    avg_price: Optional[float] = None
    filled_qty: Optional[float] = None


class Exchange(Protocol):
    def get_assets(self) -> Dict[str, Any]: ...
    def get_ticker(self, symbol: Optional[str] = None) -> Dict[str, Any]: ...
    def place_order(
        self,
        symbol: str,
        side: str,
        quantity: float,
        order_type: str,
        price: Optional[float] = None,
        stop_loss: Optional[float] = None,
        take_profit: Optional[float] = None,
    ) -> Dict[str, Any]: ...


class OrderService:
    def __init__(self, exchange: Exchange, caps: OrderCaps = OrderCaps()):
        self.exchange = exchange
        self.caps = caps

    @staticmethod
    def _abs(x: float) -> float:
        return -x if x < 0 else x

    def _calc_qty(self, equity_usdt: float, price: float, sl: float, risk_pct: float) -> float:
        dist = self._abs(price - sl)
        if dist <= 0:
            return 0.0
        risk_usdt = max(0.0, equity_usdt * risk_pct)
        return 0.0 if price <= 0 else (risk_usdt / dist)

    def prepare_and_place(self, equity_usdt: float, req: OrderRequest) -> OrderResult:
        qty = self._calc_qty(equity_usdt, req.price, req.sl, req.risk_pct)
        if qty <= 0:
            return OrderResult(False, "invalid_size")
        notional = qty * req.price
        if notional < self.caps.min_trade_usdt:
            return OrderResult(False, "under_min_notional")
        assets = self.exchange.get_assets()
        available = extract_available_balance(assets)
        required_margin = notional / max(1.0, self.caps.leverage)
        if available < required_margin:
            return OrderResult(False, "insufficient_margin")
        side = "BUY" if req.side == "long" else "SELL"
        out = self.exchange.place_order(
            symbol=req.symbol, side=side, quantity=qty,
            order_type="limit", price=req.price,
            stop_loss=req.sl, take_profit=req.tp
        )
        # extraire infos utiles
        oid = None; status = None; avg = None; filled = None
        try:
            data = out.get("data") if isinstance(out, dict) else out
            if isinstance(data, dict):
                oid = str(data.get("orderId") or data.get("ordId") or data.get("id") or "")
                status = (data.get("status") or data.get("state") or "new").lower()
                avg = float(data.get("avgPrice", data.get("avgPx", 0)) or 0)
                filled = float(data.get("filledQty", data.get("fillSz", 0)) or 0)
        except Exception:
            pass
        return OrderResult(True, "", out, oid, status, avg, filled)


--------------------------------------------------------------------------------
FILE: scalper/services/utils.py
--------------------------------------------------------------------------------
# scalper/services/utils.py
from __future__ import annotations
import asyncio
from typing import Callable, Any


class NullNotifier:
    async def send(self, _msg: str) -> None:
        return


async def heartbeat_task(running_getter: Callable[[], bool], notifier: Any, period: float = 30.0) -> None:
    if notifier is None:
        notifier = NullNotifier()
    try:
        while running_getter():
            await notifier.send("heartbeat alive")
            await asyncio.sleep(period)
    except asyncio.CancelledError:
        pass


async def log_stats_task(
    notifier: Any,
    ticks_getter: Callable[[], int],
    symbols_getter: Callable[[], list[str]],
    period: float = 30.0,
) -> None:
    if notifier is None:
        notifier = NullNotifier()
    last = 0
    try:
        while True:
            total = int(ticks_getter() or 0)
            delta = total - last
            last = total
            syms = symbols_getter() or []
            msg = f"[stats] ticks_total={total} (+{delta} /30s) | pairs=" + ",".join(syms)
            print(msg)
            await notifier.send(msg)
            await asyncio.sleep(period)
    except asyncio.CancelledError:
        pass

--------------------------------------------------------------------------------
FILE: scalper/signals/__init__.py
--------------------------------------------------------------------------------
__all__ = ["factory"]

--------------------------------------------------------------------------------
FILE: scalper/signals/current.py
--------------------------------------------------------------------------------
# scalper/signals/current.py
from __future__ import annotations

# Wrapper pour utiliser la stratégie live actuelle en mode "plugin"
from scalper.strategy import generate_signal as _generate_signal

def generate_signal(**kwargs):
    """
    Expose la même signature que scalper.strategy.generate_signal.
    Sert d’adaptateur pour la factory.
    """
    return _generate_signal(**kwargs)

--------------------------------------------------------------------------------
FILE: scalper/signals/factory.py
--------------------------------------------------------------------------------
# scalper/signals/factory.py
from __future__ import annotations
from typing import Callable, Dict, Any
import importlib
import os
import json

try:
    import yaml  # type: ignore
except Exception:
    yaml = None  # type: ignore

SignalFn = Callable[..., Any]

# IMPORTANT : on pointe par défaut sur TA stratégie actuelle dans scalper/strategy.py
_REGISTRY: Dict[str, str] = {
    "current": "scalper.strategy:generate_signal",
    # Tu pourras ajouter d'autres stratégies ici, par ex :
    # "ema_cross": "scalper.strategies.ema_cross:generate_signal",
}

def _load_callable(path: str) -> SignalFn:
    if ":" not in path:
        raise ValueError(f"Chemin callable invalide: {path}")
    module_name, attr = path.split(":", 1)
    mod = importlib.import_module(module_name)
    fn = getattr(mod, attr, None)
    if not callable(fn):
        raise ValueError(f"{attr} n'est pas callable dans {module_name}")
    return fn  # type: ignore

def load_signal(name: str) -> SignalFn:
    key = (name or "").strip().lower()
    if key not in _REGISTRY:
        raise KeyError(f"Stratégie inconnue: '{name}'. Registre: {list(_REGISTRY)}")
    return _load_callable(_REGISTRY[key])

def _read_yaml(path: str) -> dict:
    if yaml is None:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f) or {}

def load_strategies_cfg(path: str | None) -> dict:
    """
    Charge le mapping (symbole, timeframe) -> nom de stratégie.
    Si le fichier n'existe pas, retourne une config par défaut fonctionnelle.
    """
    default_cfg = {"default": "current", "by_timeframe": {}, "by_symbol": {}}
    if not path:
        return default_cfg
    if not os.path.isfile(path):
        # Pas de fichier ? On continue avec les valeurs par défaut.
        return default_cfg
    cfg = _read_yaml(path)
    cfg.setdefault("default", "current")
    cfg.setdefault("by_timeframe", {})
    cfg.setdefault("by_symbol", {})
    return cfg

def resolve_strategy_name(symbol: str, timeframe: str, cfg: dict) -> str:
    symbol = (symbol or "").upper()
    timeframe = (timeframe or "").lower()
    return (
        cfg.get("by_symbol", {}).get(symbol, {}).get(timeframe)
        or cfg.get("by_timeframe", {}).get(timeframe)
        or cfg.get("default", "current")
    )

def resolve_signal_fn(symbol: str, timeframe: str, cfg: dict) -> SignalFn:
    return load_signal(resolve_strategy_name(symbol, timeframe, cfg))

--------------------------------------------------------------------------------
FILE: scalper/signals/generator.py
--------------------------------------------------------------------------------
from __future__ import annotations

from typing import Any, Dict, List, Optional

import pandas as pd

from data.indicators import compute_all

__all__ = ["generate_signal"]


def _quality_from_score(score: float) -> str:
    if score >= 0.8:
        return "A"
    if score >= 0.5:
        return "B"
    return "C"


def generate_signal(
    df: pd.DataFrame,
    *,
    trend_tf: Optional[pd.DataFrame] = None,
    confirm_tf: Optional[pd.DataFrame] = None,
    atr_mult: float = 1.0,
    trailing: bool = False,
    **_: Any,
) -> Optional[Dict[str, Any]]:
    """Generate a trading signal with confluence scoring.

    Parameters
    ----------
    df: pd.DataFrame
        Primary timeframe OHLCV data.
    trend_tf: pd.DataFrame, optional
        Higher timeframe used for trend filtering.
    confirm_tf: pd.DataFrame, optional
        Lower timeframe used for confirmation.
    atr_mult: float, optional
        Multiplier applied to ATR for stop/target calculation.
    trailing: bool, optional
        When ``True`` include a ``trail`` distance (ATR * ``atr_mult``).

    Returns
    -------
    dict | None
        Dictionary describing the signal or ``None`` if no trade setup exists.
    """

    if df is None or len(df) < 2:
        return None

    df = compute_all(df)
    last = df.iloc[-1]

    conditions: List[bool] = []
    reasons: List[str] = []
    direction: Optional[str] = None

    # --- Basic trend via EMAs ----------------------------------------------
    if last["close"] > last["ema20"] > last["ema50"]:
        direction = "long"
        reasons.append("price_above_ema")
        conditions.append(True)
    elif last["close"] < last["ema20"] < last["ema50"]:
        direction = "short"
        reasons.append("price_below_ema")
        conditions.append(True)
    else:
        conditions.append(False)
        return None

    # --- RSI ---------------------------------------------------------------
    if direction == "long":
        cond = last["rsi"] > 55
        if cond:
            reasons.append("rsi_bullish")
        conditions.append(cond)
    else:
        cond = last["rsi"] < 45
        if cond:
            reasons.append("rsi_bearish")
        conditions.append(cond)

    # --- MACD --------------------------------------------------------------
    if direction == "long":
        cond = last["macd"] > last["macd_signal"]
        if cond:
            reasons.append("macd_bullish")
        conditions.append(cond)
    else:
        cond = last["macd"] < last["macd_signal"]
        if cond:
            reasons.append("macd_bearish")
        conditions.append(cond)

    # --- OBV momentum ------------------------------------------------------
    if len(df) >= 2:
        obv_up = df["obv"].iloc[-1] > df["obv"].iloc[-2]
        if obv_up:
            reasons.append("obv_trending")
        conditions.append(obv_up)

    # --- Trend timeframe filter -------------------------------------------
    if trend_tf is not None and len(trend_tf) >= 2:
        tdf = compute_all(trend_tf)
        ema50 = tdf["ema50"]
        slope = ema50.iloc[-1] - ema50.iloc[-2]
        if direction == "long":
            cond = slope > 0
            if cond:
                reasons.append("trend_up")
            conditions.append(cond)
        else:
            cond = slope < 0
            if cond:
                reasons.append("trend_down")
            conditions.append(cond)

    # --- Confirmation timeframe filter ------------------------------------
    if confirm_tf is not None and len(confirm_tf) > 0:
        cdf = compute_all(confirm_tf)
        rsi = cdf["rsi"].iloc[-1]
        if direction == "long":
            cond = rsi > 50
            if cond:
                reasons.append("confirm_rsi_bullish")
            conditions.append(cond)
        else:
            cond = rsi < 50
            if cond:
                reasons.append("confirm_rsi_bearish")
            conditions.append(cond)

    score = (
        sum(1 for c in conditions if c) / len(conditions) if conditions else 0.0
    )
    quality = _quality_from_score(score)

    atr = last.get("atr")
    if pd.isna(atr) or atr == 0:
        return None

    entry = float(last["close"])
    if direction == "long":
        sl = entry - atr * atr_mult
        tp = entry + atr * atr_mult * 2
    else:
        sl = entry + atr * atr_mult
        tp = entry - atr * atr_mult * 2

    result: Dict[str, Any] = {
        "direction": direction,
        "entry": entry,
        "sl": sl,
        "tp": tp,
        "score": round(score, 3),
        "reasons": reasons,
        "quality": quality,
    }

    if trailing:
        result["trail"] = atr * atr_mult

    return result


--------------------------------------------------------------------------------
FILE: scalper/strategy/factory.py
--------------------------------------------------------------------------------
annulé

--------------------------------------------------------------------------------
FILE: scalper/strategy.py
--------------------------------------------------------------------------------
"""Core trading strategy components for scalping EMA/VWAP/RSI/ATR.

This module implements a minimal but functional version of the strategy
outlined in the project specification.  The focus is on pure Python
implementations so the logic can easily be unit tested without requiring
external services or heavy third‑party dependencies.

The strategy is deliberately stateless; functions operate on passed data and
return simple data structures.  This makes it easy to plug the logic into
real‑time trading loops or backtest engines.
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Sequence, List, Dict, Optional, Tuple, Any

from .metrics import calc_rsi, calc_atr, calc_pnl_pct, calc_macd
from .risk import calc_position_size

# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

def ema(series: Sequence[float], window: int) -> List[float]:
    """Return the exponential moving average of *series*.

    The first value is the raw input to remain consistent with most trading
    platforms.  ``window`` must be positive; when it equals ``1`` the input is
    returned unchanged.
    """

    if window <= 1 or not series:
        return list(series)
    k = 2.0 / (window + 1.0)
    out: List[float] = [float(series[0])]
    prev = out[0]
    for x in series[1:]:
        prev = float(x) * k + prev * (1.0 - k)
        out.append(prev)
    return out

def vwap(highs: Sequence[float], lows: Sequence[float],
         closes: Sequence[float], volumes: Sequence[float]) -> float:
    """Compute the volume weighted average price (VWAP).

    Parameters
    ----------
    highs, lows, closes, volumes: Sequence[float]
        Matching sequences for the period considered.
    """

    tp_vol = 0.0
    vol_sum = 0.0
    for h, low, c, v in zip(highs, lows, closes, volumes):
        tp = (h + low + c) / 3.0
        tp_vol += tp * v
        vol_sum += v
    return tp_vol / vol_sum if vol_sum else 0.0

def obv(closes: Sequence[float], volumes: Sequence[float]) -> List[float]:
    """Return the On Balance Volume (OBV) series."""

    if not closes:
        return []
    out: List[float] = [0.0]
    for i in range(1, len(closes)):
        if closes[i] > closes[i - 1]:
            out.append(out[-1] + volumes[i])
        elif closes[i] < closes[i - 1]:
            out.append(out[-1] - volumes[i])
        else:
            out.append(out[-1])
    return out


def cross(last_fast: float, last_slow: float, prev_fast: float, prev_slow: float) -> int:
    """Detect a crossing between two series.

    Returns ``1`` for a bullish crossover, ``-1`` for a bearish crossover and
    ``0`` otherwise.
    """

    if prev_fast <= prev_slow and last_fast > last_slow:
        return 1
    if prev_fast >= prev_slow and last_fast < last_slow:
        return -1
    return 0


def order_book_imbalance(bid_vol: float, ask_vol: float) -> float:
    """Compute order book imbalance.

    The value is normalised between ``-1`` and ``1`` where positive numbers
    indicate bid dominance.  ``0`` is returned when both volumes are zero.
    """

    total = bid_vol + ask_vol
    return (bid_vol - ask_vol) / total if total else 0.0


def swing_levels(
    highs: Sequence[float], lows: Sequence[float], lookback: int
) -> Tuple[float, float]:
    """Return the most recent swing high and swing low.

    ``lookback`` defines how many completed candles are inspected.  The current
    candle is excluded to avoid look‑ahead bias.
    """

    if len(highs) < lookback + 1 or len(lows) < lookback + 1:
        return highs[-1], lows[-1]
    high = max(highs[-lookback - 1 : -1])
    low = min(lows[-lookback - 1 : -1])
    return high, low

# ---------------------------------------------------------------------------
# Pair selection
# ---------------------------------------------------------------------------

# The first and second level pair selection helpers now live in
# :mod:`scalper.selection`.  They are re-exported here for backward compatibility
# and to keep the public API unchanged.
from .selection.scanner import scan_pairs  # noqa: E402
from .selection.momentum import select_active_pairs  # noqa: E402

# ---------------------------------------------------------------------------
# Signal generation
# ---------------------------------------------------------------------------

@dataclass
class Signal:
    """Trading signal with risk parameters."""

    symbol: str
    side: int  # 1 for long, -1 for short
    entry: float
    sl: float
    tp1: float
    tp2: float
    qty: float = 0.0
    score: Optional[float] = None
    quality: Optional[float] = None
    reasons: Optional[List[str]] = None

    def __post_init__(self) -> None:  # pragma: no cover - simple coercion
        if isinstance(self.side, str):
            self.side = 1 if self.side.lower() in {"long", "buy", "1", "true"} else -1

    @property
    def price(self) -> float:
        return self.entry


def _generate_signal(
    symbol: str,
    ohlcv: Dict[str, Sequence[float]],
    *,
    equity: float,
    risk_pct: float,
    ohlcv_15m: Optional[Dict[str, Sequence[float]]] = None,
    ohlcv_1h: Optional[Dict[str, Sequence[float]]] = None,
    order_book: Optional[Dict[str, float]] = None,
    tick_ratio_buy: Optional[float] = None,
    atr_disable_pct: float = 0.2,
    atr_reduce_pct: float = 2.0,
    swing_lookback: int = 5,
    macd_fast: int = 12,
    macd_slow: int = 26,
    macd_signal: int = 9,
    trend_ema_period: int = 200,
) -> Optional[Signal]:
    """Return a trading :class:`Signal` if conditions are met.

    ``ohlcv`` must contain ``open``, ``high``, ``low``, ``close`` and ``volume``
    sequences ordered from oldest to newest.  The function checks the following
    rules:

    * price positioned relative to VWAP and EMA20/EMA50 trend
    * RSI(14) crossing key levels (40/60)
    * OBV rising or high short‑term volume
    * Multi time frame confirmation (H1 EMA50 slope, RSI15 >/< 50)
    * Micro‑structure breakout of last swing high/low
    * MACD trend filter
    * Long‑term trend via configurable EMA filter
    * Order book imbalance and tape filters
    * Dynamic ATR‑based stop‑loss and take‑profit
    * Position sizing via ``calc_position_size``
    """

    closes = [float(x) for x in ohlcv.get("close", [])]
    highs = [float(x) for x in ohlcv.get("high", [])]
    lows = [float(x) for x in ohlcv.get("low", [])]
    vols = [float(x) for x in ohlcv.get("volume", [])]
    if len(closes) < 60 or len(highs) != len(lows) or len(closes) != len(highs):
        return None

    price = closes[-1]
    ema20 = ema(closes, 20)
    ema50 = ema(closes, 50)
    ema_trend = ema(closes, trend_ema_period)
    v = vwap(highs, lows, closes, vols)
    obv_series = obv(closes, vols)
    obv_rising = obv_series[-1] > obv_series[-2]
    vol_last3 = sum(vols[-3:])
    vol_ma20 = sum(vols[-20:]) / 20.0
    vol_rising = vol_last3 > vol_ma20

    macd_val, macd_sig, _ = calc_macd(
        closes, fast=macd_fast, slow=macd_slow, signal=macd_signal
    )

    # Multi timeframe filters -------------------------------------------------
    trend_dir = 0  # 1 = long only, -1 = short only, 0 = neutral
    if ohlcv_1h:
        h_closes = [float(x) for x in ohlcv_1h.get("close", [])]
        if len(h_closes) >= 52:
            h_ema50 = ema(h_closes, 50)
            if len(h_ema50) >= 2:
                slope = h_ema50[-1] - h_ema50[-2]
                if slope > 0:
                    trend_dir = 1
                elif slope < 0:
                    trend_dir = -1

    rsi_15 = None
    if ohlcv_15m:
        m_closes = [float(x) for x in ohlcv_15m.get("close", [])]
        if len(m_closes) >= 15:
            rsi_15 = calc_rsi(m_closes, 14)

    # RSI crossing logic (5m)
    rsi_curr = calc_rsi(closes[-15:], 14)
    rsi_prev = calc_rsi(closes[-16:-1], 14)

    atr = calc_atr(highs, lows, closes, 14)
    atr_pct = atr / price * 100.0 if price else 0.0
    if atr_pct < atr_disable_pct:
        return None
    size_mult = 0.5 if atr_pct > atr_reduce_pct else 1.0

    sl_dist = 0.5 * atr
    tp1_dist = 1.0 * atr
    tp2_dist = 1.5 * atr

    swing_high, swing_low = swing_levels(highs, lows, swing_lookback)

    obi_ok_long = obi_ok_short = True
    if order_book is not None:
        bid = float(order_book.get("bid_vol_aggreg", 0))
        ask = float(order_book.get("ask_vol_aggreg", 0))
        obi = order_book_imbalance(bid, ask)
        obi_ok_long = obi > 0.1
        obi_ok_short = obi < -0.1

    tick_ok_long = tick_ratio_buy is None or tick_ratio_buy > 0.55
    tick_ok_short = tick_ratio_buy is None or tick_ratio_buy < 0.45

    def _size(dist: float) -> float:
        return calc_position_size(equity, risk_pct, dist) * size_mult
    weights = {
        "ema": 15.0,
        "macd": 15.0,
        "vwap": 15.0,
        "rsi": 15.0,
        "obv": 10.0,
        "swing": 10.0,
        "atr": 20.0,
    }

    atr_score = min(atr_pct / atr_reduce_pct, 1.0) * weights["atr"]

    long_score = atr_score
    long_reasons: List[str] = []
    if price > v:
        long_score += weights["vwap"]
        long_reasons.append("vwap")
    if ema20[-1] > ema50[-1]:
        long_score += weights["ema"]
        long_reasons.append("ema")
    if rsi_prev <= 40 < rsi_curr:
        long_score += weights["rsi"]
        long_reasons.append("rsi")
    if macd_val > macd_sig:
        long_score += weights["macd"]
        long_reasons.append("macd")
    if obv_rising or vol_rising:
        long_score += weights["obv"]
        long_reasons.append("obv")
    if price > swing_high:
        long_score += weights["swing"]
        long_reasons.append("swing")

    short_score = atr_score
    short_reasons: List[str] = []
    if price < v:
        short_score += weights["vwap"]
        short_reasons.append("vwap")
    if ema20[-1] < ema50[-1]:
        short_score += weights["ema"]
        short_reasons.append("ema")
    if rsi_prev >= 60 > rsi_curr:
        short_score += weights["rsi"]
        short_reasons.append("rsi")
    if macd_val < macd_sig:
        short_score += weights["macd"]
        short_reasons.append("macd")
    if obv_series[-1] < obv_series[-2] or vol_rising:
        short_score += weights["obv"]
        short_reasons.append("obv")
    if price < swing_low:
        short_score += weights["swing"]
        short_reasons.append("swing")

    side: Optional[str] = None
    score: float = 0.0
    reasons: List[str] = []
    if (
        long_score >= short_score
        and long_score > 0
        and macd_val > macd_sig
        and obi_ok_long
        and tick_ok_long
        and trend_dir >= 0
        and price > ema_trend[-1]
    ):
        side = "long"
        score = long_score
        reasons = long_reasons
        sl = price - sl_dist
        tp1 = price + tp1_dist
        tp2 = price + tp2_dist
    elif (
        short_score > long_score
        and short_score > 0
        and macd_val < macd_sig
        and obi_ok_short
        and tick_ok_short
        and trend_dir <= 0
        and price < ema_trend[-1]
    ):
        side = "short"
        score = short_score
        reasons = short_reasons
        sl = price + sl_dist
        tp1 = price - tp1_dist
        tp2 = price - tp2_dist
    else:
        return None

    qty = _size(sl_dist)
    return Signal(symbol, side, price, sl, tp1, tp2, qty, score, score, reasons)


def generate_signal(*args, **kwargs) -> Optional[Signal]:
    if "config" in kwargs:
        config = kwargs.pop("config")
        symbol = kwargs.pop("symbol", None)
        ohlcv = kwargs.pop("ohlcv", None)
        if ohlcv is None:
            raise TypeError("ohlcv argument required")
        return _generate_signal(
            symbol or ohlcv.get("symbol", ""),
            ohlcv,
            equity=kwargs.pop("equity", 0.0),
            risk_pct=getattr(config, "RISK_PCT", 0.0),
            **kwargs,
        )
    return _generate_signal(*args, **kwargs)

# ---------------------------------------------------------------------------
# Backtesting utilities
# ---------------------------------------------------------------------------

def max_drawdown(equity_curve: Sequence[float]) -> float:
    peak = equity_curve[0]
    mdd = 0.0
    for x in equity_curve:
        if x > peak:
            peak = x
        dd = (peak - x) / peak * 100.0
        if dd > mdd:
            mdd = dd
    return mdd

def backtest(
    trades: Sequence[Dict[str, Any]],
    *,
    equity_start: float = 1_000.0,
    fee_rate: float = 0.0,
) -> Dict[str, float]:
    """Evaluate a list of trade dictionaries.

    Each trade must provide ``symbol``, ``entry``, ``exit``, ``side`` and may
    optionally include ``duration`` in minutes.  Results are aggregated into
    common performance metrics to quickly evaluate the strategy.
    """

    equity = equity_start
    equity_curve = [equity]
    pnl_pct_list: List[float] = []
    wins = losses = 0
    win_sum = loss_sum = 0.0
    total_duration = 0.0

    for t in trades:
        pnl_pct = calc_pnl_pct(t["entry"], t["exit"], t["side"], fee_rate)
        pnl_pct_list.append(pnl_pct)
        if pnl_pct >= 0:
            wins += 1
            win_sum += pnl_pct
        else:
            losses += 1
            loss_sum += pnl_pct
        equity *= 1 + pnl_pct / 100.0
        equity_curve.append(equity)
        total_duration += float(t.get("duration", 0.0))

    pnl_pct_total = sum(pnl_pct_list)
    pnl_usdt = equity - equity_start
    profit_factor = (win_sum / abs(loss_sum)) if loss_sum else float("inf")
    winrate = wins / len(trades) * 100.0 if trades else 0.0
    mdd = max_drawdown(equity_curve)
    avg_trade_time = total_duration / len(trades) if trades else 0.0
    exposure = total_duration  # in minutes, callers can normalise if desired
    # Sharpe ratio based on per-trade returns
    if len(pnl_pct_list) > 1:
        mean = sum(pnl_pct_list) / len(pnl_pct_list)
        var = sum((r - mean) ** 2 for r in pnl_pct_list) / (len(pnl_pct_list) - 1)
        sharpe = mean / (var ** 0.5) if var > 0 else 0.0
    else:
        sharpe = 0.0

    return {
        "pnl_usdt": pnl_usdt,
        "pnl_pct": pnl_pct_total,
        "profit_factor": profit_factor,
        "winrate": winrate,
        "max_drawdown": mdd,
        "avg_trade_time": avg_trade_time,
        "exposure": exposure,
        "sharpe": sharpe,
    }


--------------------------------------------------------------------------------
FILE: scalper/trade_utils.py
--------------------------------------------------------------------------------
# scalper/trade_utils.py
from __future__ import annotations

from typing import Optional


def compute_position_size(
    equity: float,
    price: float,
    risk_pct: float,
    *,
    symbol: Optional[str] = None,
    min_qty: float = 0.0,
    max_leverage: float = 1.0,
) -> float:
    """
    Sizing simple: position notionnelle = equity * risk_pct * max_leverage
    qty = notionnel / price
    - min_qty : borne basse éventuelle (0 pour ignorer)
    - max_leverage : si tu veux simuler un levier (1 par défaut)
    """
    equity = float(max(0.0, equity))
    price = float(max(1e-12, price))
    risk_pct = float(max(0.0, risk_pct))
    notionnel = equity * risk_pct * max_leverage
    qty = notionnel / price
    if min_qty > 0 and qty < min_qty:
        return 0.0
    return float(qty)

--------------------------------------------------------------------------------
FILE: scalper/version.py
--------------------------------------------------------------------------------
"""Utilities for managing the Scalp bot version."""

from __future__ import annotations

from pathlib import Path
import re

import subprocess


# Path to the VERSION file within the package
_VERSION_FILE = Path(__file__).resolve().parent / "VERSION"
_VERSION_RE = re.compile(r"^(\d+)\.(\d+)\.(\d+)$")


def get_version() -> str:
    """Return the current version of the bot.

    If the VERSION file does not exist the default version ``0.0.0`` is
    returned.
    """
    if not _VERSION_FILE.exists():
        return "0.0.0"
    return _VERSION_FILE.read_text().strip()


def _parse(version: str) -> tuple[int, int, int]:
    match = _VERSION_RE.match(version)
    if not match:
        raise ValueError(f"Invalid version: {version!r}")
    return tuple(int(x) for x in match.groups())


def bump_version(part: str = "patch") -> str:
    """Bump the version stored in the VERSION file.

    Parameters
    ----------
    part:
        Which component to increment. Accepted values are ``"major"``,
        ``"minor"`` and ``"patch"`` (default).
    """
    major, minor, patch = _parse(get_version())
    if part == "major":
        major += 1
        minor = 0
        patch = 0
    elif part == "minor":
        minor += 1
        patch = 0

    elif part == "patch":
        patch += 1
    else:
        raise ValueError(f"Unknown part: {part}")
    new_version = f"{major}.{minor}.{patch}"
    _VERSION_FILE.write_text(f"{new_version}\n")
    return new_version


def bump_version_from_message(message: str) -> str:
    """Bump the version according to a commit message.

    ``message`` is evaluated using a tiny subset of the Conventional
    Commits spec. Messages starting with ``feat`` bump the *minor*
    version, messages whose header ends with ``!`` or contain
    ``BREAKING CHANGE`` bump the *major* version. All other messages
    bump the *patch* component.
    """

    header = message.strip().splitlines()[0].lower()
    lower = message.lower()
    type_part = header.split(":")[0]
    if "!" in type_part or "breaking change" in lower:
        part = "major"
    elif type_part.startswith("feat"):
        part = "minor"
    else:
        part = "patch"
    return bump_version(part)


def bump_version_from_git() -> str:
    """Read the latest git commit message and bump the version accordingly."""
    try:
        message = subprocess.check_output(
            ["git", "log", "-1", "--pretty=%B"], text=True
        ).strip()
    except Exception:
        message = ""
    return bump_version_from_message(message)


if __name__ == "__main__":
    print(bump_version_from_git())


--------------------------------------------------------------------------------
FILE: scalper/ws.py
--------------------------------------------------------------------------------
"""Minimal websocket manager with heartbeat and auto-resubscribe.

This module provides a light-weight framework to maintain a realtime
connection to an exchange.  The actual network layer is expected to be
supplied by the caller via ``connect`` and ``subscribe`` callbacks.  The
manager handles retrying failed connections and periodically invoking the
``subscribe`` callback as a heartbeat.  This keeps the code fully testable
without opening real network sockets.
"""
from __future__ import annotations

import asyncio
import logging
from typing import Awaitable, Callable, Optional


class WebsocketManager:
    """Maintain a websocket connection with heartbeat and retry."""

    def __init__(
        self,
        connect: Callable[[], Awaitable[None]],
        subscribe: Callable[[], Awaitable[None]],
        *,
        heartbeat_interval: float = 30.0,
        max_retries: int = 3,
    ) -> None:
        self._connect = connect
        self._subscribe = subscribe
        self.heartbeat_interval = heartbeat_interval
        self.max_retries = max_retries
        self._heartbeat_task: Optional[asyncio.Task] = None

    async def run(self) -> None:
        """Open the connection retrying on failure."""
        retries = 0
        while True:
            try:
                await self._connect()
                await self._subscribe()
                self._heartbeat_task = asyncio.create_task(self._heartbeat())
                return
            except Exception as exc:  # pragma: no cover - network errors
                logging.error("websocket connect failed: %s", exc)
                retries += 1
                if retries > self.max_retries:
                    raise
                await asyncio.sleep(1)

    async def _heartbeat(self) -> None:
        """Send periodic heartbeats and resubscribe on failure."""
        while True:
            await asyncio.sleep(self.heartbeat_interval)
            try:
                await self._subscribe()
            except Exception as exc:  # pragma: no cover - network errors
                logging.warning("websocket heartbeat failed: %s", exc)
                await self.run()
                break

    async def stop(self) -> None:
        """Cancel the heartbeat task if it is running."""
        task = self._heartbeat_task
        if task and not task.done():
            task.cancel()
            try:
                await task
            except BaseException:  # pragma: no cover - cancellation
                pass
        self._heartbeat_task = None


--------------------------------------------------------------------------------
FILE: sitecustomize.py
--------------------------------------------------------------------------------
# sitecustomize.py
"""
Ce fichier est importé automatiquement par Python au démarrage, si présent sur sys.path.
On l'utilise pour lancer un préflight de 'scalper' avant l'exécution du bot,
sans modifier bot.py. Désactivable via SKIP_PREFLIGHT=1.
"""

import os

if os.getenv("SKIP_PREFLIGHT", "0") not in ("1", "true", "yes"):
    try:
        # Optionnel: charger /notebooks/.env si présent
        try:
            from dotenv import load_dotenv  # pip install python-dotenv si besoin
            load_dotenv("/notebooks/.env")
        except Exception:
            pass

    except Exception:
        pass

    try:
        from scalper.selfcheck import preflight_or_die
        preflight_or_die(verbose=False)
    except SystemExit:
        # le préflight a signalé un problème -> on laisse l'arrêt se propager
        raise
    except Exception as e:
        # On ne bloque pas le démarrage si le selfcheck lui-même plante,
        # mais on affiche une alerte claire.
        print(f"[sitecustomize] Avertissement: selfcheck non exécuté ({e})")

--------------------------------------------------------------------------------
FILE: tests/conftest.py
--------------------------------------------------------------------------------
"""Test configuration and shared fixtures."""

import sys
import types
from pathlib import Path


# Ensure the project root is importable so tests can ``import bot``.
ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(ROOT))


# Provide a dummy ``requests`` module so ``bot.py`` doesn't attempt to install
# the real dependency during test collection. Individual tests patch the
# functions they need (``request``/``post``/``get``).
sys.modules.setdefault(
    "requests",
    types.SimpleNamespace(HTTPError=Exception, request=None, post=None, get=None),
)



--------------------------------------------------------------------------------
FILE: tests/test_analyse_risque.py
--------------------------------------------------------------------------------
import os
import sys
import types

sys.path.append(os.path.dirname(os.path.dirname(__file__)))
sys.modules['requests'] = types.SimpleNamespace(
    request=lambda *a, **k: None,
    post=lambda *a, **k: None,
    HTTPError=Exception,
)

from bot import analyse_risque  # noqa: E402


def make_contract_detail():
    return {
        "data": [
            {
                "symbol": "BTC_USDT",
                "contractSize": 0.01,
                "volUnit": 1,
                "minVol": 1,
            }
        ]
    }


def test_analyse_risque_limits_and_leverage():
    contract_detail = make_contract_detail()
    # Risk level 1: leverage halved, limit 1 position
    open_pos = [{"symbol": "BTC_USDT", "side": "long"}]
    vol, lev = analyse_risque(contract_detail, open_pos, 1000, 50000, 0.01, 10,
                               symbol="BTC_USDT", side="long", risk_level=1)
    assert lev == 5
    assert vol == 0  # already one long position

    # Risk level 2: base leverage, limit 3 positions
    open_pos = [
        {"symbol": "BTC_USDT", "side": "long"},
        {"symbol": "BTC_USDT", "side": "long"},
        {"symbol": "BTC_USDT", "side": "long"},
    ]
    vol, lev = analyse_risque(contract_detail, open_pos, 1000, 50000, 0.01, 10,
                               symbol="BTC_USDT", side="long", risk_level=2)
    assert lev == 10
    assert vol == 0

    # Risk level 3: leverage doubled, no existing position
    open_pos = []
    vol, lev = analyse_risque(contract_detail, open_pos, 1000, 50000, 0.01, 10,
                               symbol="BTC_USDT", side="long", risk_level=3)
    assert lev == 20
    assert vol == 1


--------------------------------------------------------------------------------
FILE: tests/test_backtest.py
--------------------------------------------------------------------------------
import pytest

import bot


def test_backtest_trades():
    trades = [
        {"symbol": "AAA", "entry": 100.0, "exit": 110.0, "side": 1},
        {"symbol": "BBB", "entry": 100.0, "exit": 90.0, "side": -1},
    ]
    pnl = bot.backtest_trades(trades, fee_rate=0.001)
    # Both trades: 10% - 0.2% fee = 9.8% each
    assert pnl == pytest.approx(19.6)


--------------------------------------------------------------------------------
FILE: tests/test_backtest_multi.py
--------------------------------------------------------------------------------
import csv
import random
from datetime import datetime, timedelta, timezone
from pathlib import Path

import pytest

from scalper.backtest.run_multi import run_backtest_multi
from scalper.strategy import Signal


def make_csv(tmp_path: Path, symbol: str, timeframe: str = "1m") -> None:
    start = datetime(2024, 1, 1, tzinfo=timezone.utc)
    filename = tmp_path / f"{symbol.replace('/', '')}-{timeframe}.csv"
    with open(filename, "w", newline="") as fh:
        writer = csv.writer(fh)
        writer.writerow(["timestamp", "open", "high", "low", "close", "volume"])
        for i in range(200):
            ts = int((start + timedelta(minutes=i)).timestamp() * 1000)
            price = 100 + i
            writer.writerow([ts, price, price * 1.02, price * 0.995, price, 1])


def simple_signal(symbol, ohlcv, equity, risk_pct, **kwargs):
    closes = ohlcv["close"]
    if len(closes) < 10:
        return None
    price = closes[-1]
    sl = price * 0.99
    tp = price * 1.01
    qty = equity * risk_pct / (price - sl)
    return Signal(symbol, "long", price, sl, tp, tp * 1.01, qty, score=1.0, reasons=["test"])


def random_signal(symbol, ohlcv, equity, risk_pct, **kwargs):
    if len(ohlcv["close"]) < 10 or random.random() > 0.3:
        return None
    price = ohlcv["close"][-1]
    sl = price * 0.99
    tp = price * 1.01
    qty = equity * risk_pct / (price - sl)
    return Signal(symbol, "long", price, sl, tp, tp * 1.01, qty)


def tiny_qty_signal(symbol, ohlcv, equity, risk_pct, **kwargs):
    closes = ohlcv["close"]
    if len(closes) < 10:
        return None
    price = closes[-1]
    sl = price * 0.99
    tp = price * 1.01
    return Signal(symbol, "long", price, sl, tp, tp * 1.01, 0.00005)


def find_row(summary, symbol):
    for row in summary:
        if row["symbol"] == symbol:
            return row
    raise KeyError(symbol)


def test_csv_multi_pairs(tmp_path, monkeypatch):
    for sym in ["BTC/USDT", "ETH/USDT"]:
        make_csv(tmp_path, sym)
    monkeypatch.setattr("scalper.strategy.generate_signal", simple_signal)
    monkeypatch.setattr("backtest.engine.generate_signal", simple_signal)
    out = tmp_path / "out"
    summary, trades = run_backtest_multi(
        symbols=["BTC/USDT", "ETH/USDT"],
        exchange="csv",
        timeframe="1m",
        csv_dir=str(tmp_path),
        fee_rate=0.0,
        slippage_bps=0.0,
        risk_pct=0.01,
        initial_equity=1000,
        leverage=1.0,
        paper_constraints=True,
        seed=42,
        out_dir=str(out),
        plot=False,
    )
    btc_trades = [t for t in trades if t["symbol"] == "BTC/USDT"]
    eth_trades = [t for t in trades if t["symbol"] == "ETH/USDT"]
    assert len(btc_trades) > 0 and len(eth_trades) > 0
    assert find_row(summary, "BTC/USDT")["pnl_usdt"] > 0
    total = find_row(summary, "TOTAL")["pnl_usdt"]
    assert pytest.approx(total) == find_row(summary, "BTC/USDT")["pnl_usdt"] + find_row(summary, "ETH/USDT")["pnl_usdt"]
    # files
    assert (out / "report_summary.csv").exists()
    assert (out / "report_trades.csv").exists()
    assert (out / "equity_curve_total.csv").exists()
    assert (out / "equity_curve_BTC_USDT.csv").exists()
    # columns in trades
    for col in ["entry_time", "exit_time", "symbol", "side", "entry", "exit", "pnl_pct", "pnl_usdt"]:
        assert col in trades[0]


def test_fee_slippage(tmp_path, monkeypatch):
    make_csv(tmp_path, "BTC/USDT")
    monkeypatch.setattr("scalper.strategy.generate_signal", simple_signal)
    monkeypatch.setattr("backtest.engine.generate_signal", simple_signal)
    summary1, _ = run_backtest_multi(
        symbols=["BTC/USDT"],
        exchange="csv",
        timeframe="1m",
        csv_dir=str(tmp_path),
        fee_rate=0.0,
        slippage_bps=0.0,
        out_dir=str(tmp_path / "o1"),
    )
    summary2, _ = run_backtest_multi(
        symbols=["BTC/USDT"],
        exchange="csv",
        timeframe="1m",
        csv_dir=str(tmp_path),
        fee_rate=0.01,
        slippage_bps=100,
        out_dir=str(tmp_path / "o2"),
    )
    pnl1 = find_row(summary1, "TOTAL")["pnl_usdt"]
    pnl2 = find_row(summary2, "TOTAL")["pnl_usdt"]
    assert pnl2 < pnl1


def test_paper_constraints(tmp_path, monkeypatch):
    make_csv(tmp_path, "BTC/USDT")
    monkeypatch.setattr("scalper.strategy.generate_signal", tiny_qty_signal)
    monkeypatch.setattr("backtest.engine.generate_signal", tiny_qty_signal)
    summary, trades = run_backtest_multi(
        symbols=["BTC/USDT"],
        exchange="csv",
        timeframe="1m",
        csv_dir=str(tmp_path),
        paper_constraints=True,
        out_dir=str(tmp_path / "o"),
    )
    assert all(t["qty"] >= 0.001 for t in trades)
    assert all(abs((t["qty"] * 10000) % 1) < 1e-9 for t in trades)
    assert all(t["entry"] * t["qty"] >= 5 - 1e-9 for t in trades)


def test_seed_reproducible(tmp_path, monkeypatch):
    make_csv(tmp_path, "BTC/USDT")
    monkeypatch.setattr("scalper.strategy.generate_signal", random_signal)
    monkeypatch.setattr("backtest.engine.generate_signal", random_signal)
    s1, t1 = run_backtest_multi(
        symbols=["BTC/USDT"],
        exchange="csv",
        timeframe="1m",
        csv_dir=str(tmp_path),
        seed=7,
        out_dir=str(tmp_path / "o1"),
    )
    s2, t2 = run_backtest_multi(
        symbols=["BTC/USDT"],
        exchange="csv",
        timeframe="1m",
        csv_dir=str(tmp_path),
        seed=7,
        out_dir=str(tmp_path / "o2"),
    )
    assert t1 == t2
    assert s1 == s2


--------------------------------------------------------------------------------
FILE: tests/test_backtest_position.py
--------------------------------------------------------------------------------
import os
import sys
import pytest

sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from scalper.metrics import backtest_position


def test_backtest_position_long():
    prices = [100.0, 110.0, 120.0]
    assert backtest_position(prices, 0, 2, 1) is True


def test_backtest_position_short():
    prices = [100.0, 90.0, 80.0]
    assert backtest_position(prices, 0, 2, -1) is True


def test_backtest_position_incoherent():
    prices = [100.0, 110.0, 120.0]
    assert backtest_position(prices, 0, 2, -1) is False


def test_backtest_position_bad_indices():
    prices = [100.0, 110.0]
    with pytest.raises(ValueError):
        backtest_position(prices, 1, 0, 1)


--------------------------------------------------------------------------------
FILE: tests/test_bitget_futures_pairs.py
--------------------------------------------------------------------------------
import json
from pathlib import Path
from typing import Any, Dict

import pytest

import bitget_futures_pairs as bfp


class DummyResponse:
    def __init__(self, status: int, payload: Dict[str, Any]):
        self.status_code = status
        self._payload = payload
        self.text = json.dumps(payload)

    def json(self):
        return self._payload


def test_fetch_contracts_success(monkeypatch):
    payload = {"code": "00000", "data": [{"symbol": "BTCUSDT"}]}

    def fake_get(url, params=None, timeout=0):
        return DummyResponse(200, payload)

    monkeypatch.setattr(bfp, "requests", type("R", (), {"get": staticmethod(fake_get)})())
    contracts = bfp.fetch_contracts("USDT-FUTURES")
    assert contracts == payload["data"]


def test_fetch_contracts_error(monkeypatch):
    payload = {"code": "10001"}

    def fake_get(url, params=None, timeout=0):
        return DummyResponse(200, payload)

    monkeypatch.setattr(bfp, "requests", type("R", (), {"get": staticmethod(fake_get)})())
    with pytest.raises(RuntimeError):
        bfp.fetch_contracts("USDT-FUTURES")


def test_normalize_rows():
    contracts = [
        {
            "symbol": "BTCUSDT",
            "baseCoin": "BTC",
            "quoteCoin": "USDT",
            "symbolType": "perpetual",
            "symbolStatus": "normal",
            "maxLever": "50",
            "minLever": "1",
            "minTradeNum": "0.001",
            "sizeMultiplier": "1",
            "pricePlace": "2",
            "volumePlace": "3",
            "launchTime": 0,
            "deliveryTime": 0,
        }
    ]
    rows = bfp.normalize_rows("USDT-FUTURES", contracts)
    assert rows[0]["symbol"] == "BTCUSDT"
    assert rows[0]["productType"] == "USDT-FUTURES"


def test_write_csv(tmp_path: Path):
    path = tmp_path / "pairs.csv"
    bfp.write_csv([], str(path))
    assert path.exists()
    content = path.read_text().splitlines()
    assert content[0].startswith("productType,")


--------------------------------------------------------------------------------
FILE: tests/test_bot_place_order_caps.py
--------------------------------------------------------------------------------
import os
import sys
import types
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
sys.modules['requests'] = types.ModuleType('requests')

from bot import attempt_entry, Signal


class DummyClient:
    def __init__(self):
        self.last_order = None

    def place_order(self, *args, **kwargs):  # pragma: no cover - simple store
        self.last_order = (args, kwargs)
        return {"code": "00000"}


class DummyRisk:
    def __init__(self, pct):
        self.risk_pct = pct


def _detail():
    return {
        "data": [
            {
                "symbol": "BTC_USDT",
                "contractSize": 0.001,
                "volUnit": 1,
                "minVol": 1,
                "minTradeUSDT": 5,
            }
        ]
    }


def test_attempt_entry_respects_caps(monkeypatch):
    captured = {}

    def fake_notify(event, payload):
        captured[event] = payload

    monkeypatch.setattr("bot.notify", fake_notify)
    client = DummyClient()
    sig = Signal("BTC_USDT", "long", 10000, 9900, 10100, 10200, 1, score=80)
    rm = DummyRisk(0.02)
    equity = 100
    available = 2.2  # just enough for 1 contract with buffer
    params = attempt_entry(
        client,
        _detail(),
        sig,
        equity_usdt=equity,
        available_usdt=available,
        cfg={"LEVERAGE": 10},
        risk_mgr=rm,
        user_risk_level=1,
    )
    assert client.last_order is not None
    assert params["vol"] >= 1
    opened = captured["position_opened"]
    assert opened["notional_usdt"] >= 5
    assert opened["vol"] >= 1


def test_attempt_entry_insufficient_margin(monkeypatch):
    captured = {}

    def fake_notify(event, payload):
        captured[event] = payload

    monkeypatch.setattr("bot.notify", fake_notify)
    client = DummyClient()
    sig = Signal("BTC_USDT", "long", 10000, 9900, 10100, 10200, 1, score=80)
    rm = DummyRisk(0.02)
    equity = 100
    available = 1.0  # below required margin
    params = attempt_entry(
        client,
        _detail(),
        sig,
        equity_usdt=equity,
        available_usdt=available,
        cfg={"LEVERAGE": 10},
        risk_mgr=rm,
        user_risk_level=1,
    )
    assert client.last_order is None
    assert params["vol"] == 0
    assert captured["order_blocked"]["reason"].startswith("volume reduced")


def test_attempt_entry_under_min_trade(monkeypatch):
    captured = {}

    def fake_notify(event, payload):
        captured[event] = payload

    monkeypatch.setattr("bot.notify", fake_notify)
    client = DummyClient()
    sig = Signal("BTC_USDT", "long", 10000, 9900, 10100, 10200, 1, score=80)
    rm = DummyRisk(0.02)
    detail = {
        "data": [
            {
                "symbol": "BTC_USDT",
                "contractSize": 0.001,
                "volUnit": 1,
                "minVol": 1,
                "minTradeUSDT": 50,
            }
        ]
    }
    equity = 100
    available = 100
    params = attempt_entry(
        client,
        detail,
        sig,
        equity_usdt=equity,
        available_usdt=available,
        cfg={"LEVERAGE": 10},
        risk_mgr=rm,
        user_risk_level=1,
    )
    assert client.last_order is None
    assert params["vol"] == 0
    assert captured["order_blocked"]["reason"].startswith("volume reduced")


--------------------------------------------------------------------------------
FILE: tests/test_bot_update.py
--------------------------------------------------------------------------------
import logging
import bot


def test_update_displays_pairs(monkeypatch, caplog):
    def fake_send(client, top_n=40):
        assert (client, top_n) == ("cli", 5)
        return {"green": "BTC", "orange": "ETH", "red": "XRP"}

    monkeypatch.setattr(bot, "send_selected_pairs", fake_send)
    with caplog.at_level(logging.INFO):
        payload = bot.update("cli", top_n=5)
    assert payload["green"] == "BTC"
    assert "Listing ok" in caplog.text


def test_update_survives_errors(monkeypatch, caplog):
    """``update`` should never raise even if pair selection fails."""

    def boom(client, top_n=40):  # pragma: no cover - simulated failure
        raise RuntimeError("network down")

    monkeypatch.setattr(bot, "send_selected_pairs", boom)
    with caplog.at_level(logging.INFO):
        payload = bot.update("cli", top_n=5)

    # The function returns an empty payload and logs the error, but still logs
    # the "Listing ok" acknowledgement so callers can proceed.
    assert payload == {}
    assert "network down" in caplog.text
    assert "Listing ok" in caplog.text



--------------------------------------------------------------------------------
FILE: tests/test_break_even_stop.py
--------------------------------------------------------------------------------
from scalper.trade_utils import break_even_stop


def test_break_even_stop_long() -> None:
    sl = break_even_stop("long", entry_price=100, current_price=110, atr=5, sl=95)
    assert sl == 100
    sl = break_even_stop("long", entry_price=100, current_price=102, atr=5, sl=95)
    assert sl == 95


def test_break_even_stop_short() -> None:
    sl = break_even_stop("short", entry_price=100, current_price=90, atr=5, sl=105)
    assert sl == 100
    sl = break_even_stop("short", entry_price=100, current_price=97, atr=5, sl=105)
    assert sl == 105


--------------------------------------------------------------------------------
FILE: tests/test_calc_pnl_pct.py
--------------------------------------------------------------------------------
import os
import sys
import pytest
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from scalper.metrics import calc_pnl_pct


def test_calc_pnl_pct_long():
    assert calc_pnl_pct(100.0, 110.0, 1) == 10.0

def test_calc_pnl_pct_short():
    assert calc_pnl_pct(100.0, 90.0, -1) == 10.0


def test_calc_pnl_pct_with_fee():
    # 10% move minus 0.1%*2 fees = 9.8%
    assert calc_pnl_pct(100.0, 110.0, 1, fee_rate=0.001) == pytest.approx(9.8)


--------------------------------------------------------------------------------
FILE: tests/test_check_config.py
--------------------------------------------------------------------------------
import logging
from bot import check_config


def test_check_config_only_logs_critical_missing(monkeypatch, caplog):
    monkeypatch.delenv("BITGET_ACCESS_KEY", raising=False)
    monkeypatch.delenv("BITGET_SECRET_KEY", raising=False)
    monkeypatch.delenv("NOTIFY_URL", raising=False)
    with caplog.at_level(logging.INFO):
        check_config()
    messages = [r.getMessage() for r in caplog.records]
    assert any("BITGET_ACCESS_KEY" in m for m in messages)
    assert any("BITGET_SECRET_KEY" in m for m in messages)
    assert all("NOTIFY_URL" not in m for m in messages)


def test_check_config_does_not_log_present_keys(monkeypatch, caplog):
    monkeypatch.setenv("BITGET_ACCESS_KEY", "abcdef")
    monkeypatch.setenv("BITGET_SECRET_KEY", "abcdef")
    monkeypatch.setenv("BITGET_PASSPHRASE", "abcdef")
    with caplog.at_level(logging.INFO):
        check_config()
    assert caplog.records == []


--------------------------------------------------------------------------------
FILE: tests/test_cli.py
--------------------------------------------------------------------------------
"""Tests for the command line interface defined in :mod:`cli`."""

from __future__ import annotations

import cli


def test_opt_invokes_parallel_optimization(monkeypatch):
    """The ``opt`` command should call ``run_parallel_optimization``."""

    called = {}

    def fake_run(pairs, tf, jobs):  # pragma: no cover - executed via CLI
        called["args"] = (pairs, tf, jobs)

    monkeypatch.setattr(cli, "run_parallel_optimization", fake_run)
    cli.main(["opt", "--pairs", "BTCUSDT", "ETHUSDT", "--tf", "1h", "--jobs", "4"])
    assert called["args"] == (["BTCUSDT", "ETHUSDT"], "1h", 4)


def test_walkforward_invokes_analysis(monkeypatch):
    """The ``walkforward`` command calls ``run_walkforward_analysis``."""

    called = {}

    def fake_run(pair, tf, splits, train_ratio):  # pragma: no cover
        called["args"] = (pair, tf, splits, train_ratio)

    monkeypatch.setattr(cli, "run_walkforward_analysis", fake_run)
    cli.main(
        [
            "walkforward",
            "--pair",
            "BTCUSDT",
            "--tf",
            "1m",
            "--splits",
            "3",
            "--train-ratio",
            "0.8",
        ]
    )
    assert called["args"] == ("BTCUSDT", "1m", 3, 0.8)


def test_live_invokes_async_pipeline(monkeypatch):
    """The ``live`` command must execute the async pipeline via ``asyncio.run``."""

    called = {}

    async def fake_live(pairs, tfs):  # pragma: no cover - executed asynchronously
        called["args"] = (pairs, list(tfs))

    monkeypatch.setattr(cli, "run_live_pipeline", fake_live)
    cli.main(["live", "--pairs", "BTCUSDT", "ETHUSDT", "--tfs", "1m", "1h"])
    assert called["args"] == (["BTCUSDT", "ETHUSDT"], ["1m", "1h"])


def test_bump_version_invokes_helper(monkeypatch):
    """The ``bump-version`` command calls ``bump_version_from_git``."""

    called = {}

    def fake_bump():  # pragma: no cover - executed via CLI
        called["called"] = True
        return "0.1.0"

    monkeypatch.setattr(cli, "bump_version_from_git", fake_bump)
    cli.main(["bump-version"])
    assert called["called"] is True



--------------------------------------------------------------------------------
FILE: tests/test_client.py
--------------------------------------------------------------------------------
import json
import hmac
import hashlib
import base64
import pytest
import bot
from bot import BitgetFuturesClient


@pytest.fixture(autouse=True)
def no_log_event(monkeypatch):
    monkeypatch.setattr(bot, "log_event", lambda *a, **k: None)


def test_private_request_get_signature(monkeypatch):
    client = BitgetFuturesClient("key", "secret", "https://test")
    monkeypatch.setattr(BitgetFuturesClient, "_ms", staticmethod(lambda: 1000))

    called = {}

    def fake_request(method, url, headers=None, timeout=None):
        called["method"] = method
        called["url"] = url
        called["headers"] = headers

        class Resp:
            def raise_for_status(self):
                pass

            def json(self):
                return {"success": True}

        return Resp()

    monkeypatch.setattr(bot.requests, "request", fake_request)

    resp = client._private_request("GET", "/api/test", params={"b": "2", "a": "1"})
    assert resp["success"] is True
    qs = "a=1&b=2"
    prehash = f"1000GET/api/test?{qs}"
    expected = base64.b64encode(
        hmac.new(b"secret", prehash.encode(), hashlib.sha256).digest()
    ).decode()
    assert called["headers"]["ACCESS-SIGN"] == expected
    assert called["headers"]["ACCESS-KEY"] == "key"
    assert called["headers"]["ACCESS-TIMESTAMP"] == "1000"
    assert called["headers"]["ACCESS-RECV-WINDOW"] == "30"
    assert called["url"] == "https://test/api/test?a=1&b=2"


def test_private_request_post_signature(monkeypatch):
    client = BitgetFuturesClient("key", "secret", "https://test")
    monkeypatch.setattr(BitgetFuturesClient, "_ms", staticmethod(lambda: 1000))

    called = {}

    def fake_post(url, data=None, headers=None, timeout=None):
        called["url"] = url
        called["data"] = data
        called["headers"] = headers

        class Resp:
            def raise_for_status(self):
                pass

            def json(self):
                return {"success": True}

        return Resp()

    monkeypatch.setattr(bot.requests, "post", fake_post)

    resp = client._private_request("POST", "/api/test", body={"a": 1, "b": 2})
    assert resp["success"] is True
    body = json.dumps({"a": 1, "b": 2}, separators=(",", ":"), ensure_ascii=False)
    prehash = f"1000POST/api/test{body}"
    expected = base64.b64encode(
        hmac.new(b"secret", prehash.encode(), hashlib.sha256).digest()
    ).decode()
    assert called["headers"]["ACCESS-SIGN"] == expected
    assert called["headers"]["ACCESS-KEY"] == "key"
    assert called["headers"]["ACCESS-TIMESTAMP"] == "1000"
    assert called["headers"]["ACCESS-RECV-WINDOW"] == "30"
    assert called["data"].decode("utf-8") == body
    assert called["url"] == "https://test/api/test"


def test_private_request_http_error(monkeypatch):
    client = BitgetFuturesClient("key", "secret", "https://test")
    monkeypatch.setattr(BitgetFuturesClient, "_ms", staticmethod(lambda: 1000))

    class Resp:
        status_code = 418

        def raise_for_status(self):
            raise bot.requests.HTTPError("teapot")

        def json(self):
            return {"unused": True}

    monkeypatch.setattr(bot.requests, "request", lambda *a, **k: Resp())

    resp = client._private_request("GET", "/api/test")
    assert resp["success"] is False
    assert resp["status_code"] == 418
    assert "teapot" in resp["error"]


def test_get_assets_normalization(monkeypatch):
    client = BitgetFuturesClient("key", "secret", "https://test")

    called = {}

    def fake_private(self, method, path, params=None, body=None):
        called["method"] = method
        called["path"] = path
        called["params"] = params
        return {"code": "00000", "data": [{"marginCoin": "usdt", "equity": "1"}]}

    monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)

    assets = client.get_assets()

    assert assets["success"] is True
    usdt = assets.get("data", [])[0]
    assert usdt["currency"].upper() == "USDT"
    assert usdt["equity"] == 1.0
    assert called["params"] == {"productType": "USDT-FUTURES", "marginCoin": "USDT"}


def test_get_assets_equity_fallback(monkeypatch):
    client = BitgetFuturesClient("key", "secret", "https://test")

    def fake_private(self, method, path, params=None, body=None):
        return {"code": "00000", "data": [{"marginCoin": "USDT", "available": "2"}]}

    monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)

    assets = client.get_assets()
    usdt = assets.get("data", [])[0]
    assert usdt["currency"] == "USDT"
    assert usdt["equity"] == 2.0


def test_get_assets_prefers_available(monkeypatch):
    """When both equity and available are returned, available should win."""
    client = BitgetFuturesClient("key", "secret", "https://test")

    def fake_private(self, method, path, params=None, body=None):
        return {
            "code": "00000",
            "data": [
                {
                    "marginCoin": "USDT",
                    "equity": "5",
                    "available": "1",
                }
            ],
        }

    monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)

    assets = client.get_assets()
    usdt = assets.get("data", [])[0]
    assert usdt["equity"] == 1.0



def test_get_assets_zero_available(monkeypatch):
    """Zero available balance should propagate as zero equity."""
    client = BitgetFuturesClient("key", "secret", "https://test")

    def fake_private(self, method, path, params=None, body=None):
        return {
            "code": "00000",
            "data": [
                {
                    "marginCoin": "USDT",
                    "available": "0",
                    "equity": "5",
                }
            ],
        }

    monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)

    assets = client.get_assets()
    usdt = assets.get("data", [])[0]
    assert usdt["equity"] == 0.0


def test_get_assets_available_balance(monkeypatch):
    """Support alternative ``availableBalance`` field name."""
    client = BitgetFuturesClient("key", "secret", "https://test")

    def fake_private(self, method, path, params=None, body=None):
        return {
            "code": "00000",
            "data": [{"marginCoin": "USDT", "availableBalance": "3.5"}],
        }

    monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)

    assets = client.get_assets()
    usdt = assets.get("data", [])[0]
    assert usdt["equity"] == 3.5


def test_get_ticker_normalization(monkeypatch):
    client = BitgetFuturesClient("key", "secret", "https://test")

    called = {}

    def fake_get(url, params=None, timeout=None):
        called["url"] = url
        called["params"] = params

        class Resp:
            def raise_for_status(self):
                pass

            def json(self):
                return {
                    "data": {
                        "instId": "BTCUSDT",
                        "lastPr": "1",
                        "bestBidPrice": "0.9",
                        "bestAskPrice": "1.1",
                        "usdtVolume": "100",
                    }
                }

        return Resp()

    monkeypatch.setattr(bot.requests, "get", fake_get, raising=False)

    ticker = client.get_ticker("BTC_USDT")

    assert ticker["success"] is True
    data = ticker["data"][0]
    assert data["symbol"] == "BTCUSDT"
    assert data["lastPrice"] == "1"
    assert data["bidPrice"] == "0.9"
    assert data["askPrice"] == "1.1"
    assert data["volume"] == 100.0
    assert called["params"] == {"symbol": "BTCUSDT", "productType": "USDT-FUTURES"}


def test_http_client_context_manager(monkeypatch):
    import sys
    import importlib
    sys.modules.pop('requests', None)
    real_requests = importlib.import_module('requests')
    sys.modules['requests'] = real_requests
    import scalper.client as http_client
    importlib.reload(http_client)

    closed = {"count": 0}

    class DummySession:
        def mount(self, *a, **k):
            pass

        def request(self, *a, **k):
            class Resp:
                def raise_for_status(self):
                    pass

                def json(self):
                    return {}

                text = "{}"

            return Resp()

        def close(self):
            closed["count"] += 1

    monkeypatch.setattr(http_client.requests, "Session", lambda: DummySession())

    http = http_client.HttpClient("http://example.com")
    http.close()
    assert closed["count"] == 1

    closed["count"] = 0
    with http_client.HttpClient("http://example.com") as hc:
        hc.request("GET", "/")
    assert closed["count"] == 1


def test_get_kline_query_params(monkeypatch):
    """Ensure ``get_kline`` hits the correct endpoint and passes symbol as a
    query parameter. The previous implementation embedded the symbol in the
    path which resulted in a 404 from Bitget."""

    client = BitgetFuturesClient("key", "secret", "https://test")

    called = {}

    def fake_get(url, params=None, timeout=None):
        called["url"] = url
        called["params"] = params

        class Resp:
            def raise_for_status(self):
                pass

            def json(self):
                return {"data": []}

        return Resp()

    # Some tests replace ``bot.requests`` with a lightweight namespace that
    # doesn't define ``get``. ``raising=False`` ensures the attribute is added
    # even if missing so we can observe the call.
    monkeypatch.setattr(bot.requests, "get", fake_get, raising=False)

    client.get_kline("BTC_USDT", interval="Min1")

    assert called["url"].endswith("/api/v2/mix/market/candles")
    assert called["params"] == {
        "symbol": "BTCUSDT",
        "productType": "USDT-FUTURES",
        "granularity": "1m",
    }


def test_get_open_orders_endpoint(monkeypatch):
    client = BitgetFuturesClient("key", "secret", "https://test", paper_trade=False)

    called = {}

    def fake_private(self, method, path, params=None, body=None):
        called["method"] = method
        called["path"] = path
        called["params"] = params
        return {"success": True}

    monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)

    client.get_open_orders("BTCUSDT_UMCBL")

    assert called["path"] == "/api/v2/mix/order/orders-pending"
    assert called["params"] == {
        "productType": "USDT-FUTURES",
        "symbol": "BTCUSDT",
    }


def test_product_type_alias():
    client = BitgetFuturesClient("key", "secret", "https://test", product_type="umcbl")
    assert client.product_type == "USDT-FUTURES"


def test_get_contract_detail_endpoint(monkeypatch):
    client = BitgetFuturesClient("key", "secret", "https://test")

    called = {}

    def fake_get(url, params=None, timeout=None):
        called["url"] = url
        called["params"] = params

        class Resp:
            status_code = 200

            def raise_for_status(self):
                pass

            def json(self):
                return {"data": []}

        return Resp()

    monkeypatch.setattr(bot.requests, "get", fake_get, raising=False)

    client.get_contract_detail("BTCUSDT_UMCBL")

    assert called["url"].endswith("/api/v2/mix/market/contracts")
    assert called["params"] == {
        "productType": "USDT-FUTURES",
        "symbol": "BTCUSDT",
    }


def test_cancel_all_endpoint(monkeypatch):
    client = BitgetFuturesClient("key", "secret", "https://test", paper_trade=False)

    called = {}

    def fake_private(self, method, path, params=None, body=None):
        called["method"] = method
        called["path"] = path
        called["params"] = params
        called["body"] = body
        return {"success": True}

    monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)

    client.cancel_all("BTCUSDT_UMCBL", margin_coin="USDT")

    assert called["method"] == "POST"
    assert called["path"] == "/api/v2/mix/order/cancel-all-orders"
    assert called["params"] is None
    assert called["body"] == {
        "productType": "USDT-FUTURES",
        "symbol": "BTCUSDT",
        "marginCoin": "USDT",
    }


def test_place_order_endpoint(monkeypatch):
    client = BitgetFuturesClient("key", "secret", "https://test", paper_trade=False)

    called = {}

    monkeypatch.setattr(BitgetFuturesClient, "_get_contract_precision", lambda self, symbol: (0, 0))

    def fake_private(self, method, path, params=None, body=None):
        called["method"] = method
        called["path"] = path
        called["body"] = body
        return {"success": True}

    monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)

    resp = client.place_order("BTCUSDT_UMCBL", side=1, vol=1, order_type=1)

    assert resp["success"] is True
    assert called["method"] == "POST"
    assert called["path"] == "/api/v2/mix/order/place-order"
    body = called["body"]
    assert body["symbol"] == "BTCUSDT"
    assert body["marginCoin"] == "USDT"
    assert body["marginMode"] == "crossed"
    assert body["side"] == "buy"
    assert body["posSide"] == "long"
    assert "reduceOnly" not in body
    assert body["posMode"] == "hedge_mode"


@pytest.mark.parametrize(
    "code, side_str, pos_side",
    [
        (4, "sell", "long"),
        (2, "buy", "short"),
    ],
)
def test_place_order_close_positions(monkeypatch, code, side_str, pos_side):
    client = BitgetFuturesClient("key", "secret", "https://test", paper_trade=False)

    monkeypatch.setattr(BitgetFuturesClient, "_get_contract_precision", lambda self, symbol: (0, 0))

    called = {}

    def fake_private(self, method, path, params=None, body=None):
        called["body"] = body
        return {"success": True}

    monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)

    client.place_order("BTCUSDT_UMCBL", side=code, vol=1, order_type=1)

    body = called["body"]
    assert body["side"] == side_str
    assert body["posSide"] == pos_side
    assert "reduceOnly" not in body


def test_place_order_precision(monkeypatch):
    client = BitgetFuturesClient("key", "secret", "https://test", paper_trade=False)

    monkeypatch.setattr(BitgetFuturesClient, "_get_contract_precision", lambda self, symbol: (2, 3))

    called = {}

    def fake_private(self, method, path, params=None, body=None):
        called["body"] = body
        return {"success": True}

    monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)

    client.place_order(
        "BTCUSDT_UMCBL", side=1, vol=1.23456, order_type=1, price=1234.5678
    )

    assert called["body"]["price"] == 1234.57
    assert called["body"]["size"] == 1.235


def test_margin_cap_skips_order(monkeypatch):
    client = BitgetFuturesClient("key", "secret", "https://test", paper_trade=False)
    called = {}

    def fake_private(method, path, **kwargs):
        called["path"] = path
        return {"code": "00000"}

    monkeypatch.setattr(client, "_private_request", fake_private)
    contract_detail = {
        "data": {
            "symbol": "BTCUSDT_UMCBL",
            "contractSize": 1,
            "volUnit": 1,
            "minVol": 1,
            "minTradeUSDT": 5,
        }
    }
    price = 100.0
    available = 0.5
    vol = bot.compute_position_size(
        contract_detail,
        equity_usdt=available,
        price=price,
        risk_pct=1.0,
        leverage=10,
        symbol="BTCUSDT_UMCBL",
        available_usdt=available,
    )
    if vol > 0:
        client.place_order(
            "BTCUSDT_UMCBL", side=1, vol=vol, order_type=1, price=price, leverage=10
        )
    assert called == {}


def test_margin_cap_reduces_volume(monkeypatch):
    client = BitgetFuturesClient("key", "secret", "https://test", paper_trade=False)
    called = {}

    def fake_private(method, path, **kwargs):
        called["body"] = kwargs.get("body")
        return {"code": "00000"}

    monkeypatch.setattr(client, "_private_request", fake_private)
    contract_detail = {
        "data": {
            "symbol": "BTCUSDT_UMCBL",
            "contractSize": 1,
            "volUnit": 1,
            "minVol": 1,
            "minTradeUSDT": 5,
        }
    }
    price = 10.0
    vol_theoretical = bot.compute_position_size(
        contract_detail,
        equity_usdt=100,
        price=price,
        risk_pct=1.0,
        leverage=10,
        symbol="BTCUSDT_UMCBL",
    )
    available = 20.0
    vol_final = bot.compute_position_size(
        contract_detail,
        equity_usdt=available,
        price=price,
        risk_pct=1.0,
        leverage=10,
        symbol="BTCUSDT_UMCBL",
        available_usdt=available,
    )
    assert vol_final < vol_theoretical
    client.place_order(
        "BTCUSDT_UMCBL", side=1, vol=vol_final, order_type=1, price=price, leverage=10
    )
    assert called["body"]["size"] == vol_final

def test_get_open_orders_paper_trade(monkeypatch):
    client = BitgetFuturesClient("key", "secret", "https://test", paper_trade=True)

    called = {"count": 0}

    def fake_private(*a, **k):
        called["count"] += 1
        return {"success": True}

    monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)

    resp = client.get_open_orders("BTCUSDT_UMCBL")

    assert resp["success"] is True
    assert resp["data"] == []
    assert called["count"] == 0


def test_cancel_all_paper_trade(monkeypatch):
    client = BitgetFuturesClient("key", "secret", "https://test", paper_trade=True)

    called = {"count": 0}

    def fake_private(*a, **k):
        called["count"] += 1
        return {"success": True}

    monkeypatch.setattr(BitgetFuturesClient, "_private_request", fake_private)

    resp = client.cancel_all("BTCUSDT_UMCBL", margin_coin="USDT")

    assert resp["success"] is True
    assert called["count"] == 0


def test_get_kline_transforms_data(monkeypatch):
    client = BitgetFuturesClient("key", "secret", "https://test")

    def fake_get(url, params=None, timeout=None):
        class Resp:
            def raise_for_status(self):
                pass

            def json(self):
                return {
                    "data": [
                        ["1", "2", "3", "1", "2", "10", "20"],
                        ["2", "3", "4", "2", "3", "11", "21"],
                    ]
                }

        return Resp()

    monkeypatch.setattr(bot.requests, "get", fake_get, raising=False)

    data = client.get_kline("BTC_USDT", interval="1m")
    kdata = data["data"]
    assert kdata["open"] == [2.0, 3.0]
    assert kdata["high"] == [3.0, 4.0]
    assert kdata["low"] == [1.0, 2.0]
    assert kdata["close"] == [2.0, 3.0]
    assert kdata["volume"] == [10.0, 11.0]
    assert kdata["quoteVolume"] == [20.0, 21.0]


--------------------------------------------------------------------------------
FILE: tests/test_compute_position_size.py
--------------------------------------------------------------------------------
import os
import sys
import types
import pytest

sys.path.append(os.path.dirname(os.path.dirname(__file__)))
sys.modules["requests"] = types.ModuleType("requests")
import bot  # noqa: E402
from bot import compute_position_size  # noqa: E402


def test_compute_position_size_basic():
    contract_detail = {
        "data": [
            {
                "symbol": "BTC_USDT",
                "contractSize": 0.01,
                "volUnit": 1,
                "minVol": 1,
            }
        ]
    }
    vol = compute_position_size(contract_detail, equity_usdt=1000, price=50000,
                                risk_pct=0.01, leverage=10, symbol="BTC_USDT")
    assert vol == 1


def test_compute_position_size_symbol_not_found():
    contract_detail = {"data": [{"symbol": "ETH_USDT", "contractSize": 0.1}]}
    with pytest.raises(ValueError):
        compute_position_size(contract_detail, equity_usdt=1000, price=500,
                                risk_pct=0.01, leverage=10, symbol="BTC_USDT")


def test_compute_position_size_invalid_price():
    contract_detail = {
        "data": [
            {
                "symbol": "BTC_USDT",
                "contractSize": 0.01,
                "volUnit": 1,
                "minVol": 1,
            }
        ]
    }
    vol = compute_position_size(
        contract_detail,
        equity_usdt=1000,
        price=0,
        risk_pct=0.01,
        leverage=10,
        symbol="BTC_USDT",
    )
    assert vol == 0


def test_compute_position_size_respects_equity():
    contract_detail = {
        "data": [
            {
                "symbol": "BTC_USDT",
                "contractSize": 1,
                "volUnit": 1,
                "minVol": 1,
            }
        ]
    }
    vol = compute_position_size(
        contract_detail,
        equity_usdt=5,
        price=100,
        risk_pct=0.01,
        leverage=10,
        symbol="BTC_USDT",
    )
    assert vol == 0


def test_compute_position_size_leaves_fee_buffer():
    contract_detail = {
        "data": [
            {
                "symbol": "BTC_USDT",
                "contractSize": 1,
                "volUnit": 1,
                "minVol": 1,
            }
        ]
    }
    vol = compute_position_size(
        contract_detail,
        equity_usdt=100,
        price=100,
        risk_pct=1.0,
        leverage=1,
        symbol="BTC_USDT",
    )
    assert vol == 0


def test_compute_position_size_under_min_notional_returns_zero():
    contract_detail = {
        "data": [
            {
                "symbol": "PI_USDT",
                "contractSize": 1,
                "volUnit": 1,
                "minVol": 1,
                "minTradeUSDT": 5,
            }
        ]
    }
    vol = compute_position_size(
        contract_detail,
        equity_usdt=100,
        price=0.5,
        risk_pct=0.0001,
        leverage=20,
        symbol="PI_USDT",
    )
    assert vol == 0


def test_compute_position_size_cap_by_available():
    contract_detail = {
        "data": [
            {
                "symbol": "BTC_USDT",
                "contractSize": 1,
                "volUnit": 2,
                "minVol": 2,
                "minTradeUSDT": 5,
            }
        ]
    }
    vol = compute_position_size(
        contract_detail,
        equity_usdt=100,
        price=10,
        risk_pct=0.5,
        leverage=10,
        symbol="BTC_USDT",
        available_usdt=0.5,
    )
    assert vol == 0
    vol = compute_position_size(
        contract_detail,
        equity_usdt=100,
        price=10,
        risk_pct=0.5,
        leverage=10,
        symbol="BTC_USDT",
        available_usdt=10,
    )
    assert vol == 8
    fee_rate = max(bot.CONFIG.get("FEE_RATE", 0.0), 0.001)
    required = (10 * 1 * vol / 10 + fee_rate * 10 * 1 * vol) * 1.03
    assert required <= 10


--------------------------------------------------------------------------------
FILE: tests/test_compute_position_size_cap.py
--------------------------------------------------------------------------------
import os
import sys
import types
import pytest

sys.path.append(os.path.dirname(os.path.dirname(__file__)))
sys.modules['requests'] = types.ModuleType('requests')

from bot import compute_position_size, CONFIG


def _detail(vol_unit=1, min_vol=1, min_trade=5):
    return {
        "data": [
            {
                "symbol": "BTC_USDT",
                "contractSize": 0.001,
                "volUnit": vol_unit,
                "minVol": min_vol,
                "minTradeUSDT": min_trade,
            }
        ]
    }


def test_volume_zero_when_available_low():
    detail = _detail()
    vol = compute_position_size(
        detail,
        equity_usdt=1000,
        price=10000,
        risk_pct=0.01,
        leverage=10,
        symbol="BTC_USDT",
        available_usdt=0.5,
    )
    assert vol == 0


def test_margin_close_to_available():
    detail = _detail()
    CONFIG["FEE_RATE"] = 0.001
    available = 1.05
    vol = compute_position_size(
        detail,
        equity_usdt=1000,
        price=10000,
        risk_pct=1,
        leverage=10,
        symbol="BTC_USDT",
        available_usdt=available,
    )
    assert vol == 1
    notional = 10000 * 0.001 * vol
    fee = max(CONFIG.get("FEE_RATE", 0.0), 0.001) * notional
    required = (notional / 10 + fee) * 1.03
    assert required == pytest.approx(available, rel=0.05)


def test_respects_units_and_minimums():
    detail = _detail(vol_unit=2, min_vol=2, min_trade=5)
    vol = compute_position_size(
        detail,
        equity_usdt=1000,
        price=1000,
        risk_pct=1,
        leverage=5,
        symbol="BTC_USDT",
        available_usdt=1000,
    )
    assert vol % 2 == 0 and vol >= 2


--------------------------------------------------------------------------------
FILE: tests/test_dynamic_allocation.py
--------------------------------------------------------------------------------
import math
from scalper.risk import adjust_risk_pct


def test_adjust_risk_pct_increase_decrease():
    base = 0.01
    assert adjust_risk_pct(base, win_streak=2, loss_streak=0) > base
    assert adjust_risk_pct(base, win_streak=0, loss_streak=2) < base


def test_adjust_risk_pct_bounds():
    assert math.isclose(
        adjust_risk_pct(0.05, win_streak=2, loss_streak=0, max_pct=0.05), 0.05
    )
    assert math.isclose(
        adjust_risk_pct(0.001, win_streak=0, loss_streak=2, min_pct=0.001), 0.001
    )


--------------------------------------------------------------------------------
FILE: tests/test_effective_leverage.py
--------------------------------------------------------------------------------
import pytest
from scalper.trade_utils import effective_leverage


def test_effective_leverage_basic():
    lev = effective_leverage(
        entry_price=100.0,
        liquidation_price=90.0,
        position_margin=10.0,
        position_size=1.0,
    )
    assert lev == pytest.approx(10.0)


def test_effective_leverage_estimated_margin():
    lev = effective_leverage(
        entry_price=200.0,
        liquidation_price=180.0,
        position_margin=0.0,
        position_size=2.0,
    )
    # price diff 20 * size 2 -> margin 40; notional 400
    assert lev == pytest.approx(10.0)


def test_effective_leverage_short_position():
    lev = effective_leverage(
        entry_price=100.0,
        liquidation_price=110.0,
        position_margin=10.0,
        position_size=-1.5,
    )
    assert lev == pytest.approx(15.0)


def test_effective_leverage_invalid():
    assert effective_leverage(0, 0, 0, 0) == 0.0


--------------------------------------------------------------------------------
FILE: tests/test_env_loading.py
--------------------------------------------------------------------------------
"""Tests for loading environment variables from ``notebook/.env``."""

from __future__ import annotations

import importlib
import os
import sys
from pathlib import Path


def test_parent_env_loaded(tmp_path, monkeypatch) -> None:
    """Module should load variables from ``notebook/.env`` if present."""

    notebook = tmp_path / "notebook"
    spot = notebook / "spot"
    spot.mkdir(parents=True)
    bitget_bot = spot / "bitget_bot.py"
    bitget_bot.write_text("")
    env_file = notebook / ".env"
    env_file.write_text("BITGET_ACCESS_KEY=from_env\n")

    old = os.environ.pop("BITGET_ACCESS_KEY", None)
    monkeypatch.setattr(sys, "argv", [str(bitget_bot)])
    import scalp

    importlib.reload(scalp)

    try:
        assert os.getenv("BITGET_ACCESS_KEY") == "from_env"
    finally:
        env_file.unlink(missing_ok=True)
        if old is None:
            os.environ.pop("BITGET_ACCESS_KEY", None)
        else:
            os.environ["BITGET_ACCESS_KEY"] = old


--------------------------------------------------------------------------------
FILE: tests/test_grid_search.py
--------------------------------------------------------------------------------
import json
import random

import pytest

from scalper.backtest import grid_search


def test_build_grid_sampling():
    param_lists = {
        "timeframe": ["1m", "5m", "15m"],
        "score_min": [50, 55, 60],
        "atr_min_ratio": [0.0015, 0.002, 0.003],
    }
    combos = grid_search.build_param_grid(param_lists, grid_max=6)
    assert len(combos) == 6
    tfs = {c["timeframe"] for c in combos}
    assert {"1m", "5m", "15m"}.issubset(tfs)


def test_run_grid_search_with_mock(tmp_path):
    calls = []

    def fake_run_backtest_multi(**kwargs):
        tf = kwargs.get("timeframe")
        risk = kwargs.get("risk_pct")
        # fabricate metrics based on params
        pf = {"1m": 1.5, "5m": 3.0}[tf]
        pf += risk  # tiny variation
        metrics = {
            "symbol": "TOTAL",
            "pnl_usdt": 100 * risk,
            "profit_factor": pf,
            "max_drawdown_pct": 5.0 if tf == "1m" else 3.0,
            "winrate_pct": 50.0,
            "trades": 40 if tf == "1m" else 30,
        }
        calls.append((tf, risk))
        return [metrics], []

    param_lists = {
        "timeframe": ["1m", "5m"],
        "risk_pct": [0.005, 0.01],
    }
    base_params = {
        "timeframe": "1m",
        "risk_pct": 0.005,
    }
    out_dir = tmp_path / "grid"
    grid_search.run_grid_search(
        symbols=["BTC/USDT"],
        exchange="csv",
        base_params=base_params,
        param_lists=param_lists,
        grid_max=4,
        csv_dir="/dev/null",
        out_dir=str(out_dir),
        run_func=fake_run_backtest_multi,
    )
    best = json.loads((out_dir / "best_config.json").read_text())
    # best PF should be timeframe 5m risk 0.01
    assert best["params"]["timeframe"] == "5m"
    assert best["params"]["risk_pct"] == 0.01
    assert len(calls) == 4


def test_parse_hours():
    assert grid_search.parse_hours("7-11,13-17") == [7, 8, 9, 10, 11, 13, 14, 15, 16, 17]


def test_deterministic_results(tmp_path):
    def fake_run_backtest_multi(**kwargs):
        # metrics vary with global random state
        pf = random.uniform(1.0, 3.0)
        metrics = {
            "symbol": "TOTAL",
            "pnl_usdt": random.uniform(-10, 10),
            "profit_factor": pf,
            "max_drawdown_pct": random.uniform(1, 5),
            "winrate_pct": 50.0,
            "trades": random.randint(10, 50),
        }
        return [metrics], []

    param_lists = {"timeframe": ["1m", "5m"]}
    base_params = {"timeframe": "1m"}
    out_dir = tmp_path / "grid"
    res1 = grid_search.run_grid_search(
        symbols=["BTC/USDT"],
        exchange="csv",
        base_params=base_params,
        param_lists=param_lists,
        grid_max=2,
        csv_dir="/dev/null",
        out_dir=str(out_dir),
        seed=42,
        run_func=fake_run_backtest_multi,
    )
    best1 = json.loads((out_dir / "best_config.json").read_text())
    # run again
    out_dir2 = tmp_path / "grid2"
    res2 = grid_search.run_grid_search(
        symbols=["BTC/USDT"],
        exchange="csv",
        base_params=base_params,
        param_lists=param_lists,
        grid_max=2,
        csv_dir="/dev/null",
        out_dir=str(out_dir2),
        seed=42,
        run_func=fake_run_backtest_multi,
    )
    best2 = json.loads((out_dir2 / "best_config.json").read_text())
    assert best1 == best2
    # also ensure results object same best params
    assert res1[0].params == res2[0].params


--------------------------------------------------------------------------------
FILE: tests/test_heat_score.py
--------------------------------------------------------------------------------
from scalper.pairs import heat_score, select_top_heat_pairs, decorrelate_pairs


def test_heat_score_value():
    assert heat_score(2.0, 100.0) == 200.0
    assert heat_score(2.0, 100.0, news=True) == 400.0


def test_select_and_decorrelate_pairs():
    pairs = [
        {"symbol": "A", "volatility": 2, "volume": 100, "news": True},
        {"symbol": "B", "volatility": 1, "volume": 200, "news": False},
        {"symbol": "C", "volatility": 1.5, "volume": 150, "news": False},
        {"symbol": "D", "volatility": 3, "volume": 50, "news": True},
    ]
    top = select_top_heat_pairs(pairs, top_n=3)
    assert len(top) == 3
    corr = {"A": {"B": 0.9}, "B": {"A": 0.9}, "C": {}, "D": {}}
    selected = decorrelate_pairs(pairs, corr, threshold=0.8, top_n=3)
    syms = {p["symbol"] for p in selected}
    assert not ("A" in syms and "B" in syms)


--------------------------------------------------------------------------------
FILE: tests/test_indicators.py
--------------------------------------------------------------------------------


import os
import sys
import pytest
sys.path.append(os.path.dirname(os.path.dirname(__file__)))




from scalper.metrics import calc_rsi, calc_atr, calc_macd


def test_calc_rsi_uptrend():
    prices = list(range(1, 16))  # strictly increasing
    assert calc_rsi(prices, period=14) == pytest.approx(100.0)


def test_calc_rsi_downtrend():
    prices = list(range(15, 0, -1))  # strictly decreasing
    assert calc_rsi(prices, period=14) == pytest.approx(0.0)



def test_calc_rsi_flat():
    prices = [1.0] * 15  # no movement
    assert calc_rsi(prices, period=14) == pytest.approx(50.0)



    highs = [10, 11, 12, 13, 14]
    lows = [9, 10, 11, 12, 13]
    closes = [9.5, 10.5, 11.5, 12.5, 13.5]
    assert calc_atr(highs, lows, closes, period=3) == pytest.approx(1.5)


def test_calc_macd_trend():
    prices = list(range(1, 60))
    macd, signal, hist = calc_macd(prices)
    assert macd > signal
    assert hist > 0


def test_calc_macd_flat():
    prices = [100.0] * 60
    macd, signal, hist = calc_macd(prices)
    assert macd == pytest.approx(0.0)
    assert signal == pytest.approx(0.0)
    assert hist == pytest.approx(0.0)



@pytest.mark.parametrize("prices, period", [([1, 2, 3], 0), ([1, 2, 3], 5)])
def test_calc_rsi_invalid_inputs(prices, period):
    with pytest.raises(ValueError):
        calc_rsi(prices, period=period)


@pytest.mark.parametrize(
    "highs, lows, closes, period",
    [
        ([1, 2, 3], [1, 2], [1, 2, 3], 2),
        ([1, 2], [1, 1], [1, 1], 3),
    ],
)
def test_calc_atr_invalid_inputs(highs, lows, closes, period):
    with pytest.raises(ValueError):
        calc_atr(highs, lows, closes, period=period)



--------------------------------------------------------------------------------
FILE: tests/test_min_qty_rules.py
--------------------------------------------------------------------------------
import os
import sys
import types

sys.path.append(os.path.dirname(os.path.dirname(__file__)))
sys.modules['requests'] = types.ModuleType('requests')

from bot import _apply_contract_checks


def _detail():
    return {
        "data": [
            {
                "symbol": "BTC_USDT",
                "contractSize": 1,
                "volUnit": 5,
                "minVol": 10,
                "minTradeUSDT": 5,
            }
        ]
    }


def test_min_qty_floor_and_validation():
    detail = _detail()
    vol, N, req = _apply_contract_checks(1, 13, 10, 100, detail, "BTC_USDT")
    assert vol == 10
    vol2, N2, req2 = _apply_contract_checks(1, 7, 10, 100, detail, "BTC_USDT")
    assert vol2 == 0


--------------------------------------------------------------------------------
FILE: tests/test_notifier.py
--------------------------------------------------------------------------------
import scalper.notifier as notifier


def test_notify_skips_without_targets(monkeypatch):
    called = False

    def fake_post(url, json=None, timeout=5):  # pragma: no cover - fallback
        nonlocal called
        called = True

    monkeypatch.delenv("NOTIFY_URL", raising=False)
    monkeypatch.delenv("TELEGRAM_BOT_TOKEN", raising=False)
    monkeypatch.delenv("TELEGRAM_CHAT_ID", raising=False)
    monkeypatch.setattr(notifier.requests, "post", fake_post)
    notifier.notify("test", {"foo": 1})
    assert called is False


def test_notify_posts_http(monkeypatch):
    payload = {}

    def fake_post(url, json=None, timeout=5):
        payload["url"] = url
        payload["json"] = json
        payload["timeout"] = timeout

    monkeypatch.delenv("TELEGRAM_BOT_TOKEN", raising=False)
    monkeypatch.delenv("TELEGRAM_CHAT_ID", raising=False)
    monkeypatch.setenv("NOTIFY_URL", "http://example.com")
    monkeypatch.setattr(notifier.requests, "post", fake_post)
    notifier.notify("evt", {"bar": 2})
    assert payload["url"] == "http://example.com"
    assert payload["json"]["event"] == "evt"
    assert payload["json"]["bar"] == 2


def test_notify_posts_telegram(monkeypatch):
    payload = {}

    def fake_post(url, json=None, timeout=5):
        payload["url"] = url
        payload["json"] = json
        payload["timeout"] = timeout

    monkeypatch.delenv("NOTIFY_URL", raising=False)
    monkeypatch.setenv("TELEGRAM_BOT_TOKEN", "abc")
    monkeypatch.setenv("TELEGRAM_CHAT_ID", "123")
    monkeypatch.setattr(notifier.requests, "post", fake_post)

    notifier.notify("evt", {"bar": 2})

    assert payload["url"] == "https://api.telegram.org/botabc/sendMessage"
    assert payload["json"]["chat_id"] == "123"
    assert "evt" in payload["json"]["text"]


def test_notify_posts_both(monkeypatch):
    calls = []

    def fake_post(url, json=None, timeout=5):
        calls.append({"url": url, "json": json, "timeout": timeout})

    monkeypatch.setenv("NOTIFY_URL", "http://example.com")
    monkeypatch.setenv("TELEGRAM_BOT_TOKEN", "abc")
    monkeypatch.setenv("TELEGRAM_CHAT_ID", "123")
    monkeypatch.setattr(notifier.requests, "post", fake_post)

    notifier.notify("evt", {"bar": 2})

    assert len(calls) == 2
    urls = {c["url"] for c in calls}
    assert "http://example.com" in urls
    assert "https://api.telegram.org/botabc/sendMessage" in urls


def test_notify_skips_telegram_for_pair_list(monkeypatch):
    calls = []

    def fake_post(url, json=None, timeout=5):
        calls.append(url)

    monkeypatch.setenv("NOTIFY_URL", "http://example.com")
    monkeypatch.setenv("TELEGRAM_BOT_TOKEN", "abc")
    monkeypatch.setenv("TELEGRAM_CHAT_ID", "123")
    monkeypatch.setattr(notifier.requests, "post", fake_post)

    notifier.notify("pair_list", {"pairs": "BTC"})

    # Only the generic webhook should be called, not Telegram
    assert calls == ["http://example.com"]


def test_format_text_open_position():
    payload = {
        "symbol": "BTCUSDT",
        "side": "short",
        "price": 18350,
        "vol": 37,
        "contract_size": 1,
        "notional_usdt": 120.5,
        "leverage": 5,
        "required_margin_usdt": 25.3,
        "available_usdt": 134,
        "risk_level_user": 3,
        "signal_level": 2,
        "risk_color": "🟡",
        "risk_pct_eff": 0.01,
        "fee_rate": 0.001,
    }
    text = notifier._format_text("position_opened", payload)
    lines = text.splitlines()

    assert lines[0] == "🟡 Ouvre short BTC"
    assert lines[1] == "Notional: 120.5 USDT   Levier: x5"
    assert lines[2] == "Marge estimée: 25.3 USDT (dispo: 134 USDT)"
    assert lines[3] == "Risque: lvl 2/3 (risk_pct=1.0000%)"
    assert lines[4] == "Prix: 18350   Vol: 37 (cs=1)"


def test_format_text_closed_position():
    payload = {
        "symbol": "BTCUSDT",
        "side": "short",
        "entry_price": 18350,
        "exit_price": 18328,
        "vol": 37,
        "contract_size": 1,
        "notional_entry_usdt": 120.5,
        "notional_exit_usdt": 120.3,
        "fees_usdt": 0.03,
        "pnl_usdt": 0.84,
        "pnl_pct_on_margin": 3.25,
        "leverage": 5,
        "risk_color": "🟡",
        "fee_rate": 0.001,
    }
    text = notifier._format_text("position_closed", payload)
    lines = text.splitlines()
    assert lines[0] == "Ferme short BTC 🟡"
    assert lines[1] == "PnL net: +0.84 USDT (frais: 0.03)"
    assert lines[2] == "% sur marge: 3.25%"
    assert lines[3] == "Entrée: 18350  Sortie: 18328"
    assert lines[4] == "Vol: 37  Notional: in 120.5 → out 120.3 USDT"


def test_format_text_pair_list_and_start():
    assert notifier._format_text("bot_started") == "🤖 Bot démarré"
    text = notifier._format_text(
        "pair_list", {"green": "AAA", "orange": "BBB", "red": "CCC"}
    )
    assert text == "Listing ok"


def test_format_pair_list_helper():
    payload = {"green": "AAA", "orange": "BBB", "red": "CCC"}
    text = notifier._format_pair_list(payload)
    assert text == "Listing ok"


def test_format_position_event_helper():
    payload = {
        "symbol": "BTCUSDT",
        "side": "short",
        "price": 18350,
        "vol": 37,
        "contract_size": 1,
        "notional_usdt": 120.5,
        "leverage": 5,
        "required_margin_usdt": 25.3,
        "available_usdt": 134,
        "risk_level_user": 3,
        "signal_level": 2,
        "risk_color": "🟡",
        "risk_pct_eff": 0.01,
        "fee_rate": 0.001,
    }
    text = notifier._format_position_event("position_opened", payload)
    assert text.splitlines()[0] == "🟡 Ouvre short BTC"




--------------------------------------------------------------------------------
FILE: tests/test_notional_and_pnl_units.py
--------------------------------------------------------------------------------
import os, sys, types, pytest
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
sys.modules['requests'] = types.ModuleType('requests')

from scalper.trade_utils import (
    get_contract_size,
    notional as calc_notional,
    required_margin as calc_required_margin,
    compute_pnl_usdt,
    compute_pnl_with_fees,
)


def _detail():
    return {"data": [{"symbol": "BTC_USDT", "contractSize": 0.001}]}


def test_notional_and_pnl_units():
    detail = _detail()
    cs = get_contract_size(detail, "BTC_USDT")
    N = calc_notional(10000, 2, cs)
    assert N == pytest.approx(10000 * 0.001 * 2)
    margin = calc_required_margin(N, 10, 0.001, buffer=0.0)
    assert margin == pytest.approx(N / 10 + 0.001 * N)
    pnl = compute_pnl_usdt(detail, 10000, 10100, 2, 1, symbol="BTC_USDT")
    assert pnl == pytest.approx((10100 - 10000) * 0.001 * 2)
    pnl_net, pct = compute_pnl_with_fees(
        detail, 10000, 10100, 2, 1, 10, 0.001, symbol="BTC_USDT"
    )
    gross = (10100 - 10000) * cs * 2
    fees = 0.001 * (calc_notional(10000, 2, cs) + calc_notional(10100, 2, cs))
    expected = gross - fees
    expected_pct = expected / (N / 10) * 100
    assert pnl_net == pytest.approx(expected)
    assert pct == pytest.approx(expected_pct)


--------------------------------------------------------------------------------
FILE: tests/test_pair_selection.py
--------------------------------------------------------------------------------
import bot


def test_get_trade_pairs():
    class Client:
        def get_ticker(self, symbol=None):
            return {
                "success": True,
                "data": [
                    {"symbol": "BTC_USDT"},
                    {"symbol": "ETH_USDT"},
                ],
            }

    pairs = bot.get_trade_pairs(Client())
    assert [p["symbol"] for p in pairs] == ["BTC_USDT", "ETH_USDT"]


def test_select_top_pairs():
    class Client:
        def get_ticker(self, symbol=None):
            return {
                "success": True,
                "data": [
                    {"symbol": "A", "volume": "1"},
                    {"symbol": "B", "volume": "3"},
                    {"symbol": "C", "volume": "2"},
                ],
            }

    top = bot.select_top_pairs(Client(), top_n=2)
    assert [p["symbol"] for p in top] == ["B", "C"]


def test_select_top_pairs_default_count():
    class Client:
        def get_ticker(self, symbol=None):
            data = []
            for i in range(100):
                data.append({"symbol": str(i), "volume": str(i)})
            return {"success": True, "data": data}

    top = bot.select_top_pairs(Client())
    assert len(top) == 40


def test_filter_trade_pairs():
    class Client:
        def get_ticker(self, symbol=None):
            return {
                "success": True,
                "data": [
                    {
                        "symbol": "AAA",
                        "volume": "6000000",
                        "bidPrice": "100",
                        "askPrice": "100.03",
                    },  # spread ~3 bps
                    {
                        "symbol": "BBB",
                        "volume": "10000000",
                        "bidPrice": "50",
                        "askPrice": "50.1",
                    },  # spread ~200 bps
                    {
                        "symbol": "CCC",
                        "volume": "7000000",
                        "bidPrice": "10",
                        "askPrice": "10.01",
                    },  # spread ~100 bps
                    {
                        "symbol": "DDD",
                        "volume": "4000000",
                        "bidPrice": "20",
                        "askPrice": "20.01",
                    },  # volume trop faible
                ],
            }

    pairs = bot.filter_trade_pairs(
        Client(),
        volume_min=5_000_000,
        max_spread_bps=5,
    )
    assert [p["symbol"] for p in pairs] == ["AAA"]


def test_find_trade_positions(monkeypatch):
    class Client:
        def __init__(self):
            self.data = {
                "AAA": {"data": {"close": [1, 2, 3]}},
                "BBB": {"data": {"close": [3, 2, 1]}},
            }

        def get_kline(self, symbol, interval="1m"):
            return self.data[symbol]

    pairs = [
        {"symbol": "AAA", "lastPrice": "1"},
        {"symbol": "BBB", "lastPrice": "1"},
    ]

    monkeypatch.setattr(bot, "ema", lambda series, window: series)

    def fake_cross(last_fast, last_slow, prev_fast, prev_slow):
        if last_fast > prev_fast:
            return 1
        if last_fast < prev_fast:
            return -1
        return 0

    monkeypatch.setattr(bot, "cross", fake_cross)

    signals = bot.find_trade_positions(Client(), pairs, ema_fast_n=1, ema_slow_n=1)
    assert signals == [
        {"symbol": "AAA", "signal": "long", "price": 1.0},
        {"symbol": "BBB", "signal": "short", "price": 1.0},
    ]


--------------------------------------------------------------------------------
FILE: tests/test_pairs.py
--------------------------------------------------------------------------------
import bot


def test_send_selected_pairs(monkeypatch):
    sent = {}

    def fake_notify(event, payload=None):
        sent["event"] = event
        sent["payload"] = payload

    monkeypatch.setattr(bot, "notify", fake_notify)
    monkeypatch.setattr(
        bot,
        "filter_trade_pairs",
        lambda client, top_n=120: [
            {"symbol": "WIFUSDT", "volume": 10},
            {"symbol": "WIFUSDT", "volume": 9},
            {"symbol": "BTCUSD", "volume": 8},
            {"symbol": "BTCUSDT", "volume": 7},
            {"symbol": "DOGEUSDT", "volume": 6},
            {"symbol": "ETHUSDC", "volume": 5},
            {"symbol": "ETHUSDT", "volume": 4},
        ],
    )

    monkeypatch.setitem(bot.CONFIG, "ALLOWED_SYMBOLS", ["BTCUSDT", "ETHUSDT"])

    payload = bot.send_selected_pairs(object(), top_n=4)

    assert sent["event"] == "pair_list"
    assert sent["payload"]["green"] == "BTC"
    assert sent["payload"]["orange"] == "ETH"
    assert "red" not in sent["payload"]
    assert payload == sent["payload"]


def test_send_selected_pairs_no_whitelist(monkeypatch):
    sent = {}

    def fake_notify(event, payload=None):
        sent["payload"] = payload

    monkeypatch.setattr(bot, "notify", fake_notify)
    monkeypatch.setattr(
        bot,
        "filter_trade_pairs",
        lambda client, top_n=120: [
            {"symbol": "AAAUSDT", "volume": 10},
            {"symbol": "BBBUSD", "volume": 9},
            {"symbol": "CCCUSDC", "volume": 8},
            {"symbol": "DDDUSDT", "volume": 7},
        ],
    )
    monkeypatch.setitem(bot.CONFIG, "ALLOWED_SYMBOLS", [])

    payload = bot.send_selected_pairs(object(), top_n=4)

    assert payload == sent["payload"]
    assert payload["green"] == "AAA"
    assert payload["orange"] == "BBB"
    assert payload["red"] == "CCC, DDD"


def test_filter_trade_pairs_all_pairs(monkeypatch):
    class DummyClient:
        def get_ticker(self):
            return {
                "data": [
                    {"symbol": "BTCUSDT", "volume": 100, "bidPrice": 1, "askPrice": 1.0001},
                    {"symbol": "ETHUSDT", "volume": 90, "bidPrice": 1, "askPrice": 1.0001},
                ]
            }

    client = DummyClient()
    res = bot.filter_trade_pairs(client, volume_min=0, max_spread_bps=10, top_n=5)
    assert [r["symbol"] for r in res] == ["BTCUSDT", "ETHUSDT"]



--------------------------------------------------------------------------------
FILE: tests/test_risk_manager.py
--------------------------------------------------------------------------------
from scalp import RiskManager


def test_kill_switch_triggered() -> None:
    rm = RiskManager(max_daily_loss_pct=2.0, max_positions=1, risk_pct=0.01)
    rm.record_trade(-1.0)
    rm.record_trade(-1.5)
    assert rm.kill_switch is True


def test_profit_kill_switch_triggered() -> None:
    rm = RiskManager(
        max_daily_loss_pct=10.0,
        max_daily_profit_pct=3.0,
        max_positions=1,
        risk_pct=0.01,
    )
    rm.record_trade(1.5)
    rm.record_trade(1.6)
    assert rm.kill_switch is True


def test_pause_and_can_open() -> None:
    rm = RiskManager(max_daily_loss_pct=10.0, max_positions=1, risk_pct=0.01)
    rm.record_trade(-0.5)
    rm.record_trade(-0.6)
    rm.record_trade(-0.7)
    assert rm.pause_duration() == 15 * 60
    rm.record_trade(-0.8)
    rm.record_trade(-0.9)
    assert rm.pause_duration() == 60 * 60
    assert rm.can_open(0) is True
    assert rm.can_open(1) is False


def test_risk_pct_scaling() -> None:
    rm = RiskManager(max_daily_loss_pct=10.0, max_positions=1, risk_pct=0.01)
    rm.record_trade(1.0)
    rm.record_trade(1.0)
    assert rm.risk_pct > 0.01
    rm.record_trade(-1.0)
    rm.record_trade(-1.0)
    assert rm.risk_pct < 0.01


--------------------------------------------------------------------------------
FILE: tests/test_risk_utils.py
--------------------------------------------------------------------------------
import pytest

from scalper.risk import calc_risk_amount, calc_position_size


def test_calc_risk_amount_basic():
    assert calc_risk_amount(1000, 0.01) == 10.0


def test_calc_position_size_basic():
    # risk_amount = 1000 * 0.01 = 10; position size = 10 / 50 = 0.2
    assert calc_position_size(1000, 0.01, 50) == 0.2


@pytest.mark.parametrize("equity,risk_pct", [
    (0, 0.01),
    (-100, 0.01),
    (1000, 0),
    (1000, -0.1),
    (1000, 1.5),
])
def test_calc_risk_amount_invalid(equity, risk_pct):
    with pytest.raises(ValueError):
        calc_risk_amount(equity, risk_pct)


@pytest.mark.parametrize("stop_distance", [0, -1])
def test_calc_position_size_invalid_stop(stop_distance):
    with pytest.raises(ValueError):
        calc_position_size(1000, 0.01, stop_distance)


--------------------------------------------------------------------------------
FILE: tests/test_signal_risk.py
--------------------------------------------------------------------------------
import types
import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(__file__)))
sys.modules['requests'] = types.ModuleType('requests')

from bot import (
    map_score_to_sig_level,
    compute_risk_params,
    prepare_order,
    Signal,
    CONFIG,
)


class DummyRisk:
    def __init__(self, pct: float) -> None:
        self.risk_pct = pct


def _contract_detail():
    return {
        "data": [
            {
                "symbol": "BTC_USDT",
                "contractSize": 0.001,
                "volUnit": 1,
                "minVol": 1,
                "minTradeUSDT": 5,
            }
        ]
    }


def test_score_to_level_mapping():
    assert map_score_to_sig_level(10) == 1
    assert map_score_to_sig_level(35) == 2
    assert map_score_to_sig_level(69.9) == 2
    assert map_score_to_sig_level(70) == 3


def test_risk_tables():
    rp, lev, cap = compute_risk_params(2, 3, 0.01, 20)
    assert rp == 0.01 * 1.25
    assert lev == int(20 * 0.75)
    assert cap == 0.55
    rp2, lev2, cap2 = compute_risk_params(3, 1, 0.01, 20)
    assert rp2 == 0.01 * 1.0
    assert lev2 == int(20 * 0.5)
    assert cap2 == 0.35


def test_notional_cap():
    rm = DummyRisk(0.05)
    sig = Signal("BTC_USDT", "long", 10000, 9900, 10100, 10200, 1, score=80)
    available = 1000
    params = prepare_order(
        sig,
        _contract_detail(),
        equity_usdt=available,
        available_usdt=available,
        base_leverage=10,
        risk_mgr=rm,
        user_risk_level=2,
    )
    assert params["notional"] <= params["cap_ratio"] * available + 1e-6


--------------------------------------------------------------------------------
FILE: tests/test_slippage.py
--------------------------------------------------------------------------------
from scalper.trade_utils import marketable_limit_price


def test_marketable_limit_price_buy_sell():
    price_buy = marketable_limit_price("buy", best_bid=9.9, best_ask=10.0, slippage=0.001)
    assert price_buy == 10.0 * 1.001
    price_sell = marketable_limit_price("sell", best_bid=9.9, best_ask=10.0, slippage=0.001)
    assert price_sell == 9.9 * (1 - 0.001)


--------------------------------------------------------------------------------
FILE: tests/test_strategy_v2.py
--------------------------------------------------------------------------------
import pytest

from scalp import strategy
from scalper.trade_utils import trailing_stop, should_scale_in, timeout_exit


def make_ohlcv(n=60, start=100, step=1):
    closes = [start + i * step for i in range(n)]
    highs = [c + 1 for c in closes]
    lows = [c - 1 for c in closes]
    vols = [1 for _ in closes]
    return {"open": closes, "high": highs, "low": lows, "close": closes, "volume": vols}


def test_generate_signal_atr_adaptation(monkeypatch):
    base = make_ohlcv(step=2)
    ohlcv_15 = make_ohlcv(n=15, step=2)
    ohlcv_1h = make_ohlcv(step=2)

    # patches for deterministic RSI values
    rsi_vals = iter([60, 41, 39])
    monkeypatch.setattr(strategy, "calc_rsi", lambda *args, **kwargs: next(rsi_vals))
    monkeypatch.setattr(strategy, "calc_position_size", lambda equity, risk, dist: 100)
    # low ATR -> signal disabled
    monkeypatch.setattr(strategy, "calc_atr", lambda *args, **kwargs: 0.1)
    sig = strategy.generate_signal(
        "AAA",
        base,
        equity=1_000,
        risk_pct=0.01,
        ohlcv_15m=ohlcv_15,
        ohlcv_1h=ohlcv_1h,
        order_book={"bid_vol_aggreg": 120, "ask_vol_aggreg": 80},
        tick_ratio_buy=0.6,
    )
    assert sig is None

    # high ATR -> size reduced
    rsi_vals = iter([60, 41, 39])
    monkeypatch.setattr(strategy, "calc_rsi", lambda *args, **kwargs: next(rsi_vals))
    monkeypatch.setattr(strategy, "calc_atr", lambda *args, **kwargs: 5.0)
    sig = strategy.generate_signal(
        "AAA",
        base,
        equity=1_000,
        risk_pct=0.01,
        ohlcv_15m=ohlcv_15,
        ohlcv_1h=ohlcv_1h,
        order_book={"bid_vol_aggreg": 120, "ask_vol_aggreg": 80},
        tick_ratio_buy=0.6,
    )
    assert sig and sig.side == "long"
    assert sig.qty == 50


def test_generate_signal_short_with_filters(monkeypatch):
    base = make_ohlcv(start=200, step=-2)
    ohlcv_15 = make_ohlcv(n=15, start=200, step=-2)
    ohlcv_1h = make_ohlcv(start=200, step=-2)

    rsi_vals = iter([40, 59, 61])
    monkeypatch.setattr(strategy, "calc_rsi", lambda *args, **kwargs: next(rsi_vals))
    monkeypatch.setattr(strategy, "calc_position_size", lambda equity, risk, dist: 100)
    monkeypatch.setattr(strategy, "calc_atr", lambda *args, **kwargs: 1.0)

    sig = strategy.generate_signal(
        "AAA",
        base,
        equity=1_000,
        risk_pct=0.01,
        ohlcv_15m=ohlcv_15,
        ohlcv_1h=ohlcv_1h,
        order_book={"bid_vol_aggreg": 80, "ask_vol_aggreg": 120},
        tick_ratio_buy=0.4,
    )
    assert sig and sig.side == "short"
    assert sig.qty == 100


def test_trailing_and_timeout():
    # trailing stop
    sl = trailing_stop("long", current_price=110, atr=10, sl=90)
    assert sl == pytest.approx(102.5)
    # scaling
    assert should_scale_in(100, 105, 100, 10, "long") is True
    assert should_scale_in(100, 95, 100, 10, "short") is True
    # timeout
    # before the progress window no exit should be triggered
    assert not timeout_exit(0, 10 * 60, 100, 99, "long", progress_min=15, timeout_min=30)
    # after ``progress_min`` minutes without favourable movement we close
    assert timeout_exit(0, 20 * 60, 100, 99, "long", progress_min=15, timeout_min=30)


def test_generate_signal_macd_filter(monkeypatch):
    base = make_ohlcv(step=2)
    ohlcv_15 = make_ohlcv(n=15, step=2)
    ohlcv_1h = make_ohlcv(step=2)

    rsi_vals = iter([60, 41, 39])
    monkeypatch.setattr(strategy, "calc_rsi", lambda *args, **kwargs: next(rsi_vals))
    monkeypatch.setattr(strategy, "calc_position_size", lambda equity, risk, dist: 100)
    monkeypatch.setattr(strategy, "calc_atr", lambda *args, **kwargs: 1.0)
    monkeypatch.setattr(strategy, "calc_macd", lambda *args, **kwargs: (-1.0, 0.0, -1.0))

    sig = strategy.generate_signal(
        "AAA",
        base,
        equity=1_000,
        risk_pct=0.01,
        ohlcv_15m=ohlcv_15,
        ohlcv_1h=ohlcv_1h,
        order_book={"bid_vol_aggreg": 120, "ask_vol_aggreg": 80},
        tick_ratio_buy=0.6,
    )
    assert sig is None



def test_generate_signal_trend_ema_filter(monkeypatch):
    base = make_ohlcv(step=2)
    ohlcv_15 = make_ohlcv(n=15, step=2)
    ohlcv_1h = make_ohlcv(step=2)

    rsi_vals = iter([60, 41, 39])
    monkeypatch.setattr(strategy, "calc_rsi", lambda *args, **kwargs: next(rsi_vals))
    monkeypatch.setattr(strategy, "calc_position_size", lambda equity, risk, dist: 100)
    monkeypatch.setattr(strategy, "calc_atr", lambda *args, **kwargs: 1.0)

    orig_ema = strategy.ema

    def fake_ema(series, window):
        if window == 200:
            return [x + 1000 for x in orig_ema(series, window)]
        return orig_ema(series, window)

    monkeypatch.setattr(strategy, "ema", fake_ema)

    sig = strategy.generate_signal(
        "AAA",
        base,
        equity=1_000,
        risk_pct=0.01,
        ohlcv_15m=ohlcv_15,
        ohlcv_1h=ohlcv_1h,
        order_book={"bid_vol_aggreg": 120, "ask_vol_aggreg": 80},
        tick_ratio_buy=0.6,
        trend_ema_period=200,
    )
    assert sig is None
    

--------------------------------------------------------------------------------
FILE: tests/test_telegram_bot.py
--------------------------------------------------------------------------------
from scalper.telegram_bot import TelegramBot


class DummyClient:

    def __init__(self):
        self.closed = []
        self.closed_all = False


    def get_assets(self):
        return {"data": [{"currency": "USDT", "equity": 123.45}]}

    def get_positions(self):
        return {
            "data": [
                {
                    "symbol": "BTC_USDT",
                    "side": "long",
                    "vol": 2,
                    "pnl_usd": 1.0,
                    "pnl_pct": 5.0,
                }
            ]
        }

    def close_position(self, sym):
        self.closed.append(sym)

    def close_all_positions(self):
        self.closed_all = True



class DummyRiskMgr:

    def __init__(self):
        self.reset_called = False
        self.max_positions = 1
        self.risk_pct = 0.01

    def reset_day(self):
        self.reset_called = True


class DummyRequests:
    def __init__(self):
        self.posts = []

    def post(self, url, json=None, timeout=5):
        self.posts.append((url, json))

    def get(self, url, params=None, timeout=5):  # pragma: no cover - unused
        return type("R", (), {"json": lambda self: {}, "raise_for_status": lambda self: None})()


def make_bot(config=None, requests_module=None):
    cfg = {"RISK_LEVEL": 2, "MAX_POSITIONS": 1}
    if config:
        cfg.update(config)
    if requests_module is None:
        requests_module = DummyRequests()
    return TelegramBot("t", "1", DummyClient(), cfg, DummyRiskMgr(), requests_module=requests_module)


def test_handle_balance():
    bot = make_bot()

    resp, kb = bot.handle_callback("balance", 0.0)
    assert "123.45" in resp
    assert kb == bot.main_keyboard



def test_handle_positions():
    bot = make_bot()
    resp, _ = bot.handle_callback("positions", 0.0)
    assert "BTC" in resp
    assert "PnL" in resp


def test_handle_positions_zero_pnl():
    bot = make_bot()

    def zero_positions():
        return {
            "data": [
                {
                    "symbol": "BTC_USDT",
                    "side": "long",
                    "vol": 1,
                    "pnl_usd": 0.0,
                    "pnl_pct": 0.0,
                }
            ]
        }

    bot.client.get_positions = zero_positions
    resp, _ = bot.handle_callback("positions", 0.0)
    assert "PnL: 0.00 USDT" in resp



def test_handle_pnl():
    bot = make_bot()
    resp, _ = bot.handle_callback("pnl", 5.0)

    assert "5.00" in resp


def test_handle_risk_change():
    bot = make_bot()

    resp, kb = bot.handle_callback("risk_red", 0.0)
    assert "3" in resp
    assert bot.config["RISK_LEVEL"] == 3
    assert kb == bot.main_keyboard


def test_risk_menu():
    bot = make_bot()
    resp, kb = bot.handle_callback("risk", 0.0)
    assert "risque" in resp.lower()
    assert kb == bot.risk_keyboard



def test_stop_menu_and_actions():
    bot = make_bot()
    resp, kb = bot.handle_callback("stop", 0.0)
    assert any(
        btn["callback_data"] == "stop_BTC_USDT" for row in kb for btn in row
    )
    assert any(btn["callback_data"] == "stop_all" for row in kb for btn in row)
    resp, _ = bot.handle_callback("stop_BTC_USDT", 0.0)
    assert "fermée" in resp.lower()
    assert bot.client.closed == ["BTC_USDT"]
    resp, _ = bot.handle_callback("stop_all", 0.0)
    assert bot.client.closed_all is True


def test_handle_unknown():
    bot = make_bot()
    resp, kb = bot.handle_callback("foobar", 0.0)
    assert resp is None
    assert kb is None


def test_reset_all():
    bot = make_bot()
    resp, kb = bot.handle_callback("reset_all", 0.0)
    assert "réinitialisés" in resp.lower()
    assert bot.risk_mgr.reset_called is True
    assert bot.client.closed_all is True
    assert kb == bot.settings_keyboard


def test_shutdown_bot():
    bot = make_bot()
    resp, kb = bot.handle_callback("shutdown", 0.0)
    assert "arrêt" in resp.lower()
    assert bot.stop_requested is True
    assert kb == bot.main_keyboard


def test_start_sends_menu():
    req = DummyRequests()
    make_bot(requests_module=req)
    assert req.posts
    text = req.posts[0][1]["text"]
    assert "Solde" in text and "PnL session" in text
    assert "Positions max" in text
    assert "Risque actuel" in text


def test_settings_menu_and_reset_risk():
    bot = make_bot()
    resp, kb = bot.handle_callback("settings", 0.0)
    assert "réglages" in resp.lower()
    assert kb == bot.settings_keyboard
    resp, kb = bot.handle_callback("reset_risk", 0.0)
    assert "risque" in resp.lower()
    assert bot.risk_mgr.reset_called is True
    assert kb == bot.settings_keyboard


def test_update_button(monkeypatch):
    bot = make_bot()
    called = {}

    def fake_update():
        called["called"] = True

    bot.update_pairs = fake_update
    resp, kb = bot.handle_callback("update", 0.0)
    assert called["called"] is True
    assert "mise à jour" in resp.lower()
    assert kb == bot.main_keyboard


def test_maxpos_menu_and_change():
    bot = make_bot()
    resp, kb = bot.handle_callback("maxpos", 0.0)
    assert "nombre" in resp.lower()
    assert kb == bot.maxpos_keyboard
    resp, kb = bot.handle_callback("maxpos_3", 0.0)
    assert "3" in resp
    assert bot.config["MAX_POSITIONS"] == 3
    assert bot.risk_mgr.max_positions == 3
    assert kb == bot.main_keyboard


def test_stop_no_positions():
    bot = make_bot()
    bot.client.get_positions = lambda: {"data": []}
    resp, kb = bot.handle_callback("stop", 0.0)
    assert "aucune crypto" in resp.lower()
    assert kb == bot.settings_keyboard



--------------------------------------------------------------------------------
FILE: tests/test_utils.py
--------------------------------------------------------------------------------
import pytest
from bot import ema, cross, compute_position_size, CONFIG
from scalper.trade_utils import extract_available_balance


def test_ema_basic():
    data = [1, 2, 3, 4, 5]
    result = ema(data, 3)
    assert result == pytest.approx([1, 1.5, 2.25, 3.125, 4.0625])


def test_cross_up_down_none():
    assert cross(3, 2, 1, 2) == 1  # up cross
    assert cross(0.5, 1, 2, 1) == -1  # down cross
    assert cross(2, 2, 2, 2) == 0  # no cross


def test_compute_position_size():
    detail = {
        "data": [
            {
                "symbol": CONFIG["SYMBOL"],
                "contractSize": 0.001,
                "volUnit": 1,
                "minVol": 1,
            }
        ]
    }
    vol = compute_position_size(detail, equity_usdt=100.0, price=20000.0,
                                risk_pct=0.01, leverage=5)
    assert vol == 1


def test_compute_position_size_missing_symbol():
    with pytest.raises(ValueError):
        compute_position_size({"data": []}, 100.0, 1.0, 0.01, 5)


def test_extract_available_balance_fallback():
    assets = {
        "data": [
            {
                "currency": "USDT",
                "available": 0,
                "cashBalance": "150.5",
                "equity": "200",
            }
        ]
    }
    assert extract_available_balance(assets) == 150.5


def test_extract_available_balance_equity_only():
    assets = {
        "data": [
            {
                "currency": "USDT",
                "equity": "42",
            }
        ]
    }
    assert extract_available_balance(assets) == 42.0


def test_extract_available_balance_zero_available_returns_zero():
    assets = {
        "data": [
            {
                "currency": "USDT",
                "available": 0,
                "availableBalance": 0,
                "equity": "42",
            }
        ]
    }
    assert extract_available_balance(assets) == 0.0


--------------------------------------------------------------------------------
FILE: tests/test_version.py
--------------------------------------------------------------------------------
import pytest
from scalp import version


def test_get_version(monkeypatch, tmp_path):
    vfile = tmp_path / "VERSION"
    vfile.write_text("1.2.3")
    monkeypatch.setattr(version, "_VERSION_FILE", vfile)
    assert version.get_version() == "1.2.3"


def test_bump_version(monkeypatch, tmp_path):
    vfile = tmp_path / "VERSION"

    vfile.write_text("0.1.2\n")
    monkeypatch.setattr(version, "_VERSION_FILE", vfile)
    assert version.bump_version("minor") == "0.2.0"
    assert vfile.read_text().strip() == "0.2.0"


def test_bump_version_invalid_part(monkeypatch, tmp_path):
    vfile = tmp_path / "VERSION"
    vfile.write_text("0.1.0\n")
    monkeypatch.setattr(version, "_VERSION_FILE", vfile)
    with pytest.raises(ValueError):
        version.bump_version("foo")


def test_bump_from_message(monkeypatch, tmp_path):
    vfile = tmp_path / "VERSION"
    vfile.write_text("1.0.0\n")
    monkeypatch.setattr(version, "_VERSION_FILE", vfile)
    assert version.bump_version_from_message("feat: add x") == "1.1.0"
    assert version.bump_version_from_message("fix: bug") == "1.1.1"
    assert version.bump_version_from_message("feat!: major change") == "2.0.0"



--------------------------------------------------------------------------------
FILE: tests/test_walk_forward.py
--------------------------------------------------------------------------------
from scalper.backtest import walk_forward_windows


def test_walk_forward_windows():
    data = list(range(10))
    windows = list(walk_forward_windows(data, train=4, test=2))
    assert windows == [
        ([0, 1, 2, 3], [4, 5]),
        ([2, 3, 4, 5], [6, 7]),
        ([4, 5, 6, 7], [8, 9]),
    ]


--------------------------------------------------------------------------------
FILE: tests/test_ws.py
--------------------------------------------------------------------------------
import asyncio

from scalper.ws import WebsocketManager


def test_websocket_manager_stop():
    async def connect():
        return None

    async def subscribe():
        return None

    ws = WebsocketManager(connect, subscribe, heartbeat_interval=0.01)

    async def run_and_stop():
        await ws.run()
        assert ws._heartbeat_task is not None
        await ws.stop()
        assert ws._heartbeat_task is None

    asyncio.run(run_and_stop())


--------------------------------------------------------------------------------
FILE: tg_diag.py
--------------------------------------------------------------------------------
# tg_diag.py
import asyncio, os, aiohttp

TOKEN = os.getenv("TELEGRAM_TOKEN", "")
CHAT  = os.getenv("TELEGRAM_CHAT_ID", "")

async def main():
    if not TOKEN or not CHAT:
        print("❌ Manque TELEGRAM_TOKEN ou TELEGRAM_CHAT_ID dans l'env.")
        return
    url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
    payload = {"chat_id": CHAT, "text": "🔎 Test Telegram OK ?"}
    try:
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=15)) as s:
            async with s.post(url, json=payload) as r:
                body = await r.text()
                print("HTTP:", r.status)
                print("Body:", body[:500])
    except Exception as e:
        print("❌ Exception:", repr(e))

if __name__ == "__main__":
    asyncio.run(main())

--------------------------------------------------------------------------------
FILE: tools/dump-repo.py
--------------------------------------------------------------------------------
#!/usr/bin/env python3
"""
tools/dump_repo.py

Génère un dump complet du repo notebooks/scalp :
- timestamp dans le nom
- arborescence des fichiers
- contenu intégral des fichiers texte
- exclusion des fichiers binaires et dossiers inutiles (git, cache, trash…)

Usage :
    python notebooks/scalp/tools/dump_repo.py
"""

from __future__ import annotations

import datetime as dt
import os
import sys
from pathlib import Path

# Racine du repo = notebooks/scalp/
REPO_ROOT = Path(__file__).resolve().parents[1]
DUMP_DIR = REPO_ROOT / "dumps"
DUMP_DIR.mkdir(parents=True, exist_ok=True)

TS = dt.datetime.now().strftime("%Y%m%d-%H%M%S")
OUT_PATH = DUMP_DIR / f"DUMP_{TS}.txt"

# Extensions/fichiers à ignorer (binaires ou inutiles)
IGNORE_EXT = {
    ".png", ".jpg", ".jpeg", ".gif", ".pdf",
    ".pkl", ".db", ".sqlite", ".zip", ".tar", ".gz",
    ".pyc", ".pyo",
}
IGNORE_DIRS = {".git", "__pycache__", ".ipynb_checkpoints"}
IGNORE_PREFIX = {"TRASH_"}

def is_text_file(path: Path) -> bool:
    if path.suffix.lower() in IGNORE_EXT:
        return False
    try:
        with open(path, "rb") as f:
            chunk = f.read(1024)
            if b"\x00" in chunk:
                return False
        return True
    except Exception:
        return False

def write_header(f, title: str) -> None:
    f.write("\n" + "=" * 80 + "\n")
    f.write(f"{title}\n")
    f.write("=" * 80 + "\n")

def dump_tree(root: Path, f) -> None:
    write_header(f, "ARBORESCENCE")
    for p in sorted(root.rglob("*")):
        rel = p.relative_to(root)
        if any(part in IGNORE_DIRS for part in rel.parts):
            continue
        if any(str(rel).startswith(pref) for pref in IGNORE_PREFIX):
            continue
        f.write(str(rel) + ("/" if p.is_dir() else "") + "\n")

def dump_files(root: Path, f) -> None:
    write_header(f, "FICHIERS COMPLETS")
    for p in sorted(root.rglob("*")):
        rel = p.relative_to(root)
        if p.is_dir():
            continue
        if any(part in IGNORE_DIRS for part in rel.parts):
            continue
        if any(str(rel).startswith(pref) for pref in IGNORE_PREFIX):
            continue
        if not is_text_file(p):
            continue
        try:
            content = p.read_text(encoding="utf-8", errors="replace")
        except Exception as e:
            f.write(f"\n[!!] Impossible de lire {rel}: {e}\n")
            continue
        f.write("\n" + "-" * 80 + "\n")
        f.write(f"FILE: {rel}\n")
        f.write("-" * 80 + "\n")
        f.write(content)
        f.write("\n")

def main() -> int:
    with open(OUT_PATH, "w", encoding="utf-8") as f:
        f.write(f"# DUMP {TS}\nRepo: {REPO_ROOT}\n")
        dump_tree(REPO_ROOT, f)
        dump_files(REPO_ROOT, f)
    print(f"[✓] Dump écrit: {OUT_PATH}")
    return 0

if __name__ == "__main__":
    sys.exit(main())

--------------------------------------------------------------------------------
FILE: tools/trashify.py
--------------------------------------------------------------------------------
# tools/trashify.py
# Déplacement sécurisé des fichiers/dossiers "candidats" vers TRASH_YYYYMMDD-HHMMSS/
# Usage:
#   python tools/trashify.py            # dry-run (affiche seulement)
#   python tools/trashify.py --apply    # déplace réellement
# Options:
#   --trash-dir NAME   # nom personnalisé du dossier trash (sinon timestamp)
#   --no-git           # force l'utilisation de shutil.move au lieu de `git mv`
#
# Notes:
# - Détecte automatiquement un repo Git et utilise `git mv` si possible (meilleure traçabilité).
# - Écrit un manifeste: TRASH_.../TRASH_MANIFEST.txt avec la liste des éléments déplacés.
# - La liste des "candidats" ci-dessous est issue du dump fourni le 2025-08-24 (répertoire racine: Scalp/).  #  [oai_citation:1‡Vierge 19.txt](file-service://file-9QiWVhpqthb1XibRXMXmiu)

from __future__ import annotations

import argparse
import datetime as dt
import os
import shutil
import subprocess
from pathlib import Path
from typing import Iterable, List, Tuple

# --------------------------------------------------------------------------------------
# Candidats à déplacer (conservateur). Ajuste cette liste si besoin avant --apply.
# --------------------------------------------------------------------------------------
CANDIDATES: List[str] = [
    # 1) Ancienne corbeille entière (archives obsolètes) — doublons du code actuel
    "TRASH_20250823-124533",

    # 2) Duplication manifeste: indicateurs déjà présents sous scalper/core/indicators.py
    "data/indicators.py",

    # 3) Typo de dossier de stratégie (probablement un essai non concluant)
    "scalper/strategy/startegies",  # <- oui "startegies" (typo)

    # 4) Scripts ponctuels/démo non utilisés par bot.py
    # (laisse commentés par défaut; décommente si tu valides)
    # "tg_diag.py",
    # "TRASH_20250823-124533/quick_order.py",
    # "TRASH_20250823-124533/dashboard.py",
    # "TRASH_20250823-124533/notebooks",

    # 5) Anciennes configs/legacy dans TRASH (redondantes avec scalper/config/* actuels)
    # (déjà couvert par la ligne 1 déplaçant le dossier complet)
]

# Racine du repo = dossier parent de CE fichier, puis deux niveaux si placé dans tools/
HERE = Path(__file__).resolve()
REPO_ROOT = HERE.parent.parent if HERE.parent.name == "tools" else HERE.parent
assert (REPO_ROOT / ".").exists(), f"Repo root introuvable: {REPO_ROOT}"


def _is_git_repo(root: Path) -> bool:
    return (root / ".git").exists()


def _git_mv(src: Path, dst: Path) -> Tuple[bool, str]:
    try:
        subprocess.run(["git", "mv", str(src), str(dst)], cwd=REPO_ROOT, check=True, capture_output=True)
        return True, "git mv"
    except Exception as e:
        return False, f"git mv failed: {e}"


def _shutil_mv(src: Path, dst: Path) -> Tuple[bool, str]:
    try:
        dst.parent.mkdir(parents=True, exist_ok=True)
        shutil.move(str(src), str(dst))
        return True, "shutil.move"
    except Exception as e:
        return False, f"move failed: {e}"


def _timestamp() -> str:
    return dt.datetime.now().strftime("%Y%m%d-%H%M%S")


def resolve_existing(paths: Iterable[str]) -> List[Path]:
    out: List[Path] = []
    for p in paths:
        rp = (REPO_ROOT / p).resolve()
        if rp.exists():
            out.append(rp)
    return out


def write_manifest(trash_dir: Path, moved: List[Path], skipped: List[Tuple[Path, str]]) -> None:
    manifest = trash_dir / "TRASH_MANIFEST.txt"
    lines: List[str] = []
    lines.append(f"Repo root: {REPO_ROOT}")
    lines.append(f"Trash dir: {trash_dir}")
    lines.append(f"Moved count: {len(moved)}")
    lines.append("Moved items:")
    for p in moved:
        rel = p.relative_to(trash_dir)
        lines.append(f"  - {rel}")
    if skipped:
        lines.append("")
        lines.append("Skipped/not moved (reason):")
        for p, reason in skipped:
            lines.append(f"  - {p.relative_to(REPO_ROOT)} :: {reason}")
    manifest.parent.mkdir(parents=True, exist_ok=True)
    manifest.write_text("\n".join(lines) + "\n", encoding="utf-8")


def main() -> int:
    ap = argparse.ArgumentParser(description="Déplacer des fichiers/dossiers vers un répertoire TRASH_*")
    ap.add_argument("--apply", action="store_true", help="Exécuter réellement les déplacements (sinon dry-run)")
    ap.add_argument("--trash-dir", default="", help="Nom personnalisé du répertoire trash (par défaut TRASH_<timestamp>)")
    ap.add_argument("--no-git", action="store_true", help="Ne pas utiliser git mv, forcer shutil.move")
    args = ap.parse_args()

    # Résolution des candidats présents
    existing = resolve_existing(CANDIDATES)
    missing = sorted(set(CANDIDATES) - {str(p.relative_to(REPO_ROOT)) for p in existing})
    if missing:
        print("[i] Éléments non trouvés (ignorés) :")
        for m in missing:
            print(f"    - {m}")

    if not existing:
        print("[✓] Rien à déplacer: aucun candidat présent.")
        return 0

    # Dossier TRASH cible
    trash_name = args.trash_dir.strip() or f"TRASH_{_timestamp()}"
    trash_dir = (REPO_ROOT / trash_name).resolve()

    print(f"[i] Repo: {REPO_ROOT}")
    print(f"[i] Trash: {trash_dir}")
    print("[i] Candidats résolus:")
    for p in existing:
        print(f"    - {p.relative_to(REPO_ROOT)}")

    if not args.apply:
        print("\n[DRY-RUN] Ajoute --apply pour exécuter réellement les déplacements.")
        return 0

    # Exécution
    moved: List[Path] = []
    skipped: List[Tuple[Path, str]] = []
    use_git = _is_git_repo(REPO_ROOT) and not args.no_git

    for src in existing:
        rel = src.relative_to(REPO_ROOT)
        dst = trash_dir / rel  # conserve la structure relative
        dst.parent.mkdir(parents=True, exist_ok=True)

        if use_git:
            ok, how = _git_mv(src, dst)
        else:
            ok, how = _shutil_mv(src, dst)

        if ok:
            print(f"[→] {rel}  ->  {dst.relative_to(REPO_ROOT)}  ({how})")
            moved.append(dst)
        else:
            print(f"[!] SKIP {rel} ({how})")
            skipped.append((src, how))

    # Manifeste
    write_manifest(trash_dir, moved, skipped)
    print(f"[✓] Manifeste écrit: {trash_dir / 'TRASH_MANIFEST.txt'}")
    print("[✓] Terminé.")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
