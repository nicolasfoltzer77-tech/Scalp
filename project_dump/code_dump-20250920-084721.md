# DUMP DE PROJET — 20250920-084721

- Racine: `/opt/scalp`
- Fichier d’arborescence: `tree-20250920-084721.txt`
- Copies slim: `project_dump/slim`

## Arborescence filtrée
```text
[.]
  bot_runner.py  |     5 KB | 2025-09-19 23:11:05
  bumppush.py  |    15 KB | 2025-09-20 08:34:01
  requirements.txt  |     52 B | 2025-09-17 06:54:13
[execution]
  bitget_client.py  |    752 B | 2025-09-19 18:25:51
  executor.py  |     4 KB | 2025-09-19 18:25:51
  monitor.py  |     3 KB | 2025-09-19 18:25:51
  price_feed.py  |     1 KB | 2025-09-19 18:25:51
  storage.py  |     1 KB | 2025-09-19 18:25:51
[services]
  agg_1m_to_3m.py  |     2 KB | 2025-09-19 18:25:51
  analyze_A.py  |     4 KB | 2025-09-19 18:25:51
  analyze_B.py  |     1 KB | 2025-09-19 18:25:51
  analyze_pipeline.py  |    182 B | 2025-09-19 18:25:51
  b_triggers.py  |     4 KB | 2025-09-19 18:25:51
  build_heatmap_softmax.py  |     1 KB | 2025-09-19 18:25:51
  build_softmap.py  |     2 KB | 2025-09-19 19:44:04
  exec_signals.py  |     4 KB | 2025-09-19 18:25:51
  fetch_1m_safe.py  |    946 B | 2025-09-19 18:25:51
  fetch_ohlcv.py  |     1 KB | 2025-09-19 18:25:51
  ohlcv_1m_cli.py  |     3 KB | 2025-09-19 18:25:51
  ohlcv_bitget_batch.py  |     3 KB | 2025-09-19 18:25:51
  ohlcv_bitget_cli.py  |     4 KB | 2025-09-19 18:25:51
  on_new_signals.py  |     2 KB | 2025-09-19 23:13:47
  paper_trade.py  |    10 KB | 2025-09-19 18:25:51
  positions_watcher.py  |     4 KB | 2025-09-19 18:25:51
  promote_min.py  |     1 KB | 2025-09-19 23:16:55
  run_ohlcv_batch.sh  |    257 B | 2025-09-19 18:26:16
  signals_B.py  |     8 KB | 2025-09-19 18:25:51
  top_bitget.py  |     1 KB | 2025-09-19 18:25:51
[lib]
  errors.py  |    266 B | 2025-09-19 18:25:51
[tools]
  agg_tf3.py  |     1 KB | 2025-09-19 20:41:47
  bootstrap_ohlcv_bitget.py  |     1 KB | 2025-09-19 18:58:47
  bot_ensure_service.sh  |    472 B | 2025-09-17 20:44:34
  build_top_from_heatmap.py  |    415 B | 2025-09-19 18:26:09
  check_B.sh  |     3 KB | 2025-09-17 12:18:15
  check_deps.py  |    875 B | 2025-09-19 18:26:09
  check_env.py  |    132 B | 2025-09-19 18:26:09
  check_heat.py  |     1 KB | 2025-09-19 18:26:09
  check_ohlcv_1m.py  |     1 KB | 2025-09-19 18:26:09
  diag_B.sh  |    394 B | 2025-09-17 10:59:39
  diag_heat.sh  |     2 KB | 2025-09-17 10:15:20
  diag_heatmap.py  |    589 B | 2025-09-19 18:26:09
  diag_refresh.sh  |     4 KB | 2025-09-16 20:51:48
  diag_systemd_1m.sh  |    970 B | 2025-09-17 15:07:17
  enable_B_watchers.sh  |    190 B | 2025-09-17 11:54:41
  guard_soft.sh  |    576 B | 2025-09-17 07:55:30
  health_heatmap.sh  |    430 B | 2025-09-17 06:54:38
  install_deps.sh  |    207 B | 2025-09-16 17:06:23
  json_view.py  |     2 KB | 2025-09-19 18:26:09
  make_context.py  |    890 B | 2025-09-19 20:41:29
  normalize_json.py  |     1 KB | 2025-09-19 18:26:09
  normalize_positions.py  |    836 B | 2025-09-19 18:26:09
  ohlcv_sync.py  |     3 KB | 2025-09-19 18:26:09
  on_Btop_updated.sh  |    381 B | 2025-09-17 11:54:14
  on_btop_updated.sh  |    392 B | 2025-09-17 10:59:10
  ping_telegram.py  |    907 B | 2025-09-19 18:26:09
  pretty_heat.py  |    983 B | 2025-09-19 20:18:06
  pretty_heat_60_30_15_now.py  |     1 KB | 2025-09-19 22:17:10
  pretty_positions.py  |    403 B | 2025-09-19 22:55:25
  pretty_signals.py  |    905 B | 2025-09-19 22:54:55
  pretty_status.py  |     1 KB | 2025-09-19 20:23:28
  pretty_top.py  |    555 B | 2025-09-19 20:18:18
  pretty_top_names.py  |     1 KB | 2025-09-19 22:46:40
  probe_B.sh  |     2 KB | 2025-09-17 07:58:03
  probe_pipeline.sh  |     2 KB | 2025-09-17 08:09:27
  probe_pipeline_B.sh  |   1015 B | 2025-09-17 08:16:45
  purge_state.sh  |     1 KB | 2025-09-17 17:05:54
  refresh_bot.sh  |    242 B | 2025-09-16 20:04:04
  refresh_pipeline.sh  |    823 B | 2025-09-16 20:54:54
  relaunch_all.sh  |     2 KB | 2025-09-17 11:28:51
  relaunch_clean.sh  |    720 B | 2025-09-17 09:02:44
  repair_and_restart.sh  |     5 KB | 2025-09-16 18:59:28
  reset_top_json.py  |     1 KB | 2025-09-19 18:26:09
  restart_and_preview.sh  |    648 B | 2025-09-17 05:42:28
  rotate_history.sh  |    182 B | 2025-09-18 07:49:29
  run_1m_now.sh  |    638 B | 2025-09-17 11:10:22
  run_B_pipeline_now.sh  |    271 B | 2025-09-17 11:54:34
  select_universe_bitget.py  |     3 KB | 2025-09-19 19:50:21
  set_bot_commands.py  |     2 KB | 2025-09-19 18:26:09
  setup_venv.sh  |     1 KB | 2025-09-17 06:54:13
  telegram_ping.py  |    782 B | 2025-09-19 18:26:09
  test_B.sh  |    381 B | 2025-09-17 10:49:30
  test_exec_flow.sh  |     1 KB | 2025-09-16 17:51:34
  test_heat_source.py  |    484 B | 2025-09-19 18:26:09
  test_ohlcv.py  |    662 B | 2025-09-19 18:26:09
  trade_state.py  |     3 KB | 2025-09-19 23:10:21
  validate_pipeline.sh  |    980 B | 2025-09-17 15:50:11
  view_heatmap.sh  |     89 B | 2025-09-16 18:09:09
  view_history.sh  |     91 B | 2025-09-16 18:09:09
  view_positions.sh  |     96 B | 2025-09-16 18:09:09
  view_signals.sh  |     92 B | 2025-09-16 18:09:09
[bin]
  dump_and_push.sh  |     4 KB | 2025-09-17 05:10:42
  dump_and_reset.sh  |     2 KB | 2025-09-17 05:13:48
[analyze]
  __init__.py  |     29 B | 2025-09-19 18:26:09
  analyze_a_cli.py  |    283 B | 2025-09-19 18:26:09
  b_triggers.py  |    14 KB | 2025-09-19 18:26:09
  indicators_advanced.py  |     4 KB | 2025-09-19 18:26:09
  layer_a.py  |     2 KB | 2025-09-19 18:49:54
  run_triggers_cli.py  |     2 KB | 2025-09-19 20:41:56
[bot]
  __init__.py  |      0 B | 2025-09-19 18:26:09
  _keyboard_patch.py  |    670 B | 2025-09-19 18:26:09
  bot_stdlib.py  |     2 KB | 2025-09-19 18:26:09
  commands_wire.py  |    978 B | 2025-09-19 18:26:09
  env_simple.py  |    469 B | 2025-09-19 18:26:09
  json_util.py  |     1 KB | 2025-09-19 18:26:09
  mod_heatmap.py  |     1 KB | 2025-09-19 18:26:09
  mod_signals.py  |    865 B | 2025-09-19 18:26:09
  mod_top.py  |    503 B | 2025-09-19 18:26:09
  router.py  |     3 KB | 2025-09-19 18:26:09
  singleton.py  |    477 B | 2025-09-19 18:26:09
  views.py  |     2 KB | 2025-09-19 18:26:09
  views_account.py  |    909 B | 2025-09-19 18:26:09
  views_btop.py  |     1 KB | 2025-09-19 18:26:09
  views_heat.py  |     2 KB | 2025-09-19 18:26:09
  views_history.py  |     3 KB | 2025-09-19 18:26:09
  views_menu.py  |    309 B | 2025-09-19 18:26:09
  views_positions.py  |     3 KB | 2025-09-19 18:26:09
  views_signals.py  |    969 B | 2025-09-19 18:26:09
  views_top_patch.py  |     1 KB | 2025-09-19 18:26:09
[bot/lib]
  __init__.py  |      0 B | 2025-09-19 18:26:09
[project_dump]
  code_dump-20250920-083747.md  |   226 KB | 2025-09-20 08:37:47
  tree-20250920-083747.txt  |     6 KB | 2025-09-20 08:37:47
[project_dump/slim]
```

## Détails de code


### analyze/__init__.py  
Taille: 29 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 0570d97cdf07809b

```py
# package marker for analyze

```

### analyze/analyze_a_cli.py  
Taille: 283 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: f1cdf33341082cf5

```py
#!/opt/scalp/.venv/bin/python
from pathlib import Path
import sys
sys.path.insert(0, "/opt/scalp")  # pour import absolu
from analyze.layer_a import run

def main():
    n = run()
    print(f"[A] wrote {n} files to /opt/scalp/data/analysis/A")

if __name__ == "__main__":
    main()

```

### analyze/b_triggers.py  
Taille: 14 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: af90cb5f893adf07

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import csv, json, math, os, time
from dataclasses import dataclass
from pathlib import Path
from typing import List, Dict, Optional, Tuple

BASE = Path("/opt/scalp/data")
CAND = BASE/"candles"
AN_A = Path("/opt/scalp/data/analysis/A")  # fichiers A/<sym>.json de la couche A
SIGS = Path("/opt/scalp/data/signals")     # on dépose 1 fichier par signal + append global
LOGF = Path("/opt/scalp/data/logs/b_triggers.log")
SIGFILE = BASE/"signals.json"              # append global

# ── Paramétrage
RISK_PCT = float(os.getenv("RISK_PCT", "0.01"))      # 1% par défaut
CAPITAL_USDT = float(os.getenv("CAPITAL_USDT", "1000"))
SLIPPAGE_PCT = float(os.getenv("SLIPPAGE_PCT", "0.0005"))  # 5 bps

# Hystérésis Couche A (déjà appliquée en B état long/short via layer_b.py classique)
# Ici on se contente d'exiger un contexte actif côté A pour déclencher une entrée.
ENTER_BUY  = 0.60
ENTER_SELL = 0.60
HOLD_MIN, HOLD_MAX = 0.40, 0.60

@dataclass
class Candle:
    ts: int; o: float; h: float; l: float; c: float; v: float

def log(msg: str):
    LOGF.parent.mkdir(parents=True, exist_ok=True)
    with LOGF.open("a") as f:
        f.write(time.strftime("%Y-%m-%d %H:%M:%S ", time.gmtime()) + msg + "\n")

# ── Chargements candles: support CSV (chemin /candles/TF/SYM.csv) et JSON (candles/SYM_TF.json)
def load_csv(tf: str, sym: str) -> List[Candle]:
    p = CAND/tf/f"{sym}.csv"
    if not p.exists(): return []
    out: List[Candle] = []
    with p.open() as f:
        r=csv.reader(f)
        # accepte header ou non
        head = next(r, None)
        # si 1ère ligne n'est pas un int timestamp, tente comme première donnée
        def parse_row(row):
            if not row: return None
            try:
                ts=int(row[0]); o,h,l,c,v=map(float,row[1:6]); return Candle(ts,o,h,l,c,v)
            except Exception: return None
        first = parse_row(head)
        if first: out.append(first)
        for row in r:
            x=parse_row(row)
            if x: out.append(x)
    return out

def load_json_pair(sym:str, tf:str) -> List[Candle]:
    p = CAND/f"{sym}_{tf}.json"
    if not p.exists(): return []
    try:
        rows = json.loads(p.read_text())
        if not isinstance(rows, list): return []
        out=[]
        for r in rows:
            if isinstance(r, list) and len(r)>=6:
                out.append(Candle(int(r[0]), float(r[1]), float(r[2]), float(r[3]), float(r[4]), float(r[5])))
        return out
    except Exception:
        return []

def load_candles(sym:str, tf:str) -> List[Candle]:
    # priorité CSV structuré par TF, sinon JSON à plat
    arr = load_csv(tf, sym)
    if arr: return sorted(arr, key=lambda x: x.ts)
    return sorted(load_json_pair(sym, tf), key=lambda x: x.ts)

# ── Agrégation 3m à partir du 1m (par blocs de 3 clôturées)
def aggregate_3m(c1m: List[Candle]) -> List[Candle]:
    out: List[Candle] = []
    if not c1m: return out
    # ignore bougie 1m en cours: on garde uniquement les ts multiples de 60_000 (déjà le cas)
    # regroupe par paquets de 3 consécutifs
    for i in range(0, len(c1m)//3):
        a,b,c = c1m[3*i:3*i+3]
        ts = a.ts
        o = a.o
        h = max(a.h,b.h,c.h)
        l = min(a.l,b.l,c.l)
        cl = c.c
        v = a.v + b.v + c.v
        out.append(Candle(ts,o,h,l,cl,v))
    return out

# ── Indicateurs rapides
def ema(vals: List[float], period:int) -> List[float]:
    if period<=0 or not vals: return []
    k=2/(period+1); out=[vals[0]]; e=vals[0]
    for x in vals[1:]:
        e=k*x+(1-k)*e; out.append(e)
    return out

def rsi(vals: List[float], period:int=7) -> Optional[float]:
    if len(vals) < period+1: return None
    gains=losses=0.0
    for i in range(-period,0):
        ch=vals[i]-vals[i-1]
        gains += max(ch,0.0); losses += max(-ch,0.0)
    if gains==0 and losses==0: return 50.0
    if losses==0: return 100.0
    rs=gains/losses
    return 100.0 - 100.0/(1.0+rs)

def atr(c: List[Candle], period:int=14) -> Optional[float]:
    if len(c) < period+1: return None
    trs=[]
    for i in range(1, len(c)):
        h,l = c[i].h, c[i].l
        pc = c[i-1].c
        trs.append(max(h-l, abs(h-pc), abs(l-pc)))
    return sum(trs[-period:])/period

def sma(vals: List[float], period:int) -> Optional[float]:
    if len(vals) < period: return None
    return sum(vals[-period:])/period

def stdev(vals: List[float], period:int) -> Optional[float]:
    if len(vals) < period: return None
    m = sum(vals[-period:])/period
    var = sum((x-m)**2 for x in vals[-period:]) / period
    return var**0.5

def vwap(c: List[Candle], period:int=20) -> Optional[float]:
    if len(c) < period: return None
    pv=sum((x.h+x.l+x.c)/3.0 * x.v for x in c[-period:])
    vol=sum(x.v for x in c[-period:])
    return pv/vol if vol>0 else None

def macd_hist_slope(vals: List[float], fast=12, slow=26, sig=9) -> Optional[float]:
    if len(vals) < slow+sig+3: return None
    ef=ema(vals, fast); es=ema(vals, slow)
    mac=[a-b for a,b in zip(ef[-len(es):], es)]
    sigl=ema(mac, sig)
    hist = mac[-1]-sigl[-1]
    prev = mac[-2]-sigl[-2]
    return hist - prev  # croissance si >0

def bollinger(c: List[Candle], period:int=20, k:float=2.0) -> Optional[Tuple[float,float,float]]:
    closes=[x.c for x in c]
    ma=sma(closes, period); sd=stdev(closes, period)
    if ma is None or sd is None: return None
    return (ma, ma-k*sd, ma+k*sd)

def keltner(c: List[Candle], ema_p:int=20, mul:float=1.5) -> Optional[Tuple[float,float]]:
    ma = sma([x.c for x in c], ema_p)
    a = atr(c, 10)
    if ma is None or a is None: return None
    return (ma - mul*a, ma + mul*a)

def squeeze_on(c: List[Candle]) -> Optional[bool]:
    bb = bollinger(c, 20, 2.0)
    kel = keltner(c, 20, 1.5)
    if not bb or not kel: return None
    mid, low_bb, up_bb = bb
    low_k, up_k = kel
    # squeeze si BB est à l'intérieur des Keltner
    return (low_bb > low_k) and (up_bb < up_k)

def vol_spike(c: List[Candle], k:float=1.3, look:int=20) -> Optional[bool]:
    if len(c) < look+1: return None
    avg = sum(x.v for x in c[-look-1:-1]) / look
    return c[-1].v >= k*avg

def rsi_divergence(c: List[Candle], period:int=7, look:int=10) -> Optional[str]:
    if len(c) < look+period+2: return None
    closes=[x.c for x in c]
    # pics locaux simples
    last_close=closes[-1]; prev_close=closes[-1-look]
    rsi_last = rsi(closes, period); rsi_prev = rsi(closes[:-look], period)
    if rsi_last is None or rsi_prev is None: return None
    if last_close < prev_close and rsi_last > rsi_prev: return "bull"   # divergence haussière
    if last_close > prev_close and rsi_last < rsi_prev: return "bear"   # divergence baissière
    return None

def candle_reversal(c: List[Candle]) -> Optional[str]:
    if len(c) < 2: return None
    x = c[-1]; prev = c[-2]
    body = abs(x.c - x.o); full = x.h - x.l
    if full == 0: return None
    upper = x.h - max(x.c, x.o); lower = min(x.c, x.o) - x.l
    # Hammer / Shooting-star
    if lower > 2*body and upper < body: return "hammer"
    if upper > 2*body and lower < body: return "shooting"
    # Engulfing
    if (x.c > x.o) and (prev.c < prev.o) and (x.c >= prev.o) and (x.o <= prev.c): return "bull_engulf"
    if (x.c < x.o) and (prev.c > prev.o) and (x.o >= prev.c) and (x.c <= prev.o): return "bear_engulf"
    return None

# ── Contexte Couche A
def load_context_A(sym: str) -> Optional[Dict]:
    p = Path("/opt/scalp/data/analysis/A")/f"{sym}.json"
    if not p.exists(): return None
    try:
        a = json.loads(p.read_text())
        proba = a.get("proba",{})
        p_buy, p_sell, p_hold = float(proba.get("buy",0)), float(proba.get("sell",0)), float(proba.get("hold",0))
        ctx = "none"
        if p_buy >= ENTER_BUY: ctx="bullish"
        elif p_sell >= ENTER_SELL: ctx="bearish"
        elif HOLD_MIN <= p_hold <= HOLD_MAX: ctx="range"
        return {"ctx":ctx, "proba":proba, "S":float(a.get("S",0)), "per_tf":a.get("per_tf",{})}
    except Exception:
        return None

# ── Risk / sizing
def compute_size(price: float, atr_val: float, side:str, sl_mult:float=1.2) -> Tuple[float,float,float]:
    if price<=0 or atr_val is None or atr_val<=0:
        return (0.0, 0.0, 0.0)
    sl_dist = sl_mult * atr_val
    qty = (CAPITAL_USDT * RISK_PCT) / sl_dist
    sl = price - sl_dist if side=="long" else price + sl_dist
    tp = price + 1.8*atr_val if side=="long" else price - 1.8*atr_val
    return (max(qty,0.0), sl, tp)

# ── Déclencheurs
def trigger_pullback_trend(sym:str, c1m:List[Candle], c5m:List[Candle], side_ctx:str) -> Optional[Dict]:
    if len(c1m) < 30 or len(c5m) < 30: return None
    closes1=[x.c for x in c1m]
    ema20_1m = ema(closes1, 20)[-1]
    vwap1 = vwap(c1m, 20); bb = bollinger(c1m,20,2.0)
    rsi7 = rsi(closes1, 7)
    if vwap1 is None or rsi7 is None or bb is None: return None
    mid, low_bb, up_bb = bb
    # contact zone selon config simple: EMA20 ou ±1σ (BB)
    price = c1m[-1].c
    touched = abs(price-ema20_1m) <= 0.15*atr(c1m,14) or (side_ctx=="long" and price<=up_bb and price>=mid) or (side_ctx=="short" and price>=low_bb and price<=mid)
    vol_ok = bool(vol_spike(c1m, 1.3, 20))
    cond_rsi = (rsi7>50) if side_ctx=="long" else (rsi7<50)
    if touched and vol_ok and cond_rsi:
        a = atr(c1m,14)
        qty, sl, tp = compute_size(price, a, "long" if side_ctx=="long" else "short", 1.2)
        return {"entry_set":"pullback_trend", "side":("long" if side_ctx=="long" else "short"),
                "price_entry": price*(1+SLIPPAGE_PCT if side_ctx=="long" else 1-SLIPPAGE_PCT),
                "sl":sl, "tp":tp, "size":qty}
    return None

def trigger_breakout(sym:str, c3m:List[Candle], c5m:List[Candle], side_ctx:str) -> Optional[Dict]:
    # ADX (5m) ≥20, close casse range N=20, MACD hist ↑ (croissance), squeeze -> expansion
    if len(c5m)<40 or len(c3m)<25: return None
    closes5=[x.c for x in c5m]
    # MACD croissance sur 5m
    macd_slope = macd_hist_slope(closes5)
    if macd_slope is None: return None
    # ADX simple via ATR proxy: on utilise ATR relative comme proxy si ADX non dispo ici
    a5 = atr(c5m, 14); p5 = c5m[-1].c
    adx_ok = (a5 is not None and p5>0 and (100*a5/p5) >= 0.18)  # proxy ≈ 15–20
    # squeeze 3m → expansion (dernier squeeze off = False)
    sq = squeeze_on(c3m)
    # cassure des 20 dernières (3m)
    highs=[x.h for x in c3m[-20:]]; lows=[x.l for x in c3m[-20:]]
    hi, lo = max(highs), min(lows)
    price = c3m[-1].c
    long_break = side_ctx=="long" and price>hi
    short_break= side_ctx=="short" and price<lo
    slope_ok = (macd_slope>0) if side_ctx=="long" else (macd_slope<0)
    if adx_ok and sq is not None and (not sq) and (long_break or short_break) and slope_ok:
        a = atr(c3m,14)
        qty, sl, tp = compute_size(price, a, "long" if long_break else "short", 1.2)
        return {"entry_set":"breakout", "side":("long" if long_break else "short"),
                "price_entry": price*(1+SLIPPAGE_PCT if long_break else 1-SLIPPAGE_PCT),
                "sl":sl, "tp":tp, "size":qty}
    return None

def trigger_mean_reversion(sym:str, c1m:List[Candle], side_ctx:str) -> Optional[Dict]:
    # Contexte range. Touche BB extrême + divergence RSI + bougie reversal
    if len(c1m)<40: return None
    bb = bollinger(c1m, 20, 2.0); div = rsi_divergence(c1m,7,10); rev = candle_reversal(c1m)
    if not bb: return None
    mid, low_bb, up_bb = bb
    price = c1m[-1].c
    if side_ctx!="range": return None
    long_ok  = price<=low_bb  and (div=="bull") and (rev in ("hammer","bull_engulf"))
    short_ok = price>=up_bb   and (div=="bear") and (rev in ("shooting","bear_engulf"))
    if long_ok or short_ok:
        a = atr(c1m,14)
        side = "long" if long_ok else "short"
        qty, sl, tp = compute_size(price, a, side, 1.0)
        return {"entry_set":"mean_reversion", "side":side,
                "price_entry": price*(1+SLIPPAGE_PCT if side=="long" else 1-SLIPPAGE_PCT),
                "sl":sl, "tp":tp, "size":qty}
    return None

# ── Génération fichier signal(s)
def write_signal(sym:str, tf_ref:str, base_sig:Dict) -> Dict:
    sig = {
        "t_emit": int(time.time()),
        "sym": sym,
        "tf": tf_ref,
        **base_sig
    }
    SIGS.mkdir(parents=True, exist_ok=True)
    Path(SIGS/f"{sig['t_emit']}_{sym}_{base_sig['entry_set']}.json").write_text(
        json.dumps(sig, ensure_ascii=False, separators=(",",":"))
    )
    # append global
    obj = {"signals":[]}
    try:
        if SIGFILE.exists(): obj = json.loads(SIGFILE.read_text())
        if not isinstance(obj, dict): obj={"signals":[]}
        arr = obj.get("signals", [])
        arr.append(sig)
        obj["signals"] = arr[-2000:]
    except Exception:
        obj = {"signals":[sig]}
    SIGFILE.write_text(json.dumps(obj, ensure_ascii=False, separators=(",",":")))
    return sig

# ── Orchestrateur par symbole
def process_symbol(sym:str) -> Optional[Dict]:
    ctxA = load_context_A(sym)
    if not ctxA: 
        log(f"{sym}: no context A"); 
        return None
    ctx = ctxA["ctx"]
    if ctx=="none":
        log(f"{sym}: no active context"); 
        return None

    # charge TF basses
    c1m = load_candles(sym, "1m")
    if len(c1m) < 30:
        log(f"{sym}: not enough 1m"); 
        return None
    c3m = aggregate_3m(c1m)
    c5m = load_candles(sym, "5m")
    tf_ref = "1m"

    # route par contexte
    sig=None
    if ctx=="bullish":
        sig = trigger_pullback_trend(sym, c1m, c5m, "long") or trigger_breakout(sym, c3m, c5m, "long")
    elif ctx=="bearish":
        sig = trigger_pullback_trend(sym, c1m, c5m, "short") or trigger_breakout(sym, c3m, c5m, "short")
    elif ctx=="range":
        sig = trigger_mean_reversion(sym, c1m, "range")

    if sig:
        out = write_signal(sym, tf_ref, sig)
        log(f"{sym}: signal {out['entry_set']} {out['side']} price={out['price_entry']:.4f} sl={out['sl']:.4f} tp={out['tp']:.4f} size={out['size']:.6f}")
        return out
    log(f"{sym}: no trigger")
    return None

# ── Entry CLI
def main():
    # Universe: /opt/scalp/data/universe.txt (Top15)
    ufile = BASE/"universe.txt"
    if not ufile.exists():
        print("no universe.txt"); return
    syms = [l.strip().upper() for l in ufile.read_text().splitlines() if l.strip()]
    total = 0
    for s in syms:
        r = process_symbol(s)
        if r: total += 1
    print(f"[B] triggers done, signals={total}")

if __name__=="__main__":
    main()

```

### analyze/indicators_advanced.py  
Taille: 4 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: c0bfbff002d1e6bc

```py
from __future__ import annotations
import math, statistics
from typing import List, Tuple, Sequence, Optional

# rows: [[ts, o, h, l, c, v], ...] triées ASC

def _ema(vals: Sequence[float], period: int) -> List[float]:
    if period <= 0 or not vals: return []
    k = 2/(period+1)
    out: List[float] = []
    ema = vals[0]
    out.append(ema)
    for x in vals[1:]:
        ema = k*x + (1-k)*ema
        out.append(ema)
    return out

def _true_ranges(rows: Sequence[Sequence[float]]) -> List[float]:
    trs: List[float] = []
    prev_c = rows[0][4]
    for i in range(1, len(rows)):
        h, l, c = rows[i][2], rows[i][3], rows[i][4]
        trs.append(max(h-l, abs(h-prev_c), abs(l-prev_c)))
        prev_c = c
    return trs

def atr(rows: Sequence[Sequence[float]], period: int=14) -> Optional[float]:
    if len(rows) < period+1: return None
    trs = _true_ranges(rows)
    return sum(trs[-period:]) / period

def atr_pct(rows: Sequence[Sequence[float]], period: int=14) -> Optional[float]:
    a = atr(rows, period)
    if a is None: return None
    c = rows[-1][4]
    if c <= 0: return None
    return 100.0 * a / c

def rsi(rows: Sequence[Sequence[float]], period: int=14) -> Optional[float]:
    if len(rows) < period+1: return None
    gains=0.0; losses=0.0
    for i in range(-period, 0):
        chg = rows[i][4] - rows[i-1][4]
        gains += max(chg, 0.0)
        losses += max(-chg, 0.0)
    if gains==0 and losses==0: return 50.0
    if losses==0: return 100.0
    rs = gains/losses
    return 100.0 - (100.0/(1.0+rs))

def adx(rows: Sequence[Sequence[float]], period: int=14) -> Optional[float]:
    # Implémentation légère (Wilder-like, fin de série uniquement)
    if len(rows) < period+2: return None
    trs = _true_ranges(rows)
    plus_dm: List[float] = []
    minus_dm: List[float] = []
    for i in range(1, len(rows)):
        up = rows[i][2] - rows[i-1][2]
        dn = rows[i-1][3] - rows[i][3]
        plus_dm.append(max(up, 0.0) if up>dn else 0.0)
        minus_dm.append(max(dn, 0.0) if dn>up else 0.0)
    tr14 = sum(trs[-period:])
    pdm14 = sum(plus_dm[-period:])
    mdm14 = sum(minus_dm[-period:])
    if tr14 == 0: return 0.0
    pdi = 100.0 * pdm14 / tr14
    mdi = 100.0 * mdm14 / tr14
    s = pdi + mdi
    if s == 0: return 0.0
    dx = 100.0 * abs(pdi - mdi) / s
    return dx  # approximation ADX

def macd_hist(rows: Sequence[Sequence[float]], fast:int=12, slow:int=26, sig:int=9) -> Optional[Tuple[float,float]]:
    closes = [r[4] for r in rows]
    if len(closes) < slow+sig+2: return None
    ema_fast = _ema(closes, fast)
    ema_slow = _ema(closes, slow)
    # aligne par la fin
    m = [a-b for a,b in zip(ema_fast[-len(ema_slow):], ema_slow)]
    sig_line = _ema(m, sig)
    hist = m[-1] - sig_line[-1]
    # sigma hist pour normalisation robuste
    look = min(120, len(m))
    sigma = statistics.pstdev([m[i] - sig_line[i] for i in range(-look, 0)]) or 1e-12
    return hist, sigma

def obv_slope(rows: Sequence[Sequence[float]], lookback:int=20) -> Optional[Tuple[float,float]]:
    if len(rows) < lookback+2: return None
    obv = [0.0]
    for i in range(1, len(rows)):
        c0, c1 = rows[i-1][4], rows[i][4]
        v = rows[i][5]
        if c1>c0: obv.append(obv[-1] + v)
        elif c1<c0: obv.append(obv[-1] - v)
        else: obv.append(obv[-1])
    d_obv = obv[-1] - obv[-1-lookback]
    med_abs = statistics.median([abs(x) for x in obv[-lookback:]]) or 1e-12
    return d_obv, med_abs

def tanh_norm(x: float, scale: float) -> float:
    if scale <= 0: scale = 1e-12
    return math.tanh(x/scale)

def clip_unit(x: float) -> float:
    return max(-1.0, min(1.0, x))

```

### analyze/layer_a.py  
Taille: 2 KB  |  MàJ: 2025-09-19 18:49:54  |  SHA256: c40eca6be96a2c68

```py
#!/opt/scalp/.venv/bin/python
import json, time
from pathlib import Path

DATA = Path("/opt/scalp/data")
SRC  = DATA/"heatmap.json"
OUT  = DATA/"analysis/A"

# paramètres A
WIN   = 20           # nb de points S récents utilisés
BAND  = 0.10         # zone neutre |S|<BAND => hold
TH_BULL = 0.60       # p_buy >= 0.60
TH_BEAR = 0.60       # p_sell >= 0.60
RNG_MIN, RNG_MAX = 0.40, 0.60  # 0.40<=p_hold<=0.60

def _probs(seq):
    """retourne p_buy, p_hold, p_sell à partir d'une séquence S (liste de floats)"""
    if not seq: 
        return (0.0, 1.0, 0.0)
    b=h=s=0
    for v in seq:
        v=float(v)
        if abs(v) < BAND: h += 1
        elif v > 0:       b += 1
        else:             s += 1
    n = max(1, b+h+s)
    return b/n, h/n, s/n

def _ctx(pb, ph, ps):
    if pb >= TH_BULL:        return "bullish"
    if ps >= TH_BEAR:        return "bearish"
    if RNG_MIN <= ph <= RNG_MAX: return "range"
    return "none"

def analyze_row(row):
    sym = row.get("sym")
    seq = row.get("S", [])[-WIN:]
    pb,ph,ps = _probs(seq)
    ctx = _ctx(pb,ph,ps)
    return {
        "sym": sym,
        "updated": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        "win": WIN,
        "band": BAND,
        "p_buy": round(pb,3),
        "p_hold": round(ph,3),
        "p_sell": round(ps,3),
        "ctx": ctx,
        "S_last": seq[-1] if seq else 0.0
    }

def run():
    OUT.mkdir(parents=True, exist_ok=True)
    if not SRC.exists():
        print("heatmap.json absent"); return 0
    obj = json.loads(SRC.read_text())
    if isinstance(obj, dict):
        rows = obj.get("rows", [])
    else:
        rows = obj  # si c’est déjà une liste

    count=0
    for r in rows:
        res = analyze_row(r)
        (OUT/f"{res['sym']}.json").write_text(json.dumps(res, ensure_ascii=False))
        count+=1
    # petit résumé global
    (OUT/"_summary.json").write_text(json.dumps({
        "updated": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        "count": count
    }, ensure_ascii=False))
    return count

```

### analyze/run_triggers_cli.py  
Taille: 2 KB  |  MàJ: 2025-09-19 20:41:56  |  SHA256: a64ebf8ba323c959

```py
#!/opt/scalp/.venv/bin/python
import json, math
from pathlib import Path
D=Path("/opt/scalp/data"); C3=D/"candles_3m"; CTX=json.loads((D/"context.json").read_text())
EQUITY=float((Path("/opt/scalp/etc/scalp.env").read_text().splitlines() if (Path("/opt/scalp/etc/scalp.env").exists()) else ["EQUITY=1000"])[0].split("=")[-1]) if False else 1000.0
RISK=0.01; MAX_LEV=10

def ema(vals,p):
    k=2/(p+1); e=None
    for v in vals:
        e=v if e is None else e+k*(v-e)
    return e or (vals[-1] if vals else None)

signals=[]
for f in C3.glob("*_3m.json"):
    sym=f.stem.replace("_3m","")
    rows=json.loads(f.read_text()); closes=[r["c"] for r in rows]
    if len(closes)<60 or sym not in CTX: continue
    e9=ema(closes[-60:],9); e21=ema(closes[-60:],21); last=closes[-1]
    ctx=CTX[sym]; pbuy,psell=ctx["pbuy"],ctx["psell"]
    # règle d’entrée simple cross + contexte
    side=None
    if pbuy and e9 is not None and e21 is not None and e9>e21: side="LONG"
    if psell and e9 is not None and e21 is not None and e9<e21: side="SHORT"
    if not side: continue
    # SL/TP via ATR-like (vol absolue 20)
    highs=[r["h"] for r in rows[-20:]]; lows=[r["l"] for r in rows[-20:]]
    tr=[max(h-l,abs(h-last),abs(l-last)) for h,l in zip(highs,lows)]
    atr=sum(tr)/len(tr) if tr else last*0.01
    if side=="LONG":
        sl= last-2*atr; tp= last+3*atr
    else:
        sl= last+2*atr; tp= last-3*atr
    # taille et levier
    risk_amt=EQUITY*RISK
    stop_dist=abs(last-sl) or (last*0.005)
    qty=risk_amt/stop_dist
    lev=min(MAX_LEV, max(1,int((qty*last)/max(1.0,EQUITY))))
    signals.append({"sym":sym,"side":side,"px":last,"sl":sl,"tp":tp,"qty":qty,"lev":lev})
(D/"signals.json").write_text(json.dumps(signals,ensure_ascii=False,indent=2))
print("signals:",len(signals))

```

### bin/dump_and_push.sh  
Taille: 4 KB  |  MàJ: 2025-09-17 05:10:42  |  SHA256: e8fae927be8e9112

```sh
#!/usr/bin/env bash
set -euo pipefail

# --------- Réglages ---------
ROOT="/opt/scalp"
DUMP_DIR="${ROOT}/dump"
TS="$(date +'%Y%m%d_%H%M%S')"
OUT="${DUMP_DIR}/scalp_code_${TS}.txt"
TMP_LIST="$(mktemp)"
MAX_FILE_SIZE_KB="${MAX_FILE_SIZE_KB:-512}"
MAX_FILES="${MAX_FILES:-4000}"
DRY_RUN="${DRY_RUN:-1}"

mkdir -p "$DUMP_DIR"
trap 'rm -f "$TMP_LIST"' EXIT

# --------- Git depuis /etc/scalp.env ---------
. /etc/scalp.env

: "${GIT_USER:?manquant}"
: "${GIT_TOKEN:?manquant}"

GIT_BRANCH="${GIT_BRANCH:-main}"
GIT_EMAIL_USE="${GIT_EMAIL:-${GIT_USER}@users.noreply.github.com}"
GIT_HOST="${GIT_HOST:-github.com}"
GIT_OWNER="${GIT_OWNER:-$GIT_USER}"
GIT_REPO="${GIT_REPO:-scalp}"
GIT_REMOTE="${GIT_REMOTE:-}"

if [ -n "$GIT_REMOTE" ]; then
  REMOTE_URL="$GIT_REMOTE"
else
  REMOTE_URL="https://${GIT_HOST}/${GIT_OWNER}/${GIT_REPO}.git"
fi

echo "[dump_and_push] branch=${GIT_BRANCH} dry_run=${DRY_RUN} remote=${REMOTE_URL}"

# --------- Collecte fichiers ---------
find "$ROOT" -type f \
  -not -path '*/.*' \
  -not -path '*/.git/*' \
  -not -path '*/__pycache__/*' \
  -not -path '*/venv/*' -not -path '*/.venv/*' \
  -not -path '*/var/*' \
  -not -path '*/logs/*' \
  -not -path '*/data/*' \
  -not -path '*/reports/*' \
  -not -path '*/dump/*' \
  -size -"${MAX_FILE_SIZE_KB}"k \
  \( -name '*.py' -o -name '*.sh' -o -name '*.bash' -o -name '*.ini' -o -name '*.cfg' -o -name '*.conf' -o -name '*.toml' -o -name '*.yaml' -o -name '*.yml' -o -name '*.md' -o -name '*.txt' \) \
  -print0 > "$TMP_LIST"

# Limite à MAX_FILES
TMP2="$(mktemp)"; trap 'rm -f "$TMP2"' EXIT
awk -v max="$MAX_FILES" -v RS='\0' -v ORS='\0' 'NR<=max{print}' "$TMP_LIST" > "$TMP2"
mv "$TMP2" "$TMP_LIST"

# Utilitaires
file_size() { stat -c %s -- "$1" 2>/dev/null || wc -c <"$1" 2>/dev/null || echo 0; }
file_mtime() { stat -c %y -- "$1" 2>/dev/null || date -r "$1" +'%Y-%m-%d %H:%M:%S %Z' 2>/dev/null || echo "unknown"; }

# En-tête
{
  echo "# Scalp Project Code Dump"
  echo "# Generated: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
  echo "# Root: ${ROOT}"
  echo "# Caps: ${MAX_FILE_SIZE_KB}KB/file, max ${MAX_FILES} files"
  echo "# Exclusions: hidden, .git, __pycache__, venv/.venv, var, logs, data, reports, dump"
  echo "# Extensions: py, sh, bash, ini, cfg, conf, toml, yaml/yml, md, txt"
  echo
  echo "========== TREE (size, mtime) =========="
} > "$OUT"

# TREE
tr '\0' '\n' < "$TMP_LIST" | sort | while IFS= read -r f; do
  [ -n "$f" ] || continue
  printf "%-80s  %12s  %s\n" "$f" "$(file_size "$f")" "$(file_mtime "$f")" >> "$OUT"
done

# TOP 10
{
  echo
  echo "========== TOP 10 BIGGEST FILES =========="
} >> "$OUT"
tr '\0' '\n' < "$TMP_LIST" | awk 'NF' | while IFS= read -r f; do
  sz="$(file_size "$f")"
  printf "%012d\t%s\n" "$sz" "$f"
done | sort -r | head -n 10 | awk -F'\t' '{printf "%-80s  %12d\n", $2, $1+0}' >> "$OUT"

# Contenu
{
  echo
  echo "========== CONCAT CONTENT =========="
} >> "$OUT"

tr '\0' '\n' < "$TMP_LIST" | awk 'NF' | while IFS= read -r f; do
  sz="$(file_size "$f")"
  mt="$(file_mtime "$f")"
  {
    echo
    echo "----- FILE BEGIN -----"
    echo "Path: $f"
    echo "Size: $sz"
    echo "MTime: $mt"
    echo "----- CONTENT -----"
  } >> "$OUT"

  if [ "$sz" -gt $((MAX_FILE_SIZE_KB*1024)) ]; then
    head -c $((MAX_FILE_SIZE_KB*1024)) -- "$f" 2>/dev/null >> "$OUT" || true
    echo -e "\n[TRUNCATED]" >> "$OUT"
  else
    cat -- "$f" 2>/dev/null >> "$OUT" || true
  fi
  echo "----- FILE END -----" >> "$OUT"
done

echo "Dump prêt: $OUT"

# --------- Git: commit + push du dump ---------
cd "$ROOT"
git rev-parse --is-inside-work-tree >/dev/null 2>&1 || git init -q .
git config user.name "${GIT_USER}"
git config user.email "${GIT_EMAIL_USE}"
git remote get-url origin >/dev/null 2>&1 || git remote add origin "${REMOTE_URL}"

touch .gitignore
for p in var/ logs/ data/ reports/ dump/; do grep -qxF "$p" .gitignore || echo "$p" >> .gitignore; done

git add -f "$OUT"
git commit -m "dump: ${OUT##*/}" || true

if [ "$DRY_RUN" = "1" ]; then
  echo "DRY_RUN=1 -> push désactivé"
else
  AUTH_URL="$(git remote get-url origin | sed -E "s#^https://#https://${GIT_USER}:${GIT_TOKEN}@#")"
  git push "$AUTH_URL" "HEAD:${GIT_BRANCH}"
  echo "OK: push vers ${REMOTE_URL} sur ${GIT_BRANCH}"
fi

```

### bin/dump_and_reset.sh  
Taille: 2 KB  |  MàJ: 2025-09-17 05:13:48  |  SHA256: 9a5d9d9038c80be7

```sh
#!/usr/bin/env bash
set -euo pipefail

ROOT="/opt/scalp"
DUMP_DIR="${ROOT}/dump"
TS="$(date +'%Y%m%d_%H%M%S')"
OUT="${DUMP_DIR}/scalp_code_${TS}.txt"
TMP_LIST="$(mktemp)"
MAX_FILE_SIZE_KB="${MAX_FILE_SIZE_KB:-512}"
MAX_FILES="${MAX_FILES:-4000}"

mkdir -p "$DUMP_DIR"
trap 'rm -f "$TMP_LIST"' EXIT

# -------- Git depuis /etc/scalp.env --------
. /etc/scalp.env
: "${GIT_USER:?manquant}"
: "${GIT_TOKEN:?manquant}"
GIT_EMAIL_USE="${GIT_EMAIL:-${GIT_USER}@users.noreply.github.com}"
GIT_BRANCH="${GIT_BRANCH:-main}"
GIT_HOST="${GIT_HOST:-github.com}"
GIT_OWNER="${GIT_OWNER:-$GIT_USER}"
GIT_REPO="${GIT_REPO:-scalp}"
REMOTE_URL="${GIT_REMOTE:-https://${GIT_HOST}/${GIT_OWNER}/${GIT_REPO}.git}"

echo "[dump_and_reset] remote=${REMOTE_URL} branch=${GIT_BRANCH}"

# -------- Collecte fichiers --------
find "$ROOT" -type f \
  -not -path '*/.*' \
  -not -path '*/.git/*' \
  -not -path '*/__pycache__/*' \
  -not -path '*/venv/*' -not -path '*/.venv/*' \
  -not -path '*/var/*' \
  -not -path '*/logs/*' \
  -not -path '*/data/*' \
  -not -path '*/reports/*' \
  -not -path '*/dump/*' \
  -size -"${MAX_FILE_SIZE_KB}"k \
  \( -name '*.py' -o -name '*.sh' -o -name '*.bash' -o -name '*.ini' -o -name '*.cfg' -o -name '*.conf' -o -name '*.toml' -o -name '*.yaml' -o -name '*.yml' -o -name '*.md' -o -name '*.txt' \) \
  -print0 > "$TMP_LIST"

# -------- Génère le dump --------
{
  echo "# Scalp Project Code Dump"
  echo "# Generated: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
} > "$OUT"

tr '\0' '\n' < "$TMP_LIST" | head -n "$MAX_FILES" | while IFS= read -r f; do
  echo "----- FILE BEGIN -----" >> "$OUT"
  echo "Path: $f" >> "$OUT"
  cat "$f" >> "$OUT" || true
  echo "----- FILE END -----" >> "$OUT"
done

echo "Dump généré: $OUT"

# -------- Réinit git complet --------
cd "$ROOT"
rm -rf .git
git init -q .
git config user.name "${GIT_USER}"
git config user.email "${GIT_EMAIL_USE}"
git remote add origin "${REMOTE_URL}"

# Commit unique
git add -f "$OUT"
git commit -m "reset: dump ${OUT##*/}"

# Push forcé (écrase distant)
AUTH_URL="$(git remote get-url origin | sed -E "s#^https://#https://${GIT_USER}:${GIT_TOKEN}@#")"
git branch -M "${GIT_BRANCH}"
git push --force "$AUTH_URL" "${GIT_BRANCH}"

echo "OK: repo réinitialisé et poussé sur ${REMOTE_URL} (${GIT_BRANCH})"

```

### bot/__init__.py  
Taille: 0 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: e3b0c44298fc1c14

```py

```

### bot/_keyboard_patch.py  
Taille: 670 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 7b38739c8a2a5af8

```py
import json, os, urllib.parse, urllib.request
TOKEN=os.getenv("TELEGRAM_BOT_TOKEN","")
API=f"https://api.telegram.org/bot{TOKEN}/sendMessage"
KB={"keyboard":[
    [ {"text":"/top"}, {"text":"/heat"} ],
    [ {"text":"/signals"}, {"text":"/positions"} ],
    [ {"text":"/history"}, {"text":"/ping"} ]
], "resize_keyboard": True, "one_time_keyboard": False}

def send(chat_id, text, parse_mode=None):
    data={"chat_id":chat_id,"text":text,"reply_markup":json.dumps(KB, ensure_ascii=False)}
    if parse_mode: data["parse_mode"]=parse_mode
    req=urllib.request.Request(API, data=urllib.parse.urlencode(data).encode())
    urllib.request.urlopen(req, timeout=10).read()

```

### bot/bot_stdlib.py  
Taille: 2 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 8e5d6bd230416ff5

```py
#!/opt/scalp/.venv/bin/python
import os, time, json, urllib.request, urllib.parse, pathlib, traceback, inspect
from bot.views_heat import render_heatmap as render_heatmap_soft
from .views import render_top15, render_signals
from .views_positions import render_positions
from .views_history  import render_history

BASE=pathlib.Path("/opt/scalp"); DATA=BASE/"data"
TOKEN=os.getenv("TELEGRAM_BOT_TOKEN",""); CHAT=os.getenv("TELEGRAM_CHAT_ID","")
API=f"https://api.telegram.org/bot{TOKEN}"

assert TOKEN and CHAT, "⚠️ TELEGRAM_BOT_TOKEN / CHAT_ID manquant"
assert "views_heat.py" in (inspect.getsourcefile(render_heatmap_soft) or ""), \
    "Heatmap pas issue de bot/views_heat.py"

def _post(m,p):
    req=urllib.request.Request(f"{API}/{m}",data=urllib.parse.urlencode(p).encode())
    with urllib.request.urlopen(req,timeout=10) as r: return json.loads(r.read())

def _send(cid,txt,pm="HTML",kb=True):
    pl={"chat_id":cid,"text":txt,"disable_web_page_preview":True}
    if pm: pl["parse_mode"]=pm
    if kb:
        pl["reply_markup"]=json.dumps({"keyboard":[
            [{"text":"/top"},{"text":"/heat"}],
            [{"text":"/signals"},{"text":"/positions"}],
            [{"text":"/history"},{"text":"/ping"}]],"resize_keyboard":True})
    try: _post("sendMessage",pl)
    except Exception as e: print("send fail:",e)

def _answer(cmd):
    return {"/top":render_top15,"/heat":render_heatmap_soft,
            "/signals":render_signals,"/positions":render_positions,
            "/history":render_history,"/ping":lambda:"pong ✅"}.get(cmd,lambda:"(commande inconnue)")()

def _ofs(): return DATA/".tg_offset"

def main():
    try: _send(CHAT,"SCALP bot prêt ✅")
    except: pass
    off=0
    if _ofs().exists():
        try: off=int((_ofs().read_text() or "0").strip())
        except: pass
    while True:
        try:
            res=_post("getUpdates",{"timeout":25,"offset":off+1})
            for u in res.get("result",[]):
                off=u["update_id"]
                m=u.get("message") or u.get("edited_message") or {}
                txt=(m.get("text") or "").strip(); cid=str(m.get("chat",{}).get("id",""))
                if not txt or not cid: continue
                try: _send(cid,_answer(txt))
                except Exception: _send(cid,f"<pre>{traceback.format_exc()}</pre>")
            _ofs().write_text(str(off))
        except Exception as e:
            print("loop error:",e); time.sleep(1)

if __name__=="__main__": main()

```

### bot/commands_wire.py  
Taille: 978 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 449ef6e244cf0386

```py
#!/opt/scalp/.venv/bin/python
# Fonctions à appeler depuis ton handler Telegram
from __future__ import annotations
from typing import Optional
from views_positions import render_positions
from views_history  import render_history
from views_signals  import render_signals
from views_btop     import render_btop
from views_heat     import render_heatmap

def cmd_positions(bot, chat_id):
    bot.send_message(chat_id, render_positions())

def cmd_history(bot, chat_id, minutes:Optional[int]=None):
    txt = render_history(since_minutes=minutes, limit=50 if minutes else 30)
    bot.send_message(chat_id, txt)

def cmd_signals(bot, chat_id, minutes:Optional[int]=None):
    txt = render_signals(limit=0 if minutes else 20, since_minutes=minutes)
    bot.send_message(chat_id, txt)

def cmd_btop(bot, chat_id, n:Optional[int]=None):
    bot.send_message(chat_id, render_btop(n))

def cmd_heat(bot, chat_id, n:Optional[int]=None):
    bot.send_message(chat_id, render_heatmap(n))

```

### bot/env_simple.py  
Taille: 469 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: a75e09ead631b4f8

```py
import pathlib,re
ENV=pathlib.Path("/etc/scalp.env"); RGX=re.compile(r'^\s*([A-Za-z_]\w*)\s*=\s*(.*)\s*$')
def load():
    d={}
    if ENV.exists():
        for L in ENV.read_text(encoding="utf-8",errors="ignore").splitlines():
            m=RGX.match(L); 
            if m: d[m.group(1)]=m.group(2).strip().strip('"').strip("'")
    s=type("S",(),{})(); s.TOKEN=d.get("TELEGRAM_BOT_TOKEN",""); s.CHAT_ID=d.get("TELEGRAM_CHAT_ID"); s.BUILD=d.get("BUILD","-"); return s

```

### bot/json_util.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 89aa28d11d2e8238

```py
import json, pathlib
from typing import Any, Optional

def load_last_json(path: pathlib.Path | str, default: Optional[Any]=None) -> Any:
    p = pathlib.Path(path)
    if not p.exists():
        return default
    txt = p.read_text(encoding="utf-8").strip()
    if not txt:
        return default
    # 1/ essai direct
    try:
        return json.loads(txt)
    except Exception:
        pass
    # 2/ parcourir tous les objets JSON concaténés et garder le dernier valide
    dec = json.JSONDecoder()
    i, last = 0, default
    while i < len(txt):
        # sauter espaces / séparateurs
        while i < len(txt) and txt[i] not in "{[":
            i += 1
        if i >= len(txt):
            break
        try:
            obj, j = dec.raw_decode(txt, idx=i)
            last = obj
            i = j
        except Exception:
            i += 1
    return last

def load_json(path: pathlib.Path | str, default: Optional[Any]=None) -> Any:
    import json, pathlib
    p = pathlib.Path(path)
    if not p.exists():
        return default
    try:
        return json.loads(p.read_text(encoding="utf-8"))
    except Exception:
        return default

```

### bot/lib/__init__.py  
Taille: 0 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: e3b0c44298fc1c14

```py

```

### bot/mod_heatmap.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: d736b6a6529bcd00

```py
import json,pathlib,re; from lib.errors import err
DATA=pathlib.Path("/opt/scalp/data"); TRI=re.compile(r'\s*(\d+)\s*/\s*(\d+)\s*/\s*(\d+)\s*')
def _t(x): 
    if isinstance(x,dict): return {k:int(x.get(k,0)) for k in ("b","h","s")}
    m=TRI.match((x or "")); return {"b":int(m.group(1)),"h":int(m.group(2)),"s":int(m.group(3))} if m else {"b":0,"h":0,"s":0}
def run():
    p=DATA/"heatmap.json"
    if not p.exists(): return f"(à connecter: {p})"
    try: o=json.loads(p.read_text()); rows=o.get("rows") or []
    except Exception: return err("E11","heatmap.json illisible")
    if not rows: return "(pas de données)"
    def B(b,h,s): m=max(b,h,s); f=lambda x: f"<b>{x}</b>" if x==m else f"{x}"; return f"[ {f(b)} | {f(h)} | {f(s)} ]"
    L=["coin    5m             15m            30m","──────────────────────────────────────────"]
    for r in rows:
        sym=(r.get("sym") or r.get("symb") or r.get("coin") or "").replace("/USDT","").replace("USDT",""); 
        if not sym: continue
        t=lambda tf:_t(r.get(tf))
        L.append(f"{sym[:6].ljust(6)}  " + "   ".join([B(**t('5m')),B(**t('15m')),B(**t('30m'))]))
    return "<pre>"+"\n".join(L)+"</pre>"

```

### bot/mod_signals.py  
Taille: 865 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: e7758865ceb08c95

```py
import json,pathlib,time; from lib.errors import err
DATA=pathlib.Path("/opt/scalp/data")
def run(limit:int=20):
    p=DATA/"signals.json"
    if not p.exists(): return f"(à connecter: {p})"
    try: o=json.loads(p.read_text())
    except Exception: return err("E11","signals.json illisible")
    arr=o.get("signals") if isinstance(o,dict) else (o if isinstance(o,list) else [])
    if not arr: return "(aucun signal)"
    arr=sorted(arr,key=lambda s:(s or {}).get("t_emit",0),reverse=True)[:limit]
    L=["Derniers signaux:"]
    for s in arr:
        s=s or {}; ts=int(str(s.get("t_emit",0))[:10]) if s.get("t_emit") else 0
        when=time.strftime("%Y-%m-%d %H:%MZ", time.gmtime(ts)) if ts else "—"
        L.append(f"{when}  {s.get('sym','?')}  {s.get('side','?')}  tf={s.get('tf','?')}  rule={s.get('rule','?')}")
    return "<pre>"+"\n".join(L)+"</pre>"

```

### bot/mod_top.py  
Taille: 503 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: ae0ab2c3d6e8a47f

```py
import json,pathlib; from lib.errors import err
DATA=pathlib.Path("/opt/scalp/data")
def run():
    p=DATA/"top.json"
    if not p.exists(): return f"(à connecter: {p})"
    try: o=json.loads(p.read_text())
    except Exception: return err("E11","top.json illisible")
    arr=(o or {}).get("assets",[])
    if not arr: return "(top vide)"
    L=["Top volume/volatilité:"]+[f"{x.get('sym','?'):6} v={x.get('vol','?')} σ={x.get('vola','?')}" for x in arr[:20]]
    return "<pre>"+"\n".join(L)+"</pre>"

```

### bot/router.py  
Taille: 3 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 4e6d3a2653ef9014

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import os, logging
from telegram import Update, BotCommand
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters

from .views_signals import render_signals
from .views_positions import render_positions
from .views_history import render_history
from .views_heat import render_heat
from .views_menu import main_menu

logging.basicConfig(level=logging.INFO)
LOG=logging.getLogger("router")

TOKEN=os.getenv("TELEGRAM_TOKEN") or os.getenv("TELEGRAM_BOT_TOKEN") or ""
ALLOW=os.getenv("ALLOW_CHAT_ID") or os.getenv("TELEGRAM_CHAT_ID") or ""

def _ok(u:Update)->bool:
    return not ALLOW or str(u.effective_chat.id)==str(ALLOW)

async def _deny(u:Update,c:ContextTypes.DEFAULT_TYPE):
    await c.bot.send_message(chat_id=u.effective_chat.id, text="(accès refusé)")

async def _set_cmds(app):
    cmds=[BotCommand("heat","Heatmap"),
          BotCommand("signals","Derniers signaux"),
          BotCommand("positions","Positions ouvertes"),
          BotCommand("history","Historique des ordres")]
    await app.bot.set_my_commands(cmds)

async def start(u:Update,c:ContextTypes.DEFAULT_TYPE):
    if not _ok(u): return await _deny(u,c)
    await _set_cmds(c.application)
    await c.bot.send_message(chat_id=u.effective_chat.id, text="SCALP bot prêt", reply_markup=main_menu())

async def heat(u:Update,c:ContextTypes.DEFAULT_TYPE):
    if not _ok(u): return await _deny(u,c)
    await c.bot.send_message(chat_id=u.effective_chat.id, text=render_heat(), reply_markup=main_menu())

async def signals(u:Update,c:ContextTypes.DEFAULT_TYPE):
    if not _ok(u): return await _deny(u,c)
    await c.bot.send_message(chat_id=u.effective_chat.id, text=render_signals(), reply_markup=main_menu())

async def positions(u:Update,c:ContextTypes.DEFAULT_TYPE):
    if not _ok(u): return await _deny(u,c)
    await c.bot.send_message(chat_id=u.effective_chat.id, text=render_positions(), reply_markup=main_menu())

async def history(u:Update,c:ContextTypes.DEFAULT_TYPE):
    if not _ok(u): return await _deny(u,c)
    text = u.message.text or "/history"
    await c.bot.send_message(chat_id=u.effective_chat.id, text=render_history(text), reply_markup=main_menu())

async def fallback(u:Update,c:ContextTypes.DEFAULT_TYPE):
    if not _ok(u): return await _deny(u,c)
    await c.bot.send_message(chat_id=u.effective_chat.id, text="Choisis une commande.", reply_markup=main_menu())

def main()->int:
    assert TOKEN,"TELEGRAM_TOKEN manquant"
    app=ApplicationBuilder().token(TOKEN).build()
    app.add_handler(CommandHandler("start",start))
    app.add_handler(CommandHandler("heat",heat))
    app.add_handler(CommandHandler("signals",signals))
    app.add_handler(CommandHandler("positions",positions))
    app.add_handler(CommandHandler("history",history))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, fallback))
    app.run_polling(allowed_updates=None)
    return 0

if __name__=="__main__":
    raise SystemExit(main())

```

### bot/singleton.py  
Taille: 477 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: f0fdc9455c132561

```py
import os,sys,fcntl
LOCK="/run/scalp-bot.lock"
def acquire_or_exit():
    os.makedirs("/run",exist_ok=True)
    fd=os.open(LOCK,os.O_CREAT|os.O_RDWR,0o644)
    try:
        fcntl.flock(fd, fcntl.LOCK_EX|fcntl.LOCK_NB); os.ftruncate(fd,0); os.write(fd,f"{os.getpid()}\n".encode()); os.fsync(fd); return fd
    except BlockingIOError:
        os.lseek(fd,0,os.SEEK_SET); pid=(os.read(fd,64).decode().strip() or "?"); print(f"[singleton] pid={pid}",file=sys.stderr); sys.exit(16)

```

### bot/views.py  
Taille: 2 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 322bd3e1235cec1b

```py
#!/opt/scalp/.venv/bin/python
# Vues textuelles hors heatmap (top, signals, positions, history)
import json, pathlib, datetime as dt
BASE = pathlib.Path("/opt/scalp"); DATA = BASE/"data"

def _safe_read(path):
    try: return json.loads(path.read_text())
    except Exception: return {}

def render_top15():
    obj = _safe_read(DATA/"top.json")
    rows = obj.get("rows", [])
    tstr = obj.get("time","")
    head = f"Top15  {tstr}" if tstr else "Top15"
    names = [r.get("sym","?") for r in rows[:15]]
    # colonne double (1..15)
    left  = [f"{i+1}. {names[i]:<3}" for i in range(0, min(5, len(names)))]
    right = [f"{i+6}. {names[i+5]:<3}" for i in range(0, min(5, max(0,len(names)-5)))]
    third = [f"{i+11}. {names[i+10]:<3}" for i in range(0, min(5, max(0,len(names)-10)))]
    # assemble lisible même si listes courtes
    lines = [head, ""]
    for i in range(5):
        a = left[i]  if i < len(left)  else " " * 8
        b = right[i] if i < len(right) else " " * 8
        c = third[i] if i < len(third) else " " * 8
        lines.append(f"{a:10} {b:10} {c}")
    return "\n".join(lines)

def render_signals():
    p = DATA/"signals.json"
    obj = _safe_read(p)
    sigs = obj.get("signals", [])
    if not sigs: return "(pas de signaux)"
    out = ["Signals", ""]
    for s in sigs[:10]:
        out.append(f"{s.get('timestamp','')}  {s.get('symbol','?')}  {s.get('side','?')}  {s.get('entry_set','')}")
    return "\n".join(out)

def render_positions():
    p = DATA/"positions.json"
    obj = _safe_read(p)
    pos = obj.get("positions", [])
    if not pos: return "(pas de positions)"
    out = ["Positions", ""]
    for x in pos[:10]:
        out.append(f"{x.get('symbol','?')}  {x.get('side','?')}  {x.get('qty','')}  @ {x.get('price','')}")
    return "\n".join(out)

def render_history():
    p = DATA/"history.json"
    obj = _safe_read(p)
    h = obj.get("history", [])
    if not h: return "(historique vide)"
    out = ["History", ""]
    for x in h[:10]:
        out.append(f"{x.get('timestamp','')}  {x.get('symbol','?')}  {x.get('pnl','')}")
    return "\n".join(out)

```

### bot/views_account.py  
Taille: 909 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: cd594886f0d665d2

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json, time
from pathlib import Path

DATA=Path("/opt/scalp/data")
ACCT=DATA/"account.json"
POSF=DATA/"positions.json"

def _read_json(p:Path, d): 
    try: return json.loads(p.read_text())
    except: return d

def render_account()->str:
    a=_read_json(ACCT, {"balance":0,"equity":0,"open_pnl":0,"currency":"USDT","updated":0})
    pos=_read_json(POSF, {"positions":[]})
    rows = pos.get("positions") if isinstance(pos,dict) else pos
    n_open = sum(1 for x in rows if isinstance(x,dict) and x.get("status")=="open")
    ts=time.strftime("%Y-%m-%d %H:%M:%SZ", time.gmtime(a.get("updated",0)))
    return (f"Balance : {a['balance']:.2f} {a.get('currency','USDT')}\n"
            f"OpenPnL : {a['open_pnl']:.2f}\n"
            f"Equity  : {a['equity']:.2f}\n"
            f"Positions ouvertes : {n_open}\n"
            f"Maj : {ts}")

```

### bot/views_btop.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 5302192866f47be4

```py
#!/opt/scalp/.venv/bin/python
# /Btop : affiche par crypto -> S, max(pb/ph/ps) avec libellé, et ctx
from __future__ import annotations
import json, time
from pathlib import Path
from typing import Dict, Any, List

DATA = Path("/opt/scalp/data")
SRC  = DATA/"Btop.json"

def _read():
    if not SRC.exists(): return {"updated": None, "assets": []}
    try: return json.loads(SRC.read_text())
    except: return {"updated": None, "assets": []}

def _argmax_prob(a:Dict[str,Any])->tuple[str,float]:
    pb=a.get("pb",0.0); ph=a.get("ph",0.0); ps=a.get("ps",0.0)
    if pb>=ph and pb>=ps: return ("pb", pb)
    if ps>=ph and ps>=pb: return ("ps", ps)
    return ("ph", ph)

def render_btop(max_rows:int|None=None)->str:
    src=_read()
    rows=src.get("assets", [])
    if max_rows is not None: rows=rows[:max_rows]

    w_sym=max(3, min(8, max((len(r.get("sym","")) for r in rows), default=3)))

    lines=[]
    lines.append(f"{'sym':<{w_sym}}  {'S':>6}  {'max':>3}  {'p':>5}  {'ctx'}")
    for r in rows:
        sym=r.get("sym","UNK")
        S=float(r.get("S",0.0))
        k,v=_argmax_prob(r)            # k in {'pb','ph','ps'}
        ctx=r.get("ctx")
        lines.append(f"{sym:<{w_sym}}  {S:>6.3f}  {k:>3}  {v:>5.3f}  {ctx}")
    return "\n".join(lines) if lines else "Btop vide"

# Exemple d’usage dans le handler Telegram:
#   from views_btop import render_btop
#   bot.send_message(chat_id, render_btop())        # tout
#   bot.send_message(chat_id, render_btop(20))      # top 20 en ordre fichier

```

### bot/views_heat.py  
Taille: 2 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: bc839008af17167b

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json
from pathlib import Path
from datetime import datetime, timezone

HEATMAP = Path("/opt/scalp/data/heatmap.json")

def render_heat() -> str:
    if not HEATMAP.exists():
        return "Heatmap (indisponible)"
    try:
        obj = json.loads(HEATMAP.read_text())
    except Exception:
        return "Heatmap (erreur lecture)"

    updated = obj.get("updated", "")
    try:
        t = datetime.fromisoformat(updated.replace("Z","+00:00"))
        ts = t.astimezone(timezone.utc).strftime("%H:%M")
    except Exception:
        ts = updated or ""

    # collecte en gardant l'ordre du JSON
    rows = []
    for r in obj.get("rows", []):
        snap = r.get("snap", {})
        vals = [
            int(10*snap.get("60m",0)),
            int(10*snap.get("30m",0)),
            int(10*snap.get("15m",0)),
            int(10*snap.get("now",0)),
        ]
        rows.append((str(r.get("sym","?")).upper(), *vals))

    if not rows:
        return "Heatmap " + ts

    # largeurs de colonnes pour un alignement propre
    w0 = max(len(sym) for sym, *vs in rows)
    # largeur signée par colonne
    w = [max(len(f"{v:+d}") for _, *vs in rows for i,v in enumerate(vs) if i==k) for k in range(4)]

    # formatage
    lines = [f"Heatmap {ts}" if ts else "Heatmap"]
    buf = []
    for i, (sym, v1, v2, v3, v4) in enumerate(rows, 1):
        line = f"{sym:<{w0}}  {v1:+{w[0]}d}  {v2:+{w[1]}d}  {v3:+{w[2]}d}  {v4:+{w[3]}d}"
        buf.append(line)
        if i % 5 == 0:
            lines.append("\n".join(buf))
            buf = []
    if buf:
        lines.append("\n".join(buf))

    return "\n\n".join(lines)

```

### bot/views_history.py  
Taille: 3 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 702f8a3c0c9ce198

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json, datetime as dt
from pathlib import Path
from typing import Any, Dict, List

DATA = Path("/opt/scalp/data")
HIST = DATA/"positions_hist.jsonl"

def _rd(f, n=2):
    try: return f"{float(f):+0.{n}f}$"
    except: return "+0.00$"

def _ts(i)->dt.datetime|None:
    try: return dt.datetime.utcfromtimestamp(int(i))
    except: return None

def _hhmm(t): return t.strftime("%H:%M") if t else "--:--"

def _durm(o,c)->str:
    if not o or not c: return "?"
    m=int((c-o).total_seconds()//60)
    h, m = divmod(m, 60)
    return f"{h}h{m:02d}" if h else f"{m}m"

def _read()->List[Dict[str,Any]]:
    if not HIST.exists(): return []
    out=[]
    for line in HIST.read_text().splitlines():
        try:
            r=json.loads(line)
            if isinstance(r,dict): out.append(r)
        except: pass
    return out

def _args(text:str)->Dict[str,str]:
    t=(text or "").lower().split()
    a={}
    # ex: /history tp sym btc side long last 50
    for i in range(len(t)):
        if t[i] in {"tp","sl","cancelled","rejected"}: a["status"]=t[i]
        if t[i]=="sym" and i+1<len(t): a["sym"]=t[i+1].upper()
        if t[i]=="side" and i+1<len(t): a["side"]=t[i+1].upper()
        if t[i]=="last" and i+1<len(t) and t[i+1].isdigit(): a["last"]=t[i+1]
    return a

def render_history(text:str="")->str:
    q=_args(text)
    rows=_read()
    if not rows: return "History\n(vide)"

    # enrich
    enh=[]
    for r in rows:
        o=_ts(r.get("ts_open")); c=_ts(r.get("ts_close"))
        enh.append({
            **r,
            "_o":o, "_c":c, "_hh":_hhmm(o),
            "_dur":_durm(o,c),
            "_sym":str(r.get("symbol") or r.get("sym") or "?").upper(),
            "_side":str(r.get("side") or "?").upper(),
            "_stat":str(r.get("status") or "").lower(),
            "_reason":str(r.get("reason") or ""),
            "_setup":str(r.get("entry_set") or r.get("setup") or "?"),
        })

    # filtres
    if "sym" in q:   enh=[r for r in enh if r["_sym"]==q["sym"]]
    if "side" in q:  enh=[r for r in enh if r["_side"]==q["side"]]
    if "status" in q:
        s=q["status"]
        if s in {"tp","sl"}:      enh=[r for r in enh if r["_reason"]==s]
        elif s=="cancelled":      enh=[r for r in enh if r["_stat"]=="rejected"]
        elif s=="rejected":       enh=[r for r in enh if r["_stat"]=="rejected"]

    # tri + limite
    enh.sort(key=lambda r: (r["_c"] or r["_o"] or dt.datetime.min))
    n=int(q.get("last","20")) if q.get("last","").isdigit() else 20
    enh=enh[-n:]

    # header
    pnl=[r.get("pnl") for r in enh if isinstance(r.get("pnl"),(int,float,float))]
    pnl_tot=sum(pnl) if pnl else 0.0
    wins=sum(1 for x in pnl if x>0); losses=sum(1 for x in pnl if x<0)
    wr=int(round(100.0*wins/max(1,(wins+losses))))
    best=max(pnl) if pnl else 0.0
    worst=min(pnl) if pnl else 0.0
    out=[f"History n:{len(enh)}  win%:{wr}%  pnl:{pnl_tot:+.2f}$  best:{best:+.2f}$  worst:{worst:+.2f}$"]

    # rendu groupé par jour
    cur=None
    for r in enh:
        day=(r["_c"] or r["_o"] or dt.datetime.utcnow()).strftime("%Y-%m-%d")
        if day!=cur:
            if cur is not None: out.append("")  # ligne vide
            out.append(day); cur=day
        # ligne compacte: heure ouverture • durée • PnL • setup
        pnl_s=_rd(r.get("pnl",0),2)
        setup=r["_setup"]
        out.append(f"{r['_hh']} {r['_sym']} {r['_side']} {r['_dur']} {pnl_s} {setup}{' rej:'+r['_reason'] if r['_stat']=='rejected' else ''}")

    return "\n".join(out)

```

### bot/views_menu.py  
Taille: 309 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: cf9723b2a368078f

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
from telegram import ReplyKeyboardMarkup

def main_menu() -> ReplyKeyboardMarkup:
    keyboard = [
        ["/heat"],
        ["/signals", "/positions"],
        ["/history"]
    ]
    return ReplyKeyboardMarkup(keyboard, resize_keyboard=True)

```

### bot/views_positions.py  
Taille: 3 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 54b4f786cb03928c

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json, datetime
from pathlib import Path
from collections import defaultdict

DATA = Path("/opt/scalp/data")
POSF = DATA/"positions.json"
TOP1 = DATA/"top.json"
TOP2 = DATA/"Btop.json"

def _load_json(p: Path):
    try: return json.loads(p.read_text())
    except Exception: return None

def _top_order() -> list[str]:
    obj = _load_json(TOP1) or _load_json(TOP2) or {}
    syms: list[str] = []
    if isinstance(obj, dict) and "assets" in obj:
        for a in obj["assets"]:
            s = (a.get("sym") if isinstance(a, dict) else a) or ""
            if s: syms.append(str(s).upper())
    elif isinstance(obj, list):
        syms = [str(x).upper() for x in obj]
    return syms

def _pnl_quote(side:str, entry:float, last:float, size:float, lev:int) -> float:
    L = max(int(lev or 1),1)
    return ((last-entry) if str(side).lower().startswith("long") else (entry-last)) * size * L

def _progress(side:str, entry:float, sl:float, tp:float, last:float) -> float:
    s = str(side).lower()
    if entry<=0 or last<=0 or sl==tp: return 0.0
    if s.startswith("long"):
        up = max(tp-entry, 1e-9); dn = max(entry-sl, 1e-9)
        return 100.0*(last-entry)/up if last>=entry else -100.0*(entry-last)/dn
    else:
        up = max(entry-tp, 1e-9); dn = max(sl-entry, 1e-9)
        return 100.0*(entry-last)/up if last<=entry else -100.0*(last-entry)/dn

def render_positions(n:int=100) -> str:
    obj = _load_json(POSF) or {}
    rows = obj.get("positions", []) if isinstance(obj, dict) else []
    rows = [p for p in rows if str(p.get("status","open")).lower() in ("open","opened","opening","pending","")]
    if not rows:
        return "Positions\n(pas de positions)"

    # agrégation par coin
    agg = defaultdict(lambda: {"count":0, "pnl":0.0, "wprog":0.0, "w":0.0})
    total = 0.0
    for r in rows[:n]:
        sym = str((r.get("symbol") or r.get("sym") or "?")).upper()
        side = r.get("side","")
        entry=float(r.get("entry",0) or 0)
        sl   =float(r.get("sl",0) or 0)
        tp   =float(r.get("tp",0) or 0)
        last =float(r.get("last", entry) or entry)
        size =float(r.get("size", r.get("qty",0)) or 0)
        lev  =int(r.get("leverage", r.get("lev",1)) or 1)
        pnl  = r.get("pnl"); 
        if not isinstance(pnl,(int,float)): pnl=_pnl_quote(side,entry,last,size,lev)
        prog = _progress(side,entry,sl,tp,last)
        w = max(size*lev, 0.0)
        A = agg[sym]; A["count"]+=1; A["pnl"]+=float(pnl); A["wprog"]+=prog*w; A["w"]+=w
        total += float(pnl)

    # ordre: 5 fixes puis le reste, selon top.json, puis les absents à la fin
    top = _top_order()
    fixed = top[:5]
    rest  = top[5:]
    order = [s for s in fixed+rest if s in agg]
    others = [s for s in agg.keys() if s not in order]
    ordered_syms = order + others

    # rendu compact, saut de ligne toutes les 5
    lines = [f"Positions  PnL:{total:+.2f}$"]
    buf = []
    for i, sym in enumerate(ordered_syms, 1):
        A = agg[sym]
        avg_prog = (A["wprog"]/A["w"]) if A["w"]>0 else 0.0
        buf.append(f"{sym} ({A['count']})  {A['pnl']:+0.3f}$  {int(round(avg_prog)):+d}%")
        if i % 5 == 0:
            lines.append("\n".join(buf))
            buf = []
    if buf: lines.append("\n".join(buf))
    return "\n\n".join(lines)

```

### bot/views_signals.py  
Taille: 969 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: e3f8c5f0a3c4459d

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json, datetime
from pathlib import Path

DATA = Path("/opt/scalp/data")
SIGF = DATA/"signals.json"

def _now(ts):
    try: return datetime.datetime.fromisoformat(ts.replace("Z","+00:00")).strftime("%H:%M")
    except: return "--:--"

def render_signals(n:int=10)->str:
    try: obj=json.loads(SIGF.read_text())
    except: return "Signals\n(erreur lecture)"
    sigs = obj.get("signals", obj if isinstance(obj,list) else [])
    if not sigs: return "Signals\n(vide)"
    hhmm=_now(obj.get("updated", sigs[-1].get("timestamp","")))
    lines=[f"Signals {hhmm}"]
    for s in sigs[-n:]:
        sym=str(s.get("sym") or "?").upper()
        side=s.get("side","?")
        qty=s.get("size",0); lev=s.get("leverage",1)
        entry=s.get("price_entry",0); sl=s.get("sl",0); tp=s.get("tp",0)
        lines.append(f"{sym} {side} {qty:g}x{lev} {entry:.4f}/{sl:.4f}/{tp:.4f}")
    return "\n".join(lines)

```

### bot/views_top_patch.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 63c4b73df8a6daed

```py
# -*- coding: utf-8 -*-
import json, pathlib, time
DATA = pathlib.Path("/opt/scalp/data")

def _hmm(secs:int)->str:
    m,s=divmod(max(0,secs),60); h,m=divmod(m,60)
    return f"{h:d}:{m:02d}" if h else f"{m:d}:{s:02d}"

def _next_5m_eta()->str:
    now=int(time.time()); return _hmm(300-(now%300))

def render_top15():
    rows=[]
    p=DATA/"top.json"
    if p.exists():
        try:
            obj=json.loads(p.read_text())
            rows = obj.get("rows") or obj.get("syms") or []
        except: rows=[]
    if not rows:
        u=DATA/"universe.txt"
        if u.exists(): rows=[l.strip().upper() for l in u.read_text().splitlines() if l.strip()]
    rows=rows[:15]

    t=f"<pre><b>Top15   {_next_5m_eta()}</b>\n"
    out=[t]
    # largeur compacte: " 1.BTC" -> 6 chars
    fmt=lambda i,sym: f"{i:>2}.{sym:<3}"
    col1=[fmt(i+1, rows[i])      if i     <len(rows) else "" for i in range(0,5)]
    col2=[fmt(i+6, rows[i+5])    if i+5   <len(rows) else "" for i in range(0,5)]
    col3=[fmt(i+11,rows[i+10])   if i+10  <len(rows) else "" for i in range(0,5)]
    for a,b,c in zip(col1,col2,col3):
        out.append(f"{a:<8}{b:<8}{c}")
    out.append("</pre>")
    return "\n".join(out)

```

### bot_runner.py  
Taille: 5 KB  |  MàJ: 2025-09-19 23:11:05  |  SHA256: 890abf61436093b9

```py
import os, json
from pathlib import Path
from datetime import datetime as dt
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes
from tools.trade_state import promote_signals_to_positions, reconcile_with_ccxt, load_all

ROOT = Path("/opt/scalp"); DATA = ROOT / "data"
TOKEN   = os.getenv("TELEGRAM_TOKEN", "PLACE_TOKEN")
CHAT_ID = int(os.getenv("TELEGRAM_CHAT_ID", "7552287774"))

def _fmt_time(): return dt.utcnow().strftime("%H:%M")
def _replyable(update): return update and update.message and update.effective_chat and (CHAT_ID==0 or update.effective_chat.id==CHAT_ID)

async def status(u:Update, c:ContextTypes.DEFAULT_TYPE):
    if not _replyable(u): return
    await u.message.reply_text("active")

async def heat(u:Update, c:ContextTypes.DEFAULT_TYPE):
    if not _replyable(u): return
    f = DATA/"s_history"/"heatmap.json"
    if not f.exists(): 
        await u.message.reply_text("heatmap: (vide)")
        return
    obj = json.loads(f.read_text()); rows = obj.get("rows",[])
    lines=[]
    for r in rows:
        s = r.get("sym","").replace("USDT:USDT","")
        vals = r.get("S",[])  # S60,S30,S15, now
        four = [f"{int(round(x)):>+3}" for x in (vals[-4:] if len(vals)>=4 else vals)]
        lines.append(f"{s:5}  {' '.join(four)}")
    msg = "Heatmap "+_fmt_time()+"\n" + "\n".join(lines)
    await u.message.reply_text(msg)

async def top(u:Update, c:ContextTypes.DEFAULT_TYPE):
    if not _replyable(u): return
    f = DATA/"top.json"
    if not f.exists(): 
        await u.message.reply_text("top: (vide)")
        return
    rows = json.loads(f.read_text()).get("scored",[])[:15]
    names = [x.get("symbol","").replace("/USDT:USDT","") for x in rows]
    chunks=[names[i:i+3] for i in range(0,len(names),3)]
    lines=["  ".join([f"{n:6}" for n in ch]) for ch in chunks]
    await u.message.reply_text("Top (vol×vola) "+_fmt_time()+"\n"+"\n".join(lines))

def _fmt_money(x): 
    try: return f"{float(x):+.2f}$"
    except: return str(x)

async def signals(u:Update, c:ContextTypes.DEFAULT_TYPE):
    if not _replyable(u): return
    sigs, _, _ = load_all()
    if not sigs: await u.message.reply_text("signals: (0)"); return
    lines=[]
    for s in sigs[:15]:
        sym = s.get("sym","").replace("USDTUSDT","USDT").replace("USDT:USDT","")
        lines.append(f"{sym:10} {s.get('side',''):5} @ {s.get('px')}")
    await u.message.reply_text("Signals "+_fmt_time()+"\n"+"\n".join(lines))

async def positions(u:Update, c:ContextTypes.DEFAULT_TYPE):
    if not _replyable(u): return
    _, pos, _ = load_all()
    if not pos: await u.message.reply_text("positions: (0)"); return
    lines=[]
    for p in pos[:20]:
        sym=p.get("sym",""); side=p.get("side","")
        lines.append(f"{sym:12} {side:5} {p.get('qty',0):.3f} @ {p.get('entry_px')}")
    await u.message.reply_text("Positions "+_fmt_time()+"\n"+"\n".join(lines))

async def history(u:Update, c:ContextTypes.DEFAULT_TYPE):
    if not _replyable(u): return
    _, _, hist = load_all()
    if not hist: await u.message.reply_text("history: (0)"); return
    last = hist[-10:][::-1]
    lines=[f"{h.get('sym',''):10} {_fmt_money(h.get('pnl',0))}" for h in last]
    await u.message.reply_text("History "+_fmt_time()+"\n"+"\n".join(lines))

def _bitget_fetcher():
    key=os.getenv("BITGET_API_KEY"); sec=os.getenv("BITGET_API_SECRET"); ph=os.getenv("BITGET_PASSPHRASE")
    if not (key and sec and ph): return None
    try:
        import ccxt
        ex = ccxt.bitget({"apiKey":key,"secret":sec,"password":ph,"options":{"defaultType":"swap"}})
        ex.load_markets()
        def fetch(sym):
            m = sym.replace("USDT:USDT","/USDT:USDT").replace("USDTUSDT","/USDT:USDT")
            m = m if "/" in m else sym
            # size: via fetchPositions/positions risk; fallback ticker last
            last = ex.fetch_ticker(sym.replace("USDT:USDT","/USDT:USDT"))["last"]
            size = 0.0
            try:
                for p in ex.fetch_positions([sym.replace("USDT:USDT","/USDT:USDT")]):
                    if p.get("symbol")==sym.replace("USDT:USDT","/USDT:USDT"):
                        size = float(p.get("contracts") or p.get("contractsSize") or 0)
            except: pass
            return {"last": float(last), "size": float(size)}
        return fetch
    except Exception:
        return None

async def sync(u:Update, c:ContextTypes.DEFAULT_TYPE):
    if not _replyable(u): return
    added = promote_signals_to_positions(auto_exec=True, max_new=10)
    fetch = _bitget_fetcher()
    res = reconcile_with_ccxt(fetch)
    await u.message.reply_text(f"sync: +{added} promoted, closed={res['closed']}, open={res['open']}")

def main():
    app = ApplicationBuilder().token(TOKEN).build()
    app.add_handler(CommandHandler("status",   status))
    app.add_handler(CommandHandler("heat",     heat))
    app.add_handler(CommandHandler("top",      top))
    app.add_handler(CommandHandler("signals",  signals))
    app.add_handler(CommandHandler("positions",positions))
    app.add_handler(CommandHandler("history",  history))
    app.add_handler(CommandHandler("sync",     sync))
    app.run_polling(close_loop=False)

if __name__ == "__main__":
    main()

```

### bumppush.py  
Taille: 15 KB  |  MàJ: 2025-09-20 08:34:01  |  SHA256: c2471b84c03ed917

```py
from __future__ import annotations
import os
import sys
import stat
import io
import re
import json
import tarfile
import hashlib
import subprocess
from datetime import datetime
from pathlib import Path
from typing import Iterable, Tuple, Dict, Optional

# ---------- Configuration par défaut ----------
ROOT = Path.cwd()
NOW = datetime.now().strftime("%Y%m%d-%H%M%S")
OUT_DIR = ROOT / "project_dump"
OUT_DIR.mkdir(exist_ok=True)
TREE_TXT = OUT_DIR / f"tree-{NOW}.txt"
DUMP_MD = OUT_DIR / f"code_dump-{NOW}.md"
SLIM_DIR = OUT_DIR / "slim"
SLIM_DIR.mkdir(exist_ok=True)
ARCHIVE = OUT_DIR / f"dump_bundle-{NOW}.tar.gz"

# Seuils et extensions
MAX_INLINE_BYTES = 400_000        # taille max d’un fichier inclus en entier dans le dump
TRUNCATE_TARGET = 80_000          # si > MAX_INLINE_BYTES et texte, tronquer à cette taille
LARGE_FILE_BYTES = 5_000_000      # seuil pour fabriquer une copie "slim" avant push
TEXT_EXT = {
    ".py",".pyi",".pyx",".pxd",".pxi",".pyw",
    ".md",".rst",".txt",".toml",".ini",".cfg",".conf",".json",".yml",".yaml",
    ".gitignore",".gitattributes",".editorconfig",".env.example",
    ".cfg",".in",".pip",".requirements",".dockerfile",".sh",".bat",".ps1",
    ".html",".css",".js",".ts",".jsx",".tsx",
    ".cfg",".properties",".service",".desktop"
}
CODE_FIRST_EXT = {".py",".toml",".ini",".cfg",".conf",".json",".yml",".yaml",".md",".sh"}
NOTEBOOK_EXT = {".ipynb"}

# Motifs d’exclusion
EXCLUDED_DIRS = {
    ".git",".github",".venv","venv","env","ENV","dist","build","site-packages",
    "__pycache__",".mypy_cache",".pytest_cache",".ruff_cache",".idea",".vscode",
    ".tox",".nox",".cache",".egg-info",".DS_Store","node_modules","coverage",
    "data","datasets","output","outputs","logs","log","tmp","temp"
}
EXCLUDED_FILE_PATTERNS = [
    r".*\.log$", r".*\.csv$", r".*\.tsv$", r".*\.parquet$", r".*\.feather$",
    r".*\.npy$", r".*\.npz$", r".*\.pkl$", r".*\.pickle$", r".*\.joblib$",
    r".*\.h5$", r".*\.hdf5$", r".*\.pt$", r".*\.onnx$", r".*\.tflite$",
    r".*\.pdf$", r".*\.png$", r".*\.jpg$", r".*\.jpeg$", r".*\.gif$", r".*\.svg$",
    r".*\.ico$", r".*\.mp4$", r".*\.mp3$", r".*\.wav$", r".*\.flac$",
    r".*\.zip$", r".*\.tar$", r".*\.tar\.gz$", r".*\.7z$", r".*\.rar$",
    r"^\.",  # fichiers cachés
]
EXCL_FILE_RE = [re.compile(p, re.IGNORECASE) for p in EXCLUDED_FILE_PATTERNS]

# ---------- Utilitaires ----------
def is_hidden(path: Path) -> bool:
    name = path.name
    if name.startswith("."):
        return True
    try:
        if os.name == "nt":
            import ctypes
            attrs = ctypes.windll.kernel32.GetFileAttributesW(str(path))
            return bool(attrs & 2)
        else:
            return False
    except Exception:
        return False

def should_exclude(path: Path) -> bool:
    if any(part in EXCLUDED_DIRS for part in path.parts):
        return True
    name = path.name
    for rx in EXCL_FILE_RE:
        if rx.match(name):
            return True
    return False

def is_textual(p: Path) -> bool:
    if p.suffix.lower() in TEXT_EXT or p.suffix.lower() in NOTEBOOK_EXT:
        return True
    try:
        with open(p, "rb") as f:
            chunk = f.read(1024)
        if b"\x00" in chunk:
            return False
        # Heuristique simple
        text_chars = bytearray({7,8,9,10,12,13,27} | set(range(0x20,0x100)))
        return all(c in text_chars for c in chunk)
    except Exception:
        return False

def human(n: int) -> str:
    for unit in ["B","KB","MB","GB","TB"]:
        if n < 1024:
            return f"{n:.0f} {unit}"
        n /= 1024
    return f"{n:.0f} PB"

def rel(p: Path) -> str:
    try:
        return str(p.relative_to(ROOT))
    except Exception:
        return str(p)

def file_mtime(p: Path) -> str:
    try:
        ts = p.stat().st_mtime
        return datetime.fromtimestamp(ts).strftime("%Y-%m-%d %H:%M:%S")
    except Exception:
        return "NA"

def sha256sum(p: Path) -> str:
    h = hashlib.sha256()
    with open(p, "rb") as f:
        for chunk in iter(lambda: f.read(8192), b""):
            h.update(chunk)
    return h.hexdigest()[:16]

def load_env_file(dotenv_path: Path) -> Dict[str,str]:
    env = {}
    if not dotenv_path.exists():
        return env
    for line in dotenv_path.read_text(encoding="utf-8", errors="ignore").splitlines():
        line = line.strip()
        if not line or line.startswith("#"):
            continue
        if "=" not in line:
            continue
        k,v = line.split("=",1)
        env[k.strip()] = v.strip().strip('"').strip("'")
    return env

# ---------- Arborescence ----------
def build_tree(root: Path) -> Tuple[str, list[Path]]:
    lines = []
    kept_files: list[Path] = []
    for dirpath, dirnames, filenames in os.walk(root):
        dirpath = Path(dirpath)
        # Filtrer dossiers sur place
        dirnames[:] = [d for d in dirnames
                       if d not in EXCLUDED_DIRS and not d.startswith(".")]
        # Entrée dossier
        if dirpath == root:
            prefix = "."
        else:
            prefix = rel(dirpath)
        lines.append(f"[{prefix}]")
        # Fichiers triés par nom
        for fn in sorted(filenames):
            p = dirpath / fn
            if is_hidden(p) or should_exclude(p):
                continue
            try:
                st = p.stat()
                size = st.st_size
                mtime = file_mtime(p)
                lines.append(f"  {fn}  | {human(size):>8} | {mtime}")
                kept_files.append(p)
            except Exception:
                continue
    return "\n".join(lines), kept_files

# ---------- Dump de code ----------
def read_text_safely(p: Path, max_bytes: int) -> Tuple[str,bool]:
    size = p.stat().st_size
    truncated = False
    if size <= max_bytes:
        return p.read_text(encoding="utf-8", errors="replace"), False
    # Fichier large
    truncated = True
    with open(p, "rb") as f:
        data = f.read(TRUNCATE_TARGET)
    return data.decode("utf-8", errors="replace") + "\n\n# [TRONQUÉ]\n", truncated

def strip_notebook_outputs(data: dict) -> dict:
    nb = dict(data)  # shallow copy
    cells = nb.get("cells", [])
    for c in cells:
        if c.get("cell_type") == "code":
            c["outputs"] = []
            c["execution_count"] = None
    md = nb.get("metadata", {})
    for k in list(md.keys()):
        if k.lower() in {"widgets","language_info","kernelspec","colab"}:
            md.pop(k, None)
    nb["metadata"] = md
    nb["cells"] = cells
    return nb

def dump_code(files: Iterable[Path]) -> None:
    # Ordonner: code d’abord
    def key(p: Path):
        ext = p.suffix.lower()
        return (0 if ext in CODE_FIRST_EXT or ext in NOTEBOOK_EXT else 1, rel(p).lower())

    files_sorted = sorted(files, key=key)

    with open(DUMP_MD, "w", encoding="utf-8") as out:
        out.write(f"# DUMP DE PROJET — {NOW}\n\n")
        out.write("## Arborescence filtrée\n\n")
        out.write("Voir `tree` ci-dessous.\n\n")
        out.write("## Détails de code\n\n")
        for p in files_sorted:
            try:
                ext = p.suffix.lower()
                size = p.stat().st_size
                mtime = file_mtime(p)
                header = f"### {rel(p)}  \nTaille: {human(size)}  |  MàJ: {mtime}  |  SHA256: {sha256sum(p)}\n\n"
                out.write(header)
                if ext in NOTEBOOK_EXT:
                    try:
                        data = json.loads(p.read_text(encoding="utf-8", errors="replace"))
                        slim = strip_notebook_outputs(data)
                        text = json.dumps(slim, ensure_ascii=False, indent=2)
                        if len(text.encode("utf-8")) > MAX_INLINE_BYTES:
                            # tronquer JSON
                            text = text[:TRUNCATE_TARGET].rstrip() + "\n...\n# [TRONQUÉ]\n"
                            truncated = True
                        else:
                            truncated = False
                        out.write("```json\n")
                        out.write(text)
                        out.write("\n```\n\n")
                        if truncated:
                            out.write("> Note: Notebook tronqué pour la lisibilité.\n\n")
                    except Exception:
                        # fallback binaire
                        out.write("_Notebook non lisible, contenu ignoré._\n\n")
                elif is_textual(p):
                    text, truncated = read_text_safely(p, MAX_INLINE_BYTES)
                    fence = "```" + (ext[1:] if ext.startswith(".") else "")
                    out.write(fence + "\n")
                    out.write(text)
                    out.write("\n```\n\n")
                    if truncated:
                        out.write("> Note: Fichier tronqué pour rester sous les limites.\n\n")
                else:
                    out.write("_Binaire ignoré._\n\n")
            except Exception as e:
                out.write(f"_Erreur lecture: {e}_\n\n")

def write_tree_file(tree_txt: str) -> None:
    with open(TREE_TXT, "w", encoding="utf-8") as f:
        f.write(f"# TREE — {NOW}\n\n")
        f.write("Chemins relatifs à la racine du repo.\n\n")
        f.write(tree_txt)
        f.write("\n")

# ---------- Slim copies pour gros fichiers ----------
def make_slim_copy(src: Path, dst_root: Path) -> Optional[Path]:
    try:
        relp = Path(rel(src))
        outp = dst_root / relp
        outp.parent.mkdir(parents=True, exist_ok=True)
        if src.suffix.lower() in NOTEBOOK_EXT:
            data = json.loads(src.read_text(encoding="utf-8", errors="replace"))
            slim = strip_notebook_outputs(data)
            outp.write_text(json.dumps(slim, ensure_ascii=False, separators=(",",":")), encoding="utf-8")
            return outp
        if is_textual(src):
            # Tronquer texte long
            with open(src, "rb") as f:
                chunk = f.read(TRUNCATE_TARGET)
            outp.write_bytes(chunk)
            return outp
        # Binaire: on ignore
        return None
    except Exception:
        return None

def prepare_slim_artifacts(files: Iterable[Path]) -> list[Path]:
    produced = []
    for p in files:
        try:
            if p.stat().st_size >= LARGE_FILE_BYTES:
                slim = make_slim_copy(p, SLIM_DIR)
                if slim:
                    produced.append(slim)
        except FileNotFoundError:
            continue
    return produced

# ---------- Git helpers ----------
def run(cmd: list[str], env: Optional[Dict[str,str]]=None, check: bool=True) -> subprocess.CompletedProcess:
    return subprocess.run(cmd, cwd=str(ROOT), env=env or os.environ.copy(),
                          stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, check=check)

def detect_current_branch() -> str:
    try:
        cp = run(["git","rev-parse","--abbrev-ref","HEAD"])
        return cp.stdout.strip()
    except Exception:
        return "main"

def ensure_git_repo() -> None:
    try:
        run(["git","rev-parse","--is-inside-work-tree"])
    except Exception:
        print("Erreur: ce dossier n’est pas un dépôt Git.", file=sys.stderr)
        sys.exit(2)

def git_setup_env_from_scalp(envfile: Path = Path("/etc/scalp.env")) -> Dict[str,str]:
    env = os.environ.copy()
    parsed = load_env_file(envfile)
    env.update(parsed)
    # Support variables communes
    ssh_key = parsed.get("SSH_KEY_PATH") or parsed.get("GIT_SSH_KEY") or ""
    token = parsed.get("GH_TOKEN") or parsed.get("GITHUB_TOKEN") or ""
    if ssh_key:
        env["GIT_SSH_COMMAND"] = f"ssh -i {ssh_key} -o IdentitiesOnly=yes -o StrictHostKeyChecking=no"
    # Auteur si fournis
    if parsed.get("GIT_AUTHOR_NAME"):
        env["GIT_AUTHOR_NAME"] = parsed["GIT_AUTHOR_NAME"]
        env["GIT_COMMITTER_NAME"] = parsed["GIT_AUTHOR_NAME"]
    if parsed.get("GIT_AUTHOR_EMAIL"):
        env["GIT_AUTHOR_EMAIL"] = parsed["GIT_AUTHOR_EMAIL"]
        env["GIT_COMMITTER_EMAIL"] = parsed["GIT_AUTHOR_EMAIL"]
    # Si token et remote https, on le place dans l’URL au vol
    try:
        remote = parsed.get("GIT_REMOTE","origin")
        cp = run(["git","remote","get-url", remote], check=False)
        url = cp.stdout.strip()
        if token and url.startswith("https://") and "@" not in url:
            # https://github.com/user/repo.git -> https://TOKEN@github.com/user/repo.git
            parts = url.split("https://",1)[1]
            auth_url = "https://" + token + "@" + parts
            run(["git","remote","set-url", remote, auth_url], env=env, check=False)
    except Exception:
        pass
    return env

def git_commit_and_push(env: Dict[str,str], message: str) -> None:
    branch = detect_current_branch()
    dump_branch = f"dump/{NOW}"
    # créer branche de dump pour isoler
    try:
        run(["git","checkout","-b", dump_branch], env=env)
    except subprocess.CalledProcessError:
        run(["git","checkout", dump_branch], env=env, check=False)
    # add artefacts
    run(["git","add", rel(OUT_DIR)], env=env)
    # facultatif: ajouter copies slim
    if SLIM_DIR.exists():
        run(["git","add", rel(SLIM_DIR)], env=env, check=False)
    # Commit
    run(["git","commit","-m", message], env=env, check=False)
    # Push
    remote = os.environ.get("GIT_REMOTE") or "origin"
    run(["git","push","-f", remote, dump_branch], env=env, check=False)
    # revenir sur la branche d’origine
    run(["git","checkout", branch], env=env, check=False)

# ---------- Archive ----------
def build_archive(paths: Iterable[Path]) -> None:
    with tarfile.open(ARCHIVE, "w:gz") as tar:
        for p in paths:
            tar.add(p, arcname=p.name)

# ---------- Main ----------
def main() -> None:
    ensure_git_repo()
    tree_txt, kept_files = build_tree(ROOT)
    write_tree_file(tree_txt)
    dump_code(kept_files)
    # écrire un sommaire court en tête du dump
    with open(DUMP_MD, "r+", encoding="utf-8") as f:
        content = f.read()
        header = [
            f"# DUMP DE PROJET — {NOW}",
            "",
            f"- Racine: `{ROOT}`",
            f"- Fichier d’arborescence: `{TREE_TXT.name}`",
            f"- Copies slim: `{rel(SLIM_DIR)}`",
            "",
            "## Arborescence filtrée",
            "```text",
            tree_txt,
            "```",
            "",
            "## Détails de code",
            ""
        ]
        f.seek(0)
        f.write("\n".join(header) + content.split("## Détails de code",1)[-1])
        f.truncate()

    # Copies slim pour gros fichiers
    slimmed = prepare_slim_artifacts(kept_files)
    # Archive bundle pratique
    build_archive([TREE_TXT, DUMP_MD])

    # Git push avec /etc/scalp.env si disponible
    env = git_setup_env_from_scalp(Path("/etc/scalp.env"))
    # Marquer les fichiers générés pour Git
    msg = f"dump: arborescence et code {NOW} ({len(kept_files)} fichiers, {len(slimmed)} slim)"
    git_commit_and_push(env, msg)

    print("OK")
    print(f"- Arborescence: {TREE_TXT}")
    print(f"- Dump code:   {DUMP_MD}")
    print(f"- Slim dir:    {SLIM_DIR} ({len(slimmed)} fichiers)")
    print(f"- Archive:     {ARCHIVE}")

if __name__ == "__main__":
    main()

```

### execution/bitget_client.py  
Taille: 752 B  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 47b674b021fb7b32

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import os, ccxt

def get_mode()->str:
    m = os.getenv("EXEC_MODE","PAPER").upper()
    return "REAL" if m in ("REAL","LIVE") else "PAPER"

def client_or_none():
    if get_mode()=="PAPER": return None
    api, sec, pwd = os.getenv("BITGET_API_KEY"), os.getenv("BITGET_API_SECRET"), os.getenv("BITGET_PASSPHRASE")
    if not (api and sec and pwd): raise RuntimeError("EENV: clés Bitget manquantes")
    ex = ccxt.bitget({
        "apiKey": api, "secret": sec, "password": pwd,
        "enableRateLimit": True,
        "options": {"defaultType":"swap"},
    })
    ex.load_markets()
    return ex

def symbol_to_bitget(sym:str)->str:
    return f"{sym.upper().split('/')[0]}/USDT:USDT"

```

### execution/executor.py  
Taille: 4 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 914c478c3146997a

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json, os, time, uuid, shutil
from pathlib import Path
from typing import Dict, Any
from .bitget_client import client_or_none, symbol_to_bitget, get_mode
from .price_feed import last_price
from .storage import append_order, load_positions, save_positions

SIGNALS_DIR = Path("/opt/scalp/data/signals")
PROC_DIR    = SIGNALS_DIR/"processed"
LOGF        = Path("/opt/scalp/data/logs/executor.log")

FEE_RATE = float(os.getenv("FEE_RATE", "0.0006"))   # 6 bps estimé par côté
SLIPPAGE = float(os.getenv("EXE_SLIPPAGE", "0.0005"))

def log(msg:str):
    LOGF.parent.mkdir(parents=True, exist_ok=True)
    with LOGF.open("a") as f:
        f.write(time.strftime("%Y-%m-%d %H:%M:%S ", time.gmtime())+msg+"\n")

def _fill_price(sym:str, side:str, wanted:float|None)->float|None:
    p = last_price(sym)
    if p is None: return None
    return p*(1+SLIPPAGE if side=="long" else 1-SLIPPAGE)

def exec_paper(sig:Dict[str,Any])->Dict[str,Any]:
    sym=sig["sym"]; side=sig["side"]; qty=float(sig.get("size",0.0))
    px=_fill_price(sym, side, sig.get("price_entry"))
    if px is None or qty<=0:
        raise RuntimeError("EPRICE: prix ou taille indisponible")
    order_id=str(uuid.uuid4())
    filled_qty=qty; filled_price=px
    fees = FEE_RATE * filled_qty * filled_price
    return {"mode":"PAPER","order_id":order_id,"status":"filled","price":filled_price,"qty":filled_qty,"fee":fees}

def exec_real(sig:Dict[str,Any])->Dict[str,Any]:
    ex=client_or_none()
    sym_mkt=symbol_to_bitget(sig["sym"])
    side=sig["side"]
    qty=float(sig.get("size",0.0))
    if qty<=0: raise RuntimeError("ESIZE: taille nulle")
    # market order
    ord_side="buy" if side=="long" else "sell"
    o=ex.create_order(sym_mkt, "market", ord_side, qty)
    # Bitget renvoie average fill price / filled size si dispo
    px=float(o.get("average") or o.get("price") or 0.0)
    qf=float(o.get("filled") or o.get("amount") or qty)
    fee=float(o.get("fee") or 0.0)
    return {"mode":"REAL","order_id":o.get("id","?"),"status":o.get("status","filled"),"price":px,"qty":qf,"fee":fee}

def create_position(sig:Dict[str,Any], exe:Dict[str,Any])->Dict[str,Any]:
    now=int(time.time())
    return {
        "id": exe["order_id"],
        "sym": sig["sym"],
        "side": sig["side"],           # long/short
        "entry_price": exe["price"],
        "qty": exe["qty"],
        "fee_open": exe.get("fee",0.0),
        "sl": float(sig.get("sl",0.0)),
        "tp": float(sig.get("tp",0.0)),
        "opened_at": now,
        "entry_set": sig.get("entry_set"),
        "mode": exe.get("mode"),
        "status":"open",
        "trail_started": False,
        "trail_ref": None
    }

def process_one_file(p:Path):
    try:
        sig=json.loads(p.read_text())
        # attentes: sym, side, price_entry, sl, tp, size, entry_set
        if not all(k in sig for k in ("sym","side","sl","tp","size","entry_set")):
            raise RuntimeError("EBAD: signal incomplet")
        mode=get_mode()
        exe = exec_real(sig) if mode=="REAL" else exec_paper(sig)
        pos = create_position(sig, exe)
        # append order + add to positions
        append_order({
            "t": int(time.time()), "mode":exe["mode"], "order_id":exe["order_id"], "sym":sig["sym"],
            "side":sig["side"], "price":exe["price"], "qty":exe["qty"], "fee":exe.get("fee",0.0),
            "entry_set": sig.get("entry_set")
        })
        cur=load_positions(); cur.append(pos); save_positions(cur)
        # archive signal
        PROC_DIR.mkdir(parents=True, exist_ok=True)
        shutil.move(str(p), PROC_DIR/f"{int(time.time())}_{p.name}")
        log(f"EXEC {mode} {sig['sym']} {sig['side']} px={exe['price']:.4f} qty={exe['qty']:.6f}")
    except Exception as e:
        log(f"ERR processing {p.name}: {e}")

def main():
    for p in sorted(SIGNALS_DIR.glob("*.json")):
        if p.name=="signals.json": continue
        process_one_file(p)

if __name__=="__main__":
    main()

```

### execution/monitor.py  
Taille: 3 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: f592784cd8ab1c3a

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import time, os
from pathlib import Path
from typing import List, Dict, Any
from .price_feed import last_price
from .storage import load_positions, save_positions, append_history, append_order
from .bitget_client import client_or_none, symbol_to_bitget, get_mode

LOGF = Path("/opt/scalp/data/logs/monitor.log")
FEE_RATE = float(os.getenv("FEE_RATE", "0.0006"))

def log(msg:str):
    LOGF.parent.mkdir(parents=True, exist_ok=True)
    LOGF.open("a").write(time.strftime("%Y-%m-%d %H:%M:%S ", time.gmtime())+msg+"\n")

def close_position(pos:Dict[str,Any], reason:str, price:float):
    mode=get_mode()
    qty=pos["qty"]
    sym=pos["sym"]
    side_close = "sell" if pos["side"]=="long" else "buy"
    fee_close=0.0
    if mode=="REAL":
        try:
            ex=client_or_none()
            o=ex.create_order(symbol_to_bitget(sym), "market", side_close, qty)
            fee_close=float(o.get("fee") or 0.0)
            price=float(o.get("average") or o.get("price") or price)
        except Exception as e:
            log(f"ERR close {sym}: {e}")
    else:
        fee_close = FEE_RATE * qty * price

    # realized pnl
    signed = 1.0 if pos["side"]=="long" else -1.0
    pnl = (price - pos["entry_price"]) * qty * signed - (pos["fee_open"] + fee_close)

    # history append
    append_history({
        "id": pos["id"], "sym": sym, "side": pos["side"], "entry_price": pos["entry_price"],
        "exit_price": price, "qty": qty, "opened_at": pos["opened_at"], "closed_at": int(time.time()),
        "reason": reason, "fee_open": pos["fee_open"], "fee_close": fee_close, "pnl": pnl,
        "entry_set": pos.get("entry_set"), "mode": mode
    })

    append_order({"t": int(time.time()), "mode":mode, "order_id":pos["id"]+"-close", "sym":sym,
                  "side":side_close, "price":price, "qty":qty, "fee":fee_close, "close_reason":reason})

def monitor_once():
    arr=load_positions()
    out=[]
    for pos in arr:
        if pos.get("status")!="open":
            out.append(pos); continue
        sym=pos["sym"]; cur=last_price(sym)
        if cur is None:
            out.append(pos); continue
        # PnL live
        signed = 1.0 if pos["side"]=="long" else -1.0
        upnl = (cur - pos["entry_price"]) * pos["qty"] * signed
        pos["pnl_unreal"] = upnl
        pos["last_price"] = cur
        # SL/TP check
        sl=float(pos.get("sl") or 0.0); tp=float(pos.get("tp") or 0.0)
        if pos["side"]=="long":
            if sl>0 and cur<=sl:
                close_position(pos, "SL", cur); pos["status"]="closed"
            elif tp>0 and cur>=tp:
                close_position(pos, "TP", cur); pos["status"]="closed"
        else:
            if sl>0 and cur>=sl:
                close_position(pos, "SL", cur); pos["status"]="closed"
            elif tp>0 and cur<=tp:
                close_position(pos, "TP", cur); pos["status"]="closed"
        # trailing simple: active après +1xATR, si trail_ref absent on le fixe à entry_price
        # (ATR exact n'est pas stocké ici; à perfectionner plus tard)
        if pos["status"]=="open":
            out.append(pos)
    save_positions(out)

if __name__=="__main__":
    monitor_once()

```

### execution/price_feed.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 7563f13eac7f6b43

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import csv, os
from pathlib import Path
from typing import Optional
from .bitget_client import client_or_none, symbol_to_bitget, get_mode

CAND = Path("/opt/scalp/data/candles/1m")

def last_close_from_csv(sym:str)->Optional[float]:
    f=CAND/f"{sym}.csv"
    if not f.exists(): return None
    try:
        last=None
        with f.open() as fh:
            r=csv.reader(fh)
            header=next(r, None)
            # si header, détecte
            try:
                int(header[0]); row=header
                last=row
            except Exception:
                pass
            for row in r:
                last=row
        if not last: return None
        c=float(last[4])  # ts,o,h,l,c,v
        return c
    except Exception:
        return None

def last_price(sym:str)->Optional[float]:
    # 1) CSV 1m
    p = last_close_from_csv(sym)
    if p is not None: return p
    # 2) Ticker ccxt si REAL
    if get_mode()=="REAL":
        try:
            ex=client_or_none()
            t=ex.fetch_ticker(symbol_to_bitget(sym))
            return float(t["last"])
        except Exception:
            return None
    return None

```

### execution/storage.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 13ee75ffc09c907e

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json, os, time
from pathlib import Path
from typing import Dict, Any, List

BASE=Path("/opt/scalp/data")
ORDERS = BASE/"orders/orders.json"
POSIT  = BASE/"positions/positions.json"
HIST   = BASE/"history/history.json"

def _read(p:Path, default):
    try: return json.loads(p.read_text())
    except Exception: return default

def _write_atomic(p:Path, obj):
    tmp=p.with_suffix(".tmp")
    tmp.write_text(json.dumps(obj, ensure_ascii=False, separators=(",",":")))
    os.replace(tmp, p)

def append_order(o:Dict[str,Any]):
    d=_read(ORDERS, {"orders":[]})
    arr=d.get("orders",[])
    arr.append(o)
    d["orders"]=arr[-5000:]
    _write_atomic(ORDERS,d)

def load_positions()->List[Dict[str,Any]]:
    d=_read(POSIT, {"positions":[]})
    arr=d.get("positions",[])
    return arr if isinstance(arr,list) else []

def save_positions(arr:List[Dict[str,Any]]):
    _write_atomic(POSIT, {"positions":arr})

def append_history(h:Dict[str,Any]):
    d=_read(HIST, {"trades":[]})
    arr=d.get("trades",[])
    arr.append(h)
    d["trades"]=arr[-10000:]
    _write_atomic(HIST,d)

```

### lib/errors.py  
Taille: 266 B  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 560e715ee3a3163e

```py
CODES={"E01":"env manquant","E02":"chat non autorisé","E10":"fichier absent","E11":"json invalide","E12":"fonction indisponible"}
def err(code,msg="",ctx=""):
    s=f"{code}: {CODES.get(code,'?')}"
    if msg: s+=" • "+msg
    if ctx: s+=" • "+ctx
    return s

```

### project_dump/code_dump-20250920-083747.md  
Taille: 226 KB  |  MàJ: 2025-09-20 08:37:47  |  SHA256: f5176ce891df4148

```md
# DUMP DE PROJET — 20250920-083747

- Racine: `/opt/scalp`
- Fichier d’arborescence: `tree-20250920-083747.txt`
- Copies slim: `project_dump/slim`

## Arborescence filtrée
```text
[.]
  bot_runner.py  |     5 KB | 2025-09-19 23:11:05
  bumppush.py  |    15 KB | 2025-09-20 08:34:01
  requirements.txt  |     52 B | 2025-09-17 06:54:13
[execution]
  bitget_client.py  |    752 B | 2025-09-19 18:25:51
  executor.py  |     4 KB | 2025-09-19 18:25:51
  monitor.py  |     3 KB | 2025-09-19 18:25:51
  price_feed.py  |     1 KB | 2025-09-19 18:25:51
  storage.py  |     1 KB | 2025-09-19 18:25:51
[services]
  agg_1m_to_3m.py  |     2 KB | 2025-09-19 18:25:51
  analyze_A.py  |     4 KB | 2025-09-19 18:25:51
  analyze_B.py  |     1 KB | 2025-09-19 18:25:51
  analyze_pipeline.py  |    182 B | 2025-09-19 18:25:51
  b_triggers.py  |     4 KB | 2025-09-19 18:25:51
  build_heatmap_softmax.py  |     1 KB | 2025-09-19 18:25:51
  build_softmap.py  |     2 KB | 2025-09-19 19:44:04
  exec_signals.py  |     4 KB | 2025-09-19 18:25:51
  fetch_1m_safe.py  |    946 B | 2025-09-19 18:25:51
  fetch_ohlcv.py  |     1 KB | 2025-09-19 18:25:51
  ohlcv_1m_cli.py  |     3 KB | 2025-09-19 18:25:51
  ohlcv_bitget_batch.py  |     3 KB | 2025-09-19 18:25:51
  ohlcv_bitget_cli.py  |     4 KB | 2025-09-19 18:25:51
  on_new_signals.py  |     2 KB | 2025-09-19 23:13:47
  paper_trade.py  |    10 KB | 2025-09-19 18:25:51
  positions_watcher.py  |     4 KB | 2025-09-19 18:25:51
  promote_min.py  |     1 KB | 2025-09-19 23:16:55
  run_ohlcv_batch.sh  |    257 B | 2025-09-19 18:26:16
  signals_B.py  |     8 KB | 2025-09-19 18:25:51
  top_bitget.py  |     1 KB | 2025-09-19 18:25:51
[lib]
  errors.py  |    266 B | 2025-09-19 18:25:51
[tools]
  agg_tf3.py  |     1 KB | 2025-09-19 20:41:47
  bootstrap_ohlcv_bitget.py  |     1 KB | 2025-09-19 18:58:47
  bot_ensure_service.sh  |    472 B | 2025-09-17 20:44:34
  build_top_from_heatmap.py  |    415 B | 2025-09-19 18:26:09
  check_B.sh  |     3 KB | 2025-09-17 12:18:15
  check_deps.py  |    875 B | 2025-09-19 18:26:09
  check_env.py  |    132 B | 2025-09-19 18:26:09
  check_heat.py  |     1 KB | 2025-09-19 18:26:09
  check_ohlcv_1m.py  |     1 KB | 2025-09-19 18:26:09
  diag_B.sh  |    394 B | 2025-09-17 10:59:39
  diag_heat.sh  |     2 KB | 2025-09-17 10:15:20
  diag_heatmap.py  |    589 B | 2025-09-19 18:26:09
  diag_refresh.sh  |     4 KB | 2025-09-16 20:51:48
  diag_systemd_1m.sh  |    970 B | 2025-09-17 15:07:17
  enable_B_watchers.sh  |    190 B | 2025-09-17 11:54:41
  guard_soft.sh  |    576 B | 2025-09-17 07:55:30
  health_heatmap.sh  |    430 B | 2025-09-17 06:54:38
  install_deps.sh  |    207 B | 2025-09-16 17:06:23
  json_view.py  |     2 KB | 2025-09-19 18:26:09
  make_context.py  |    890 B | 2025-09-19 20:41:29
  normalize_json.py  |     1 KB | 2025-09-19 18:26:09
  normalize_positions.py  |    836 B | 2025-09-19 18:26:09
  ohlcv_sync.py  |     3 KB | 2025-09-19 18:26:09
  on_Btop_updated.sh  |    381 B | 2025-09-17 11:54:14
  on_btop_updated.sh  |    392 B | 2025-09-17 10:59:10
  ping_telegram.py  |    907 B | 2025-09-19 18:26:09
  pretty_heat.py  |    983 B | 2025-09-19 20:18:06
  pretty_heat_60_30_15_now.py  |     1 KB | 2025-09-19 22:17:10
  pretty_positions.py  |    403 B | 2025-09-19 22:55:25
  pretty_signals.py  |    905 B | 2025-09-19 22:54:55
  pretty_status.py  |     1 KB | 2025-09-19 20:23:28
  pretty_top.py  |    555 B | 2025-09-19 20:18:18
  pretty_top_names.py  |     1 KB | 2025-09-19 22:46:40
  probe_B.sh  |     2 KB | 2025-09-17 07:58:03
  probe_pipeline.sh  |     2 KB | 2025-09-17 08:09:27
  probe_pipeline_B.sh  |   1015 B | 2025-09-17 08:16:45
  purge_state.sh  |     1 KB | 2025-09-17 17:05:54
  refresh_bot.sh  |    242 B | 2025-09-16 20:04:04
  refresh_pipeline.sh  |    823 B | 2025-09-16 20:54:54
  relaunch_all.sh  |     2 KB | 2025-09-17 11:28:51
  relaunch_clean.sh  |    720 B | 2025-09-17 09:02:44
  repair_and_restart.sh  |     5 KB | 2025-09-16 18:59:28
  reset_top_json.py  |     1 KB | 2025-09-19 18:26:09
  restart_and_preview.sh  |    648 B | 2025-09-17 05:42:28
  rotate_history.sh  |    182 B | 2025-09-18 07:49:29
  run_1m_now.sh  |    638 B | 2025-09-17 11:10:22
  run_B_pipeline_now.sh  |    271 B | 2025-09-17 11:54:34
  select_universe_bitget.py  |     3 KB | 2025-09-19 19:50:21
  set_bot_commands.py  |     2 KB | 2025-09-19 18:26:09
  setup_venv.sh  |     1 KB | 2025-09-17 06:54:13
  telegram_ping.py  |    782 B | 2025-09-19 18:26:09
  test_B.sh  |    381 B | 2025-09-17 10:49:30
  test_exec_flow.sh  |     1 KB | 2025-09-16 17:51:34
  test_heat_source.py  |    484 B | 2025-09-19 18:26:09
  test_ohlcv.py  |    662 B | 2025-09-19 18:26:09
  trade_state.py  |     3 KB | 2025-09-19 23:10:21
  validate_pipeline.sh  |    980 B | 2025-09-17 15:50:11
  view_heatmap.sh  |     89 B | 2025-09-16 18:09:09
  view_history.sh  |     91 B | 2025-09-16 18:09:09
  view_positions.sh  |     96 B | 2025-09-16 18:09:09
  view_signals.sh  |     92 B | 2025-09-16 18:09:09
[bin]
  dump_and_push.sh  |     4 KB | 2025-09-17 05:10:42
  dump_and_reset.sh  |     2 KB | 2025-09-17 05:13:48
[analyze]
  __init__.py  |     29 B | 2025-09-19 18:26:09
  analyze_a_cli.py  |    283 B | 2025-09-19 18:26:09
  b_triggers.py  |    14 KB | 2025-09-19 18:26:09
  indicators_advanced.py  |     4 KB | 2025-09-19 18:26:09
  layer_a.py  |     2 KB | 2025-09-19 18:49:54
  run_triggers_cli.py  |     2 KB | 2025-09-19 20:41:56
[bot]
  __init__.py  |      0 B | 2025-09-19 18:26:09
  _keyboard_patch.py  |    670 B | 2025-09-19 18:26:09
  bot_stdlib.py  |     2 KB | 2025-09-19 18:26:09
  commands_wire.py  |    978 B | 2025-09-19 18:26:09
  env_simple.py  |    469 B | 2025-09-19 18:26:09
  json_util.py  |     1 KB | 2025-09-19 18:26:09
  mod_heatmap.py  |     1 KB | 2025-09-19 18:26:09
  mod_signals.py  |    865 B | 2025-09-19 18:26:09
  mod_top.py  |    503 B | 2025-09-19 18:26:09
  router.py  |     3 KB | 2025-09-19 18:26:09
  singleton.py  |    477 B | 2025-09-19 18:26:09
  views.py  |     2 KB | 2025-09-19 18:26:09
  views_account.py  |    909 B | 2025-09-19 18:26:09
  views_btop.py  |     1 KB | 2025-09-19 18:26:09
  views_heat.py  |     2 KB | 2025-09-19 18:26:09
  views_history.py  |     3 KB | 2025-09-19 18:26:09
  views_menu.py  |    309 B | 2025-09-19 18:26:09
  views_positions.py  |     3 KB | 2025-09-19 18:26:09
  views_signals.py  |    969 B | 2025-09-19 18:26:09
  views_top_patch.py  |     1 KB | 2025-09-19 18:26:09
[bot/lib]
  __init__.py  |      0 B | 2025-09-19 18:26:09
[project_dump]
[project_dump/slim]
```

## Détails de code


### analyze/__init__.py  
Taille: 29 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 0570d97cdf07809b

```py
# package marker for analyze

```

### analyze/analyze_a_cli.py  
Taille: 283 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: f1cdf33341082cf5

```py
#!/opt/scalp/.venv/bin/python
from pathlib import Path
import sys
sys.path.insert(0, "/opt/scalp")  # pour import absolu
from analyze.layer_a import run

def main():
    n = run()
    print(f"[A] wrote {n} files to /opt/scalp/data/analysis/A")

if __name__ == "__main__":
    main()

```

### analyze/b_triggers.py  
Taille: 14 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: af90cb5f893adf07

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import csv, json, math, os, time
from dataclasses import dataclass
from pathlib import Path
from typing import List, Dict, Optional, Tuple

BASE = Path("/opt/scalp/data")
CAND = BASE/"candles"
AN_A = Path("/opt/scalp/data/analysis/A")  # fichiers A/<sym>.json de la couche A
SIGS = Path("/opt/scalp/data/signals")     # on dépose 1 fichier par signal + append global
LOGF = Path("/opt/scalp/data/logs/b_triggers.log")
SIGFILE = BASE/"signals.json"              # append global

# ── Paramétrage
RISK_PCT = float(os.getenv("RISK_PCT", "0.01"))      # 1% par défaut
CAPITAL_USDT = float(os.getenv("CAPITAL_USDT", "1000"))
SLIPPAGE_PCT = float(os.getenv("SLIPPAGE_PCT", "0.0005"))  # 5 bps

# Hystérésis Couche A (déjà appliquée en B état long/short via layer_b.py classique)
# Ici on se contente d'exiger un contexte actif côté A pour déclencher une entrée.
ENTER_BUY  = 0.60
ENTER_SELL = 0.60
HOLD_MIN, HOLD_MAX = 0.40, 0.60

@dataclass
class Candle:
    ts: int; o: float; h: float; l: float; c: float; v: float

def log(msg: str):
    LOGF.parent.mkdir(parents=True, exist_ok=True)
    with LOGF.open("a") as f:
        f.write(time.strftime("%Y-%m-%d %H:%M:%S ", time.gmtime()) + msg + "\n")

# ── Chargements candles: support CSV (chemin /candles/TF/SYM.csv) et JSON (candles/SYM_TF.json)
def load_csv(tf: str, sym: str) -> List[Candle]:
    p = CAND/tf/f"{sym}.csv"
    if not p.exists(): return []
    out: List[Candle] = []
    with p.open() as f:
        r=csv.reader(f)
        # accepte header ou non
        head = next(r, None)
        # si 1ère ligne n'est pas un int timestamp, tente comme première donnée
        def parse_row(row):
            if not row: return None
            try:
                ts=int(row[0]); o,h,l,c,v=map(float,row[1:6]); return Candle(ts,o,h,l,c,v)
            except Exception: return None
        first = parse_row(head)
        if first: out.append(first)
        for row in r:
            x=parse_row(row)
            if x: out.append(x)
    return out

def load_json_pair(sym:str, tf:str) -> List[Candle]:
    p = CAND/f"{sym}_{tf}.json"
    if not p.exists(): return []
    try:
        rows = json.loads(p.read_text())
        if not isinstance(rows, list): return []
        out=[]
        for r in rows:
            if isinstance(r, list) and len(r)>=6:
                out.append(Candle(int(r[0]), float(r[1]), float(r[2]), float(r[3]), float(r[4]), float(r[5])))
        return out
    except Exception:
        return []

def load_candles(sym:str, tf:str) -> List[Candle]:
    # priorité CSV structuré par TF, sinon JSON à plat
    arr = load_csv(tf, sym)
    if arr: return sorted(arr, key=lambda x: x.ts)
    return sorted(load_json_pair(sym, tf), key=lambda x: x.ts)

# ── Agrégation 3m à partir du 1m (par blocs de 3 clôturées)
def aggregate_3m(c1m: List[Candle]) -> List[Candle]:
    out: List[Candle] = []
    if not c1m: return out
    # ignore bougie 1m en cours: on garde uniquement les ts multiples de 60_000 (déjà le cas)
    # regroupe par paquets de 3 consécutifs
    for i in range(0, len(c1m)//3):
        a,b,c = c1m[3*i:3*i+3]
        ts = a.ts
        o = a.o
        h = max(a.h,b.h,c.h)
        l = min(a.l,b.l,c.l)
        cl = c.c
        v = a.v + b.v + c.v
        out.append(Candle(ts,o,h,l,cl,v))
    return out

# ── Indicateurs rapides
def ema(vals: List[float], period:int) -> List[float]:
    if period<=0 or not vals: return []
    k=2/(period+1); out=[vals[0]]; e=vals[0]
    for x in vals[1:]:
        e=k*x+(1-k)*e; out.append(e)
    return out

def rsi(vals: List[float], period:int=7) -> Optional[float]:
    if len(vals) < period+1: return None
    gains=losses=0.0
    for i in range(-period,0):
        ch=vals[i]-vals[i-1]
        gains += max(ch,0.0); losses += max(-ch,0.0)
    if gains==0 and losses==0: return 50.0
    if losses==0: return 100.0
    rs=gains/losses
    return 100.0 - 100.0/(1.0+rs)

def atr(c: List[Candle], period:int=14) -> Optional[float]:
    if len(c) < period+1: return None
    trs=[]
    for i in range(1, len(c)):
        h,l = c[i].h, c[i].l
        pc = c[i-1].c
        trs.append(max(h-l, abs(h-pc), abs(l-pc)))
    return sum(trs[-period:])/period

def sma(vals: List[float], period:int) -> Optional[float]:
    if len(vals) < period: return None
    return sum(vals[-period:])/period

def stdev(vals: List[float], period:int) -> Optional[float]:
    if len(vals) < period: return None
    m = sum(vals[-period:])/period
    var = sum((x-m)**2 for x in vals[-period:]) / period
    return var**0.5

def vwap(c: List[Candle], period:int=20) -> Optional[float]:
    if len(c) < period: return None
    pv=sum((x.h+x.l+x.c)/3.0 * x.v for x in c[-period:])
    vol=sum(x.v for x in c[-period:])
    return pv/vol if vol>0 else None

def macd_hist_slope(vals: List[float], fast=12, slow=26, sig=9) -> Optional[float]:
    if len(vals) < slow+sig+3: return None
    ef=ema(vals, fast); es=ema(vals, slow)
    mac=[a-b for a,b in zip(ef[-len(es):], es)]
    sigl=ema(mac, sig)
    hist = mac[-1]-sigl[-1]
    prev = mac[-2]-sigl[-2]
    return hist - prev  # croissance si >0

def bollinger(c: List[Candle], period:int=20, k:float=2.0) -> Optional[Tuple[float,float,float]]:
    closes=[x.c for x in c]
    ma=sma(closes, period); sd=stdev(closes, period)
    if ma is None or sd is None: return None
    return (ma, ma-k*sd, ma+k*sd)

def keltner(c: List[Candle], ema_p:int=20, mul:float=1.5) -> Optional[Tuple[float,float]]:
    ma = sma([x.c for x in c], ema_p)
    a = atr(c, 10)
    if ma is None or a is None: return None
    return (ma - mul*a, ma + mul*a)

def squeeze_on(c: List[Candle]) -> Optional[bool]:
    bb = bollinger(c, 20, 2.0)
    kel = keltner(c, 20, 1.5)
    if not bb or not kel: return None
    mid, low_bb, up_bb = bb
    low_k, up_k = kel
    # squeeze si BB est à l'intérieur des Keltner
    return (low_bb > low_k) and (up_bb < up_k)

def vol_spike(c: List[Candle], k:float=1.3, look:int=20) -> Optional[bool]:
    if len(c) < look+1: return None
    avg = sum(x.v for x in c[-look-1:-1]) / look
    return c[-1].v >= k*avg

def rsi_divergence(c: List[Candle], period:int=7, look:int=10) -> Optional[str]:
    if len(c) < look+period+2: return None
    closes=[x.c for x in c]
    # pics locaux simples
    last_close=closes[-1]; prev_close=closes[-1-look]
    rsi_last = rsi(closes, period); rsi_prev = rsi(closes[:-look], period)
    if rsi_last is None or rsi_prev is None: return None
    if last_close < prev_close and rsi_last > rsi_prev: return "bull"   # divergence haussière
    if last_close > prev_close and rsi_last < rsi_prev: return "bear"   # divergence baissière
    return None

def candle_reversal(c: List[Candle]) -> Optional[str]:
    if len(c) < 2: return None
    x = c[-1]; prev = c[-2]
    body = abs(x.c - x.o); full = x.h - x.l
    if full == 0: return None
    upper = x.h - max(x.c, x.o); lower = min(x.c, x.o) - x.l
    # Hammer / Shooting-star
    if lower > 2*body and upper < body: return "hammer"
    if upper > 2*body and lower < body: return "shooting"
    # Engulfing
    if (x.c > x.o) and (prev.c < prev.o) and (x.c >= prev.o) and (x.o <= prev.c): return "bull_engulf"
    if (x.c < x.o) and (prev.c > prev.o) and (x.o >= prev.c) and (x.c <= prev.o): return "bear_engulf"
    return None

# ── Contexte Couche A
def load_context_A(sym: str) -> Optional[Dict]:
    p = Path("/opt/scalp/data/analysis/A")/f"{sym}.json"
    if not p.exists(): return None
    try:
        a = json.loads(p.read_text())
        proba = a.get("proba",{})
        p_buy, p_sell, p_hold = float(proba.get("buy",0)), float(proba.get("sell",0)), float(proba.get("hold",0))
        ctx = "none"
        if p_buy >= ENTER_BUY: ctx="bullish"
        elif p_sell >= ENTER_SELL: ctx="bearish"
        elif HOLD_MIN <= p_hold <= HOLD_MAX: ctx="range"
        return {"ctx":ctx, "proba":proba, "S":float(a.get("S",0)), "per_tf":a.get("per_tf",{})}
    except Exception:
        return None

# ── Risk / sizing
def compute_size(price: float, atr_val: float, side:str, sl_mult:float=1.2) -> Tuple[float,float,float]:
    if price<=0 or atr_val is None or atr_val<=0:
        return (0.0, 0.0, 0.0)
    sl_dist = sl_mult * atr_val
    qty = (CAPITAL_USDT * RISK_PCT) / sl_dist
    sl = price - sl_dist if side=="long" else price + sl_dist
    tp = price + 1.8*atr_val if side=="long" else price - 1.8*atr_val
    return (max(qty,0.0), sl, tp)

# ── Déclencheurs
def trigger_pullback_trend(sym:str, c1m:List[Candle], c5m:List[Candle], side_ctx:str) -> Optional[Dict]:
    if len(c1m) < 30 or len(c5m) < 30: return None
    closes1=[x.c for x in c1m]
    ema20_1m = ema(closes1, 20)[-1]
    vwap1 = vwap(c1m, 20); bb = bollinger(c1m,20,2.0)
    rsi7 = rsi(closes1, 7)
    if vwap1 is None or rsi7 is None or bb is None: return None
    mid, low_bb, up_bb = bb
    # contact zone selon config simple: EMA20 ou ±1σ (BB)
    price = c1m[-1].c
    touched = abs(price-ema20_1m) <= 0.15*atr(c1m,14) or (side_ctx=="long" and price<=up_bb and price>=mid) or (side_ctx=="short" and price>=low_bb and price<=mid)
    vol_ok = bool(vol_spike(c1m, 1.3, 20))
    cond_rsi = (rsi7>50) if side_ctx=="long" else (rsi7<50)
    if touched and vol_ok and cond_rsi:
        a = atr(c1m,14)
        qty, sl, tp = compute_size(price, a, "long" if side_ctx=="long" else "short", 1.2)
        return {"entry_set":"pullback_trend", "side":("long" if side_ctx=="long" else "short"),
                "price_entry": price*(1+SLIPPAGE_PCT if side_ctx=="long" else 1-SLIPPAGE_PCT),
                "sl":sl, "tp":tp, "size":qty}
    return None

def trigger_breakout(sym:str, c3m:List[Candle], c5m:List[Candle], side_ctx:str) -> Optional[Dict]:
    # ADX (5m) ≥20, close casse range N=20, MACD hist ↑ (croissance), squeeze -> expansion
    if len(c5m)<40 or len(c3m)<25: return None
    closes5=[x.c for x in c5m]
    # MACD croissance sur 5m
    macd_slope = macd_hist_slope(closes5)
    if macd_slope is None: return None
    # ADX simple via ATR proxy: on utilise ATR relative comme proxy si ADX non dispo ici
    a5 = atr(c5m, 14); p5 = c5m[-1].c
    adx_ok = (a5 is not None and p5>0 and (100*a5/p5) >= 0.18)  # proxy ≈ 15–20
    # squeeze 3m → expansion (dernier squeeze off = False)
    sq = squeeze_on(c3m)
    # cassure des 20 dernières (3m)
    highs=[x.h for x in c3m[-20:]]; lows=[x.l for x in c3m[-20:]]
    hi, lo = max(highs), min(lows)
    price = c3m[-1].c
    long_break = side_ctx=="long" and price>hi
    short_break= side_ctx=="short" and price<lo
    slope_ok = (macd_slope>0) if side_ctx=="long" else (macd_slope<0)
    if adx_ok and sq is not None and (not sq) and (long_break or short_break) and slope_ok:
        a = atr(c3m,14)
        qty, sl, tp = compute_size(price, a, "long" if long_break else "short", 1.2)
        return {"entry_set":"breakout", "side":("long" if long_break else "short"),
                "price_entry": price*(1+SLIPPAGE_PCT if long_break else 1-SLIPPAGE_PCT),
                "sl":sl, "tp":tp, "size":qty}
    return None

def trigger_mean_reversion(sym:str, c1m:List[Candle], side_ctx:str) -> Optional[Dict]:
    # Contexte range. Touche BB extrême + divergence RSI + bougie reversal
    if len(c1m)<40: return None
    bb = bollinger(c1m, 20, 2.0); div = rsi_divergence(c1m,7,10); rev = candle_reversal(c1m)
    if not bb: return None
    mid, low_bb, up_bb = bb
    price = c1m[-1].c
    if side_ctx!="range": return None
    long_ok  = price<=low_bb  and (div=="bull") and (rev in ("hammer","bull_engulf"))
    short_ok = price>=up_bb   and (div=="bear") and (rev in ("shooting","bear_engulf"))
    if long_ok or short_ok:
        a = atr(c1m,14)
        side = "long" if long_ok else "short"
        qty, sl, tp = compute_size(price, a, side, 1.0)
        return {"entry_set":"mean_reversion", "side":side,
                "price_entry": price*(1+SLIPPAGE_PCT if side=="long" else 1-SLIPPAGE_PCT),
                "sl":sl, "tp":tp, "size":qty}
    return None

# ── Génération fichier signal(s)
def write_signal(sym:str, tf_ref:str, base_sig:Dict) -> Dict:
    sig = {
        "t_emit": int(time.time()),
        "sym": sym,
        "tf": tf_ref,
        **base_sig
    }
    SIGS.mkdir(parents=True, exist_ok=True)
    Path(SIGS/f"{sig['t_emit']}_{sym}_{base_sig['entry_set']}.json").write_text(
        json.dumps(sig, ensure_ascii=False, separators=(",",":"))
    )
    # append global
    obj = {"signals":[]}
    try:
        if SIGFILE.exists(): obj = json.loads(SIGFILE.read_text())
        if not isinstance(obj, dict): obj={"signals":[]}
        arr = obj.get("signals", [])
        arr.append(sig)
        obj["signals"] = arr[-2000:]
    except Exception:
        obj = {"signals":[sig]}
    SIGFILE.write_text(json.dumps(obj, ensure_ascii=False, separators=(",",":")))
    return sig

# ── Orchestrateur par symbole
def process_symbol(sym:str) -> Optional[Dict]:
    ctxA = load_context_A(sym)
    if not ctxA: 
        log(f"{sym}: no context A"); 
        return None
    ctx = ctxA["ctx"]
    if ctx=="none":
        log(f"{sym}: no active context"); 
        return None

    # charge TF basses
    c1m = load_candles(sym, "1m")
    if len(c1m) < 30:
        log(f"{sym}: not enough 1m"); 
        return None
    c3m = aggregate_3m(c1m)
    c5m = load_candles(sym, "5m")
    tf_ref = "1m"

    # route par contexte
    sig=None
    if ctx=="bullish":
        sig = trigger_pullback_trend(sym, c1m, c5m, "long") or trigger_breakout(sym, c3m, c5m, "long")
    elif ctx=="bearish":
        sig = trigger_pullback_trend(sym, c1m, c5m, "short") or trigger_breakout(sym, c3m, c5m, "short")
    elif ctx=="range":
        sig = trigger_mean_reversion(sym, c1m, "range")

    if sig:
        out = write_signal(sym, tf_ref, sig)
        log(f"{sym}: signal {out['entry_set']} {out['side']} price={out['price_entry']:.4f} sl={out['sl']:.4f} tp={out['tp']:.4f} size={out['size']:.6f}")
        return out
    log(f"{sym}: no trigger")
    return None

# ── Entry CLI
def main():
    # Universe: /opt/scalp/data/universe.txt (Top15)
    ufile = BASE/"universe.txt"
    if not ufile.exists():
        print("no universe.txt"); return
    syms = [l.strip().upper() for l in ufile.read_text().splitlines() if l.strip()]
    total = 0
    for s in syms:
        r = process_symbol(s)
        if r: total += 1
    print(f"[B] triggers done, signals={total}")

if __name__=="__main__":
    main()

```

### analyze/indicators_advanced.py  
Taille: 4 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: c0bfbff002d1e6bc

```py
from __future__ import annotations
import math, statistics
from typing import List, Tuple, Sequence, Optional

# rows: [[ts, o, h, l, c, v], ...] triées ASC

def _ema(vals: Sequence[float], period: int) -> List[float]:
    if period <= 0 or not vals: return []
    k = 2/(period+1)
    out: List[float] = []
    ema = vals[0]
    out.append(ema)
    for x in vals[1:]:
        ema = k*x + (1-k)*ema
        out.append(ema)
    return out

def _true_ranges(rows: Sequence[Sequence[float]]) -> List[float]:
    trs: List[float] = []
    prev_c = rows[0][4]
    for i in range(1, len(rows)):
        h, l, c = rows[i][2], rows[i][3], rows[i][4]
        trs.append(max(h-l, abs(h-prev_c), abs(l-prev_c)))
        prev_c = c
    return trs

def atr(rows: Sequence[Sequence[float]], period: int=14) -> Optional[float]:
    if len(rows) < period+1: return None
    trs = _true_ranges(rows)
    return sum(trs[-period:]) / period

def atr_pct(rows: Sequence[Sequence[float]], period: int=14) -> Optional[float]:
    a = atr(rows, period)
    if a is None: return None
    c = rows[-1][4]
    if c <= 0: return None
    return 100.0 * a / c

def rsi(rows: Sequence[Sequence[float]], period: int=14) -> Optional[float]:
    if len(rows) < period+1: return None
    gains=0.0; losses=0.0
    for i in range(-period, 0):
        chg = rows[i][4] - rows[i-1][4]
        gains += max(chg, 0.0)
        losses += max(-chg, 0.0)
    if gains==0 and losses==0: return 50.0
    if losses==0: return 100.0
    rs = gains/losses
    return 100.0 - (100.0/(1.0+rs))

def adx(rows: Sequence[Sequence[float]], period: int=14) -> Optional[float]:
    # Implémentation légère (Wilder-like, fin de série uniquement)
    if len(rows) < period+2: return None
    trs = _true_ranges(rows)
    plus_dm: List[float] = []
    minus_dm: List[float] = []
    for i in range(1, len(rows)):
        up = rows[i][2] - rows[i-1][2]
        dn = rows[i-1][3] - rows[i][3]
        plus_dm.append(max(up, 0.0) if up>dn else 0.0)
        minus_dm.append(max(dn, 0.0) if dn>up else 0.0)
    tr14 = sum(trs[-period:])
    pdm14 = sum(plus_dm[-period:])
    mdm14 = sum(minus_dm[-period:])
    if tr14 == 0: return 0.0
    pdi = 100.0 * pdm14 / tr14
    mdi = 100.0 * mdm14 / tr14
    s = pdi + mdi
    if s == 0: return 0.0
    dx = 100.0 * abs(pdi - mdi) / s
    return dx  # approximation ADX

def macd_hist(rows: Sequence[Sequence[float]], fast:int=12, slow:int=26, sig:int=9) -> Optional[Tuple[float,float]]:
    closes = [r[4] for r in rows]
    if len(closes) < slow+sig+2: return None
    ema_fast = _ema(closes, fast)
    ema_slow = _ema(closes, slow)
    # aligne par la fin
    m = [a-b for a,b in zip(ema_fast[-len(ema_slow):], ema_slow)]
    sig_line = _ema(m, sig)
    hist = m[-1] - sig_line[-1]
    # sigma hist pour normalisation robuste
    look = min(120, len(m))
    sigma = statistics.pstdev([m[i] - sig_line[i] for i in range(-look, 0)]) or 1e-12
    return hist, sigma

def obv_slope(rows: Sequence[Sequence[float]], lookback:int=20) -> Optional[Tuple[float,float]]:
    if len(rows) < lookback+2: return None
    obv = [0.0]
    for i in range(1, len(rows)):
        c0, c1 = rows[i-1][4], rows[i][4]
        v = rows[i][5]
        if c1>c0: obv.append(obv[-1] + v)
        elif c1<c0: obv.append(obv[-1] - v)
        else: obv.append(obv[-1])
    d_obv = obv[-1] - obv[-1-lookback]
    med_abs = statistics.median([abs(x) for x in obv[-lookback:]]) or 1e-12
    return d_obv, med_abs

def tanh_norm(x: float, scale: float) -> float:
    if scale <= 0: scale = 1e-12
    return math.tanh(x/scale)

def clip_unit(x: float) -> float:
    return max(-1.0, min(1.0, x))

```

### analyze/layer_a.py  
Taille: 2 KB  |  MàJ: 2025-09-19 18:49:54  |  SHA256: c40eca6be96a2c68

```py
#!/opt/scalp/.venv/bin/python
import json, time
from pathlib import Path

DATA = Path("/opt/scalp/data")
SRC  = DATA/"heatmap.json"
OUT  = DATA/"analysis/A"

# paramètres A
WIN   = 20           # nb de points S récents utilisés
BAND  = 0.10         # zone neutre |S|<BAND => hold
TH_BULL = 0.60       # p_buy >= 0.60
TH_BEAR = 0.60       # p_sell >= 0.60
RNG_MIN, RNG_MAX = 0.40, 0.60  # 0.40<=p_hold<=0.60

def _probs(seq):
    """retourne p_buy, p_hold, p_sell à partir d'une séquence S (liste de floats)"""
    if not seq: 
        return (0.0, 1.0, 0.0)
    b=h=s=0
    for v in seq:
        v=float(v)
        if abs(v) < BAND: h += 1
        elif v > 0:       b += 1
        else:             s += 1
    n = max(1, b+h+s)
    return b/n, h/n, s/n

def _ctx(pb, ph, ps):
    if pb >= TH_BULL:        return "bullish"
    if ps >= TH_BEAR:        return "bearish"
    if RNG_MIN <= ph <= RNG_MAX: return "range"
    return "none"

def analyze_row(row):
    sym = row.get("sym")
    seq = row.get("S", [])[-WIN:]
    pb,ph,ps = _probs(seq)
    ctx = _ctx(pb,ph,ps)
    return {
        "sym": sym,
        "updated": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        "win": WIN,
        "band": BAND,
        "p_buy": round(pb,3),
        "p_hold": round(ph,3),
        "p_sell": round(ps,3),
        "ctx": ctx,
        "S_last": seq[-1] if seq else 0.0
    }

def run():
    OUT.mkdir(parents=True, exist_ok=True)
    if not SRC.exists():
        print("heatmap.json absent"); return 0
    obj = json.loads(SRC.read_text())
    if isinstance(obj, dict):
        rows = obj.get("rows", [])
    else:
        rows = obj  # si c’est déjà une liste

    count=0
    for r in rows:
        res = analyze_row(r)
        (OUT/f"{res['sym']}.json").write_text(json.dumps(res, ensure_ascii=False))
        count+=1
    # petit résumé global
    (OUT/"_summary.json").write_text(json.dumps({
        "updated": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        "count": count
    }, ensure_ascii=False))
    return count

```

### analyze/run_triggers_cli.py  
Taille: 2 KB  |  MàJ: 2025-09-19 20:41:56  |  SHA256: a64ebf8ba323c959

```py
#!/opt/scalp/.venv/bin/python
import json, math
from pathlib import Path
D=Path("/opt/scalp/data"); C3=D/"candles_3m"; CTX=json.loads((D/"context.json").read_text())
EQUITY=float((Path("/opt/scalp/etc/scalp.env").read_text().splitlines() if (Path("/opt/scalp/etc/scalp.env").exists()) else ["EQUITY=1000"])[0].split("=")[-1]) if False else 1000.0
RISK=0.01; MAX_LEV=10

def ema(vals,p):
    k=2/(p+1); e=None
    for v in vals:
        e=v if e is None else e+k*(v-e)
    return e or (vals[-1] if vals else None)

signals=[]
for f in C3.glob("*_3m.json"):
    sym=f.stem.replace("_3m","")
    rows=json.loads(f.read_text()); closes=[r["c"] for r in rows]
    if len(closes)<60 or sym not in CTX: continue
    e9=ema(closes[-60:],9); e21=ema(closes[-60:],21); last=closes[-1]
    ctx=CTX[sym]; pbuy,psell=ctx["pbuy"],ctx["psell"]
    # règle d’entrée simple cross + contexte
    side=None
    if pbuy and e9 is not None and e21 is not None and e9>e21: side="LONG"
    if psell and e9 is not None and e21 is not None and e9<e21: side="SHORT"
    if not side: continue
    # SL/TP via ATR-like (vol absolue 20)
    highs=[r["h"] for r in rows[-20:]]; lows=[r["l"] for r in rows[-20:]]
    tr=[max(h-l,abs(h-last),abs(l-last)) for h,l in zip(highs,lows)]
    atr=sum(tr)/len(tr) if tr else last*0.01
    if side=="LONG":
        sl= last-2*atr; tp= last+3*atr
    else:
        sl= last+2*atr; tp= last-3*atr
    # taille et levier
    risk_amt=EQUITY*RISK
    stop_dist=abs(last-sl) or (last*0.005)
    qty=risk_amt/stop_dist
    lev=min(MAX_LEV, max(1,int((qty*last)/max(1.0,EQUITY))))
    signals.append({"sym":sym,"side":side,"px":last,"sl":sl,"tp":tp,"qty":qty,"lev":lev})
(D/"signals.json").write_text(json.dumps(signals,ensure_ascii=False,indent=2))
print("signals:",len(signals))

```

### bin/dump_and_push.sh  
Taille: 4 KB  |  MàJ: 2025-09-17 05:10:42  |  SHA256: e8fae927be8e9112

```sh
#!/usr/bin/env bash
set -euo pipefail

# --------- Réglages ---------
ROOT="/opt/scalp"
DUMP_DIR="${ROOT}/dump"
TS="$(date +'%Y%m%d_%H%M%S')"
OUT="${DUMP_DIR}/scalp_code_${TS}.txt"
TMP_LIST="$(mktemp)"
MAX_FILE_SIZE_KB="${MAX_FILE_SIZE_KB:-512}"
MAX_FILES="${MAX_FILES:-4000}"
DRY_RUN="${DRY_RUN:-1}"

mkdir -p "$DUMP_DIR"
trap 'rm -f "$TMP_LIST"' EXIT

# --------- Git depuis /etc/scalp.env ---------
. /etc/scalp.env

: "${GIT_USER:?manquant}"
: "${GIT_TOKEN:?manquant}"

GIT_BRANCH="${GIT_BRANCH:-main}"
GIT_EMAIL_USE="${GIT_EMAIL:-${GIT_USER}@users.noreply.github.com}"
GIT_HOST="${GIT_HOST:-github.com}"
GIT_OWNER="${GIT_OWNER:-$GIT_USER}"
GIT_REPO="${GIT_REPO:-scalp}"
GIT_REMOTE="${GIT_REMOTE:-}"

if [ -n "$GIT_REMOTE" ]; then
  REMOTE_URL="$GIT_REMOTE"
else
  REMOTE_URL="https://${GIT_HOST}/${GIT_OWNER}/${GIT_REPO}.git"
fi

echo "[dump_and_push] branch=${GIT_BRANCH} dry_run=${DRY_RUN} remote=${REMOTE_URL}"

# --------- Collecte fichiers ---------
find "$ROOT" -type f \
  -not -path '*/.*' \
  -not -path '*/.git/*' \
  -not -path '*/__pycache__/*' \
  -not -path '*/venv/*' -not -path '*/.venv/*' \
  -not -path '*/var/*' \
  -not -path '*/logs/*' \
  -not -path '*/data/*' \
  -not -path '*/reports/*' \
  -not -path '*/dump/*' \
  -size -"${MAX_FILE_SIZE_KB}"k \
  \( -name '*.py' -o -name '*.sh' -o -name '*.bash' -o -name '*.ini' -o -name '*.cfg' -o -name '*.conf' -o -name '*.toml' -o -name '*.yaml' -o -name '*.yml' -o -name '*.md' -o -name '*.txt' \) \
  -print0 > "$TMP_LIST"

# Limite à MAX_FILES
TMP2="$(mktemp)"; trap 'rm -f "$TMP2"' EXIT
awk -v max="$MAX_FILES" -v RS='\0' -v ORS='\0' 'NR<=max{print}' "$TMP_LIST" > "$TMP2"
mv "$TMP2" "$TMP_LIST"

# Utilitaires
file_size() { stat -c %s -- "$1" 2>/dev/null || wc -c <"$1" 2>/dev/null || echo 0; }
file_mtime() { stat -c %y -- "$1" 2>/dev/null || date -r "$1" +'%Y-%m-%d %H:%M:%S %Z' 2>/dev/null || echo "unknown"; }

# En-tête
{
  echo "# Scalp Project Code Dump"
  echo "# Generated: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
  echo "# Root: ${ROOT}"
  echo "# Caps: ${MAX_FILE_SIZE_KB}KB/file, max ${MAX_FILES} files"
  echo "# Exclusions: hidden, .git, __pycache__, venv/.venv, var, logs, data, reports, dump"
  echo "# Extensions: py, sh, bash, ini, cfg, conf, toml, yaml/yml, md, txt"
  echo
  echo "========== TREE (size, mtime) =========="
} > "$OUT"

# TREE
tr '\0' '\n' < "$TMP_LIST" | sort | while IFS= read -r f; do
  [ -n "$f" ] || continue
  printf "%-80s  %12s  %s\n" "$f" "$(file_size "$f")" "$(file_mtime "$f")" >> "$OUT"
done

# TOP 10
{
  echo
  echo "========== TOP 10 BIGGEST FILES =========="
} >> "$OUT"
tr '\0' '\n' < "$TMP_LIST" | awk 'NF' | while IFS= read -r f; do
  sz="$(file_size "$f")"
  printf "%012d\t%s\n" "$sz" "$f"
done | sort -r | head -n 10 | awk -F'\t' '{printf "%-80s  %12d\n", $2, $1+0}' >> "$OUT"

# Contenu
{
  echo
  echo "========== CONCAT CONTENT =========="
} >> "$OUT"

tr '\0' '\n' < "$TMP_LIST" | awk 'NF' | while IFS= read -r f; do
  sz="$(file_size "$f")"
  mt="$(file_mtime "$f")"
  {
    echo
    echo "----- FILE BEGIN -----"
    echo "Path: $f"
    echo "Size: $sz"
    echo "MTime: $mt"
    echo "----- CONTENT -----"
  } >> "$OUT"

  if [ "$sz" -gt $((MAX_FILE_SIZE_KB*1024)) ]; then
    head -c $((MAX_FILE_SIZE_KB*1024)) -- "$f" 2>/dev/null >> "$OUT" || true
    echo -e "\n[TRUNCATED]" >> "$OUT"
  else
    cat -- "$f" 2>/dev/null >> "$OUT" || true
  fi
  echo "----- FILE END -----" >> "$OUT"
done

echo "Dump prêt: $OUT"

# --------- Git: commit + push du dump ---------
cd "$ROOT"
git rev-parse --is-inside-work-tree >/dev/null 2>&1 || git init -q .
git config user.name "${GIT_USER}"
git config user.email "${GIT_EMAIL_USE}"
git remote get-url origin >/dev/null 2>&1 || git remote add origin "${REMOTE_URL}"

touch .gitignore
for p in var/ logs/ data/ reports/ dump/; do grep -qxF "$p" .gitignore || echo "$p" >> .gitignore; done

git add -f "$OUT"
git commit -m "dump: ${OUT##*/}" || true

if [ "$DRY_RUN" = "1" ]; then
  echo "DRY_RUN=1 -> push désactivé"
else
  AUTH_URL="$(git remote get-url origin | sed -E "s#^https://#https://${GIT_USER}:${GIT_TOKEN}@#")"
  git push "$AUTH_URL" "HEAD:${GIT_BRANCH}"
  echo "OK: push vers ${REMOTE_URL} sur ${GIT_BRANCH}"
fi

```

### bin/dump_and_reset.sh  
Taille: 2 KB  |  MàJ: 2025-09-17 05:13:48  |  SHA256: 9a5d9d9038c80be7

```sh
#!/usr/bin/env bash
set -euo pipefail

ROOT="/opt/scalp"
DUMP_DIR="${ROOT}/dump"
TS="$(date +'%Y%m%d_%H%M%S')"
OUT="${DUMP_DIR}/scalp_code_${TS}.txt"
TMP_LIST="$(mktemp)"
MAX_FILE_SIZE_KB="${MAX_FILE_SIZE_KB:-512}"
MAX_FILES="${MAX_FILES:-4000}"

mkdir -p "$DUMP_DIR"
trap 'rm -f "$TMP_LIST"' EXIT

# -------- Git depuis /etc/scalp.env --------
. /etc/scalp.env
: "${GIT_USER:?manquant}"
: "${GIT_TOKEN:?manquant}"
GIT_EMAIL_USE="${GIT_EMAIL:-${GIT_USER}@users.noreply.github.com}"
GIT_BRANCH="${GIT_BRANCH:-main}"
GIT_HOST="${GIT_HOST:-github.com}"
GIT_OWNER="${GIT_OWNER:-$GIT_USER}"
GIT_REPO="${GIT_REPO:-scalp}"
REMOTE_URL="${GIT_REMOTE:-https://${GIT_HOST}/${GIT_OWNER}/${GIT_REPO}.git}"

echo "[dump_and_reset] remote=${REMOTE_URL} branch=${GIT_BRANCH}"

# -------- Collecte fichiers --------
find "$ROOT" -type f \
  -not -path '*/.*' \
  -not -path '*/.git/*' \
  -not -path '*/__pycache__/*' \
  -not -path '*/venv/*' -not -path '*/.venv/*' \
  -not -path '*/var/*' \
  -not -path '*/logs/*' \
  -not -path '*/data/*' \
  -not -path '*/reports/*' \
  -not -path '*/dump/*' \
  -size -"${MAX_FILE_SIZE_KB}"k \
  \( -name '*.py' -o -name '*.sh' -o -name '*.bash' -o -name '*.ini' -o -name '*.cfg' -o -name '*.conf' -o -name '*.toml' -o -name '*.yaml' -o -name '*.yml' -o -name '*.md' -o -name '*.txt' \) \
  -print0 > "$TMP_LIST"

# -------- Génère le dump --------
{
  echo "# Scalp Project Code Dump"
  echo "# Generated: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
} > "$OUT"

tr '\0' '\n' < "$TMP_LIST" | head -n "$MAX_FILES" | while IFS= read -r f; do
  echo "----- FILE BEGIN -----" >> "$OUT"
  echo "Path: $f" >> "$OUT"
  cat "$f" >> "$OUT" || true
  echo "----- FILE END -----" >> "$OUT"
done

echo "Dump généré: $OUT"

# -------- Réinit git complet --------
cd "$ROOT"
rm -rf .git
git init -q .
git config user.name "${GIT_USER}"
git config user.email "${GIT_EMAIL_USE}"
git remote add origin "${REMOTE_URL}"

# Commit unique
git add -f "$OUT"
git commit -m "reset: dump ${OUT##*/}"

# Push forcé (écrase distant)
AUTH_URL="$(git remote get-url origin | sed -E "s#^https://#https://${GIT_USER}:${GIT_TOKEN}@#")"
git branch -M "${GIT_BRANCH}"
git push --force "$AUTH_URL" "${GIT_BRANCH}"

echo "OK: repo réinitialisé et poussé sur ${REMOTE_URL} (${GIT_BRANCH})"

```

### bot/__init__.py  
Taille: 0 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: e3b0c44298fc1c14

```py

```

### bot/_keyboard_patch.py  
Taille: 670 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 7b38739c8a2a5af8

```py
import json, os, urllib.parse, urllib.request
TOKEN=os.getenv("TELEGRAM_BOT_TOKEN","")
API=f"https://api.telegram.org/bot{TOKEN}/sendMessage"
KB={"keyboard":[
    [ {"text":"/top"}, {"text":"/heat"} ],
    [ {"text":"/signals"}, {"text":"/positions"} ],
    [ {"text":"/history"}, {"text":"/ping"} ]
], "resize_keyboard": True, "one_time_keyboard": False}

def send(chat_id, text, parse_mode=None):
    data={"chat_id":chat_id,"text":text,"reply_markup":json.dumps(KB, ensure_ascii=False)}
    if parse_mode: data["parse_mode"]=parse_mode
    req=urllib.request.Request(API, data=urllib.parse.urlencode(data).encode())
    urllib.request.urlopen(req, timeout=10).read()

```

### bot/bot_stdlib.py  
Taille: 2 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 8e5d6bd230416ff5

```py
#!/opt/scalp/.venv/bin/python
import os, time, json, urllib.request, urllib.parse, pathlib, traceback, inspect
from bot.views_heat import render_heatmap as render_heatmap_soft
from .views import render_top15, render_signals
from .views_positions import render_positions
from .views_history  import render_history

BASE=pathlib.Path("/opt/scalp"); DATA=BASE/"data"
TOKEN=os.getenv("TELEGRAM_BOT_TOKEN",""); CHAT=os.getenv("TELEGRAM_CHAT_ID","")
API=f"https://api.telegram.org/bot{TOKEN}"

assert TOKEN and CHAT, "⚠️ TELEGRAM_BOT_TOKEN / CHAT_ID manquant"
assert "views_heat.py" in (inspect.getsourcefile(render_heatmap_soft) or ""), \
    "Heatmap pas issue de bot/views_heat.py"

def _post(m,p):
    req=urllib.request.Request(f"{API}/{m}",data=urllib.parse.urlencode(p).encode())
    with urllib.request.urlopen(req,timeout=10) as r: return json.loads(r.read())

def _send(cid,txt,pm="HTML",kb=True):
    pl={"chat_id":cid,"text":txt,"disable_web_page_preview":True}
    if pm: pl["parse_mode"]=pm
    if kb:
        pl["reply_markup"]=json.dumps({"keyboard":[
            [{"text":"/top"},{"text":"/heat"}],
            [{"text":"/signals"},{"text":"/positions"}],
            [{"text":"/history"},{"text":"/ping"}]],"resize_keyboard":True})
    try: _post("sendMessage",pl)
    except Exception as e: print("send fail:",e)

def _answer(cmd):
    return {"/top":render_top15,"/heat":render_heatmap_soft,
            "/signals":render_signals,"/positions":render_positions,
            "/history":render_history,"/ping":lambda:"pong ✅"}.get(cmd,lambda:"(commande inconnue)")()

def _ofs(): return DATA/".tg_offset"

def main():
    try: _send(CHAT,"SCALP bot prêt ✅")
    except: pass
    off=0
    if _ofs().exists():
        try: off=int((_ofs().read_text() or "0").strip())
        except: pass
    while True:
        try:
            res=_post("getUpdates",{"timeout":25,"offset":off+1})
            for u in res.get("result",[]):
                off=u["update_id"]
                m=u.get("message") or u.get("edited_message") or {}
                txt=(m.get("text") or "").strip(); cid=str(m.get("chat",{}).get("id",""))
                if not txt or not cid: continue
                try: _send(cid,_answer(txt))
                except Exception: _send(cid,f"<pre>{traceback.format_exc()}</pre>")
            _ofs().write_text(str(off))
        except Exception as e:
            print("loop error:",e); time.sleep(1)

if __name__=="__main__": main()

```

### bot/commands_wire.py  
Taille: 978 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 449ef6e244cf0386

```py
#!/opt/scalp/.venv/bin/python
# Fonctions à appeler depuis ton handler Telegram
from __future__ import annotations
from typing import Optional
from views_positions import render_positions
from views_history  import render_history
from views_signals  import render_signals
from views_btop     import render_btop
from views_heat     import render_heatmap

def cmd_positions(bot, chat_id):
    bot.send_message(chat_id, render_positions())

def cmd_history(bot, chat_id, minutes:Optional[int]=None):
    txt = render_history(since_minutes=minutes, limit=50 if minutes else 30)
    bot.send_message(chat_id, txt)

def cmd_signals(bot, chat_id, minutes:Optional[int]=None):
    txt = render_signals(limit=0 if minutes else 20, since_minutes=minutes)
    bot.send_message(chat_id, txt)

def cmd_btop(bot, chat_id, n:Optional[int]=None):
    bot.send_message(chat_id, render_btop(n))

def cmd_heat(bot, chat_id, n:Optional[int]=None):
    bot.send_message(chat_id, render_heatmap(n))

```

### bot/env_simple.py  
Taille: 469 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: a75e09ead631b4f8

```py
import pathlib,re
ENV=pathlib.Path("/etc/scalp.env"); RGX=re.compile(r'^\s*([A-Za-z_]\w*)\s*=\s*(.*)\s*$')
def load():
    d={}
    if ENV.exists():
        for L in ENV.read_text(encoding="utf-8",errors="ignore").splitlines():
            m=RGX.match(L); 
            if m: d[m.group(1)]=m.group(2).strip().strip('"').strip("'")
    s=type("S",(),{})(); s.TOKEN=d.get("TELEGRAM_BOT_TOKEN",""); s.CHAT_ID=d.get("TELEGRAM_CHAT_ID"); s.BUILD=d.get("BUILD","-"); return s

```

### bot/json_util.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 89aa28d11d2e8238

```py
import json, pathlib
from typing import Any, Optional

def load_last_json(path: pathlib.Path | str, default: Optional[Any]=None) -> Any:
    p = pathlib.Path(path)
    if not p.exists():
        return default
    txt = p.read_text(encoding="utf-8").strip()
    if not txt:
        return default
    # 1/ essai direct
    try:
        return json.loads(txt)
    except Exception:
        pass
    # 2/ parcourir tous les objets JSON concaténés et garder le dernier valide
    dec = json.JSONDecoder()
    i, last = 0, default
    while i < len(txt):
        # sauter espaces / séparateurs
        while i < len(txt) and txt[i] not in "{[":
            i += 1
        if i >= len(txt):
            break
        try:
            obj, j = dec.raw_decode(txt, idx=i)
            last = obj
            i = j
        except Exception:
            i += 1
    return last

def load_json(path: pathlib.Path | str, default: Optional[Any]=None) -> Any:
    import json, pathlib
    p = pathlib.Path(path)
    if not p.exists():
        return default
    try:
        return json.loads(p.read_text(encoding="utf-8"))
    except Exception:
        return default

```

### bot/lib/__init__.py  
Taille: 0 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: e3b0c44298fc1c14

```py

```

### bot/mod_heatmap.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: d736b6a6529bcd00

```py
import json,pathlib,re; from lib.errors import err
DATA=pathlib.Path("/opt/scalp/data"); TRI=re.compile(r'\s*(\d+)\s*/\s*(\d+)\s*/\s*(\d+)\s*')
def _t(x): 
    if isinstance(x,dict): return {k:int(x.get(k,0)) for k in ("b","h","s")}
    m=TRI.match((x or "")); return {"b":int(m.group(1)),"h":int(m.group(2)),"s":int(m.group(3))} if m else {"b":0,"h":0,"s":0}
def run():
    p=DATA/"heatmap.json"
    if not p.exists(): return f"(à connecter: {p})"
    try: o=json.loads(p.read_text()); rows=o.get("rows") or []
    except Exception: return err("E11","heatmap.json illisible")
    if not rows: return "(pas de données)"
    def B(b,h,s): m=max(b,h,s); f=lambda x: f"<b>{x}</b>" if x==m else f"{x}"; return f"[ {f(b)} | {f(h)} | {f(s)} ]"
    L=["coin    5m             15m            30m","──────────────────────────────────────────"]
    for r in rows:
        sym=(r.get("sym") or r.get("symb") or r.get("coin") or "").replace("/USDT","").replace("USDT",""); 
        if not sym: continue
        t=lambda tf:_t(r.get(tf))
        L.append(f"{sym[:6].ljust(6)}  " + "   ".join([B(**t('5m')),B(**t('15m')),B(**t('30m'))]))
    return "<pre>"+"\n".join(L)+"</pre>"

```

### bot/mod_signals.py  
Taille: 865 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: e7758865ceb08c95

```py
import json,pathlib,time; from lib.errors import err
DATA=pathlib.Path("/opt/scalp/data")
def run(limit:int=20):
    p=DATA/"signals.json"
    if not p.exists(): return f"(à connecter: {p})"
    try: o=json.loads(p.read_text())
    except Exception: return err("E11","signals.json illisible")
    arr=o.get("signals") if isinstance(o,dict) else (o if isinstance(o,list) else [])
    if not arr: return "(aucun signal)"
    arr=sorted(arr,key=lambda s:(s or {}).get("t_emit",0),reverse=True)[:limit]
    L=["Derniers signaux:"]
    for s in arr:
        s=s or {}; ts=int(str(s.get("t_emit",0))[:10]) if s.get("t_emit") else 0
        when=time.strftime("%Y-%m-%d %H:%MZ", time.gmtime(ts)) if ts else "—"
        L.append(f"{when}  {s.get('sym','?')}  {s.get('side','?')}  tf={s.get('tf','?')}  rule={s.get('rule','?')}")
    return "<pre>"+"\n".join(L)+"</pre>"

```

### bot/mod_top.py  
Taille: 503 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: ae0ab2c3d6e8a47f

```py
import json,pathlib; from lib.errors import err
DATA=pathlib.Path("/opt/scalp/data")
def run():
    p=DATA/"top.json"
    if not p.exists(): return f"(à connecter: {p})"
    try: o=json.loads(p.read_text())
    except Exception: return err("E11","top.json illisible")
    arr=(o or {}).get("assets",[])
    if not arr: return "(top vide)"
    L=["Top volume/volatilité:"]+[f"{x.get('sym','?'):6} v={x.get('vol','?')} σ={x.get('vola','?')}" for x in arr[:20]]
    return "<pre>"+"\n".join(L)+"</pre>"

```

### bot/router.py  
Taille: 3 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 4e6d3a2653ef9014

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import os, logging
from telegram import Update, BotCommand
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters

from .views_signals import render_signals
from .views_positions import render_positions
from .views_history import render_history
from .views_heat import render_heat
from .views_menu import main_menu

logging.basicConfig(level=logging.INFO)
LOG=logging.getLogger("router")

TOKEN=os.getenv("TELEGRAM_TOKEN") or os.getenv("TELEGRAM_BOT_TOKEN") or ""
ALLOW=os.getenv("ALLOW_CHAT_ID") or os.getenv("TELEGRAM_CHAT_ID") or ""

def _ok(u:Update)->bool:
    return not ALLOW or str(u.effective_chat.id)==str(ALLOW)

async def _deny(u:Update,c:ContextTypes.DEFAULT_TYPE):
    await c.bot.send_message(chat_id=u.effective_chat.id, text="(accès refusé)")

async def _set_cmds(app):
    cmds=[BotCommand("heat","Heatmap"),
          BotCommand("signals","Derniers signaux"),
          BotCommand("positions","Positions ouvertes"),
          BotCommand("history","Historique des ordres")]
    await app.bot.set_my_commands(cmds)

async def start(u:Update,c:ContextTypes.DEFAULT_TYPE):
    if not _ok(u): return await _deny(u,c)
    await _set_cmds(c.application)
    await c.bot.send_message(chat_id=u.effective_chat.id, text="SCALP bot prêt", reply_markup=main_menu())

async def heat(u:Update,c:ContextTypes.DEFAULT_TYPE):
    if not _ok(u): return await _deny(u,c)
    await c.bot.send_message(chat_id=u.effective_chat.id, text=render_heat(), reply_markup=main_menu())

async def signals(u:Update,c:ContextTypes.DEFAULT_TYPE):
    if not _ok(u): return await _deny(u,c)
    await c.bot.send_message(chat_id=u.effective_chat.id, text=render_signals(), reply_markup=main_menu())

async def positions(u:Update,c:ContextTypes.DEFAULT_TYPE):
    if not _ok(u): return await _deny(u,c)
    await c.bot.send_message(chat_id=u.effective_chat.id, text=render_positions(), reply_markup=main_menu())

async def history(u:Update,c:ContextTypes.DEFAULT_TYPE):
    if not _ok(u): return await _deny(u,c)
    text = u.message.text or "/history"
    await c.bot.send_message(chat_id=u.effective_chat.id, text=render_history(text), reply_markup=main_menu())

async def fallback(u:Update,c:ContextTypes.DEFAULT_TYPE):
    if not _ok(u): return await _deny(u,c)
    await c.bot.send_message(chat_id=u.effective_chat.id, text="Choisis une commande.", reply_markup=main_menu())

def main()->int:
    assert TOKEN,"TELEGRAM_TOKEN manquant"
    app=ApplicationBuilder().token(TOKEN).build()
    app.add_handler(CommandHandler("start",start))
    app.add_handler(CommandHandler("heat",heat))
    app.add_handler(CommandHandler("signals",signals))
    app.add_handler(CommandHandler("positions",positions))
    app.add_handler(CommandHandler("history",history))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, fallback))
    app.run_polling(allowed_updates=None)
    return 0

if __name__=="__main__":
    raise SystemExit(main())

```

### bot/singleton.py  
Taille: 477 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: f0fdc9455c132561

```py
import os,sys,fcntl
LOCK="/run/scalp-bot.lock"
def acquire_or_exit():
    os.makedirs("/run",exist_ok=True)
    fd=os.open(LOCK,os.O_CREAT|os.O_RDWR,0o644)
    try:
        fcntl.flock(fd, fcntl.LOCK_EX|fcntl.LOCK_NB); os.ftruncate(fd,0); os.write(fd,f"{os.getpid()}\n".encode()); os.fsync(fd); return fd
    except BlockingIOError:
        os.lseek(fd,0,os.SEEK_SET); pid=(os.read(fd,64).decode().strip() or "?"); print(f"[singleton] pid={pid}",file=sys.stderr); sys.exit(16)

```

### bot/views.py  
Taille: 2 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 322bd3e1235cec1b

```py
#!/opt/scalp/.venv/bin/python
# Vues textuelles hors heatmap (top, signals, positions, history)
import json, pathlib, datetime as dt
BASE = pathlib.Path("/opt/scalp"); DATA = BASE/"data"

def _safe_read(path):
    try: return json.loads(path.read_text())
    except Exception: return {}

def render_top15():
    obj = _safe_read(DATA/"top.json")
    rows = obj.get("rows", [])
    tstr = obj.get("time","")
    head = f"Top15  {tstr}" if tstr else "Top15"
    names = [r.get("sym","?") for r in rows[:15]]
    # colonne double (1..15)
    left  = [f"{i+1}. {names[i]:<3}" for i in range(0, min(5, len(names)))]
    right = [f"{i+6}. {names[i+5]:<3}" for i in range(0, min(5, max(0,len(names)-5)))]
    third = [f"{i+11}. {names[i+10]:<3}" for i in range(0, min(5, max(0,len(names)-10)))]
    # assemble lisible même si listes courtes
    lines = [head, ""]
    for i in range(5):
        a = left[i]  if i < len(left)  else " " * 8
        b = right[i] if i < len(right) else " " * 8
        c = third[i] if i < len(third) else " " * 8
        lines.append(f"{a:10} {b:10} {c}")
    return "\n".join(lines)

def render_signals():
    p = DATA/"signals.json"
    obj = _safe_read(p)
    sigs = obj.get("signals", [])
    if not sigs: return "(pas de signaux)"
    out = ["Signals", ""]
    for s in sigs[:10]:
        out.append(f"{s.get('timestamp','')}  {s.get('symbol','?')}  {s.get('side','?')}  {s.get('entry_set','')}")
    return "\n".join(out)

def render_positions():
    p = DATA/"positions.json"
    obj = _safe_read(p)
    pos = obj.get("positions", [])
    if not pos: return "(pas de positions)"
    out = ["Positions", ""]
    for x in pos[:10]:
        out.append(f"{x.get('symbol','?')}  {x.get('side','?')}  {x.get('qty','')}  @ {x.get('price','')}")
    return "\n".join(out)

def render_history():
    p = DATA/"history.json"
    obj = _safe_read(p)
    h = obj.get("history", [])
    if not h: return "(historique vide)"
    out = ["History", ""]
    for x in h[:10]:
        out.append(f"{x.get('timestamp','')}  {x.get('symbol','?')}  {x.get('pnl','')}")
    return "\n".join(out)

```

### bot/views_account.py  
Taille: 909 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: cd594886f0d665d2

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json, time
from pathlib import Path

DATA=Path("/opt/scalp/data")
ACCT=DATA/"account.json"
POSF=DATA/"positions.json"

def _read_json(p:Path, d): 
    try: return json.loads(p.read_text())
    except: return d

def render_account()->str:
    a=_read_json(ACCT, {"balance":0,"equity":0,"open_pnl":0,"currency":"USDT","updated":0})
    pos=_read_json(POSF, {"positions":[]})
    rows = pos.get("positions") if isinstance(pos,dict) else pos
    n_open = sum(1 for x in rows if isinstance(x,dict) and x.get("status")=="open")
    ts=time.strftime("%Y-%m-%d %H:%M:%SZ", time.gmtime(a.get("updated",0)))
    return (f"Balance : {a['balance']:.2f} {a.get('currency','USDT')}\n"
            f"OpenPnL : {a['open_pnl']:.2f}\n"
            f"Equity  : {a['equity']:.2f}\n"
            f"Positions ouvertes : {n_open}\n"
            f"Maj : {ts}")

```

### bot/views_btop.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 5302192866f47be4

```py
#!/opt/scalp/.venv/bin/python
# /Btop : affiche par crypto -> S, max(pb/ph/ps) avec libellé, et ctx
from __future__ import annotations
import json, time
from pathlib import Path
from typing import Dict, Any, List

DATA = Path("/opt/scalp/data")
SRC  = DATA/"Btop.json"

def _read():
    if not SRC.exists(): return {"updated": None, "assets": []}
    try: return json.loads(SRC.read_text())
    except: return {"updated": None, "assets": []}

def _argmax_prob(a:Dict[str,Any])->tuple[str,float]:
    pb=a.get("pb",0.0); ph=a.get("ph",0.0); ps=a.get("ps",0.0)
    if pb>=ph and pb>=ps: return ("pb", pb)
    if ps>=ph and ps>=pb: return ("ps", ps)
    return ("ph", ph)

def render_btop(max_rows:int|None=None)->str:
    src=_read()
    rows=src.get("assets", [])
    if max_rows is not None: rows=rows[:max_rows]

    w_sym=max(3, min(8, max((len(r.get("sym","")) for r in rows), default=3)))

    lines=[]
    lines.append(f"{'sym':<{w_sym}}  {'S':>6}  {'max':>3}  {'p':>5}  {'ctx'}")
    for r in rows:
        sym=r.get("sym","UNK")
        S=float(r.get("S",0.0))
        k,v=_argmax_prob(r)            # k in {'pb','ph','ps'}
        ctx=r.get("ctx")
        lines.append(f"{sym:<{w_sym}}  {S:>6.3f}  {k:>3}  {v:>5.3f}  {ctx}")
    return "\n".join(lines) if lines else "Btop vide"

# Exemple d’usage dans le handler Telegram:
#   from views_btop import render_btop
#   bot.send_message(chat_id, render_btop())        # tout
#   bot.send_message(chat_id, render_btop(20))      # top 20 en ordre fichier

```

### bot/views_heat.py  
Taille: 2 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: bc839008af17167b

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json
from pathlib import Path
from datetime import datetime, timezone

HEATMAP = Path("/opt/scalp/data/heatmap.json")

def render_heat() -> str:
    if not HEATMAP.exists():
        return "Heatmap (indisponible)"
    try:
        obj = json.loads(HEATMAP.read_text())
    except Exception:
        return "Heatmap (erreur lecture)"

    updated = obj.get("updated", "")
    try:
        t = datetime.fromisoformat(updated.replace("Z","+00:00"))
        ts = t.astimezone(timezone.utc).strftime("%H:%M")
    except Exception:
        ts = updated or ""

    # collecte en gardant l'ordre du JSON
    rows = []
    for r in obj.get("rows", []):
        snap = r.get("snap", {})
        vals = [
            int(10*snap.get("60m",0)),
            int(10*snap.get("30m",0)),
            int(10*snap.get("15m",0)),
            int(10*snap.get("now",0)),
        ]
        rows.append((str(r.get("sym","?")).upper(), *vals))

    if not rows:
        return "Heatmap " + ts

    # largeurs de colonnes pour un alignement propre
    w0 = max(len(sym) for sym, *vs in rows)
    # largeur signée par colonne
    w = [max(len(f"{v:+d}") for _, *vs in rows for i,v in enumerate(vs) if i==k) for k in range(4)]

    # formatage
    lines = [f"Heatmap {ts}" if ts else "Heatmap"]
    buf = []
    for i, (sym, v1, v2, v3, v4) in enumerate(rows, 1):
        line = f"{sym:<{w0}}  {v1:+{w[0]}d}  {v2:+{w[1]}d}  {v3:+{w[2]}d}  {v4:+{w[3]}d}"
        buf.append(line)
        if i % 5 == 0:
            lines.append("\n".join(buf))
            buf = []
    if buf:
        lines.append("\n".join(buf))

    return "\n\n".join(lines)

```

### bot/views_history.py  
Taille: 3 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 702f8a3c0c9ce198

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json, datetime as dt
from pathlib import Path
from typing import Any, Dict, List

DATA = Path("/opt/scalp/data")
HIST = DATA/"positions_hist.jsonl"

def _rd(f, n=2):
    try: return f"{float(f):+0.{n}f}$"
    except: return "+0.00$"

def _ts(i)->dt.datetime|None:
    try: return dt.datetime.utcfromtimestamp(int(i))
    except: return None

def _hhmm(t): return t.strftime("%H:%M") if t else "--:--"

def _durm(o,c)->str:
    if not o or not c: return "?"
    m=int((c-o).total_seconds()//60)
    h, m = divmod(m, 60)
    return f"{h}h{m:02d}" if h else f"{m}m"

def _read()->List[Dict[str,Any]]:
    if not HIST.exists(): return []
    out=[]
    for line in HIST.read_text().splitlines():
        try:
            r=json.loads(line)
            if isinstance(r,dict): out.append(r)
        except: pass
    return out

def _args(text:str)->Dict[str,str]:
    t=(text or "").lower().split()
    a={}
    # ex: /history tp sym btc side long last 50
    for i in range(len(t)):
        if t[i] in {"tp","sl","cancelled","rejected"}: a["status"]=t[i]
        if t[i]=="sym" and i+1<len(t): a["sym"]=t[i+1].upper()
        if t[i]=="side" and i+1<len(t): a["side"]=t[i+1].upper()
        if t[i]=="last" and i+1<len(t) and t[i+1].isdigit(): a["last"]=t[i+1]
    return a

def render_history(text:str="")->str:
    q=_args(text)
    rows=_read()
    if not rows: return "History\n(vide)"

    # enrich
    enh=[]
    for r in rows:
        o=_ts(r.get("ts_open")); c=_ts(r.get("ts_close"))
        enh.append({
            **r,
            "_o":o, "_c":c, "_hh":_hhmm(o),
            "_dur":_durm(o,c),
            "_sym":str(r.get("symbol") or r.get("sym") or "?").upper(),
            "_side":str(r.get("side") or "?").upper(),
            "_stat":str(r.get("status") or "").lower(),
            "_reason":str(r.get("reason") or ""),
            "_setup":str(r.get("entry_set") or r.get("setup") or "?"),
        })

    # filtres
    if "sym" in q:   enh=[r for r in enh if r["_sym"]==q["sym"]]
    if "side" in q:  enh=[r for r in enh if r["_side"]==q["side"]]
    if "status" in q:
        s=q["status"]
        if s in {"tp","sl"}:      enh=[r for r in enh if r["_reason"]==s]
        elif s=="cancelled":      enh=[r for r in enh if r["_stat"]=="rejected"]
        elif s=="rejected":       enh=[r for r in enh if r["_stat"]=="rejected"]

    # tri + limite
    enh.sort(key=lambda r: (r["_c"] or r["_o"] or dt.datetime.min))
    n=int(q.get("last","20")) if q.get("last","").isdigit() else 20
    enh=enh[-n:]

    # header
    pnl=[r.get("pnl") for r in enh if isinstance(r.get("pnl"),(int,float,float))]
    pnl_tot=sum(pnl) if pnl else 0.0
    wins=sum(1 for x in pnl if x>0); losses=sum(1 for x in pnl if x<0)
    wr=int(round(100.0*wins/max(1,(wins+losses))))
    best=max(pnl) if pnl else 0.0
    worst=min(pnl) if pnl else 0.0
    out=[f"History n:{len(enh)}  win%:{wr}%  pnl:{pnl_tot:+.2f}$  best:{best:+.2f}$  worst:{worst:+.2f}$"]

    # rendu groupé par jour
    cur=None
    for r in enh:
        day=(r["_c"] or r["_o"] or dt.datetime.utcnow()).strftime("%Y-%m-%d")
        if day!=cur:
            if cur is not None: out.append("")  # ligne vide
            out.append(day); cur=day
        # ligne compacte: heure ouverture • durée • PnL • setup
        pnl_s=_rd(r.get("pnl",0),2)
        setup=r["_setup"]
        out.append(f"{r['_hh']} {r['_sym']} {r['_side']} {r['_dur']} {pnl_s} {setup}{' rej:'+r['_reason'] if r['_stat']=='rejected' else ''}")

    return "\n".join(out)

```

### bot/views_menu.py  
Taille: 309 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: cf9723b2a368078f

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
from telegram import ReplyKeyboardMarkup

def main_menu() -> ReplyKeyboardMarkup:
    keyboard = [
        ["/heat"],
        ["/signals", "/positions"],
        ["/history"]
    ]
    return ReplyKeyboardMarkup(keyboard, resize_keyboard=True)

```

### bot/views_positions.py  
Taille: 3 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 54b4f786cb03928c

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json, datetime
from pathlib import Path
from collections import defaultdict

DATA = Path("/opt/scalp/data")
POSF = DATA/"positions.json"
TOP1 = DATA/"top.json"
TOP2 = DATA/"Btop.json"

def _load_json(p: Path):
    try: return json.loads(p.read_text())
    except Exception: return None

def _top_order() -> list[str]:
    obj = _load_json(TOP1) or _load_json(TOP2) or {}
    syms: list[str] = []
    if isinstance(obj, dict) and "assets" in obj:
        for a in obj["assets"]:
            s = (a.get("sym") if isinstance(a, dict) else a) or ""
            if s: syms.append(str(s).upper())
    elif isinstance(obj, list):
        syms = [str(x).upper() for x in obj]
    return syms

def _pnl_quote(side:str, entry:float, last:float, size:float, lev:int) -> float:
    L = max(int(lev or 1),1)
    return ((last-entry) if str(side).lower().startswith("long") else (entry-last)) * size * L

def _progress(side:str, entry:float, sl:float, tp:float, last:float) -> float:
    s = str(side).lower()
    if entry<=0 or last<=0 or sl==tp: return 0.0
    if s.startswith("long"):
        up = max(tp-entry, 1e-9); dn = max(entry-sl, 1e-9)
        return 100.0*(last-entry)/up if last>=entry else -100.0*(entry-last)/dn
    else:
        up = max(entry-tp, 1e-9); dn = max(sl-entry, 1e-9)
        return 100.0*(entry-last)/up if last<=entry else -100.0*(last-entry)/dn

def render_positions(n:int=100) -> str:
    obj = _load_json(POSF) or {}
    rows = obj.get("positions", []) if isinstance(obj, dict) else []
    rows = [p for p in rows if str(p.get("status","open")).lower() in ("open","opened","opening","pending","")]
    if not rows:
        return "Positions\n(pas de positions)"

    # agrégation par coin
    agg = defaultdict(lambda: {"count":0, "pnl":0.0, "wprog":0.0, "w":0.0})
    total = 0.0
    for r in rows[:n]:
        sym = str((r.get("symbol") or r.get("sym") or "?")).upper()
        side = r.get("side","")
        entry=float(r.get("entry",0) or 0)
        sl   =float(r.get("sl",0) or 0)
        tp   =float(r.get("tp",0) or 0)
        last =float(r.get("last", entry) or entry)
        size =float(r.get("size", r.get("qty",0)) or 0)
        lev  =int(r.get("leverage", r.get("lev",1)) or 1)
        pnl  = r.get("pnl"); 
        if not isinstance(pnl,(int,float)): pnl=_pnl_quote(side,entry,last,size,lev)
        prog = _progress(side,entry,sl,tp,last)
        w = max(size*lev, 0.0)
        A = agg[sym]; A["count"]+=1; A["pnl"]+=float(pnl); A["wprog"]+=prog*w; A["w"]+=w
        total += float(pnl)

    # ordre: 5 fixes puis le reste, selon top.json, puis les absents à la fin
    top = _top_order()
    fixed = top[:5]
    rest  = top[5:]
    order = [s for s in fixed+rest if s in agg]
    others = [s for s in agg.keys() if s not in order]
    ordered_syms = order + others

    # rendu compact, saut de ligne toutes les 5
    lines = [f"Positions  PnL:{total:+.2f}$"]
    buf = []
    for i, sym in enumerate(ordered_syms, 1):
        A = agg[sym]
        avg_prog = (A["wprog"]/A["w"]) if A["w"]>0 else 0.0
        buf.append(f"{sym} ({A['count']})  {A['pnl']:+0.3f}$  {int(round(avg_prog)):+d}%")
        if i % 5 == 0:
            lines.append("\n".join(buf))
            buf = []
    if buf: lines.append("\n".join(buf))
    return "\n\n".join(lines)

```

### bot/views_signals.py  
Taille: 969 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: e3f8c5f0a3c4459d

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json, datetime
from pathlib import Path

DATA = Path("/opt/scalp/data")
SIGF = DATA/"signals.json"

def _now(ts):
    try: return datetime.datetime.fromisoformat(ts.replace("Z","+00:00")).strftime("%H:%M")
    except: return "--:--"

def render_signals(n:int=10)->str:
    try: obj=json.loads(SIGF.read_text())
    except: return "Signals\n(erreur lecture)"
    sigs = obj.get("signals", obj if isinstance(obj,list) else [])
    if not sigs: return "Signals\n(vide)"
    hhmm=_now(obj.get("updated", sigs[-1].get("timestamp","")))
    lines=[f"Signals {hhmm}"]
    for s in sigs[-n:]:
        sym=str(s.get("sym") or "?").upper()
        side=s.get("side","?")
        qty=s.get("size",0); lev=s.get("leverage",1)
        entry=s.get("price_entry",0); sl=s.get("sl",0); tp=s.get("tp",0)
        lines.append(f"{sym} {side} {qty:g}x{lev} {entry:.4f}/{sl:.4f}/{tp:.4f}")
    return "\n".join(lines)

```

### bot/views_top_patch.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 63c4b73df8a6daed

```py
# -*- coding: utf-8 -*-
import json, pathlib, time
DATA = pathlib.Path("/opt/scalp/data")

def _hmm(secs:int)->str:
    m,s=divmod(max(0,secs),60); h,m=divmod(m,60)
    return f"{h:d}:{m:02d}" if h else f"{m:d}:{s:02d}"

def _next_5m_eta()->str:
    now=int(time.time()); return _hmm(300-(now%300))

def render_top15():
    rows=[]
    p=DATA/"top.json"
    if p.exists():
        try:
            obj=json.loads(p.read_text())
            rows = obj.get("rows") or obj.get("syms") or []
        except: rows=[]
    if not rows:
        u=DATA/"universe.txt"
        if u.exists(): rows=[l.strip().upper() for l in u.read_text().splitlines() if l.strip()]
    rows=rows[:15]

    t=f"<pre><b>Top15   {_next_5m_eta()}</b>\n"
    out=[t]
    # largeur compacte: " 1.BTC" -> 6 chars
    fmt=lambda i,sym: f"{i:>2}.{sym:<3}"
    col1=[fmt(i+1, rows[i])      if i     <len(rows) else "" for i in range(0,5)]
    col2=[fmt(i+6, rows[i+5])    if i+5   <len(rows) else "" for i in range(0,5)]
    col3=[fmt(i+11,rows[i+10])   if i+10  <len(rows) else "" for i in range(0,5)]
    for a,b,c in zip(col1,col2,col3):
        out.append(f"{a:<8}{b:<8}{c}")
    out.append("</pre>")
    return "\n".join(out)

```

### bot_runner.py  
Taille: 5 KB  |  MàJ: 2025-09-19 23:11:05  |  SHA256: 890abf61436093b9

```py
import os, json
from pathlib import Path
from datetime import datetime as dt
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes
from tools.trade_state import promote_signals_to_positions, reconcile_with_ccxt, load_all

ROOT = Path("/opt/scalp"); DATA = ROOT / "data"
TOKEN   = os.getenv("TELEGRAM_TOKEN", "PLACE_TOKEN")
CHAT_ID = int(os.getenv("TELEGRAM_CHAT_ID", "7552287774"))

def _fmt_time(): return dt.utcnow().strftime("%H:%M")
def _replyable(update): return update and update.message and update.effective_chat and (CHAT_ID==0 or update.effective_chat.id==CHAT_ID)

async def status(u:Update, c:ContextTypes.DEFAULT_TYPE):
    if not _replyable(u): return
    await u.message.reply_text("active")

async def heat(u:Update, c:ContextTypes.DEFAULT_TYPE):
    if not _replyable(u): return
    f = DATA/"s_history"/"heatmap.json"
    if not f.exists(): 
        await u.message.reply_text("heatmap: (vide)")
        return
    obj = json.loads(f.read_text()); rows = obj.get("rows",[])
    lines=[]
    for r in rows:
        s = r.get("sym","").replace("USDT:USDT","")
        vals = r.get("S",[])  # S60,S30,S15, now
        four = [f"{int(round(x)):>+3}" for x in (vals[-4:] if len(vals)>=4 else vals)]
        lines.append(f"{s:5}  {' '.join(four)}")
    msg = "Heatmap "+_fmt_time()+"\n" + "\n".join(lines)
    await u.message.reply_text(msg)

async def top(u:Update, c:ContextTypes.DEFAULT_TYPE):
    if not _replyable(u): return
    f = DATA/"top.json"
    if not f.exists(): 
        await u.message.reply_text("top: (vide)")
        return
    rows = json.loads(f.read_text()).get("scored",[])[:15]
    names = [x.get("symbol","").replace("/USDT:USDT","") for x in rows]
    chunks=[names[i:i+3] for i in range(0,len(names),3)]
    lines=["  ".join([f"{n:6}" for n in ch]) for ch in chunks]
    await u.message.reply_text("Top (vol×vola) "+_fmt_time()+"\n"+"\n".join(lines))

def _fmt_money(x): 
    try: return f"{float(x):+.2f}$"
    except: return str(x)

async def signals(u:Update, c:ContextTypes.DEFAULT_TYPE):
    if not _replyable(u): return
    sigs, _, _ = load_all()
    if not sigs: await u.message.reply_text("signals: (0)"); return
    lines=[]
    for s in sigs[:15]:
        sym = s.get("sym","").replace("USDTUSDT","USDT").replace("USDT:USDT","")
        lines.append(f"{sym:10} {s.get('side',''):5} @ {s.get('px')}")
    await u.message.reply_text("Signals "+_fmt_time()+"\n"+"\n".join(lines))

async def positions(u:Update, c:ContextTypes.DEFAULT_TYPE):
    if not _replyable(u): return
    _, pos, _ = load_all()
    if not pos: await u.message.reply_text("positions: (0)"); return
    lines=[]
    for p in pos[:20]:
        sym=p.get("sym",""); side=p.get("side","")
        lines.append(f"{sym:12} {side:5} {p.get('qty',0):.3f} @ {p.get('entry_px')}")
    await u.message.reply_text("Positions "+_fmt_time()+"\n"+"\n".join(lines))

async def history(u:Update, c:ContextTypes.DEFAULT_TYPE):
    if not _replyable(u): return
    _, _, hist = load_all()
    if not hist: await u.message.reply_text("history: (0)"); return
    last = hist[-10:][::-1]
    lines=[f"{h.get('sym',''):10} {_fmt_money(h.get('pnl',0))}" for h in last]
    await u.message.reply_text("History "+_fmt_time()+"\n"+"\n".join(lines))

def _bitget_fetcher():
    key=os.getenv("BITGET_API_KEY"); sec=os.getenv("BITGET_API_SECRET"); ph=os.getenv("BITGET_PASSPHRASE")
    if not (key and sec and ph): return None
    try:
        import ccxt
        ex = ccxt.bitget({"apiKey":key,"secret":sec,"password":ph,"options":{"defaultType":"swap"}})
        ex.load_markets()
        def fetch(sym):
            m = sym.replace("USDT:USDT","/USDT:USDT").replace("USDTUSDT","/USDT:USDT")
            m = m if "/" in m else sym
            # size: via fetchPositions/positions risk; fallback ticker last
            last = ex.fetch_ticker(sym.replace("USDT:USDT","/USDT:USDT"))["last"]
            size = 0.0
            try:
                for p in ex.fetch_positions([sym.replace("USDT:USDT","/USDT:USDT")]):
                    if p.get("symbol")==sym.replace("USDT:USDT","/USDT:USDT"):
                        size = float(p.get("contracts") or p.get("contractsSize") or 0)
            except: pass
            return {"last": float(last), "size": float(size)}
        return fetch
    except Exception:
        return None

async def sync(u:Update, c:ContextTypes.DEFAULT_TYPE):
    if not _replyable(u): return
    added = promote_signals_to_positions(auto_exec=True, max_new=10)
    fetch = _bitget_fetcher()
    res = reconcile_with_ccxt(fetch)
    await u.message.reply_text(f"sync: +{added} promoted, closed={res['closed']}, open={res['open']}")

def main():
    app = ApplicationBuilder().token(TOKEN).build()
    app.add_handler(CommandHandler("status",   status))
    app.add_handler(CommandHandler("heat",     heat))
    app.add_handler(CommandHandler("top",      top))
    app.add_handler(CommandHandler("signals",  signals))
    app.add_handler(CommandHandler("positions",positions))
    app.add_handler(CommandHandler("history",  history))
    app.add_handler(CommandHandler("sync",     sync))
    app.run_polling(close_loop=False)

if __name__ == "__main__":
    main()

```

### bumppush.py  
Taille: 15 KB  |  MàJ: 2025-09-20 08:34:01  |  SHA256: c2471b84c03ed917

```py
from __future__ import annotations
import os
import sys
import stat
import io
import re
import json
import tarfile
import hashlib
import subprocess
from datetime import datetime
from pathlib import Path
from typing import Iterable, Tuple, Dict, Optional

# ---------- Configuration par défaut ----------
ROOT = Path.cwd()
NOW = datetime.now().strftime("%Y%m%d-%H%M%S")
OUT_DIR = ROOT / "project_dump"
OUT_DIR.mkdir(exist_ok=True)
TREE_TXT = OUT_DIR / f"tree-{NOW}.txt"
DUMP_MD = OUT_DIR / f"code_dump-{NOW}.md"
SLIM_DIR = OUT_DIR / "slim"
SLIM_DIR.mkdir(exist_ok=True)
ARCHIVE = OUT_DIR / f"dump_bundle-{NOW}.tar.gz"

# Seuils et extensions
MAX_INLINE_BYTES = 400_000        # taille max d’un fichier inclus en entier dans le dump
TRUNCATE_TARGET = 80_000          # si > MAX_INLINE_BYTES et texte, tronquer à cette taille
LARGE_FILE_BYTES = 5_000_000      # seuil pour fabriquer une copie "slim" avant push
TEXT_EXT = {
    ".py",".pyi",".pyx",".pxd",".pxi",".pyw",
    ".md",".rst",".txt",".toml",".ini",".cfg",".conf",".json",".yml",".yaml",
    ".gitignore",".gitattributes",".editorconfig",".env.example",
    ".cfg",".in",".pip",".requirements",".dockerfile",".sh",".bat",".ps1",
    ".html",".css",".js",".ts",".jsx",".tsx",
    ".cfg",".properties",".service",".desktop"
}
CODE_FIRST_EXT = {".py",".toml",".ini",".cfg",".conf",".json",".yml",".yaml",".md",".sh"}
NOTEBOOK_EXT = {".ipynb"}

# Motifs d’exclusion
EXCLUDED_DIRS = {
    ".git",".github",".venv","venv","env","ENV","dist","build","site-packages",
    "__pycache__",".mypy_cache",".pytest_cache",".ruff_cache",".idea",".vscode",
    ".tox",".nox",".cache",".egg-info",".DS_Store","node_modules","coverage",
    "data","datasets","output","outputs","logs","log","tmp","temp"
}
EXCLUDED_FILE_PATTERNS = [
    r".*\.log$", r".*\.csv$", r".*\.tsv$", r".*\.parquet$", r".*\.feather$",
    r".*\.npy$", r".*\.npz$", r".*\.pkl$", r".*\.pickle$", r".*\.joblib$",
    r".*\.h5$", r".*\.hdf5$", r".*\.pt$", r".*\.onnx$", r".*\.tflite$",
    r".*\.pdf$", r".*\.png$", r".*\.jpg$", r".*\.jpeg$", r".*\.gif$", r".*\.svg$",
    r".*\.ico$", r".*\.mp4$", r".*\.mp3$", r".*\.wav$", r".*\.flac$",
    r".*\.zip$", r".*\.tar$", r".*\.tar\.gz$", r".*\.7z$", r".*\.rar$",
    r"^\.",  # fichiers cachés
]
EXCL_FILE_RE = [re.compile(p, re.IGNORECASE) for p in EXCLUDED_FILE_PATTERNS]

# ---------- Utilitaires ----------
def is_hidden(path: Path) -> bool:
    name = path.name
    if name.startswith("."):
        return True
    try:
        if os.name == "nt":
            import ctypes
            attrs = ctypes.windll.kernel32.GetFileAttributesW(str(path))
            return bool(attrs & 2)
        else:
            return False
    except Exception:
        return False

def should_exclude(path: Path) -> bool:
    if any(part in EXCLUDED_DIRS for part in path.parts):
        return True
    name = path.name
    for rx in EXCL_FILE_RE:
        if rx.match(name):
            return True
    return False

def is_textual(p: Path) -> bool:
    if p.suffix.lower() in TEXT_EXT or p.suffix.lower() in NOTEBOOK_EXT:
        return True
    try:
        with open(p, "rb") as f:
            chunk = f.read(1024)
        if b"\x00" in chunk:
            return False
        # Heuristique simple
        text_chars = bytearray({7,8,9,10,12,13,27} | set(range(0x20,0x100)))
        return all(c in text_chars for c in chunk)
    except Exception:
        return False

def human(n: int) -> str:
    for unit in ["B","KB","MB","GB","TB"]:
        if n < 1024:
            return f"{n:.0f} {unit}"
        n /= 1024
    return f"{n:.0f} PB"

def rel(p: Path) -> str:
    try:
        return str(p.relative_to(ROOT))
    except Exception:
        return str(p)

def file_mtime(p: Path) -> str:
    try:
        ts = p.stat().st_mtime
        return datetime.fromtimestamp(ts).strftime("%Y-%m-%d %H:%M:%S")
    except Exception:
        return "NA"

def sha256sum(p: Path) -> str:
    h = hashlib.sha256()
    with open(p, "rb") as f:
        for chunk in iter(lambda: f.read(8192), b""):
            h.update(chunk)
    return h.hexdigest()[:16]

def load_env_file(dotenv_path: Path) -> Dict[str,str]:
    env = {}
    if not dotenv_path.exists():
        return env
    for line in dotenv_path.read_text(encoding="utf-8", errors="ignore").splitlines():
        line = line.strip()
        if not line or line.startswith("#"):
            continue
        if "=" not in line:
            continue
        k,v = line.split("=",1)
        env[k.strip()] = v.strip().strip('"').strip("'")
    return env

# ---------- Arborescence ----------
def build_tree(root: Path) -> Tuple[str, list[Path]]:
    lines = []
    kept_files: list[Path] = []
    for dirpath, dirnames, filenames in os.walk(root):
        dirpath = Path(dirpath)
        # Filtrer dossiers sur place
        dirnames[:] = [d for d in dirnames
                       if d not in EXCLUDED_DIRS and not d.startswith(".")]
        # Entrée dossier
        if dirpath == root:
            prefix = "."
        else:
            prefix = rel(dirpath)
        lines.append(f"[{prefix}]")
        # Fichiers triés par nom
        for fn in sorted(filenames):
            p = dirpath / fn
            if is_hidden(p) or should_exclude(p):
                continue
            try:
                st = p.stat()
                size = st.st_size
                mtime = file_mtime(p)
                lines.append(f"  {fn}  | {human(size):>8} | {mtime}")
                kept_files.append(p)
            except Exception:
                continue
    return "\n".join(lines), kept_files

# ---------- Dump de code ----------
def read_text_safely(p: Path, max_bytes: int) -> Tuple[str,bool]:
    size = p.stat().st_size
    truncated = False
    if size <= max_bytes:
        return p.read_text(encoding="utf-8", errors="replace"), False
    # Fichier large
    truncated = True
    with open(p, "rb") as f:
        data = f.read(TRUNCATE_TARGET)
    return data.decode("utf-8", errors="replace") + "\n\n# [TRONQUÉ]\n", truncated

def strip_notebook_outputs(data: dict) -> dict:
    nb = dict(data)  # shallow copy
    cells = nb.get("cells", [])
    for c in cells:
        if c.get("cell_type") == "code":
            c["outputs"] = []
            c["execution_count"] = None
    md = nb.get("metadata", {})
    for k in list(md.keys()):
        if k.lower() in {"widgets","language_info","kernelspec","colab"}:
            md.pop(k, None)
    nb["metadata"] = md
    nb["cells"] = cells
    return nb

def dump_code(files: Iterable[Path]) -> None:
    # Ordonner: code d’abord
    def key(p: Path):
        ext = p.suffix.lower()
        return (0 if ext in CODE_FIRST_EXT or ext in NOTEBOOK_EXT else 1, rel(p).lower())

    files_sorted = sorted(files, key=key)

    with open(DUMP_MD, "w", encoding="utf-8") as out:
        out.write(f"# DUMP DE PROJET — {NOW}\n\n")
        out.write("## Arborescence filtrée\n\n")
        out.write("Voir `tree` ci-dessous.\n\n")
        out.write("## Détails de code\n\n")
        for p in files_sorted:
            try:
                ext = p.suffix.lower()
                size = p.stat().st_size
                mtime = file_mtime(p)
                header = f"### {rel(p)}  \nTaille: {human(size)}  |  MàJ: {mtime}  |  SHA256: {sha256sum(p)}\n\n"
                out.write(header)
                if ext in NOTEBOOK_EXT:
                    try:
                        data = json.loads(p.read_text(encoding="utf-8", errors="replace"))
                        slim = strip_notebook_outputs(data)
                        text = json.dumps(slim, ensure_ascii=False, indent=2)
                        if len(text.encode("utf-8")) > MAX_INLINE_BYTES:
                            # tronquer JSON
                            text = text[:TRUNCATE_TARGET].rstrip() + "\n...\n# [TRONQUÉ]\n"
                            truncated = True
                        else:
                            truncated = False
                        out.write("```json\n")
                        out.write(text)
                        out.write("\n```\n\n")
                        if truncated:
                            out.write("> Note: Notebook tronqué pour la lisibilité.\n\n")
                    except Exception:
                        # fallback binaire
                        out.write("_Notebook non lisible, contenu ignoré._\n\n")
                elif is_textual(p):
                    text, truncated = read_text_safely(p, MAX_INLINE_BYTES)
                    fence = "```" + (ext[1:] if ext.startswith(".") else "")
                    out.write(fence + "\n")
                    out.write(text)
                    out.write("\n```\n\n")
                    if truncated:
                        out.write("> Note: Fichier tronqué pour rester sous les limites.\n\n")
                else:
                    out.write("_Binaire ignoré._\n\n")
            except Exception as e:
                out.write(f"_Erreur lecture: {e}_\n\n")

def write_tree_file(tree_txt: str) -> None:
    with open(TREE_TXT, "w", encoding="utf-8") as f:
        f.write(f"# TREE — {NOW}\n\n")
        f.write("Chemins relatifs à la racine du repo.\n\n")
        f.write(tree_txt)
        f.write("\n")

# ---------- Slim copies pour gros fichiers ----------
def make_slim_copy(src: Path, dst_root: Path) -> Optional[Path]:
    try:
        relp = Path(rel(src))
        outp = dst_root / relp
        outp.parent.mkdir(parents=True, exist_ok=True)
        if src.suffix.lower() in NOTEBOOK_EXT:
            data = json.loads(src.read_text(encoding="utf-8", errors="replace"))
            slim = strip_notebook_outputs(data)
            outp.write_text(json.dumps(slim, ensure_ascii=False, separators=(",",":")), encoding="utf-8")
            return outp
        if is_textual(src):
            # Tronquer texte long
            with open(src, "rb") as f:
                chunk = f.read(TRUNCATE_TARGET)
            outp.write_bytes(chunk)
            return outp
        # Binaire: on ignore
        return None
    except Exception:
        return None

def prepare_slim_artifacts(files: Iterable[Path]) -> list[Path]:
    produced = []
    for p in files:
        try:
            if p.stat().st_size >= LARGE_FILE_BYTES:
                slim = make_slim_copy(p, SLIM_DIR)
                if slim:
                    produced.append(slim)
        except FileNotFoundError:
            continue
    return produced

# ---------- Git helpers ----------
def run(cmd: list[str], env: Optional[Dict[str,str]]=None, check: bool=True) -> subprocess.CompletedProcess:
    return subprocess.run(cmd, cwd=str(ROOT), env=env or os.environ.copy(),
                          stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, check=check)

def detect_current_branch() -> str:
    try:
        cp = run(["git","rev-parse","--abbrev-ref","HEAD"])
        return cp.stdout.strip()
    except Exception:
        return "main"

def ensure_git_repo() -> None:
    try:
        run(["git","rev-parse","--is-inside-work-tree"])
    except Exception:
        print("Erreur: ce dossier n’est pas un dépôt Git.", file=sys.stderr)
        sys.exit(2)

def git_setup_env_from_scalp(envfile: Path = Path("/etc/scalp.env")) -> Dict[str,str]:
    env = os.environ.copy()
    parsed = load_env_file(envfile)
    env.update(parsed)
    # Support variables communes
    ssh_key = parsed.get("SSH_KEY_PATH") or parsed.get("GIT_SSH_KEY") or ""
    token = parsed.get("GH_TOKEN") or parsed.get("GITHUB_TOKEN") or ""
    if ssh_key:
        env["GIT_SSH_COMMAND"] = f"ssh -i {ssh_key} -o IdentitiesOnly=yes -o StrictHostKeyChecking=no"
    # Auteur si fournis
    if parsed.get("GIT_AUTHOR_NAME"):
        env["GIT_AUTHOR_NAME"] = parsed["GIT_AUTHOR_NAME"]
        env["GIT_COMMITTER_NAME"] = parsed["GIT_AUTHOR_NAME"]
    if parsed.get("GIT_AUTHOR_EMAIL"):
        env["GIT_AUTHOR_EMAIL"] = parsed["GIT_AUTHOR_EMAIL"]
        env["GIT_COMMITTER_EMAIL"] = parsed["GIT_AUTHOR_EMAIL"]
    # Si token et remote https, on le place dans l’URL au vol
    try:
        remote = parsed.get("GIT_REMOTE","origin")
        cp = run(["git","remote","get-url", remote], check=False)
        url = cp.stdout.strip()
        if token and url.startswith("https://") and "@" not in url:
            # https://github.com/user/repo.git -> https://TOKEN@github.com/user/repo.git
            parts = url.split("https://",1)[1]
            auth_url = "https://" + token + "@" + parts
            run(["git","remote","set-url", remote, auth_url], env=env, check=False)
    except Exception:
        pass
    return env

def git_commit_and_push(env: Dict[str,str], message: str) -> None:
    branch = detect_current_branch()
    dump_branch = f"dump/{NOW}"
    # créer branche de dump pour isoler
    try:
        run(["git","checkout","-b", dump_branch], env=env)
    except subprocess.CalledProcessError:
        run(["git","checkout", dump_branch], env=env, check=False)
    # add artefacts
    run(["git","add", rel(OUT_DIR)], env=env)
    # facultatif: ajouter copies slim
    if SLIM_DIR.exists():
        run(["git","add", rel(SLIM_DIR)], env=env, check=False)
    # Commit
    run(["git","commit","-m", message], env=env, check=False)
    # Push
    remote = os.environ.get("GIT_REMOTE") or "origin"
    run(["git","push","-f", remote, dump_branch], env=env, check=False)
    # revenir sur la branche d’origine
    run(["git","checkout", branch], env=env, check=False)

# ---------- Archive ----------
def build_archive(paths: Iterable[Path]) -> None:
    with tarfile.open(ARCHIVE, "w:gz") as tar:
        for p in paths:
            tar.add(p, arcname=p.name)

# ---------- Main ----------
def main() -> None:
    ensure_git_repo()
    tree_txt, kept_files = build_tree(ROOT)
    write_tree_file(tree_txt)
    dump_code(kept_files)
    # écrire un sommaire court en tête du dump
    with open(DUMP_MD, "r+", encoding="utf-8") as f:
        content = f.read()
        header = [
            f"# DUMP DE PROJET — {NOW}",
            "",
            f"- Racine: `{ROOT}`",
            f"- Fichier d’arborescence: `{TREE_TXT.name}`",
            f"- Copies slim: `{rel(SLIM_DIR)}`",
            "",
            "## Arborescence filtrée",
            "```text",
            tree_txt,
            "```",
            "",
            "## Détails de code",
            ""
        ]
        f.seek(0)
        f.write("\n".join(header) + content.split("## Détails de code",1)[-1])
        f.truncate()

    # Copies slim pour gros fichiers
    slimmed = prepare_slim_artifacts(kept_files)
    # Archive bundle pratique
    build_archive([TREE_TXT, DUMP_MD])

    # Git push avec /etc/scalp.env si disponible
    env = git_setup_env_from_scalp(Path("/etc/scalp.env"))
    # Marquer les fichiers générés pour Git
    msg = f"dump: arborescence et code {NOW} ({len(kept_files)} fichiers, {len(slimmed)} slim)"
    git_commit_and_push(env, msg)

    print("OK")
    print(f"- Arborescence: {TREE_TXT}")
    print(f"- Dump code:   {DUMP_MD}")
    print(f"- Slim dir:    {SLIM_DIR} ({len(slimmed)} fichiers)")
    print(f"- Archive:     {ARCHIVE}")

if __name__ == "__main__":
    main()

```

### execution/bitget_client.py  
Taille: 752 B  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 47b674b021fb7b32

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import os, ccxt

def get_mode()->str:
    m = os.getenv("EXEC_MODE","PAPER").upper()
    return "REAL" if m in ("REAL","LIVE") else "PAPER"

def client_or_none():
    if get_mode()=="PAPER": return None
    api, sec, pwd = os.getenv("BITGET_API_KEY"), os.getenv("BITGET_API_SECRET"), os.getenv("BITGET_PASSPHRASE")
    if not (api and sec and pwd): raise RuntimeError("EENV: clés Bitget manquantes")
    ex = ccxt.bitget({
        "apiKey": api, "secret": sec, "password": pwd,
        "enableRateLimit": True,
        "options": {"defaultType":"swap"},
    })
    ex.load_markets()
    return ex

def symbol_to_bitget(sym:str)->str:
    return f"{sym.upper().split('/')[0]}/USDT:USDT"

```

### execution/executor.py  
Taille: 4 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 914c478c3146997a

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json, os, time, uuid, shutil
from pathlib import Path
from typing import Dict, Any
from .bitget_client import client_or_none, symbol_to_bitget, get_mode
from .price_feed import last_price
from .storage import append_order, load_positions, save_positions

SIGNALS_DIR = Path("/opt/scalp/data/signals")
PROC_DIR    = SIGNALS_DIR/"processed"
LOGF        = Path("/opt/scalp/data/logs/executor.log")

FEE_RATE = float(os.getenv("FEE_RATE", "0.0006"))   # 6 bps estimé par côté
SLIPPAGE = float(os.getenv("EXE_SLIPPAGE", "0.0005"))

def log(msg:str):
    LOGF.parent.mkdir(parents=True, exist_ok=True)
    with LOGF.open("a") as f:
        f.write(time.strftime("%Y-%m-%d %H:%M:%S ", time.gmtime())+msg+"\n")

def _fill_price(sym:str, side:str, wanted:float|None)->float|None:
    p = last_price(sym)
    if p is None: return None
    return p*(1+SLIPPAGE if side=="long" else 1-SLIPPAGE)

def exec_paper(sig:Dict[str,Any])->Dict[str,Any]:
    sym=sig["sym"]; side=sig["side"]; qty=float(sig.get("size",0.0))
    px=_fill_price(sym, side, sig.get("price_entry"))
    if px is None or qty<=0:
        raise RuntimeError("EPRICE: prix ou taille indisponible")
    order_id=str(uuid.uuid4())
    filled_qty=qty; filled_price=px
    fees = FEE_RATE * filled_qty * filled_price
    return {"mode":"PAPER","order_id":order_id,"status":"filled","price":filled_price,"qty":filled_qty,"fee":fees}

def exec_real(sig:Dict[str,Any])->Dict[str,Any]:
    ex=client_or_none()
    sym_mkt=symbol_to_bitget(sig["sym"])
    side=sig["side"]
    qty=float(sig.get("size",0.0))
    if qty<=0: raise RuntimeError("ESIZE: taille nulle")
    # market order
    ord_side="buy" if side=="long" else "sell"
    o=ex.create_order(sym_mkt, "market", ord_side, qty)
    # Bitget renvoie average fill price / filled size si dispo
    px=float(o.get("average") or o.get("price") or 0.0)
    qf=float(o.get("filled") or o.get("amount") or qty)
    fee=float(o.get("fee") or 0.0)
    return {"mode":"REAL","order_id":o.get("id","?"),"status":o.get("status","filled"),"price":px,"qty":qf,"fee":fee}

def create_position(sig:Dict[str,Any], exe:Dict[str,Any])->Dict[str,Any]:
    now=int(time.time())
    return {
        "id": exe["order_id"],
        "sym": sig["sym"],
        "side": sig["side"],           # long/short
        "entry_price": exe["price"],
        "qty": exe["qty"],
        "fee_open": exe.get("fee",0.0),
        "sl": float(sig.get("sl",0.0)),
        "tp": float(sig.get("tp",0.0)),
        "opened_at": now,
        "entry_set": sig.get("entry_set"),
        "mode": exe.get("mode"),
        "status":"open",
        "trail_started": False,
        "trail_ref": None
    }

def process_one_file(p:Path):
    try:
        sig=json.loads(p.read_text())
        # attentes: sym, side, price_entry, sl, tp, size, entry_set
        if not all(k in sig for k in ("sym","side","sl","tp","size","entry_set")):
            raise RuntimeError("EBAD: signal incomplet")
        mode=get_mode()
        exe = exec_real(sig) if mode=="REAL" else exec_paper(sig)
        pos = create_position(sig, exe)
        # append order + add to positions
        append_order({
            "t": int(time.time()), "mode":exe["mode"], "order_id":exe["order_id"], "sym":sig["sym"],
            "side":sig["side"], "price":exe["price"], "qty":exe["qty"], "fee":exe.get("fee",0.0),
            "entry_set": sig.get("entry_set")
        })
        cur=load_positions(); cur.append(pos); save_positions(cur)
        # archive signal
        PROC_DIR.mkdir(parents=True, exist_ok=True)
        shutil.move(str(p), PROC_DIR/f"{int(time.time())}_{p.name}")
        log(f"EXEC {mode} {sig['sym']} {sig['side']} px={exe['price']:.4f} qty={exe['qty']:.6f}")
    except Exception as e:
        log(f"ERR processing {p.name}: {e}")

def main():
    for p in sorted(SIGNALS_DIR.glob("*.json")):
        if p.name=="signals.json": continue
        process_one_file(p)

if __name__=="__main__":
    main()

```

### execution/monitor.py  
Taille: 3 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: f592784cd8ab1c3a

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import time, os
from pathlib import Path
from typing import List, Dict, Any
from .price_feed import last_price
from .storage import load_positions, save_positions, append_history, append_order
from .bitget_client import client_or_none, symbol_to_bitget, get_mode

LOGF = Path("/opt/scalp/data/logs/monitor.log")
FEE_RATE = float(os.getenv("FEE_RATE", "0.0006"))

def log(msg:str):
    LOGF.parent.mkdir(parents=True, exist_ok=True)
    LOGF.open("a").write(time.strftime("%Y-%m-%d %H:%M:%S ", time.gmtime())+msg+"\n")

def close_position(pos:Dict[str,Any], reason:str, price:float):
    mode=get_mode()
    qty=pos["qty"]
    sym=pos["sym"]
    side_close = "sell" if pos["side"]=="long" else "buy"
    fee_close=0.0
    if mode=="REAL":
        try:
            ex=client_or_none()
            o=ex.create_order(symbol_to_bitget(sym), "market", side_close, qty)
            fee_close=float(o.get("fee") or 0.0)
            price=float(o.get("average") or o.get("price") or price)
        except Exception as e:
            log(f"ERR close {sym}: {e}")
    else:
        fee_close = FEE_RATE * qty * price

    # realized pnl
    signed = 1.0 if pos["side"]=="long" else -1.0
    pnl = (price - pos["entry_price"]) * qty * signed - (pos["fee_open"] + fee_close)

    # history append
    append_history({
        "id": pos["id"], "sym": sym, "side": pos["side"], "entry_price": pos["entry_price"],
        "exit_price": price, "qty": qty, "opened_at": pos["opened_at"], "closed_at": int(time.time()),
        "reason": reason, "fee_open": pos["fee_open"], "fee_close": fee_close, "pnl": pnl,
        "entry_set": pos.get("entry_set"), "mode": mode
    })

    append_order({"t": int(time.time()), "mode":mode, "order_id":pos["id"]+"-close", "sym":sym,
                  "side":side_close, "price":price, "qty":qty, "fee":fee_close, "close_reason":reason})

def monitor_once():
    arr=load_positions()
    out=[]
    for pos in arr:
        if pos.get("status")!="open":
            out.append(pos); continue
        sym=pos["sym"]; cur=last_price(sym)
        if cur is None:
            out.append(pos); continue
        # PnL live
        signed = 1.0 if pos["side"]=="long" else -1.0
        upnl = (cur - pos["entry_price"]) * pos["qty"] * signed
        pos["pnl_unreal"] = upnl
        pos["last_price"] = cur
        # SL/TP check
        sl=float(pos.get("sl") or 0.0); tp=float(pos.get("tp") or 0.0)
        if pos["side"]=="long":
            if sl>0 and cur<=sl:
                close_position(pos, "SL", cur); pos["status"]="closed"
            elif tp>0 and cur>=tp:
                close_position(pos, "TP", cur); pos["status"]="closed"
        else:
            if sl>0 and cur>=sl:
                close_position(pos, "SL", cur); pos["status"]="closed"
            elif tp>0 and cur<=tp:
                close_position(pos, "TP", cur); pos["status"]="closed"
        # trailing simple: active après +1xATR, si trail_ref absent on le fixe à entry_price
        # (ATR exact n'est pas stocké ici; à perfectionner plus tard)
        if pos["status"]=="open":
            out.append(pos)
    save_positions(out)

if __name__=="__main__":
    monitor_once()

```

### execution/price_feed.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 7563f13eac7f6b43

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import csv, os
from pathlib import Path
from typing import Optional
from .bitget_client import client_or_none, symbol_to_bitget, get_mode

CAND = Path("/opt/scalp/data/candles/1m")

def last_close_from_csv(sym:str)->Optional[float]:
    f=CAND/f"{sym}.csv"
    if not f.exists(): return None
    try:
        last=None
        with f.open() as fh:
            r=csv.reader(fh)
            header=next(r, None)
            # si header, détecte
            try:
                int(header[0]); row=header
                last=row
            except Exception:
                pass
            for row in r:
                last=row
        if not last: return None
        c=float(last[4])  # ts,o,h,l,c,v
        return c
    except Exception:
        return None

def last_price(sym:str)->Optional[float]:
    # 1) CSV 1m
    p = last_close_from_csv(sym)
    if p is not None: return p
    # 2) Ticker ccxt si REAL
    if get_mode()=="REAL":
        try:
            ex=client_or_none()
            t=ex.fetch_ticker(symbol_to_bitget(sym))
            return float(t["last"])
        except Exception:
            return None
    return None

```

### execution/storage.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 13ee75ffc09c907e

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json, os, time
from pathlib import Path
from typing import Dict, Any, List

BASE=Path("/opt/scalp/data")
ORDERS = BASE/"orders/orders.json"
POSIT  = BASE/"positions/positions.json"
HIST   = BASE/"history/history.json"

def _read(p:Path, default):
    try: return json.loads(p.read_text())
    except Exception: return default

def _write_atomic(p:Path, obj):
    tmp=p.with_suffix(".tmp")
    tmp.write_text(json.dumps(obj, ensure_ascii=False, separators=(",",":")))
    os.replace(tmp, p)

def append_order(o:Dict[str,Any]):
    d=_read(ORDERS, {"orders":[]})
    arr=d.get("orders",[])
    arr.append(o)
    d["orders"]=arr[-5000:]
    _write_atomic(ORDERS,d)

def load_positions()->List[Dict[str,Any]]:
    d=_read(POSIT, {"positions":[]})
    arr=d.get("positions",[])
    return arr if isinstance(arr,list) else []

def save_positions(arr:List[Dict[str,Any]]):
    _write_atomic(POSIT, {"positions":arr})

def append_history(h:Dict[str,Any]):
    d=_read(HIST, {"trades":[]})
    arr=d.get("trades",[])
    arr.append(h)
    d["trades"]=arr[-10000:]
    _write_atomic(HIST,d)

```

### lib/errors.py  
Taille: 266 B  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 560e715ee3a3163e

```py
CODES={"E01":"env manquant","E02":"chat non autorisé","E10":"fichier absent","E11":"json invalide","E12":"fonction indisponible"}
def err(code,msg="",ctx=""):
    s=f"{code}: {CODES.get(code,'?')}"
    if msg: s+=" • "+msg
    if ctx: s+=" • "+ctx
    return s

```

### services/agg_1m_to_3m.py  
Taille: 2 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 5bbeeb0bd2c98890

```py
#!/opt/scalp/.venv/bin/python
# Agrège /opt/scalp/data/candles/{SYM}_1m.json -> {SYM}_3m.json
from __future__ import annotations
import argparse, json
from pathlib import Path

DATA = Path("/opt/scalp/data")
CAND = DATA/"candles"

def _read_rows(p:Path):
    if not p.exists(): return []
    try:
        obj=json.loads(p.read_text())
        return obj.get("rows") or obj
    except:
        return []

def _write_rows(p:Path, rows):
    p.parent.mkdir(parents=True, exist_ok=True)
    tmp=p.with_suffix(".tmp")
    tmp.write_text(json.dumps({"rows":rows}, ensure_ascii=False, separators=(",",":")))
    tmp.replace(p)

def agg3(rows1):
    out=[]; buf=[]
    for r in rows1:
        buf.append(r)
        if len(buf)==3:
            ts=buf[-1][0]; o=buf[0][1]
            h=max(x[2] for x in buf); l=min(x[3] for x in buf)
            c=buf[-1][4]; v=sum(x[5] for x in buf)
            out.append([ts,o,h,l,c,v]); buf=[]
    return out

def main():
    ap=argparse.ArgumentParser()
    ap.add_argument("--symbol", action="append")
    args=ap.parse_args()
    # par défaut: dérive depuis les fichiers 1m présents
    if not args.symbol:
        syms=[p.name.split("_")[0] for p in CAND.glob("*_1m.json")]
    else:
        syms=[s.upper() for s in args.symbol]

    for s in syms:
        r1=_read_rows(CAND/f"{s}_1m.json")
        if len(r1)<3: 
            print(f"[agg3] {s} not enough data"); 
            continue
        r3=agg3(r1)
        _write_rows(CAND/f"{s}_3m.json", r3)
        print(f"[agg3] {s} n1={len(r1)} -> n3={len(r3)}")

if __name__=="__main__":
    main()

```

### services/analyze_A.py  
Taille: 4 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: f63d37c4a7b277ec

```py
#!/opt/scalp/.venv/bin/python
# A: calcule S(5m) ∈ [-1,1], conserve 12 valeurs (60m) + snapshots 60/30/15/now
from __future__ import annotations
import csv, json, math, statistics as stats, time, datetime as dt
from pathlib import Path

BASE = Path("/opt/scalp"); DATA = BASE/"data"
C5 = DATA/"candles/5m"
OUT = DATA/"heatmap.json"
TF_LIMIT = 500

def _iso(ts_ms:int)->str:
    return dt.datetime.utcfromtimestamp(ts_ms/1000).strftime("%Y-%m-%dT%H:%M:%SZ")

def _load_universe():
    u = DATA/"universe.txt"
    if u.exists(): return [l.strip().upper() for l in u.read_text().splitlines() if l.strip()]
    return ["BTC","ETH","BNB","SOL","XRP"]

def _load_5m(sym:str):
    p=C5/f"{sym}.csv"; rows=[]
    if not p.exists(): return rows
    with p.open() as f:
        r=csv.reader(f); head=next(r,None)
        def parse(row):
            try: ts=int(row[0]); o,h,l,c,v=map(float,row[1:6]); return [ts,o,h,l,c,v]
            except: return None
        x=parse(head); rows+=([x] if x else [])
        for row in r:
            x=parse(row); rows+=([x] if x else [])
    rows=sorted(rows,key=lambda x:x[0])[-TF_LIMIT:]
    # retire bougie en cours si partielle
    if rows and rows[-1][0]//1000 > int(time.time())-60: rows=rows[:-1]
    return rows

def _ema(vals, n):
    k=2/(n+1); e=vals[0]; out=[e]
    for x in vals[1:]: e=k*x+(1-k)*e; out.append(e)
    return out

def _atr(rows, n=14):
    if len(rows)<n+1: return None
    trs=[]; pc=rows[0][4]
    for i in range(1,len(rows)):
        h,l,c=rows[i][2],rows[i][3],rows[i][4]
        trs.append(max(h-l, abs(h-pc), abs(l-pc))); pc=c
    return sum(trs[-n:])/n

def _atr_pct(rows, n=14):
    a=_atr(rows,n); c=rows[-1][4] if rows else 0
    if not a or c<=0: return None
    return 100*a/c

def _macd_hist(rows, fast=12, slow=26, sig=9):
    closes=[r[4] for r in rows]
    if len(closes)<slow+sig+2: return None
    ef=_ema(closes,fast); es=_ema(closes,slow)
    m=[a-b for a,b in zip(ef[-len(es):], es)]
    s=_ema(m,sig); hist=m[-1]-s[-1]
    look=min(120,len(m)); sigma=stats.pstdev([m[i]-s[i] for i in range(-look,0)]) or 1e-12
    return hist, sigma

def _rsi(rows, n=14):
    if len(rows)<n+1: return None
    gains=losses=0.0
    for i in range(-n,0):
        ch=rows[i][4]-rows[i-1][4]
        gains+=max(ch,0.0); losses+=max(-ch,0.0)
    if gains==0 and losses==0: return 50.0
    if losses==0: return 100.0
    rs=gains/losses; return 100.0-100.0/(1.0+rs)

def _obv_slope(rows, look=20):
    if len(rows)<look+2: return None
    obv=[0.0]
    for i in range(1,len(rows)):
        c0,c1=rows[i-1][4],rows[i][4]; v=rows[i][5]
        if c1>c0: obv.append(obv[-1]+v)
        elif c1<c0: obv.append(obv[-1]-v)
        else: obv.append(obv[-1])
    d=obv[-1]-obv[-1-look]; med=stats.median([abs(x) for x in obv[-look:]]) or 1e-12
    return d, med

def _tanh(x, s): return math.tanh(x/(s or 1e-12))

W={"EMA":0.35,"MACD":0.25,"RSI":0.20,"ADX":0.10,"OBV":0.10}
ATR_GATE=0.12

def _S(rows):
    a=_atr(rows,14); atrp=_atr_pct(rows,14)
    if len(rows)<60 or a is None: return None
    closes=[r[4] for r in rows]
    s_EMA=_tanh(_ema(closes,12)[-1]-_ema(closes,26)[-1], 1.5*a)
    m=_macd_hist(rows);  s_MACD=_tanh(m[0], m[1]) if m else None
    r=_rsi(rows);        s_RSI=max(-1,min(1,(r-50)/50)) if r is not None else None
    s_ADX=max(-1,min(1,((atrp or 0)-20)/20)) if atrp is not None else 0.0
    o=_obv_slope(rows,20); s_OBV=_tanh(o[0], o[1]) if o else None
    w=dict(W)
    if (atrp or 0.0)<ATR_GATE: w["EMA"]*=0.5; w["MACD"]*=0.5
    num=sum(w[k]*v for k,v in (("EMA",s_EMA),("MACD",s_MACD),("RSI",s_RSI),("ADX",s_ADX),("OBV",s_OBV)) if v is not None)
    den=sum(w[k] for k,v in (("EMA",s_EMA),("MACD",s_MACD),("RSI",s_RSI),("ADX",s_ADX),("OBV",s_OBV)) if v is not None) or 1.0
    return max(-1.0,min(1.0,num/den))

def _hist_S(rows, n=12):
    out=[]
    for off in range(n-1,-1,-1):
        sub=rows[:len(rows)-off]
        s=_S(sub)
        if s is None: return []
        out.append(round(s,4))
    return out

def _snap(hist):
    if len(hist)!=12: return None
    return {"60m":hist[0], "30m":hist[6], "15m":hist[9], "now":hist[11]}

def main():
    syms=_load_universe()
    rows_out=[]
    for s in syms:
        r=_load_5m(s)
        if len(r)<60: continue
        hist=_hist_S(r,12)
        if not hist: continue
        rows_out.append({"sym":s, "hist":hist, "snap":_snap(hist)})
    OUT.write_text(json.dumps({"updated":_iso(int(time.time()*1000)),"rows":rows_out},
                              ensure_ascii=False, separators=(",",":")))
    print(f"A: heatmap rows={len(rows_out)}")

if __name__=="__main__": main()

```

### services/analyze_B.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: c3a1b85a6a70f19e

```py
#!/opt/scalp/.venv/bin/python
# B: lit heatmap.json (S), calcule pb/ph/ps, définit ctx, écrit Btop.json
from __future__ import annotations
import json, math, os, time
from pathlib import Path

DATA = Path("/opt/scalp/data")
SRC  = DATA/"heatmap.json"
DST  = DATA/"Btop.json"

TAU = float(os.getenv("SCALP_TAU","0.25"))

def _softmax3(S: float, tau: float):
    x = math.exp(S/tau); invx = math.exp(-S/tau); Z = x + 1.0 + invx
    return x/Z, 1.0/Z, invx/Z  # pb, ph, ps

def _ctx(pb:float, ph:float, ps:float):
    if pb>=0.60: return "bullish"
    if ps>=0.60: return "bearish"
    if 0.40<=ph<=0.60: return "range"
    return None

def main():
    if not SRC.exists():
        DST.write_text(json.dumps({"updated":None,"assets":[]}, ensure_ascii=False)); return
    src=json.loads(SRC.read_text())
    out=[]
    for r in src.get("rows",[]):
        sym=r.get("sym","")
        s_now=float((r.get("snap") or {}).get("now",0.0))
        pb,ph,ps=_softmax3(s_now, TAU)
        ctx=_ctx(pb,ph,ps)
        out.append({"sym":sym,"S":round(s_now,4),
                    "pb":round(pb,4),"ph":round(ph,4),"ps":round(ps,4),
                    "ctx":ctx})
    DATA.joinpath("Btop.json").write_text(
        json.dumps({"updated": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                    "tau": TAU, "assets": out},
                   ensure_ascii=False, separators=(",",":")))
    print(f"B: assets={len(out)} tau={TAU}")

if __name__=="__main__": main()

```

### services/analyze_pipeline.py  
Taille: 182 B  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 243dedd8d5ebd1da

```py
#!/opt/scalp/.venv/bin/python
from pathlib import Path
from loguru import logger
print("Analyze stub: déclenchement reçu")
Path("/opt/scalp/data/last.analysis").write_text("tick")

```

### services/b_triggers.py  
Taille: 4 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: e69bbd3dae23e069

```py
#!/opt/scalp/.venv/bin/python
import json, sys, time
from pathlib import Path
from typing import List, Dict, Any

BASE   = Path("/opt/scalp")
DATA   = BASE / "data"
HEAT_S = DATA / "heatmap_soft.json"   # format récent: rows: [{sym, S:[{t,s},...]}, ...]
HEAT_H = DATA / "heatmap.json"        # fallback: rows: [{sym, '5m':'a/b/c','15m':..., '30m':...}, ...]
TOP    = DATA / "top.json"            # Couche A (NE JAMAIS ÉCRASER)
BTOP   = DATA / "btop.json"           # Couche B (notre sortie)

def _now_iso() -> str:
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

def _last_S_from_soft(row: Dict[str,Any]) -> float|None:
    # heatmap_soft.json → row["S"] = [{t:..., s:...}, ...]
    seq = row.get("S") or row.get("s") or []
    if not seq: return None
    try:
        return float(seq[-1].get("s"))
    except Exception:
        return None

def _est_context(last_s: float) -> str:
    # mapping simple pour la Couche A déjà décidée ailleurs; ici on expose juste une couleur indicative
    if last_s is None:      return "unknown"
    if last_s >=  0.20:     return "bullish"
    if last_s <= -0.20:     return "bearish"
    return "range"

def _parse_ratio(x: str) -> float:
    # "2/2/1" -> score simple (ex: moyenne centrée) pour fallback heatmap.json
    try:
        a,b,c = (int(t) for t in x.split('/'))
        # normalisation grossière sur 0..1 autour de 0 via (-1..+1)
        s = (a - c) / max(1,(a+b+c))
        return float(s)
    except Exception:
        return 0.0

def _last_S_from_hard(row: Dict[str,Any]) -> float|None:
    # Derive un "S" approximatif depuis les 3 TF (5m/15m/30m) quand soft absent
    f5  = _parse_ratio(str(row.get("5m","0/0/0")))
    f15 = _parse_ratio(str(row.get("15m","0/0/0")))
    f30 = _parse_ratio(str(row.get("30m","0/0/0")))
    return round((f5 + f15 + f30)/3, 3)

def load_heat_rows() -> List[Dict[str,Any]]:
    if HEAT_S.exists():
        obj = json.loads(HEAT_S.read_text())
        rows = obj.get("rows", [])
        out  = []
        for r in rows:
            sym = r.get("sym") or r.get("symbol") or r.get("SYM")
            if not sym: continue
            s   = _last_S_from_soft(r)
            out.append({"sym": sym, "S": s, "context": _est_context(s)})
        return out

    if HEAT_H.exists():
        obj = json.loads(HEAT_H.read_text())
        rows = obj.get("rows", [])
        out  = []
        for r in rows:
            sym = r.get("sym") or r.get("symbol") or r.get("SYM")
            if not sym: continue
            s = _last_S_from_hard(r)
            out.append({"sym": sym, "S": s, "context": _est_context(s)})
        return out

    return []

def load_top_syms() -> List[str]:
    # On limite B aux actifs existants dans top.json si présent (ordre conservé)
    try:
        obj = json.loads(TOP.read_text())
        assets = obj.get("assets", [])
        syms = [a.get("sym") for a in assets if a.get("sym")]
        return syms
    except Exception:
        return []

def build_btop():
    rows = load_heat_rows()
    if not rows:
        raise SystemExit("No heatmap rows available")

    # Filtre par top.json si dispo
    top_syms = load_top_syms()
    if top_syms:
        rows = [r for r in rows if r["sym"] in top_syms]

    # Tri par |S| décroissant (les plus ‘marqués’ d’abord)
    rows.sort(key=lambda r: (0.0 if r["S"] is None else abs(r["S"])), reverse=True)

    # Écrit btop.json (sans toucher top.json)
    out = {
        "updated": _now_iso(),
        "source":  "B",
        "rows":    rows,
        "note":    "Couche B selection from heatmap; top.json untouched."
    }
    BTOP.write_text(json.dumps(out, ensure_ascii=False, separators=(',',':')))
    print(f"btop.json written: {len(rows)} rows")

if __name__ == "__main__":
    build_btop()

```

### services/build_heatmap_softmax.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: f5037dcf1c1a4cd9

```py
#!/opt/scalp/.venv/bin/python
# Heatmap viewer: lit uniquement /opt/scalp/data/heatmap.json et sort des entiers 10*S pour 60/30/15/now
import json, time
from pathlib import Path

DATA = Path("/opt/scalp/data")
SRC  = DATA/"heatmap.json"
DST  = DATA/"heatmap_view.json"  # consommé par le front si besoin

def _i10(x: float) -> int:
    # entier de 10*S (ex: 0.83 -> 8, -0.27 -> -2)
    try:
        return int(round(10.0*float(x)))
    except:
        return 0

def main():
    if not SRC.exists():
        DST.write_text(json.dumps({"updated": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()), "rows":[]}, ensure_ascii=False))
        print("viewer: source absente"); return

    src=json.loads(SRC.read_text())
    rows=[]
    for r in src.get("rows", []):
        sym=r.get("sym","")
        snap=r.get("snap") or {}
        rows.append({
            "sym": sym,
            "S_int": {
                "60": _i10(snap.get("60m",0)),
                "30": _i10(snap.get("30m",0)),
                "15": _i10(snap.get("15m",0)),
                "now": _i10(snap.get("now",0)),
            }
        })
    out={"updated": src.get("updated"), "rows": rows}
    DST.write_text(json.dumps(out, ensure_ascii=False, separators=(",",":")))
    print(f"viewer: rows={len(rows)} -> {DST}")
if __name__=="__main__": main()

```

### services/build_softmap.py  
Taille: 2 KB  |  MàJ: 2025-09-19 19:44:04  |  SHA256: 0220c3abd838a8dd

```py
#!/opt/scalp/.venv/bin/python
import json, math, statistics as st
from pathlib import Path

ROOT=Path("/opt/scalp"); DATA=ROOT/"data"; C=DATA/"candles"
OUT=DATA/"heatmap.json"; HIST=DATA/"s_history"
OUT.parent.mkdir(parents=True, exist_ok=True)

def load_candles(sym_code:str):
    # essaie 5m puis 1m
    p5=C/f"{sym_code}_5m.json"; p1=C/f"{sym_code}_1m.json"
    p=p5 if p5.exists() else p1 if p1.exists() else None
    if not p: return []
    try: rows=json.loads(p.read_text())
    except Exception: return []
    # accepte format [{"t":..,"c":..},...] ou [[ts,o,h,l,c,v],...]
    out=[]
    for r in rows:
        if isinstance(r, dict):
            out.append(float(r.get("c", r.get("close", 0)) or 0))
        else:
            out.append(float(r[4]))
    return [x for x in out if x>0]

def series_S(closes:list, win:int=20):
    """ S = z-score des rendements log sur fenêtre glissante """
    if len(closes)<win+2: return []
    rets=[math.log(closes[i]/closes[i-1]) for i in range(1,len(closes))]
    S=[]
    for i in range(win, len(rets)):
        w=rets[i-win:i]
        mu=st.mean(w); sd=st.pstdev(w) or 1e-9
        S.append((rets[i]-mu)/sd)
    return S

def norm(sym:str)->str: 
    # 'BTC/USDT:USDT' -> 'BTCUSDT'
    return ''.join(ch for ch in sym if ch.isalnum()).upper()

# charge universe
U=(DATA/"universe.txt")
syms=[l.strip() for l in U.read_text().splitlines() if l.strip()] if U.exists() else []
rows=[]
for s in syms:
    code=norm(s)
    closes=load_candles(code)
    S=series_S(closes)
    if S:
        rows.append({"sym": code, "S": S[-200:]})  # tronque raisonnablement

obj={"rows": rows, "meta":{"n": len(rows)}}
OUT.write_text(json.dumps(obj, ensure_ascii=False))
# snapshot historique si le dossier existe
if HIST.exists() and HIST.is_dir():
    (HIST/f"heatmap.json").write_text(json.dumps(obj, ensure_ascii=False))
print(f"softmap rows={len(rows)}")

```

### services/exec_signals.py  
Taille: 4 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: f269965a7ea23e0a

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json, time, os
from pathlib import Path

BASE = Path("/opt/scalp")
DATA = BASE/"data"
CAND = DATA/"candles"
SIGF = DATA/"signals.json"
POSF = DATA/"positions.json"
HISTL= DATA/"positions_hist.jsonl"

SLIPPAGE = float(os.getenv("MAX_SLIPPAGE_PCT", "0.002"))  # 0.2%

def _now_iso(): return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

def _read_json(p: Path, default):
    try:
        return json.loads(p.read_text())
    except Exception:
        return default

def _write_atomic(p: Path, obj):
    tmp = p.with_suffix(p.suffix+".tmp")
    tmp.write_text(json.dumps(obj, ensure_ascii=False, separators=(",",":")))
    tmp.replace(p)

def _append_jsonl(p: Path, row: dict):
    with p.open("a", encoding="utf-8") as f:
        f.write(json.dumps(row, ensure_ascii=False)+ "\n")

def _latest_px(sym: str) -> float|None:
    f = CAND/f"{sym}_1m.json"
    if not f.exists(): return None
    try:
        obj = json.loads(f.read_text())
        rows = obj.get("rows", obj) if isinstance(obj, dict) else obj
        if not rows: return None
        return float(rows[-1][4])  # close
    except Exception:
        return None

def _positions() -> list[dict]:
    obj = _read_json(POSF, {})
    return obj.get("positions", []) if isinstance(obj, dict) else []

def _save_positions(rows: list[dict]):
    _write_atomic(POSF, {"updated":_now_iso(),"positions":rows})

def _clear_signals():
    _write_atomic(SIGF, {"updated":_now_iso(),"signals":[]})

def process():
    obj = _read_json(SIGF, {})
    sigs = obj.get("signals", obj if isinstance(obj, list) else [])
    if not sigs: return 0
    pos = _positions()
    handled=0
    for s in sigs:
        sym=str(s.get("sym") or s.get("symbol") or "?").upper()
        side=s.get("side","?")
        px=float(s.get("price_entry") or 0)
        sl=float(s.get("sl") or 0)
        tp=float(s.get("tp") or 0)
        qty=float(s.get("size") or 0)
        lev=int(s.get("leverage") or 0)

        if px<=0 or sl==0 or tp==0 or qty<=0:
            _append_jsonl(HISTL,{
                "timestamp":_now_iso(),"symbol":sym,"side":side,"entry":px,
                "sl":sl,"tp":tp,"size":qty,"leverage":lev,
                "status":"rejected","reason":"invalid_signal"
            })
            handled+=1
            continue

        cur=_latest_px(sym)
        if cur is None:
            _append_jsonl(HISTL,{
                "timestamp":_now_iso(),"symbol":sym,"side":side,"entry":px,
                "sl":sl,"tp":tp,"size":qty,"leverage":lev,
                "status":"rejected","reason":"no_price"
            })
            handled+=1
            continue

        slip=abs(cur-px)/px
        if slip>SLIPPAGE:
            _append_jsonl(HISTL,{
                "timestamp":_now_iso(),"symbol":sym,"side":side,"entry":px,
                "sl":sl,"tp":tp,"size":qty,"leverage":lev,
                "status":"rejected","reason":"slippage","price_now":cur,"slippage":slip
            })
            handled+=1
            continue

        # OK: ouvrir position
        pos_row={
            "timestamp":_now_iso(),"ts_open":int(time.time()),
            "symbol":sym,"side":side,"entry":px,"sl":sl,"tp":tp,
            "size":qty,"leverage":lev,"status":"open","last":cur
        }
        pos.append(pos_row)
        _append_jsonl(HISTL,{**pos_row,"status":"opened"})
        handled+=1

    # maj fichiers
    _save_positions(pos)
    _clear_signals()
    return handled

def main():
    handled=process()
    print(f"[exec] handled={handled}")
    return 0

if __name__=="__main__":
    raise SystemExit(main())

```

### services/fetch_1m_safe.py  
Taille: 946 B  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 4f783bd0c0eb1a1d

```py
#!/opt/scalp/.venv/bin/python
# Placeholder safe: prépare les chemins 1m pour chaque asset du BTop
import json, time
from pathlib import Path

BASE = Path("/opt/scalp")
DATA = BASE / "data"
OUT  = DATA / "candles_1m"
TOPB = DATA / "top_B.json"
LOG  = BASE / "logs" / "fetch_1m_safe.log"
OUT.mkdir(parents=True, exist_ok=True)
LOG.parent.mkdir(parents=True, exist_ok=True)

def log(m): LOG.write_text((LOG.read_text()+m+"\n") if LOG.exists() else m+"\n")

def main():
    if not TOPB.exists():
        log("top_B.json absent -> skip")
        return 0
    tb = json.loads(TOPB.read_text())
    assets = tb.get("assets", [])
    for sym in assets:
        f = OUT / f"{sym}_1m.json"
        if not f.exists():
            f.write_text(json.dumps({"sym": sym, "updated": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()), "rows": []}))
    log(f"prepared {len(assets)} files")
    return 0

if __name__ == "__main__":
    raise SystemExit(main())

```

### services/fetch_ohlcv.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: fdba81b251b62caa

```py
#!/opt/scalp/.venv/bin/python
import os, json, time, pathlib, datetime as dt
from collections import defaultdict

BASE = pathlib.Path("/opt/scalp"); DATA = BASE/"data"; CAND = DATA/"candles"
CAND.mkdir(parents=True, exist_ok=True)

SYMS = json.loads((DATA/"top.json").read_text())["assets"]
SYMS = [a["sym"] for a in SYMS]  # top15
TFS  = ["5m","15m","30m"]

def now_utc():
    return dt.datetime.utcnow().replace(tzinfo=dt.timezone.utc)

def fetch_ccxt(symbol, tf, limit=300):
    # SABLE: stub de données pour démo; branche ccxt plus tard.
    # return list of (ts, open, high, low, close, volume)
    t0 = int(time.time())//60*60
    import random
    out=[]; base=20000+hash(symbol)%10000
    for i in range(limit):
        ts=(t0-(limit-i)*60*(5 if tf=="5m" else 15 if tf=="15m" else 30))*1000
        c=base+random.randint(-200,200)
        h=c+random.randint(0,50); l=c-random.randint(0,50); o=(h+l)//2; v=random.randint(50,200)
        out.append([ts,o,h,l,c,v])
    return out

def write_candles(sym, tf, rows):
    f = CAND/f"{sym}_{tf}.json"
    f.write_text(json.dumps({"sym":sym,"tf":tf,"rows":rows,"updated":now_utc().isoformat().replace("+00:00","Z")}))
    return f

def main():
    for s in SYMS:
        for tf in TFS:
            rows = fetch_ccxt(s, tf, 300)
            write_candles(s, tf, rows)
    (DATA/"candles.updated").write_text(now_utc().isoformat().replace("+00:00","Z"))
    print("OHLCV OK")

if __name__=="__main__": main()

```

### services/ohlcv_1m_cli.py  
Taille: 3 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 74bc840c764bc1d6

```py
#!/opt/scalp/.venv/bin/python
# Collecte OHLCV 1m Bitget -> /opt/scalp/data/candles/{SYM}_1m.json
# Source des symboles: Btop.json (ctx != None). Fallback: universe.txt.

from __future__ import annotations
import argparse, json, time
from pathlib import Path

DATA = Path("/opt/scalp/data")
CAND = DATA/"candles"
BTOP = DATA/"Btop.json"
UNIV = DATA/"universe.txt"

def _safe_write_json_rows(path:Path, rows:list[list[float]]):
    path.parent.mkdir(parents=True, exist_ok=True)
    tmp = path.with_suffix(".tmp")
    tmp.write_text(json.dumps({"rows": rows}, ensure_ascii=False, separators=(",",":")))
    tmp.replace(path)

def _syms_from_btop() -> list[str]:
    if not BTOP.exists(): return []
    try:
        obj=json.loads(BTOP.read_text())
        assets=obj.get("assets", [])
        out=[str(a.get("sym","")).upper() for a in assets if a.get("ctx") is not None]
        return [s for s in out if s]
    except: 
        return []

def _syms_from_universe() -> list[str]:
    if not UNIV.exists(): return []
    out=[]
    for line in UNIV.read_text().splitlines():
        s=line.strip().upper()
        if not s: continue
        if s.startswith("{") and s.endswith("}"):
            try:
                o=json.loads(s); s=(o.get("sym") or o.get("symbol") or "").upper()
            except: s=""
        if s: out.append(s)
    # unique en gardant l'ordre
    seen=set(); uniq=[]
    for s in out:
        if s not in seen:
            seen.add(s); uniq.append(s)
    return uniq

def resolve_symbols(cli_syms:list[str]|None) -> list[str]:
    xs=[s.upper() for s in (cli_syms or []) if isinstance(s,str) and s.strip()]
    if xs: return xs
    btop_syms=_syms_from_btop()
    if btop_syms: return btop_syms
    base=_syms_from_universe()
    return base or ["BTC","ETH"]

def bitget_symbol(sym:str)->str:
    return f"{sym}/USDT:USDT"

def fetch_1m_one(sym:str, limit:int=500)->list[list[float]]:
    import ccxt
    ex=ccxt.bitget()
    mkt=bitget_symbol(sym)
    ohlcv=ex.fetch_ohlcv(mkt, timeframe="1m", limit=limit)
    return [[int(t), float(o), float(h), float(l), float(c), float(v)] for t,o,h,l,c,v in ohlcv]

def main():
    ap=argparse.ArgumentParser()
    ap.add_argument("--symbol", action="append", help="peut être répété; sinon Btop.json ctx!=None")
    ap.add_argument("--limit", type=int, default=500)
    args=ap.parse_args()

    syms=resolve_symbols(args.symbol)
    print(f"[ohlcv_1m] syms={syms}")
    ok=err=0
    for s in syms:
        try:
            rows=fetch_1m_one(s, args.limit)
            _safe_write_json_rows(CAND/f"{s}_1m.json", rows)
            ok+=1
            print(f"[ohlcv_1m] {s} n={len(rows)}")
        except Exception as e:
            err+=1
            print(f"[ohlcv_1m] {s} ERROR {e}")
    print(f"[ohlcv_1m] done ok={ok} err={err}")

if __name__=="__main__":
    main()

```

### services/ohlcv_bitget_batch.py  
Taille: 3 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 0fcf446b56b879f8

```py
#!/opt/scalp/.venv/bin/python
import csv, time, sys
from pathlib import Path
from loguru import logger
import ccxt

DATA = Path("/opt/scalp/data")
CAND = DATA/"candles"
TF_LIST = [("5m", 300), ("15m", 300), ("30m", 300)]

def tf_ms(tf:str)->int:
    n = int(tf[:-1]); unit = tf[-1]
    return n*60_000 if unit=="m" else n*1_000

def last_closed_ts(tf:str)->int:
    # borne supérieure exclu: floor(now, tf)
    ms = int(time.time()*1000)
    size = tf_ms(tf)
    return (ms // size) * size

def write_csv(path:Path, rows):
    path.parent.mkdir(parents=True, exist_ok=True)
    hdr = ["ts","open","high","low","close","volume"]
    if not path.exists():
        with path.open("w", newline="") as f: csv.writer(f).writerow(hdr)
    # on réécrit toutes les données pour simplicité/atomicité
    with path.open("w", newline="") as f:
        w=csv.writer(f); w.writerow(hdr); w.writerows(rows)

def load_csv(path:Path):
    out=[]
    if not path.exists(): return out
    with path.open() as f:
        r=csv.reader(f); next(r, None)
        for row in r:
            if not row: continue
            out.append([int(row[0]), *map(float,row[1:])])
    return out

def merge_keep_limit(old, new, limit):
    # fusion par ts croissant, supprime doublons, garde <= limit dernières
    m={}
    for ts, *rest in old: m[ts]=[ts,*rest]
    for ts, *rest in new: m[ts]=[ts,*rest]
    merged = sorted(m.values(), key=lambda x:x[0])
    return merged[-limit:]

def main():
    try:
        uni = [l.strip() for l in (DATA/"universe.txt").read_text().splitlines() if l.strip()]
    except Exception:
        uni = ["BTC","ETH","BNB","SOL","XRP"]
    try:
        ex = ccxt.bitget({"options":{"defaultType":"swap"}, "enableRateLimit": True})
        ex.load_markets()
    except Exception as e:
        logger.error(f"E_BITGET_INIT: {e}"); sys.exit(21)

    for base in uni:
        sym = f"{base}/USDT:USDT"
        for tf, keep in TF_LIST:
            try:
                rows = ex.fetch_ohlcv(sym, timeframe=tf, limit=keep+5)
            except Exception as e:
                logger.error(f"EFETCH {sym} {tf}: {e}")
                continue
            # filtre: ne prendre que <= bougie close
            up = last_closed_ts(tf)
            rows = [r for r in rows if r[0] < up]
            # merge avec existant puis garde 'keep'
            f = CAND/tf/f"{base}.csv"
            cur = load_csv(f)
            merged = merge_keep_limit(cur, rows, keep)
            write_csv(f, merged)
            # déclenche analyse
            (DATA/"trigger.ohlcv").write_text(str(int(time.time())))
    print("OHLCV batch terminé.")

if __name__ == "__main__":
    main()

```

### services/ohlcv_bitget_cli.py  
Taille: 4 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: ed5042260b2e8eca

```py
#!/opt/scalp/.venv/bin/python
import os, sys, csv, time, json, pathlib
from datetime import datetime
import ccxt

ENV="/etc/scalp.env"
OUT=pathlib.Path("/opt/scalp/data/candles")
TRIGGER=pathlib.Path("/opt/scalp/data/trigger.ohlcv")

# Routine allégée: pas de 1m
TF_LIMIT   = {"5m":300, "15m":200, "30m":200}
TF_SECONDS = {"5m":300, "15m":900, "30m":1800}
FOCUS_1M_LIMIT = 500

def load_env(path=ENV):
    d={}
    if os.path.exists(path):
        for L in open(path):
            L=L.strip()
            if not L or L.startswith("#") or "=" not in L: continue
            k,v=L.split("=",1); d[k.strip()]=v.strip().strip('"').strip("'")
    return d

def req_env(env):
    need=["BITGET_API_KEY","BITGET_API_SECRET","BITGET_PASSPHRASE"]
    miss=[k for k in need if not env.get(k)]
    if miss: raise SystemExit(f"EENV:{','.join(miss)}")

def bitget(env):
    try:
        ex=ccxt.bitget({"apiKey":env.get("BITGET_API_KEY"),
                        "secret":env.get("BITGET_API_SECRET"),
                        "password":env.get("BITGET_PASSPHRASE"),
                        "enableRateLimit":True,
                        "options":{"defaultType":"swap"}})
        ex.load_markets(); return ex
    except ccxt.AuthenticationError as e: raise SystemExit(f"EAUTH:{e}")
    except ccxt.RateLimitExceeded as e:  raise SystemExit(f"ERATE:{e}")
    except ccxt.NetworkError as e:       raise SystemExit(f"ENET:{e}")
    except Exception as e:               raise SystemExit(f"EAPI:{e}")

def to_usdt(sym): return f"{sym.upper().split('/')[0]}/USDT:USDT"
def last_closed_ms(tf, now=None):
    period={"5m":300,"15m":900,"30m":1800,"1m":60}[tf]
    now=int(now or time.time()); return (((now//period)+1)*period - period)*1000

def fetch_one(ex, sym, tf, limit):
    rows=ex.fetch_ohlcv(to_usdt(sym), timeframe=tf, limit=limit)
    cutoff=last_closed_ms(tf)
    return [r[:6] for r in rows if r and int(r[0])<cutoff]

def write_csv(sym, tf, rows):
    dstdir=OUT/tf; dstdir.mkdir(parents=True,exist_ok=True)
    p=dstdir/(sym.upper().split('/')[0]+".csv")
    with p.open("w", newline="") as f:
        w=csv.writer(f); [w.writerow(r) for r in rows]
    return str(p)

def universe():
    u="/opt/scalp/data/universe.txt"
    if os.path.exists(u): return [l.strip().upper() for l in open(u) if l.strip()]
    return ["BTC","ETH","BNB","SOL","XRP","ADA","ARB","DOGE","LINK","LTC","TRX","OP","APT","SUI","TON"][:15]

def main(a):
    if len(a)<2:
        print("usage: ohlcv_bitget_cli.py <5m|15m|30m|focus1m> [COINS CSV]", file=sys.stderr); sys.exit(2)
    mode=a[1]; env=load_env(); req_env(env); ex=bitget(env)

    if mode=="focus1m":
        coins=[s.strip().upper() for s in (a[2] if len(a)>=3 else open("/opt/scalp/data/focus1m.txt").read()).split(",") if s.strip()]
        ok=0; fail=[]
        for c in coins:
            try: rows=fetch_one(ex,c,"1m",FOCUS_1M_LIMIT); write_csv(c,"1m",rows); ok+=1; print(f"OK {c} 1m:{len(rows)}")
            except SystemExit as e: fail.append({"sym":c,"err":str(e)})
            except Exception as e:  fail.append({"sym":c,"err":f"EUNK:{e}"})
        TRIGGER.write_text(str(int(time.time())))
        json.dump({"mode":"focus1m","ok":ok,"failed":fail,"at":datetime.utcnow().strftime("%FT%TZ")},
                  open("/opt/scalp/data/status.json","w"), separators=(",",":"))
        sys.exit(1 if fail else 0)

    tf=mode
    if tf not in TF_LIMIT: raise SystemExit("EARG: tf invalide (5m|15m|30m|focus1m)")
    coins=[s.strip().upper() for s in (a[2] if len(a)>=3 else ",".join(universe())).split(",") if s.strip()]
    ok=0; fail=[]
    for c in coins:
        try: rows=fetch_one(ex,c,tf,TF_LIMIT[tf]); write_csv(c,tf,rows); ok+=1; print(f"OK {c} {tf}:{len(rows)}")
        except SystemExit as e: fail.append({"sym":c,"err":str(e)})
        except Exception as e:  fail.append({"sym":c,"err":f"EUNK:{e}"})
    TRIGGER.write_text(str(int(time.time())))
    json.dump({"tf":tf,"ok":ok,"failed":fail,"at":datetime.utcnow().strftime("%FT%TZ")},
              open("/opt/scalp/data/status.json","w"), separators=(",",":"))
    sys.exit(1 if fail else 0)

if __name__=="__main__": main(sys.argv)

```

### services/on_new_signals.py  
Taille: 2 KB  |  MàJ: 2025-09-19 23:13:47  |  SHA256: 9d74e037655c12c8

```py
import time, json, hashlib, os
from pathlib import Path
from tools.trade_state import promote_signals_to_positions, reconcile_with_ccxt

SIG = Path("/opt/scalp/data/signals.json")
HASH=""
def file_hash(p):
    try: return hashlib.md5(Path(p).read_bytes()).hexdigest()
    except: return ""

def _fetcher():
    k=os.getenv("BITGET_API_KEY"); s=os.getenv("BITGET_API_SECRET"); p=os.getenv("BITGET_PASSPHRASE")
    if not (k and s and p): return None
    try:
        import ccxt
        ex=ccxt.bitget({"apiKey":k,"secret":s,"password":p,"options":{"defaultType":"swap"}}); ex.load_markets()
        def f(sym):
            m=sym.replace("USDT:USDT","/USDT:USDT")
            last=ex.fetch_ticker(m)["last"]
            size=0.0
            try:
                for pos in ex.fetch_positions([m]):
                    if pos.get("symbol")==m: size=float(pos.get("contracts") or 0)
            except: pass
            return {"last":float(last), "size":float(size)}
        return f
    except: return None

fetch=_fetcher()
while True:
    h=file_hash(SIG)
    if h and h!=HASH:
        HASH=h
        # s’assure que chaque signal a un timestamp
        try:
            data=json.loads(SIG.read_text())
            changed=False
            now=int(time.time())
            for s in data:
                if "ts" not in s: s["ts"]=now; changed=True
            if changed: SIG.write_text(json.dumps(data,indent=2))
        except: pass

        added=promote_signals_to_positions(auto_exec=True, max_new=50)
        reconcile_with_ccxt(fetch)
        print(f"[watch] new signals -> promoted={added}")
    time.sleep(2)

```

### services/paper_trade.py  
Taille: 10 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: dde962538c2446b2

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json, time, hashlib, datetime as dt
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple

BASE=Path("/opt/scalp"); DATA=BASE/"data"
SIGF=DATA/"signals.json"; POSF=DATA/"positions.json"; PHIST=DATA/"positions_hist.jsonl"
ACCT=DATA/"account.json"; RISKF=DATA/"risk.json"; CAND=DATA/"candles"; LOGF=DATA/"logs/paper.log"
CURRENCY="USDT"; START_BAL=100.0

# -------- utils --------
def _log(msg:str):
    LOGF.parent.mkdir(parents=True, exist_ok=True)
    LOGF.open("a").write(time.strftime("%Y-%m-%d %H:%M:%S ", time.gmtime())+msg+"\n")

def _read_json(p:Path, d): 
    try: return json.loads(p.read_text())
    except: return d

def _parse_ts(o:Dict[str,Any])->Optional[int]:
    t = o.get("ts") or o.get("timestamp") or o.get("time")
    if t is None: return None
    if isinstance(t,(int,float)): return int(t/1000) if t>1e12 else int(t)
    if isinstance(t,str):
        s=t.strip()
        try:
            if s.endswith("Z"): 
                return int(dt.datetime.strptime(s,"%Y-%m-%dT%H:%M:%SZ").replace(tzinfo=dt.timezone.utc).timestamp())
            return int(dt.datetime.fromisoformat(s.replace("Z","+00:00")).timestamp())
        except: return None
    return None

def _last_price_1m(sym:str)->float|None:
    p=CAND/f"{sym}_1m.json"
    try:
        o=json.loads(p.read_text()); rows=o.get("rows") or o
        return float(rows[-1][4]) if rows else None
    except: return None

# -------- load/save state --------
def _load_state()->Dict[str,Any]:
    s=_read_json(POSF, {"positions":[],"state":{"seen":{}}})
    s.setdefault("positions",[]); s.setdefault("state",{}); s["state"].setdefault("seen",{})
    return s

def _save_state(s:Dict[str,Any]):
    tmp=POSF.with_suffix(".tmp"); tmp.write_text(json.dumps(s, ensure_ascii=False, separators=(",",":"))); tmp.replace(POSF)

def _append_hist(row:Dict[str,Any]):
    PHIST.parent.mkdir(parents=True, exist_ok=True)
    with PHIST.open("a") as f: f.write(json.dumps(row, ensure_ascii=False)+"\n")

def _load_account()->Dict[str,Any]:
    a=_read_json(ACCT, {})
    a.setdefault("balance", START_BAL); a.setdefault("equity", a["balance"])
    a.setdefault("open_pnl", 0.0); a.setdefault("margin_used", 0.0)
    a.setdefault("currency", "USDT"); a.setdefault("updated", int(time.time()))
    return a

def _save_account(a:Dict[str,Any]):
    a["updated"]=int(time.time())
    tmp=ACCT.with_suffix(".tmp"); tmp.write_text(json.dumps(a, ensure_ascii=False, separators=(",",":"))); tmp.replace(ACCT)

def _load_risk()->Dict[str,Any]:
    r=_read_json(RISKF, {})
    r.setdefault("risk_pct", 0.005)
    r.setdefault("default_leverage", 5)
    r.setdefault("max_positions", 3)
    r.setdefault("max_pair_exposure", 0.5)
    r.setdefault("max_margin_util", 0.8)
    r.setdefault("min_notional", {"DEFAULT":10})
    r.setdefault("max_leverage", {"DEFAULT":25})
    return r

# -------- signals reader --------
def _read_signals()->List[Dict[str,Any]]:
    if not SIGF.exists(): return []
    txt=SIGF.read_text().strip()
    out:List[Dict[str,Any]]=[]
    if txt.startswith("[") and txt.endswith("]"):
        try: 
            arr=json.loads(txt)
            return [x for x in arr if isinstance(x,dict)]
        except: pass
    ok=False
    for line in txt.splitlines()[-400:]:
        line=line.strip()
        if not line: continue
        try:
            o=json.loads(line)
            if isinstance(o,dict): out.append(o); ok=True
        except: pass
    if ok: return out
    # extraction streaming basique
    buf=[]; lvl=0; ins=False; esc=False
    for ch in txt:
        if ins:
            buf.append(ch)
            if esc: esc=False
            elif ch=="\\": esc=True
            elif ch=='"': ins=False
            continue
        if ch=='"': ins=True; buf.append(ch); continue
        if ch=='{': lvl+=1; buf.append(ch); continue
        if lvl>0: buf.append(ch)
        if ch=='}' and lvl>0:
            lvl-=1
            if lvl==0:
                try:
                    o=json.loads(''.join(buf)); buf=[]
                    if isinstance(o,dict): out.append(o)
                except: buf=[]
    return out

# -------- sizing + open/close --------
def _sig_id(s:Dict[str,Any])->str:
    ts=_parse_ts(s) or 0
    key=f"{s.get('symbol')}|{s.get('entry_set')}|{s.get('side')}|{ts}"
    return hashlib.sha1(key.encode()).hexdigest()[:16]

def _cap_for(sym:str, caps:Dict[str,Any], key:str, default):
    tbl=caps.get(key) or {}
    return tbl.get(sym, tbl.get("DEFAULT", default))

def _compute_size(s:Dict[str,Any], balance:float, risk:Dict[str,Any])->Tuple[float,float,float,int,str]:
    """retourne (qty, notional, margin, lev, reason_if_reject_or_empty)"""
    sym=str(s["symbol"]).upper()
    pe=float(s["price_entry"]); sl=float(s["sl"])
    dist=abs(pe - sl)
    if dist<=0: return 0,0,0,0,"zero_dist"
    risk_pct=float(risk["risk_pct"])
    R=balance*risk_pct                       # risque fixe en USDT
    qty = float(s.get("size") or (R/dist))   # calc qty si non fournie
    lev_sig = int(s.get("leverage") or risk["default_leverage"])
    lev_cap = int(_cap_for(sym, risk, "max_leverage", 25))
    lev = max(1, min(lev_sig, lev_cap))
    notion = qty*pe
    min_not = float(_cap_for(sym, risk, "min_notional", 10))
    if notion < min_not: 
        # remonte qty au min notionnel
        qty = min_not/pe
        notion = min_not
    margin = notion/lev
    return qty, notion, margin, lev, ""
    
def _open_from_signal(s:Dict[str,Any], acct:Dict[str,Any], risk:Dict[str,Any],
                      open_now:int, by_sym:Dict[str,Any])->Tuple[Optional[Dict[str,Any]],str]:
    sym=s.get("symbol"); side=s.get("side")
    if not sym or side not in ("long","short"): return None,"invalid_side"
    ts=_parse_ts(s) or int(time.time())
    if s.get("price_entry") is None or s.get("sl") is None or s.get("tp") is None: 
        return None,"missing_prices"
    qty, notion, margin, lev, reason = _compute_size(s, float(acct["balance"]), risk)
    if reason: return None, reason
    # contraintes globales
    if open_now >= int(risk["max_positions"]): return None,"max_positions"
    if sym in by_sym: return None,"already_open"
    if notion > float(acct["balance"])*float(risk["max_pair_exposure"]): return None,"pair_exposure"
    if float(acct["margin_used"])+margin > float(acct["balance"])*float(risk["max_margin_util"]): 
        return None,"margin_util"

    pos = {
        "id": _sig_id(s),
        "symbol": str(sym).upper(),
        "side": side,
        "entry": float(s["price_entry"]),
        "sl": float(s["sl"]),
        "tp": float(s["tp"]),
        "size": float(qty),
        "leverage": int(lev),
        "notional": float(notion),
        "margin": float(margin),
        "ts_open": int(ts),
        "setup": s.get("entry_set",""),
        "status": "open",
        "pnl": 0.0
    }
    return pos,""

def _update_close(pos:Dict[str,Any], last:Optional[float])->Tuple[Dict[str,Any], Optional[Dict[str,Any]]]:
    if last is None: return pos, None
    side,e,sl,tp,sz = pos["side"], pos["entry"], pos["sl"], pos["tp"], pos["size"]
    pnl=(last-e)*sz if side=="long" else (e-last)*sz
    pos["pnl"]=round(pnl,6); pos["last"]=last
    hit=None
    if side=="long" and last<=sl: hit=("SL", sl)
    elif side=="long" and last>=tp: hit=("TP", tp)
    elif side=="short" and last>=sl: hit=("SL", sl)
    elif side=="short" and last<=tp: hit=("TP", tp)
    if not hit: return pos, None
    reason, exitp=hit
    closed={"id":pos["id"],"symbol":pos["symbol"],"side":side,"setup":pos.get("setup",""),
            "ts_open":pos["ts_open"],"entry":e,"sl":sl,"tp":tp,"size":sz,"leverage":pos.get("leverage",1),
            "notional":pos.get("notional",sz*e),"margin":pos.get("margin", (sz*e)/max(1,pos.get('leverage',1))),
            "ts_close":int(time.time()),"exit":float(exitp),
            "pnl": (exitp-e)*sz if side=="long" else (e-exitp)*sz,"reason":reason}
    pos["status"]="closed"; pos["ts_close"]=closed["ts_close"]; pos["exit"]=exitp
    return pos, closed

# -------- main --------
def main():
    state=_load_state(); acct=_load_account(); risk=_load_risk()
    pos=state["positions"]; seen=state["state"]["seen"]
    sigs=_read_signals()
    by_sym={p["symbol"]:p for p in pos if p.get("status")=="open"}
    opened=closed_cnt=0; skip_stats={}

    # open
    for s in sigs[-200:]:
        if not isinstance(s,dict): continue
        sid=_sig_id(s)
        if seen.get(sid): continue
        p, why = _open_from_signal(s, acct, risk, sum(1 for x in pos if x.get("status")=="open"), by_sym)
        if p is None:
            seen[sid]=1; skip_stats[why]=skip_stats.get(why,0)+1; continue
        pos.append(p); by_sym[p["symbol"]]=p; seen[sid]=1; opened+=1
        acct["margin_used"]=round(acct.get("margin_used",0.0)+float(p["margin"]),6)

    # update + close
    alive=[]; open_pnl=0.0
    for p in pos:
        if p.get("status")!="open": alive.append(p); continue
        last=_last_price_1m(p["symbol"])
        p,closed=_update_close(p,last)
        alive.append(p)
        if closed:
            _append_hist(closed); closed_cnt+=1
            acct["balance"]=round(float(acct["balance"])+float(closed["pnl"]),6)
            acct["margin_used"]=round(max(0.0, acct.get("margin_used",0.0)-float(closed.get("margin",0.0))),6)
        else:
            open_pnl += float(p.get("pnl",0.0))

    acct["open_pnl"]=round(open_pnl,6)
    acct["equity"]=round(float(acct["balance"])+acct["open_pnl"],6)
    state["positions"]=alive; state["state"]["seen"]=seen; state["state"]["updated"]=int(time.time())
    _save_state(state); _save_account(acct)

    msg = ("opened=%d closed=%d open_now=%d equity=%.2f margin_used=%.2f %s" %
           (opened, closed_cnt, sum(1 for x in alive if x.get("status")=="open"),
            acct["equity"], acct["margin_used"],
            ("skips="+json.dumps(skip_stats,separators=(',',':')) if skip_stats else "")))
    _log(msg); print("[paper] "+msg)

if __name__=="__main__":
    main()

```

### services/positions_watcher.py  
Taille: 4 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 7c7738f87e4f36f8

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json, time, os, math
from pathlib import Path
from typing import Any, Dict, List

BASE = Path("/opt/scalp")
DATA = BASE/"data"
CAND = DATA/"candles"
POSF = DATA/"positions.json"
HISTL= DATA/"positions_hist.jsonl"

TICK = float(os.getenv("POS_TICK_SEC","2"))  # période de suivi en secondes

def _now_iso(): return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

def _read_json(p: Path, dflt):
    try: return json.loads(p.read_text())
    except Exception: return dflt

def _write_atomic(p: Path, obj):
    tmp = p.with_suffix(p.suffix+".tmp")
    tmp.write_text(json.dumps(obj, ensure_ascii=False, separators=(",",":")))
    tmp.replace(p)

def _append_jsonl(p: Path, row: dict):
    p.parent.mkdir(parents=True, exist_ok=True)
    with p.open("a", encoding="utf-8") as f:
        f.write(json.dumps(row, ensure_ascii=False) + "\n")

def _latest_px(sym: str) -> float|None:
    f = CAND/f"{sym}_1m.json"
    if not f.exists(): return None
    try:
        obj = json.loads(f.read_text())
        rows = obj.get("rows", obj) if isinstance(obj, dict) else obj
        if not rows: return None
        return float(rows[-1][4])  # close
    except Exception:
        return None

def _pnl(side:str, entry:float, last:float, size:float, lev:int) -> tuple[float,float]:
    if side.lower().startswith("long"):
        pnl_quote = (last - entry) * size * max(lev,1)
        pct = ((last/entry)-1.0) * 100.0 * max(lev,1)
    else:  # short
        pnl_quote = (entry - last) * size * max(lev,1)
        pct = ((entry/last)-1.0) * 100.0 * max(lev,1)
    return float(pnl_quote), float(pct)

def _should_close(side:str, last:float, tp:float, sl:float) -> tuple[bool,str]:
    s = side.lower()
    if s.startswith("long"):
        if last >= tp > 0:  return True, "tp"
        if sl > 0 and last <= sl: return True, "sl"
    else:  # short
        if tp > 0 and last <= tp: return True, "tp"
        if sl > 0 and last >= sl: return True, "sl"
    return False, ""

def _load_positions() -> List[Dict[str,Any]]:
    obj = _read_json(POSF, {})
    rows = obj.get("positions", []) if isinstance(obj, dict) else []
    return [r for r in rows if isinstance(r, dict)]

def _save_positions(rows: List[Dict[str,Any]]):
    _write_atomic(POSF, {"updated": _now_iso(), "positions": rows})

def step_once() -> int:
    rows = _load_positions()
    if not rows: return 0
    out: List[Dict[str,Any]] = []
    closed = 0
    for r in rows:
        sym = str(r.get("symbol") or r.get("sym") or "?").upper()
        side = str(r.get("side",""))
        entry= float(r.get("entry",0) or 0)
        sl   = float(r.get("sl",0) or 0)
        tp   = float(r.get("tp",0) or 0)
        size = float(r.get("size", r.get("qty",0)) or 0)
        lev  = int(r.get("leverage", r.get("lev",1)) or 1)
        if not sym or entry <= 0 or size <= 0:
            # invalide → ignorer dans le book mais pousser en hist pour traçabilité
            _append_jsonl(HISTL, {**r, "timestamp": _now_iso(), "ts_close": int(time.time()),
                                  "status":"rejected", "reason":"invalid_open_position"})
            continue

        last = _latest_px(sym)
        if last is None:
            # pas de prix → garder la position telle quelle
            out.append(r)
            continue

        pnl_quote, pct = _pnl(side, entry, last, size, lev)
        r_upd = {**r,
                 "last": float(last),
                 "pnl": float(pnl_quote),
                 "pnl_pct": float(pct),
                 "ts_update": int(time.time())}

        do_close, reason = _should_close(side, last, tp, sl)
        if do_close:
            row_hist = {
                "timestamp": _now_iso(),
                "ts_open": int(r.get("ts_open") or time.time()),
                "ts_close": int(time.time()),
                "symbol": sym, "side": side,
                "entry": entry, "sl": sl, "tp": tp,
                "exit": float(last),
                "size": size, "leverage": lev,
                "status":"closed", "reason": reason,
                "pnl": float(pnl_quote), "pnl_pct": float(pct)
            }
            _append_jsonl(HISTL, row_hist)
            closed += 1
        else:
            out.append(r_upd)

    _save_positions(out)
    return closed

def main():
    while True:
        try:
            step_once()
        except Exception as e:
            # on continue même si une position pose problème
            pass
        time.sleep(TICK)

if __name__ == "__main__":
    main()

```

### services/promote_min.py  
Taille: 1 KB  |  MàJ: 2025-09-19 23:16:55  |  SHA256: 65818b090e2fd2ba

```py
import json, time, hashlib
from pathlib import Path

SIG = Path("/opt/scalp/data/signals.json")
POS = Path("/opt/scalp/data/positions.json")
HST = Path("/opt/scalp/data/history.json")

def load(p):
    try: return json.loads(p.read_text())
    except: return []

def dump(p, arr):
    p.parent.mkdir(parents=True, exist_ok=True)
    p.write_text(json.dumps(arr, indent=2))

def uid(s):
    base=f"{s.get('sym')}|{s.get('side')}|{s.get('px')}|{s.get('ts')}"
    return hashlib.md5(base.encode()).hexdigest()

def main():
    sigs = load(SIG)
    if not sigs: 
        print("no signals"); return
    # s'assure d'un ts
    now=int(time.time())
    for s in sigs: s.setdefault("ts", now)
    pos  = load(POS)
    live_ids = { p.get("id") for p in pos }
    moved=0
    for s in sigs:
        s["id"]=uid(s); s["status"]="OPEN"
        if s["id"] in live_ids: 
            continue
        pos.append(s); moved+=1
    # vide la file des signaux (on a promu ceux présents)
    dump(POS, pos)
    dump(SIG, [])
    print(f"promoted={moved}, remaining_signals=0")

if __name__ == "__main__":
    main()

```

### services/run_ohlcv_batch.sh  
Taille: 257 B  |  MàJ: 2025-09-19 18:26:16  |  SHA256: b9cf11d92010bbef

```sh
PY=/opt/scalp/.venv/bin/python
PY="/opt/scalp/.venv/bin/python"
#!/usr/bin/env bash
set -euo pipefail
/opt/scalp/services/ohlcv_bitget_cli.py 5m || true
/opt/scalp/services/ohlcv_bitget_cli.py 15m || true
/opt/scalp/services/ohlcv_bitget_cli.py 30m || true

```

### services/signals_B.py  
Taille: 8 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 68815892ab48a0ba

```py
#!/opt/scalp/.venv/bin/python
# Couche B — déclencheurs Pullback/Breakout/Mean-Reversion sur 1m/3m/5m
# Entrées : /opt/scalp/data/Btop.json ; candles/<SYM>_{1m,3m,5m}.json ([t,o,h,l,c,v])
# Sortie  : /opt/scalp/data/signals.json

import json, time, math
from pathlib import Path

BASE = Path("/opt/scalp")
DATA = BASE/"data"
CAND = DATA/"candles"
BTOP = DATA/"Btop.json"
OUT  = DATA/"signals.json"
RISK = DATA/"risk.json"
ACCT = DATA/"account.json"

# ---------- IO ----------
def _read_cand(sym, tf):
    p = CAND/f"{sym}_{tf}.json"
    if not p.exists(): return []
    try:
        rows = json.loads(p.read_text())
        if isinstance(rows, dict):
            rows = rows.get("rows", [])
        return rows[-600:]
    except Exception:
        return []

def _now(): return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

# ---------- indicateurs ----------
def _ema(vals, n):
    k = 2/(n+1); e=None; out=[]
    for v in vals:
        e = v if e is None else (v-e)*k + e
        out.append(e)
    return out

def _rsi(closes, n=7):
    if len(closes)<n+1: return []
    gains=[0]; losses=[0]
    for i in range(1,len(closes)):
        d=closes[i]-closes[i-1]
        gains.append(max(d,0)); losses.append(max(-d,0))
    def _ema_seq(x,n):
        k=2/(n+1); e=None; o=[]
        for v in x:
            e=v if e is None else (v-e)*k+e; o.append(e)
        return o
    ag=_ema_seq(gains,n); al=_ema_seq(losses,n); r=[]
    for g,l in zip(ag,al):
        r.append(100.0 if l==0 else 100.0 - 100.0/(1.0+g/l))
    return r

def _atr(ohlc, n=14):
    if len(ohlc)<n+1: return []
    trs=[]
    for i in range(1,len(ohlc)):
        _,_,h,l,_,c = ohlc[i]
        _,_,ph,pl,_,pc = ohlc[i-1]
        trs.append(max(h-l, abs(h-pc), abs(l-pc)))
    k=2/(n+1); e=None; out=[]
    for tr in trs:
        e=tr if e is None else (tr-e)*k+e; out.append(e)
    return out

def _boll(closes, n=20, k=2.0):
    if len(closes)<n: return ([],[],[])
    mid=[]; up=[]; lo=[]
    for i in range(len(closes)):
        if i+1<n: mid.append(None); up.append(None); lo.append(None); continue
        win=closes[i+1-n:i+1]
        m=sum(win)/n
        sd=(sum((x-m)**2 for x in win)/n)**0.5 * 0.5
        mid.append(m); up.append(m+k*sd); lo.append(m-k*sd)
    return mid,up,lo

def _macd(closes, f=12, s=26, sig=9):
    if not closes: return [],[],[]
    ef=_ema(closes,f); es=_ema(closes,s)
    macd=[a-b for a,b in zip(ef,es)]
    signal=_ema(macd,sig)
    hist=[m-si for m,si in zip(macd,signal)]
    return macd,signal,hist

def _adx(ohlc, n=14):
    if len(ohlc)<n+2: return []
    trs=[]; plus_dm=[]; minus_dm=[]
    for i in range(1,len(ohlc)):
        _,_,h,l,_,_ = ohlc[i]
        _,_,ph,pl,_,_ = ohlc[i-1]
        up=h-ph; dn=pl-l
        plus_dm.append(max(up,0.0) if up>dn and up>0 else 0.0)
        minus_dm.append(max(dn,0.0) if dn>up and dn>0 else 0.0)
        trs.append(max(h-l, abs(h-ohlc[i-1][4]), abs(l-ohlc[i-1][4])))
    def _ema_seq(x,n):
        k=2/(n+1); e=None; o=[]
        for v in x:
            e=v if e is None else (v-e)*k+e; o.append(e)
        return o
    trn=_ema_seq(trs,n); pdi=[]; mdi=[]
    for pd,md,tr in zip(_ema_seq(plus_dm,n), _ema_seq(minus_dm,n), trn):
        if tr==0: pdi.append(0); mdi.append(0)
        else: pdi.append(100*pd/tr); mdi.append(100*md/tr)
    dx=[0 if (a+b)==0 else 100*abs(a-b)/(a+b) for a,b in zip(pdi,mdi)]
    return _ema_seq(dx,n)

def _vwap_sigmal(ohlc, n=20):
    if len(ohlc)<n: return [None]*len(ohlc),[None]*len(ohlc),[None]*len(ohlc)
    tp=[]; pv=[]
    for _,o,h,l,c,v in ohlc:
        typ=(h+l+c)/3; tp.append(typ); pv.append(typ*v)
    vwap=[]; up=[]; lo=[]
    for i in range(len(ohlc)):
        j=max(0, i+1-n)
        wtp=tp[j:i+1]; wv=[x[5] for x in ohlc[j:i+1]]
        wsum=sum(wv) or 1e-9
        v_i=sum(a*b for a,b in zip(wtp,wv))/wsum
        vwap.append(v_i)
        m=sum(wtp)/len(wtp); sd=(sum((x-m)**2 for x in wtp)/len(wtp))**0.5
        up.append(v_i+sd); lo.append(v_i-sd)
    return vwap,up,lo

def _touch(x, a, b):
    return a is not None and b is not None and ((x<=a) or (x>=b))

def _highest(arr, n): return None if len(arr)<n else max(arr[-n:])
def _lowest(arr, n):  return None if len(arr)<n else min(arr[-n:])

# ---------- risk / size / leverage ----------
def _risk_defaults():
    try: r=json.loads(RISK.read_text())
    except Exception: r={}
    rpct=float(r.get("risk_pct_per_trade", r.get("risk_pct", 0.005)))
    lev =int(r.get("default_leverage", 5))
    return rpct, lev

def _equity_value():
    try: a=json.loads(ACCT.read_text()); return float(a.get("equity", a.get("balance", 1000.0)))
    except Exception: return 1000.0

def _qty_from_stop(entry, sl, equity, risk_pct):
    dist=abs(float(entry)-float(sl)) or 1e-9
    return float(f"{(equity*risk_pct)/dist:.6f}")

# ---------- émetteur sécurisé ----------
def _emit(siglist, sym, entry_set, side, price, sl, tp):
    if price is None or sl is None or tp is None:
        print(f"[B] drop {sym}/{entry_set}: None px={price} sl={sl} tp={tp}")
        return
    if any(v==0 for v in (price, sl, tp)):
        print(f"[B] drop {sym}/{entry_set}: zero px={price} sl={sl} tp={tp}")
        return
    rpct, lev = _risk_defaults()
    eq = _equity_value()
    qty = _qty_from_stop(price, sl, eq, rpct)
    siglist.append({
        "timestamp": _now(),
        "t_emit": int(time.time()),
        "symbol": str(sym).upper(),
        "sym":     str(sym).upper(),
        "entry_set": entry_set,
        "rule":      entry_set,
        "side": side,
        "price_entry": round(float(price),8),
        "sl":          round(float(sl),8),
        "tp":          round(float(tp),8),
        "size": float(qty),
        "leverage": int(lev),
    })

# ---------- règles ----------
def _base_move(px, atrv):
    # garde-fou: ATR ne doit pas dépasser 10% du prix
    cap = 0.1*px
    atr_use = None
    if atrv is not None:
        atr_use = atrv if atrv < cap else cap
    return atr_use if atr_use is not None else 0.003*px

def process_symbol(sym, sigs):
    m1=_read_cand(sym,"1m"); m3=_read_cand(sym,"3m"); m5=_read_cand(sym,"5m")
    if len(m1)<50 or len(m3)<50 or len(m5)<50: return

    c1=[x[4] for x in m1]; c3=[x[4] for x in m3]
    rsi1=_rsi(c1,7); ema20=_ema(c1,20)
    vwap,vu,vl=_vwap_sigmal(m1,20)
    mid,bu,bl=_boll(c1,20,2.0)
    _,_,mach=_macd(c3,12,26,9)
    adx=_adx(m5,14)
    atr=_atr(m3,14)

    px=c1[-1]
    atrv=atr[-1] if atr else None
    base=_base_move(px, atrv)

    adxv=adx[-1] if adx else 0.0
    rsi=rsi1[-1] if rsi1 else 50.0
    ema=ema20[-1] if ema20 else px
    up=bu[-1] if bu else None; lo=bl[-1] if bl else None
    vw_up=vu[-1] if vu else None; vw_lo=vl[-1] if vl else None
    hh=_highest(c3,20); ll=_lowest(c3,20)
    macdh=mach[-1] if mach else 0.0

    # Pullback Trend
    if ema and px>=ema and rsi>50 and _touch(px, vw_lo, vw_up):
        _emit(sigs,sym,"pullback_trend","long", px, px-1.2*base, px+1.8*base)
    if ema and px<=ema and rsi<50 and _touch(px, vw_lo, vw_up):
        _emit(sigs,sym,"pullback_trend","short",px, px+1.2*base, px-1.8*base)

    # Breakout
    if adxv>=20 and hh is not None and ll is not None:
        if px>hh and macdh>0:
            _emit(sigs,sym,"breakout","long", px, ll, px + max(px-hh, 1.5*base))
        if px<ll and macdh<0:
            _emit(sigs,sym,"breakout","short",px, hh, px - max(hh-px, 1.5*base))

    # Mean-Reversion
    if up is not None and lo is not None:
        if px<=lo and rsi<35:
            _emit(sigs,sym,"mean_reversion","long", px, px-1.0*base, (mid[-1] if mid else px*1.002))
        if px>=up and rsi>65:
            _emit(sigs,sym,"mean_reversion","short",px, px+1.0*base, (mid[-1] if mid else px*0.998))

# ---------- main ----------
def main():
    if not BTOP.exists(): return 0
    obj=json.loads(BTOP.read_text())
    syms=[a["sym"] for a in obj.get("assets",[])]
    sigs=[]
    for s in syms: process_symbol(s, sigs)
    OUT.write_text(json.dumps({"updated":_now(),"signals":sigs}, ensure_ascii=False, separators=(",",":")))
    print(f"[B] signals: {len(sigs)} -> {OUT}")
    return 0

if __name__=="__main__":
    raise SystemExit(main())

```

### services/top_bitget.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 605d9a5ae319a1c1

```py
#!/opt/scalp/.venv/bin/python
import json, time, sys
from pathlib import Path
from loguru import logger
import ccxt

DATA = Path("/opt/scalp/data")
FIXES = ["BTC","ETH","BNB","SOL","XRP"]

def main():
    try:
        ex = ccxt.bitget({"options":{"defaultType":"swap"}, "enableRateLimit": True})
        ex.load_markets()
        tick = ex.fetch_tickers()
    except Exception as e:
        logger.error(f"E_BITGET: {e}")
        sys.exit(20)

    # scores par volume quote USDT uniquement
    scores = []
    for s, t in tick.items():
        if ":USDT" not in s and "/USDT" not in s: 
            continue
        vol = float(t.get("quoteVolume", 0) or 0)
        base = s.split('/')[0].split(':')[0]
        scores.append((base, vol))
    scores.sort(key=lambda x: x[1], reverse=True)

    # construire la liste finale
    out = []
    seen = set()
    for b in FIXES + [b for b,_ in scores]:
        if b in seen: 
            continue
        seen.add(b)
        out.append(b)
        if len(out) >= 15: 
            break

    DATA.mkdir(parents=True, exist_ok=True)
    (DATA/"universe.txt").write_text("\n".join(out)+"\n")
    obj = {"assets":[{"sym":s,"vol":0,"vola":0} for s in out],
           "updated": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())}
    (DATA/"top.json").write_text(json.dumps(obj, ensure_ascii=False))
    print("TOP15:", out)

if __name__ == "__main__":
    main()

```

### tools/agg_tf3.py  
Taille: 1 KB  |  MàJ: 2025-09-19 20:41:47  |  SHA256: c697a854ae7ab67a

```py
#!/opt/scalp/.venv/bin/python
import json
from pathlib import Path
import math
D=Path("/opt/scalp/data"); C1=D/"candles"; C3=D/"candles_3m"; C3.mkdir(exist_ok=True)
def floor3(ts): return (ts//(3*60_000))*(3*60_000)  # borné à HH:MM:00 multiples de 3
for f in C1.glob("*_1m.json"):
    rows=json.loads(f.read_text())
    out=[]; buf=[]; cur=None
    for r in rows:
        ts=r["t"] if isinstance(r,dict) else r[0]
        b=floor3(ts)
        if cur is None: cur=b
        if b!=cur:
            if buf:
                o=buf[0]; h=max(x["h"] for x in buf); l=min(x["l"] for x in buf)
                c=buf[-1]["c"]; v=sum(x["v"] for x in buf)
                out.append({"t":cur,"o":o["o"],"h":h,"l":l,"c":c,"v":v})
            buf=[]; cur=b
        d={"t":ts,"o":r["o"],"h":r["h"],"l":r["l"],"c":r["c"],"v":r["v"]}
        buf.append(d)
    if buf:
        o=buf[0]; h=max(x["h"] for x in buf); l=min(x["l"] for x in buf)
        c=buf[-1]["c"]; v=sum(x["v"] for x in buf)
        out.append({"t":cur,"o":o["o"],"h":h,"l":l,"c":c,"v":v})
    (C3/f.name.replace("_1m","_3m")).write_text(json.dumps(out,ensure_ascii=False))
print("tf3 done")

```

### tools/bootstrap_ohlcv_bitget.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:58:47  |  SHA256: 726a4ec73eb40fbb

```py
#!/opt/scalp/.venv/bin/python
import ccxt, json, time, re
from pathlib import Path
ROOT=Path("/opt/scalp"); DATA=ROOT/"data"; C=DATA/"candles"
C.mkdir(parents=True, exist_ok=True)

def norm(sym:str)->str:
    # garde lettres et chiffres pour générer <SYM>_1m.json (ex: BTCUSDT)
    return re.sub(r'[^A-Z0-9]', '', sym.upper())

syms=[l.strip() for l in (DATA/"universe.txt").read_text().splitlines() if l.strip()]
ex=ccxt.bitget({'enableRateLimit': True, 'options': {'defaultType': 'swap'}})

now=ex.milliseconds()
for s in syms:
    s = s.upper()
    mkt = norm(s)
    out = C/f"{mkt}_1m.json"
    ohlc=[]
    since=now-1000*60*1000  # ~1000 minutes
    while True:
        batch = ex.fetch_ohlcv(s, timeframe='1m', since=since, limit=1000)
        if not batch: break
        ohlc += batch
        if len(batch) < 1000: break
        since = batch[-1][0] + 60_000
        time.sleep(ex.rateLimit/1000)
    rows=[{"t":r[0],"o":r[1],"h":r[2],"l":r[3],"c":r[4],"v":r[5]} for r in ohlc]
    out.write_text(json.dumps(rows, ensure_ascii=False))
    print(mkt, len(rows))

```

### tools/bot_ensure_service.sh  
Taille: 472 B  |  MàJ: 2025-09-17 20:44:34  |  SHA256: 4df2f4696041c062

```sh
#!/usr/bin/env bash
set -euo pipefail
API="https://api.telegram.org/bot${TELEGRAM_TOKEN:-$TELEGRAM_BOT_TOKEN}"
# stop manuel + webhook propre
pkill -f "python.*bot\.router" 2>/dev/null || true
curl -s "$API/deleteWebhook" >/dev/null || true
# redémarre le service
systemctl restart scalp-telegram-bot.service
systemctl --no-pager status scalp-telegram-bot.service -n 0 || true
# check doublons
pgrep -fa "python.*bot\.router" || echo "OK: une seule instance via systemd"

```

### tools/build_top_from_heatmap.py  
Taille: 415 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: c1437517bc481006

```py
import json
from pathlib import Path
hm=json.loads(Path("/opt/scalp/data/heatmap_soft.json").read_text())
rows=hm.get("rows",[])
order=sorted([(abs(float(r["S"][-1]["S"])) if r.get("S") else 0.0, r["sym"]) for r in rows], reverse=True)
syms=[s for _,s in order][:15]
Path("/opt/scalp/data/top.json").write_text(json.dumps({"rows":syms},separators=(',',':')))
print("top.json écrit avec",len(syms),"symbols:",syms)

```

### tools/check_B.sh  
Taille: 3 KB  |  MàJ: 2025-09-17 12:18:15  |  SHA256: 57b53030a5007f9b

```sh
#!/usr/bin/env bash
set -euo pipefail
DATA=/opt/scalp/data
PYTHON=/opt/scalp/.venv/bin/python
export PYTHONPATH=/opt/scalp

age_min(){ # age_min <file>
  [ -f "$1" ] || { echo "NA"; return; }
  now=$(date +%s); mt=$(stat -c %Y "$1" 2>/dev/null || stat -f %m "$1")
  echo $(( (now-mt)/60 ))
}

echo "== when & host =="
date -Is; uptime
echo

echo "== files =="
ls -lh --time-style=long-iso "$DATA/heatmap.json" "$DATA/Btop.json" 2>/dev/null || true
echo

echo "== Btop summary =="
if [ -f "$DATA/Btop.json" ]; then
  jq '{updated, count: (.assets|length), sample: (.assets[:8])}' "$DATA/Btop.json" || true
else
  echo "Btop.json absent"
fi
echo

echo "== quick context from heatmap =="
$PYTHON - <<'PY'
import json,sys,statistics,datetime
from pathlib import Path
DATA=Path("/opt/scalp/data")
HM=DATA/"heatmap.json"; BT=DATA/"Btop.json"
BAND=0.10; TH_BUY=0.60; TH_SELL=0.60; RNG_MIN,RNG_MAX=0.40,0.60
def probs(seq):
    b=h=s=0
    for x in seq:
        v=float(x.get("S",0))
        if abs(v) < BAND: h+=1
        elif v>0: b+=1
        else: s+=1
    n=max(1,b+h+s)
    return b/n,h/n,s/n
def ctx(pb,ph,ps):
    if pb>=TH_BUY: return "bullish"
    if ps>=TH_SELL: return "bearish"
    if RNG_MIN<=ph<=RNG_MAX: return "range"
    return "none"

if not HM.exists():
    print("heatmap.json absent"); sys.exit(0)

rows=json.loads(HM.read_text()).get("rows",[])
sym_to_seq={ r["sym"]: r.get("S", r.get("seq",[])) for r in rows }
assets=[]
if (BT.exists()):
    assets=json.loads(BT.read_text()).get("assets",[])
if not assets:
    assets=[r["sym"] for r in rows[:8]]

out=[]
for s in assets[:8]:
    seq=sym_to_seq.get(s,[]) or []
    pb,ph,ps=probs(seq[-20:])
    out.append((s, pb,ph,ps, ctx(pb,ph,ps)))
w= max(3, *(len(t[0]) for t in out)) if out else 4
print(f"{'SYM'.ljust(w)}  p_buy  p_hold  p_sell  CTX")
for s,pb,ph,ps,c in out:
    print(f"{s.ljust(w)}  {pb:5.2f}  {ph:5.2f}  {ps:5.2f}  {c}")
PY
echo

echo "== OHLCV freshness (1m / 5m) for first assets =="
if [ -f "$DATA/Btop.json" ]; then
  mapfile -t SYMS < <(jq -r '.assets[:8][]' "$DATA/Btop.json")
else
  mapfile -t SYMS < <(jq -r '.rows[:8][]|.sym' "$DATA/heatmap.json" 2>/dev/null)
fi
for s in "${SYMS[@]:-}"; do
  f1="$DATA/candles/${s}_1m.json"
  f5="$DATA/candles/${s}_5m.json"
  a1=$(age_min "$f1"); a5=$(age_min "$f5")
  echo "- $s  1m: ${a1}min  5m: ${a5}min"
done
echo

echo "== last analyze_B runs (journal) =="
journalctl -u scalp-analyze-b.path -u scalp-analyze-b.service -n 20 --no-pager 2>/dev/null || true
echo

echo "== readiness summary =="
$PYTHON - <<'PY'
import json, os
from pathlib import Path
DATA=Path("/opt/scalp/data")
BT=DATA/"Btop.json"
assets=[]
if BT.exists():
    j=json.loads(BT.read_text()); assets=j.get("assets",[])
print(f"assets_in_Btop={len(assets)} (showing readiness, not signals)")
PY

```

### tools/check_deps.py  
Taille: 875 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 6c9d3a455c54485a

```py
#!/opt/scalp/.venv/bin/python
import importlib
import subprocess
import sys

REQUIRED = {
    "ccxt": ">=4.5.4",
    "aiogram": ">=3.1.0,<3.2.0",
    "loguru": ">=0.7.0",
    "pandas": ">=2.2.0"
}

def ensure_package(pkg, constraint):
    try:
        importlib.import_module(pkg)
        print(f"[OK] {pkg} déjà installé")
    except ImportError:
        print(f"[WARN] {pkg} absent → tentative d’installation…")
        try:
            subprocess.check_call([
                "/opt/scalp/.venv/bin/pip", "install", f"{pkg}{constraint}"
            ])
            print(f"[OK] {pkg} installé")
        except Exception as e:
            print(f"[ERREUR] Impossible d’installer {pkg} ({e})")

if __name__ == "__main__":
    for pkg, constraint in REQUIRED.items():
        ensure_package(pkg, constraint)
    print("[DONE] Vérification dépendances terminée")

```

### tools/check_env.py  
Taille: 132 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: bdedbed9c59dd8f1

```py
#!/opt/scalp/.venv/bin/python
import ccxt, aiogram, pandas, loguru
print("✅ Environnement prêt")
print("ccxt", ccxt.__version__)

```

### tools/check_heat.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 1e9e2a0902d72977

```py
#!/opt/scalp/.venv/bin/python
import json, pathlib, sys, datetime as dt
DATA = pathlib.Path("/opt/scalp/data")
HEAT = DATA/"heatmap.json"; TOP = DATA/"top.json"

def load(p): return json.loads(pathlib.Path(p).read_text(encoding="utf-8"))

def age_minutes(iso):
    try:
        t = dt.datetime.fromisoformat(iso.replace("Z",""))
        return int((dt.datetime.utcnow()-t).total_seconds()//60)
    except Exception: return 10**9

def check():
    top = load(TOP); heat = load(HEAT)
    assets = [a["sym"] for a in top.get("assets", [])]
    rows = heat.get("rows", [])
    errs=[]
    # 15 lignes attendues
    if len(assets)!=15: errs.append(f"top.assets={len(assets)} (attendu 15)")
    if len(rows)!=15: errs.append(f"heat.rows={len(rows)} (attendu 15)")
    # chaque ligne: 3 TF avec b/h/s présents
    for r in rows:
        sym=r.get("sym","?")
        for tf in ("5m","15m","30m"):
            d=r.get(tf, {})
            if not isinstance(d, dict) or not all(k in d for k in ("b","h","s")):
                errs.append(f"{sym} {tf} invalide: {d}")
    # fraîcheur
    a = age_minutes(heat.get("updated",""))
    stale = a>30  # sécurité globale (si global trop ancien)
    return errs, a, stale

if __name__=="__main__":
    errs, age, stale = check()
    print(f"age_min={age}  stale={int(stale)}")
    for e in errs: print("ERR:", e)
    sys.exit(1 if errs or stale else 0)

```

### tools/check_ohlcv_1m.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 286901705840af80

```py
#!/opt/scalp/.venv/bin/python
# Vérifie existence, taille, âge et dernier timestamp des {SYM}_1m.json
import json, time
from pathlib import Path

DATA = Path("/opt/scalp/data")
CAND = DATA/"candles"
UNI  = DATA/"universe.txt"

def load_universe():
    if not UNI.exists(): return []
    return [x.strip().upper() for x in UNI.read_text().splitlines() if x.strip()]

def probe(sym:str):
    p = CAND / f"{sym}_1m.json"
    if not p.exists():
        return f"{sym:<6} MISSING"
    try:
        obj=json.loads(p.read_text())
        rows=obj.get("rows") or obj
        n=len(rows)
        ts = rows[-1][0] if n else None
        age = (time.time() - (ts/1000 if ts else 0)) if ts else None
        return f"{sym:<6} n={n:<5} last_ts={ts or 'None':<13} age_s={int(age) if age else 'NA':<6} path={p}"
    except Exception as e:
        return f"{sym:<6} ERROR {e}"

def main():
    syms=load_universe()
    if not syms:
        print("universe.txt vide"); return
    for s in syms:
        print(probe(s))

if __name__=="__main__":
    main()

```

### tools/diag_B.sh  
Taille: 394 B  |  MàJ: 2025-09-17 10:59:39  |  SHA256: 9f5d453b2f803071

```sh
#!/usr/bin/env bash
set -euo pipefail
D=/opt/scalp/data
echo "== files =="
ls -lh --time-style=long-iso "$D/heatmap.json" "$D/btop.json" 2>/dev/null || true
echo
echo "== run analyze_B =="
/opt/scalp/.venv/bin/python /opt/scalp/services/analyze_B.py || true
echo
echo "== btop preview =="
jq -c '{updated, symbols, n:(.symbols|length)}' "$D/btop.json" 2>/dev/null || cat "$D/btop.json" || true

```

### tools/diag_heat.sh  
Taille: 2 KB  |  MàJ: 2025-09-17 10:15:20  |  SHA256: 2ad25ba1c125b90c

```sh
#!/usr/bin/env bash
set -euo pipefail
export LC_ALL=C

echo "== horodatage & charge =="
date -Is; uptime
echo

echo "== service & python du bot =="
MAINPID=$(systemctl show scalp-telegram-bot.service -p MainPID --value || true)
EXE=$(readlink -f /proc/${MAINPID}/exe 2>/dev/null || true)
echo "MainPID: ${MAINPID}"
echo "python: ${EXE}"
echo

echo "== fichiers clés =="
ls -lh --time-style=long-iso /opt/scalp/data/heatmap_soft.json 2>/dev/null || true
ls -lh --time-style=long-iso /opt/scalp/data/candles/*_5m.json 2>/dev/null | tail -n 6 || true
echo

echo "== PYTHONPATH =="
export PYTHONPATH=/opt/scalp
echo "$PYTHONPATH"
echo

echo "== test source + rendu (views_heat.py) =="
/usr/bin/env python3 - <<'PY'
import inspect, json, pathlib, sys
try:
    from bot.views_heat import render_heatmap
except Exception as e:
    print("IMPORT_ERR:", e); sys.exit(2)

src = inspect.getsourcefile(render_heatmap) or "?"
print("SRC:", src)

p = pathlib.Path("/opt/scalp/data/heatmap_soft.json")
print("JSON exists:", p.exists(), "size:", (p.stat().st_size if p.exists() else 0))
rows = []
if p.exists():
    try:
        obj = json.loads(p.read_text())
        rows = obj.get("rows", [])
        first = rows[0]["sym"] if rows else "-"
        print("rows:", len(rows), "first:", first)
    except Exception as e:
        print("JSON_ERR:", e)

t = render_heatmap() or ""
print("LEN:", len(t))
print("PREVIEW:", (t[:140].encode("utf-8","ignore")))
assert "views_heat.py" in src, "Mismatch source (not bot/views_heat.py)"
assert t.strip() not in ("", "<pre></pre>"), "Empty <pre></pre> payload"
assert len(t) > 20, "Payload too short"
print("OK ✅")
PY
echo

echo "== imports côté bot_stdlib (lecture brute) =="
grep -nE 'from bot\.views_heat|render_heatmap' -n /opt/scalp/bot/bot_stdlib.py || true
echo

echo "== derniers logs systemd =="
journalctl -u scalp-telegram-bot.service --since "15 min ago" --no-pager -n 60 || true

```

### tools/diag_heatmap.py  
Taille: 589 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: ade576310e3a601e

```py
#!/opt/scalp/.venv/bin/python
import json, pathlib, datetime as dt, sys
D=pathlib.Path("/opt/scalp/data")
hm=json.loads((D/"heatmap.json").read_text())
rows=hm.get("rows",[])
ok=len(rows)
bad=[r["sym"] for r in rows if any(tf not in r or r[tf].count("/")!=2 for tf in ("5m","15m","30m"))]
upd=hm.get("updated","")
age=9999
try:
    t=dt.datetime.fromisoformat(upd.replace("Z","+00:00"))
    age=int((dt.datetime.utcnow().replace(tzinfo=dt.timezone.utc)-t).total_seconds()//60)
except: pass
print(f"rows={ok}/15  age={age}m  bad={bad}")
sys.exit(0 if ok==15 and age<=15 and not bad else 1)

```

### tools/diag_refresh.sh  
Taille: 4 KB  |  MàJ: 2025-09-16 20:51:48  |  SHA256: dc8d4a4081cd85b6

```sh
#!/usr/bin/env bash
set -euo pipefail
BASE=/opt/scalp
DATA=$BASE/data
VENv=$BASE/.venv
PY=${VENv}/bin/python || true
log(){ printf "\e[1;36m[%s]\e[0m %s\n" "$(date -u +%H:%M:%SZ)" "$*"; }

need_tools(){
  command -v jq >/dev/null || { log "jq manquant → apt install"; apt-get update -y && apt-get install -y jq >/dev/null; }
}

# --- normalise un JSON possiblement "collé-collé" (2 écritures) ---
normalize_json(){
  f="$1"; tmp="$(mktemp)"
  $PY - <<'PY' "$f" >"$tmp" || { echo "{}"; } 
import sys, json, re, pathlib
p=pathlib.Path(sys.argv[1])
raw=p.read_text(errors="ignore")
# garde uniquement le plus GRAND bloc JSON bien formé
cands=[]
stack=[]
for i,ch in enumerate(raw):
    if ch=='{': stack.append(i)
    elif ch=='}' and stack:
        s=stack.pop(0) if False else stack[-1]  # noop, just keep stack
# cherche en glouton: du 1er '{' au dernier '}'
m=re.search(r'\{.*\}', raw, re.S)
txt = m.group(0) if m else "{}"
obj=json.loads(txt)
print(json.dumps(obj, indent=2, ensure_ascii=False))
PY
  mv "$tmp" "$f"
}

# --- diag d'un fichier heatmap/top -------------------------------
diag_file(){
  f="$1"; key="$2"
  if [ ! -s "$f" ]; then echo "!! $key: fichier absent/vide"; return 1; fi
  if ! jq -e . "$f" >/dev/null 2>&1; then
    echo "!! $key: JSON invalide -> normalisation"; normalize_json "$f"
  fi
  echo "-- $key OK ($(stat -c%s "$f") bytes)"
}

# --- fraicheur heatmap -------------------------------------------
check_fresh(){
  f="$DATA/heatmap.json"
  upd=$(jq -r '.updated // empty' "$f" 2>/dev/null || true)
  if [ -z "${upd:-}" ]; then echo "stale: no 'updated'"; return 9; fi
  # minutes d'âge
  now=$(date -u +%s); ts=$(date -u -d "$upd" +%s 2>/dev/null || echo 0)
  age_min=$(( (now-ts)/60 ))
  echo "updated: $upd (âge ${age_min}m)"
  # seuils (5m pour 5m, 15m pour 15m ; on prend 6m comme garde-fou global)
  [ $age_min -le 6 ] && return 0 || return 9
}

# --- relance pipeline (OHLCV + analyse + heatmap) ----------------
refresh_pipeline(){
  log "Relance OHLCV 5m/15m/30m (service)"
  systemctl start scalp-ohlcv.service || true
  sleep 2
  log "Tentative (analyse/heatmap) si service dispo"
  systemctl start scalp-analyze.service 2>/dev/null || true
  # fallback: si un script de build heatmap existe, on l'appelle
  if [ -x "$BASE/services/build_heatmap.py" ]; then
    "$PY" "$BASE/services/build_heatmap.py" || true
  fi
}

# --- résumé Telegram bot -----------------------------------------
restart_tg(){
  log "Redémarrage bot Telegram"
  systemctl restart scalp-telegram-bot.service || true
  sleep 1
  systemctl --no-pager status scalp-telegram-bot.service -l | sed -n '1,14p'
}

# --- MAIN --------------------------------------------------------
need_tools
log "Normalisation JSON (top/heatmap/signals)"
mkdir -p "$DATA"
for f in "$DATA/top.json" "$DATA/heatmap.json" "$DATA/signals.json"; do
  [ -f "$f" ] && normalize_json "$f" || true
done

diag_file "$DATA/top.json"     "top.json"     || true
diag_file "$DATA/heatmap.json" "heatmap.json" || true
diag_file "$DATA/signals.json" "signals.json" || true

echo "assets(top): $(jq -r '.assets|length' "$DATA/top.json" 2>/dev/null || echo 0)"
echo "rows(heat):  $(jq -r '.rows|length'   "$DATA/heatmap.json" 2>/dev/null || echo 0)"
echo

log "Vérif fraîcheur heatmap"
if check_fresh; then
  log "Heatmap fraîche ✅"
else
  log "Heatmap périmée ⚠️  -> refresh pipeline"
  refresh_pipeline
  log "Re-vérif fraîcheur"
  check_fresh || log "Toujours périmée (voir logs services)."
fi

log "Contrôle cohérence (3 TF par row attendu)"
jq -r '.rows[]|select(.sym!=null)|"\(.sym) => " + ([.["5m"],.["15m"],.["30m"]] | map(if type=="object" then "ok" else "KO" end) | join("/"))' "$DATA/heatmap.json" 2>/dev/null || true

restart_tg
log "Fini."

```

### tools/diag_systemd_1m.sh  
Taille: 970 B  |  MàJ: 2025-09-17 15:07:17  |  SHA256: 345b9b480f1e0ccc

```sh
#!/usr/bin/env bash
# Inspecte timer/service 1m et 3m + derniers logs journalctl
set -euo pipefail
SYMS="${*:-$(cat /opt/scalp/data/universe.txt | awk '{print toupper($0)}')}"
echo "Syms: $SYMS"
echo "== Timers list =="
systemctl list-timers | grep -E 'scalp-(ohlcv-1m|agg-3m)@' || true
for s in $SYMS; do
  echo "---- $s ----"
  systemctl status scalp-ohlcv-1m@${s}.timer --no-pager | sed -n '1,12p'
  systemctl status scalp-ohlcv-1m@${s}.service --no-pager | sed -n '1,25p'
  echo "-- last run exit --"
  systemctl show scalp-ohlcv-1m@${s}.service -p ExecMainStatus -p Result
  echo "-- logs 1m (last 50) --"
  journalctl -u scalp-ohlcv-1m@${s}.service -n 50 --no-pager || true

  echo "-- 3m timer/service --"
  systemctl status scalp-agg-3m@${s}.timer --no-pager | sed -n '1,12p'
  systemctl status scalp-agg-3m@${s}.service --no-pager | sed -n '1,25p'
  echo "-- logs 3m (last 50) --"
  journalctl -u scalp-agg-3m@${s}.service -n 50 --no-pager || true

  echo
done

```

### tools/enable_B_watchers.sh  
Taille: 190 B  |  MàJ: 2025-09-17 11:54:41  |  SHA256: 22c9040991eec6b9

```sh
#!/usr/bin/env bash
set -euo pipefail
systemctl daemon-reload
systemctl enable --now scalp-analyze-b.path
systemctl enable --now scalp-btop-hook.path
systemctl start scalp-analyze-b.service

```

### tools/guard_soft.sh  
Taille: 576 B  |  MàJ: 2025-09-17 07:55:30  |  SHA256: 8493635fa518c286

```sh
#!/usr/bin/env bash
set -u
LOG=/opt/scalp/data/guard_soft.log
SOFT=/opt/scalp/data/heatmap_soft.json
PY=/opt/scalp/.venv/bin/python

ts(){ date -Is; }

# 1) vérifier l’import /heat
if ! grep -q 'render_heatmap as render_heat_soft' /opt/scalp/bot/bot_stdlib.py; then
  echo "$(ts) WARN bad /heat import" >>"$LOG"
fi

# 2) vérifier schéma softmap et reconstruire si vide/HS
if [ ! -s "$SOFT" ] || ! jq -e '.rows|type=="array"' "$SOFT" >/dev/null 2>&1; then
  echo "$(ts) FIX rebuild softmap" >>"$LOG"
  "$PY" /opt/scalp/services/build_softmap.py >/dev/null 2>&1 || true
fi

```

### tools/health_heatmap.sh  
Taille: 430 B  |  MàJ: 2025-09-17 06:54:38  |  SHA256: e6defee79890777c

```sh
#!/usr/bin/env bash
set -e
PY=/opt/scalp/.venv/bin/python
JSON=/opt/scalp/data/heatmap.json
rows=$($PY - <<'PY'
import json,sys,pathlib
p=pathlib.Path("/opt/scalp/data/heatmap.json")
try: print(len(json.loads(p.read_text()).get("rows",[])))
except: print(0)
PY
)
if [ "${rows:-0}" -eq 0 ]; then
  PATH=/opt/scalp/.venv/bin:$PATH /opt/scalp/services/run_ohlcv_batch.sh || true
  $PY /opt/scalp/services/build_softmap.py || true
fi

```

### tools/install_deps.sh  
Taille: 207 B  |  MàJ: 2025-09-16 17:06:23  |  SHA256: 6ab46c638a244fba

```sh
#!/bin/bash
set -e
python3 -m venv /opt/scalp/.venv 2>/dev/null || true
source /opt/scalp/.venv/bin/activate
pip install --upgrade pip
pip install -r /opt/scalp/requirements.txt
echo "[OK] deps installées"

```

### tools/json_view.py  
Taille: 2 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 929b0cc756d36c67

```py
#!/opt/scalp/.venv/bin/python
import sys, json, math
from pathlib import Path

def _is_list_of_dict(x): return isinstance(x, list) and all(isinstance(i, dict) for i in x)
def _is_dict_of_scalars(x): 
    return isinstance(x, dict) and all(not isinstance(v,(list,dict)) for v in x.values())

def _trim(s, n=48):
    s = str(s)
    return s if len(s)<=n else s[:n-1]+"…"

def render_table(rows):
    # collect columns
    cols = set()
    for r in rows: cols |= set(r.keys())
    cols = list(cols)
    # widths
    w = {c:max(len(c), *(len(_trim(r.get(c,""))) for r in rows)) for c in cols}
    # lines
    sep = " ".join("-"*w[c] for c in cols)
    head = " ".join(c.ljust(w[c]) for c in cols)
    out = [head, sep]
    for r in rows:
        out.append(" ".join(_trim(r.get(c,"")).ljust(w[c]) for c in cols))
    return "\n".join(out)

def render_dict(d):
    kmax = max(len(str(k)) for k in d) if d else 1
    lines = []
    for k in sorted(d):
        v = d[k]
        if isinstance(v,(list,dict)):
            v = json.dumps(v, ensure_ascii=False)
        lines.append(f"{str(k).ljust(kmax)} : {v}")
    return "\n".join(lines)

def main():
    if len(sys.argv)<2:
        print("usage: json_view.py <file.json> [jq-filter]", file=sys.stderr); sys.exit(2)
    p = Path(sys.argv[1])
    if not p.exists(): 
        print(f"(à connecter: {p})"); sys.exit(0)
    obj = json.loads(p.read_text(encoding="utf-8"))
    # optional jq-like key path: e.g. rows or signals
    if len(sys.argv) > 2:
        key = sys.argv[2]
        if isinstance(obj, dict) and key in obj: obj = obj[key]
    if _is_list_of_dict(obj):
        print("<pre>"+render_table(obj)+"</pre>")
    elif _is_dict_of_scalars(obj):
        print("<pre>"+render_dict(obj)+"</pre>")
    else:
        # fallback pretty json
        print("<pre>"+json.dumps(obj, ensure_ascii=False, indent=2)+"</pre>")
if __name__=="__main__": main()

```

### tools/make_context.py  
Taille: 890 B  |  MàJ: 2025-09-19 20:41:29  |  SHA256: 4de68f9646096230

```py
#!/opt/scalp/.venv/bin/python
import json, statistics as st
from pathlib import Path
D=Path("/opt/scalp/data"); H=D/"heatmap.json"
if not H.exists(): H=D/"s_history/heatmap.json"
obj=json.loads(H.read_text()); rows=obj.get("rows",obj)

def buck(x): return float(x)
def avg(S,n): 
    S=S[-n:] if len(S)>=n else S
    return st.mean(S) if S else 0.0

ctx={}
for r in rows:
    s=r["sym"]
    s60, s30, s15, snow = map(buck,[avg(r["S"],60),avg(r["S"],30),avg(r["S"],15),r["S"][-1] if r["S"] else 0])
    # règles simples de contexte
    pbuy  = 1.0 if (s60>0 and s30>0 and snow>0) else 0.0
    phold = 1.0 if (s60>0 and abs(snow)<0.5) else 0.0
    psell = 1.0 if (s60<0 and s30<0 and snow<0) else 0.0
    ctx[s]={"S":{"60":s60,"30":s30,"15":s15,"now":snow},"pbuy":pbuy,"phold":phold,"psell":psell}
(D/"context.json").write_text(json.dumps(ctx,ensure_ascii=False))
print("context:",len(ctx))

```

### tools/normalize_json.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 7323e5f84af96b69

```py
#!/opt/scalp/.venv/bin/python
import json, pathlib
D=pathlib.Path("/opt/scalp/data")
# top.json -> ensure {"assets":[...]}
tp=D/"top.json"
try:
    obj=json.loads(tp.read_text())
    if isinstance(obj, dict) and "assets" in obj: pass
    else:
        # si liste brute -> wrap
        if isinstance(obj,list): obj={"assets":[{"sym":s,"vol":0,"vola":0} for s in obj]}
        tp.write_text(json.dumps(obj))
except: pass
# heatmap.json -> force {"updated":,"rows":[{"sym":,"5m":,"15m":,"30m":}]}
hm=D/"heatmap.json"
try:
    o=json.loads(hm.read_text())
    if "rows" in o and isinstance(o["rows"],list) and o["rows"] and isinstance(o["rows"][0],dict): pass
    else: hm.write_text(json.dumps({"updated":"", "rows":[]}))
except: hm.write_text(json.dumps({"updated":"", "rows":[]}))

# signals.json -> liste
sg=D/"signals.json"
try:
    o=json.loads(sg.read_text()); 
    if isinstance(o,dict) and "signals" in o: pass
    else: sg.write_text(json.dumps({"signals":[]}))
except: sg.write_text(json.dumps({"signals":[]}))
print("JSON normalisés.")

```

### tools/normalize_positions.py  
Taille: 836 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: b630357772234e82

```py
#!/opt/scalp/.venv/bin/python
import json, math
from pathlib import Path
DATA=Path("/opt/scalp/data"); POS=DATA/"positions.json"; RISK=DATA/"risk.json"
risk=json.loads(RISK.read_text()) if RISK.exists() else {"default_leverage":5}
obj=json.loads(POS.read_text()) if POS.exists() else {"positions":[]}
chg=0
for p in obj.get("positions",[]):
    if not isinstance(p,dict): continue
    if "leverage" not in p or "notional" not in p or "margin" not in p:
        e=float(p.get("entry",0)); sz=float(p.get("size",0)); lev=int(p.get("leverage") or risk.get("default_leverage",5))
        notion=sz*e; margin= notion/max(1,lev)
        p.setdefault("leverage", lev); p.setdefault("notional", notion); p.setdefault("margin", margin); chg+=1
POS.write_text(json.dumps(obj, ensure_ascii=False, separators=(",",":")))
print(f"backfilled={chg}")

```

### tools/ohlcv_sync.py  
Taille: 3 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 0508bfbf2be45b41

```py
#!/opt/scalp/.venv/bin/python
import os, sys, time, json, pathlib, traceback

DATA = pathlib.Path("/opt/scalp/data")
LOG  = pathlib.Path("/opt/scalp/logs/ohlcv_sync.log")
DATA.mkdir(parents=True, exist_ok=True); LOG.parent.mkdir(parents=True, exist_ok=True)

TF_SECONDS = {"1m":60, "5m":300, "15m":900}

def log(msg):
    ts=time.strftime("%Y-%m-%d %H:%M:%SZ", time.gmtime())
    LOG.write_text((LOG.read_text() if LOG.exists() else "") + f"{ts} {msg}\n")

def next_close(ts:int, period:int)->int:
    return ((ts // period) + 1) * period

def fetch_bitget_ohlcv(symbol:str, tf:str, end_ts:int):
    """
    TODO: brancher l'API Bitget ici. Retour attendu: liste de bougies [ [t, o, h, l, c, v], ... ]
    Contraintes:
      - ne pas retourner une bougie 'partielle' (t < end_ts et t+period > end_ts)
      - timestamps en secondes UNIX
    Pour l’instant, on renvoie un jeu factice pour tester la chaîne.
    """
    period = TF_SECONDS[tf]
    t0 = end_ts - 50*period
    out = []
    px = 100.0
    for k in range(50):
        t = t0 + k*period
        o = px; h = px*1.01; l = px*0.99; c = px*(1.0 + (0.0005 if k%2==0 else -0.0004)); v = 10+k
        out.append([t,o,h,l,c,v]); px = c
    return out

def build_heatmap_from_ohlcv(ohlcv_by_sym_tf:dict)->dict:
    """
    Exemple simple: compte des bougies haussières/baissières sur 50 dernières bougies.
    """
    rows=[]
    for sym, tfs in ohlcv_by_sym_tf.items():
        row={"sym": sym}
        for tf, arr in tfs.items():
            b=h=s=0
            for (_,o,_,_,c,_) in arr[-50:]:
                if c>o: b+=1
                elif c<o: s+=1
                else: h+=1
            row[tf] = {"b":b,"h":h,"s":s}
        rows.append(row)
    return {"updated": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()), "rows": rows}

def main():
    SYMS = os.getenv("SYMS","BTC,ETH,LINK").split(",")
    TFS  = os.getenv("TFS","5m,15m").split(",")
    align = sorted({TF_SECONDS[tf] for tf in TFS})
    now = int(time.time())
    # on s'aligne sur la plus petite période demandée
    wait_to = min(next_close(now, p) for p in align)
    delay = max(0, wait_to - now)
    if delay>0:
        time.sleep(delay + 1)  # +1s pour laisser fermer la bougie à la source
    end = int(time.time()//align[0]*align[0])

    try:
        ohlcv = {}
        for sym in SYMS:
            ohlcv[sym]={}
            for tf in TFS:
                ohlcv[sym][tf]=fetch_bitget_ohlcv(f"{sym}USDT", tf, end)
        # construit heatmap
        heat = build_heatmap_from_ohlcv(ohlcv)
        DATA.joinpath("heatmap.json").write_text(json.dumps(heat, ensure_ascii=False, separators=(",",":")))
        # placeholders pour signals/top si besoin plus tard
        if not DATA.joinpath("signals.json").exists():
            DATA.joinpath("signals.json").write_text('{"signals":[]}')
        if not DATA.joinpath("top.json").exists():
            DATA.joinpath("top.json").write_text('{"assets":[]}')
        log(f"OK update @ {end} for {','.join(TFS)} {','.join(SYMS)}")
    except Exception as e:
        log(f"E-FETCH: {e}\n{traceback.format_exc()}")
        # on n'écrase pas les fichiers existants si erreur

if __name__=="__main__":
    main()

```

### tools/on_Btop_updated.sh  
Taille: 381 B  |  MàJ: 2025-09-17 11:54:14  |  SHA256: 904a6737972943bb

```sh
#!/usr/bin/env bash
# Orchestrateur Couche B déclenché après mise à jour de Btop.json :
# 1) fetch 1m  2) aggregate 1m->3m  3) run signals_B
set -euo pipefail
export PYTHONPATH=/opt/scalp
/opt/scalp/.venv/bin/python /opt/scalp/services/ohlcv_1m_cli.py
/opt/scalp/.venv/bin/python /opt/scalp/services/agg_1m_to_3m.py
/opt/scalp/.venv/bin/python /opt/scalp/services/signals_B.py

```

### tools/on_btop_updated.sh  
Taille: 392 B  |  MàJ: 2025-09-17 10:59:10  |  SHA256: c47d092d83b31c5d

```sh
#!/usr/bin/env bash
set -euo pipefail
log(){ printf "[on_btop] %s\n" "$*"; }
BTOP="/opt/scalp/data/btop.json"
if [[ ! -f "$BTOP" ]]; then
  log "absent ($BTOP)"; exit 0
fi
SYMS=$(jq -r '.symbols[]?' "$BTOP" 2>/dev/null || true)
log "Btop: $(echo "$SYMS" | tr '\n' ' ')"
# TODO: déclencher ici ta collecte 1m pour $SYMS
# Exemple (à adapter):
# systemctl start scalp-ohlcv-1m.service
exit 0

```

### tools/ping_telegram.py  
Taille: 907 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: b2bacfe8bc83739a

```py
#!/opt/scalp/.venv/bin/python
import os, urllib.request, urllib.parse, json, pathlib, re

# Charge /etc/scalp.env
env_file = pathlib.Path("/etc/scalp.env")
data = {}
if env_file.exists():
    RGX = re.compile(r'^\s*([A-Za-z_]\w*)\s*=\s*(.*)\s*$')
    for line in env_file.read_text().splitlines():
        m = RGX.match(line)
        if m: data[m.group(1)] = m.group(2).strip().strip('"').strip("'")

TOKEN = data.get("TELEGRAM_BOT_TOKEN")
CHAT  = data.get("TELEGRAM_CHAT_ID")

if not TOKEN or not CHAT:
    raise SystemExit("❌ TELEGRAM_BOT_TOKEN ou TELEGRAM_CHAT_ID manquant dans /etc/scalp.env")

# Envoi ping
url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
payload = {"chat_id": CHAT, "text": "ping test ✅ (depuis scalp/tools)", "parse_mode": "HTML"}
data = urllib.parse.urlencode(payload).encode()

with urllib.request.urlopen(url, data=data, timeout=20) as r:
    print(r.read().decode())

```

### tools/pretty_heat.py  
Taille: 983 B  |  MàJ: 2025-09-19 20:18:06  |  SHA256: 27722ff047f7e980

```py
#!/opt/scalp/.venv/bin/python
import json, math, datetime as dt
from pathlib import Path

ROOT=Path("/opt/scalp"); D=ROOT/"data"
HP = D/"heatmap.json"
HS = D/"s_history"/"heatmap.json"
p = HP if HP.exists() else HS
obj = json.loads(p.read_text())
rows = obj.get("rows", obj)

# bucket S -> -6..+6
def buck(v): 
    v = max(-6.0, min(6.0, v*3.0))
    return int(round(v))

# ordre: fixes d'abord puis reste
FIX = ["BTCUSDT","ETHUSDT","BNBUSDT","SOLUSDT","XRPUSDT"]
rows.sort(key=lambda r: (0 if r["sym"] in FIX else 1, FIX.index(r["sym"]) if r["sym"] in FIX else r["sym"]))

lines=[]
now = dt.datetime.utcnow().strftime("%H:%M")
lines.append(f"Heatmap {now}")
for i,r in enumerate(rows):
    sym = r["sym"].replace("USDT","")[:4].ljust(4)
    last4 = [buck(x) for x in r["S"][-4:]] if r["S"] else [0,0,0,0]
    txt = " ".join([f"{v:+d}" for v in last4])
    lines.append(f"{sym}  {txt}")
    if (i+1)%5==0 and i+1<len(rows): lines.append("")  # espace visuel

print("\n".join(lines))

```

### tools/pretty_heat_60_30_15_now.py  
Taille: 1 KB  |  MàJ: 2025-09-19 22:17:10  |  SHA256: 8ea47adf2b10c25c

```py
#!/opt/scalp/.venv/bin/python
import json, statistics as st, datetime as dt
from pathlib import Path
D=Path("/opt/scalp/data")
H = D/"heatmap.json"
if not H.exists(): H = D/"s_history"/"heatmap.json"
rows = json.loads(H.read_text()).get("rows", [])
FIX = ["BTCUSDT","ETHUSDT","BNBUSDT"]
top_scores={}
T=D/"top.json"
if T.exists():
  for x in json.loads(T.read_text()).get("scored",[]):
    top_scores[x["symbol"].replace("/USDT:USDT","USDT")] = float(x.get("score",0))
def keyscore(r):
  s=r["sym"]
  return (0, FIX.index(s), 0) if s in FIX else (1, 0, -top_scores.get(s,-1.0))
rows.sort(key=keyscore)

def clamp(v,a,b): return a if v<a else b if v>b else v
def buck(x): return int(round(clamp(x*3.0,-6.0,6.0)))
def mean_tail(S,n): 
  if not S: return 0.0
  k=min(len(S),n); return st.mean(S[-k:])
now=dt.datetime.utcnow().strftime("%H:%M")
out=[f"Heatmap {now}"]; col=[]
for i,r in enumerate(rows,1):
  S=r.get("S") or []
  sym=r["sym"].replace("USDT","")[:5].ljust(5)
  v60,v30,v15,v00 = (buck(mean_tail(S,60)), buck(mean_tail(S,30)), buck(mean_tail(S,15)), buck(S[-1] if S else 0.0))
  col.append(f"{sym} {v60:+d} {v30:+d} {v15:+d} {v00:+d}")
  if i%5==0 or i==len(rows): out.append("\n".join(col)); out.append(""); col=[]
print("\n".join(out).rstrip())

```

### tools/pretty_positions.py  
Taille: 403 B  |  MàJ: 2025-09-19 22:55:25  |  SHA256: 6aee911c57153fba

```py
from pathlib import Path, json
P=Path("/opt/scalp/data/positions.json")
if not P.exists(): print("No position"); raise SystemExit(0)
pos=json.loads(P.read_text())
print("Positions")
for p in pos[:10]:
    sym=p["sym"].replace("USDT:USDT","")
    side="L" if p["side"][0].upper()=="L" else "S"
    print(f"{sym:<6} {side}  qty {p.get('qty',0):.3g}  px {p.get('px',0):.4g}  uPnL {p.get('upnl',0):+.2f}$")

```

### tools/pretty_signals.py  
Taille: 905 B  |  MàJ: 2025-09-19 22:54:55  |  SHA256: 507826703143c81d

```py
from pathlib import Path
import json, math, datetime as dt, pytz
P=Path("/opt/scalp/data/signals.json")
if not P.exists(): print("No signal"); raise SystemExit(0)
s=json.loads(P.read_text())
# on limite et on ordonne par fraîcheur puis score interne si présent
s=sorted(s, key=lambda x: x.get("ts",0), reverse=True)[:8]
# format court
lines=["Signals " + dt.datetime.now(dt.timezone.utc).strftime("%H:%M")]
for x in s:
    sym=x["sym"].replace("USDT:USDT","").replace("USDTUSDT","")
    side="L" if x["side"].upper().startswith("L") else "S"
    px,sl,tp=float(x["px"]),float(x["sl"]),float(x["tp"])
    lev=int(x.get("lev",1)); qty=x.get("qty",0)
    r_tp = (tp-px)/px*100 if side=="L" else (px-tp)/px*100
    r_sl = (sl-px)/px*100 if side=="L" else (px-sl)/px*100
    lines.append(f"{sym:<6} {side} x{lev}  px {px:.4g}  tp {tp:.4g} ({r_tp:+.1f}%)  sl {sl:.4g} ({r_sl:+.1f}%)")
print("\n".join(lines))

```

### tools/pretty_status.py  
Taille: 1 KB  |  MàJ: 2025-09-19 20:23:28  |  SHA256: 095cd4258d1cc8b9

```py
#!/opt/scalp/.venv/bin/python
import json, datetime as dt
from pathlib import Path

p = Path("/opt/scalp/data/status.json")
if not p.exists():
    print("Status: no data")
    raise SystemExit(0)

obj = json.loads(p.read_text())
now = dt.datetime.utcnow().strftime("%H:%M")

# exemple de formatage compact
out = [f"Status {now}  Solde:{obj.get('balance','-')}"]
out.append(f"PnL: {obj.get('pnl_plus',0):+.2f}$ / {obj.get('pnl_minus',0):+.2f}$")

times = obj.get("timeframes", [])
if times:
    header = "Time " + " | ".join([t["tf"] for t in times])
    out.append(header)
    out.append("Nb   " + " | ".join([str(t.get("nb",0)) for t in times]))
    out.append("PnL  " + " | ".join([f"{t.get('pnl',0):+.2f}$" for t in times]))
    out.append("Best " + " | ".join([f"{t.get('best',0):+.2f}$" for t in times]))
    out.append("Coin " + " | ".join([t.get('best_coin','-') for t in times]))
    out.append("Worst"+ " | ".join([f"{t.get('worst',0):+.2f}$" for t in times]))
    out.append("Coin " + " | ".join([t.get('worst_coin','-') for t in times]))

print("\n".join(out))

```

### tools/pretty_top.py  
Taille: 555 B  |  MàJ: 2025-09-19 20:18:18  |  SHA256: 697b2481487cbf6c

```py
#!/opt/scalp/.venv/bin/python
import json, math
from pathlib import Path
p=Path("/opt/scalp/data/top.json")
if not p.exists(): 
    print("{}"); raise SystemExit(0)
obj=json.loads(p.read_text())
sel=obj.get("selected") or []
sc=obj.get("scored") or []
best = sorted(sc, key=lambda x:x.get("score",0), reverse=True)[:10]
def fmt(x): 
    v=float(x)/1e6
    return f"{v:.2f}M"
out=["Top (vol×vola)"]
for i,e in enumerate(best,1):
    sym=e["symbol"].split("/")[0].ljust(5)[:5]
    out.append(f"{i:>2}. {sym} {fmt(e.get('score',0))}")
print("\n".join(out))

```

### tools/pretty_top_names.py  
Taille: 1 KB  |  MàJ: 2025-09-19 22:46:40  |  SHA256: 3cca7f878b9bf4c9

```py
from pathlib import Path
from json import loads
from datetime import datetime

p = Path("/opt/scalp/data/top.json")
data = loads(p.read_text()) if p.exists() else {}
rows = data.get("scored", data if isinstance(data, list) else [])

# tri décroissant volu×vola (score)
rows = sorted(rows, key=lambda x: float(x.get("score", 0)), reverse=True)[:15]

def clean(sym:str)->str:
    s = sym.replace("/USDT:USDT","").replace(":USDT","")
    s = s.split("/")[0]
    return s.upper()

names = [clean(r.get("symbol","")) for r in rows]
# padding à 3 colonnes × 5 lignes
cols, rowsN = 3, 5
grid = [names[i::rowsN] for i in range(rowsN)]  # lignes
# largeur de chaque colonne
colW = [0]*cols
for c in range(cols):
    col = [ names[r*cols+c] for r in range(rowsN) if r*cols+c < len(names) ]
    colW[c] = max(len(x) for x in col) if col else 0

out = [f"Top (vol×vola) {datetime.utcnow():%H:%M}"]
for r in range(rowsN):
    line=[]
    for c in range(cols):
        i = r + c*rowsN
        if i < len(names):
            line.append(names[i].ljust(colW[c]+2))
    out.append("".join(line).rstrip())
print("\n".join(out))

```

### tools/probe_B.sh  
Taille: 2 KB  |  MàJ: 2025-09-17 07:58:03  |  SHA256: d2b5426c69c6d1bd

```sh
#!/usr/bin/env bash
set -euo pipefail
PY=/opt/scalp/.venv/bin/python
D=/opt/scalp/data
log(){ printf "\n# %s\n" "$*"; }

log "Horodatage et charge"
date -Is; uptime

log "Fichiers d'entrée clés"
ls -lh --time-style=long-iso $D/heatmap_soft.json $D/top.json 2>/dev/null || true
ls -lh --time-style=long-iso $D/candles/*_5m.json 2>/dev/null | tail -n 5 || true

log "Aperçu heatmap_soft.json"
$PY - <<'PY'
import json,sys,Pathlib as P
from pathlib import Path
p=Path("/opt/scalp/data/heatmap_soft.json")
if not p.exists(): 
    print("absent"); sys.exit(0)
obj=json.loads(p.read_text())
rows=obj.get("rows",[])
print("rows =",len(rows))
if rows:
    r0=rows[0]
    s=r0.get("S",[])
    print("first sym =",r0.get("sym")," seq_len =",len(s))
    print("last 5 S =", [ round(float(x["S"]),3) for x in s[-5:] ])
    # sanity: ordre temps croissant
    ok=all(s[i]["t"]<=s[i+1]["t"] for i in range(len(s)-1)) if s else True
    print("chronology_ok =",ok)
PY

log "Aperçu TOP"
$PY - <<'PY'
import json,sys
from pathlib import Path
p=Path("/opt/scalp/data/top.json")
if p.exists():
  obj=json.loads(p.read_text())
  rows=obj.get("rows") or obj.get("syms") or []
  print("top count =",len(rows), " sample =", rows[:5])
else:
  print("top.json absent")
PY

log "Service(s) liés à B"
systemctl -q is-active scalp-analyze-b.service && systemctl --no-pager -l status scalp-analyze-b.service -n 0 || echo "service scalp-analyze-b.service: not found"

log "Dry-run analyze_B s'il existe"
if [ -f /opt/scalp/services/analyze_B.py ]; then
  time $PY /opt/scalp/services/analyze_B.py --dry-run 2>&1 | tail -n +1
else
  echo "analyze_B.py: not found"
fi

log "Derniers logs bot"
journalctl -u scalp-telegram-bot.service -n 30 --no-pager || true

```

### tools/probe_pipeline.sh  
Taille: 2 KB  |  MàJ: 2025-09-17 08:09:27  |  SHA256: a6f4343343962af7

```sh
#!/usr/bin/env bash
set -euo pipefail
PY=/opt/scalp/.venv/bin/python
D=/opt/scalp/data
sep(){ printf '\n# %s\n' "$*"; }

sep "Horodatage + charge"; date -Is; uptime

sep "Présence des fichiers clés"
ls -lh --time-style=long-iso "$D/heatmap_soft.json" "$D/top.json" 2>/dev/null || true
ls -lh --time-style=long-iso "$D"/candles/*_5m.json 2>/dev/null | tail -n 5 || true
ls -lh --time-style=long-iso "$D"/candles/*_1m.json 2>/dev/null | tail -n 5 || true

sep "Aperçu heatmap_soft.json + validation schéma + 5 derniers S"
"$PY" - <<'PY'
import json
from pathlib import Path
p=Path("/opt/scalp/data/heatmap_soft.json")
if not p.exists(): print("absent"); raise SystemExit(0)
obj=json.loads(p.read_text()); rows=obj.get("rows",[])
print("rows =",len(rows)); 
if not rows: raise SystemExit(0)
S=rows[0].get("S",[]); print("first sym =",rows[0].get("sym")," seq_len =",len(S))
tail=S[-5:] if len(S)>=5 else S
print("last 5 =",[ round(float(x['S']),3) for x in tail ])
ok=all(S[i]['t']<=S[i+1]['t'] for i in range(len(S)-1)) if S else True
print("chronology_ok =",ok)
PY

sep "Détection tendance locale (derniers 2 points)"
"$PY" - <<'PY'
import json
from pathlib import Path
TH_UP=0.6; TH_DN=-0.6
def trend(seq):
    if len(seq)<2: return "—", None
    a=float(seq[-2]["S"]); b=float(seq[-1]["S"])
    d="▲" if b>a else ("▼" if b<a else "—")
    zone="blue" if -0.4<=b<=0.4 else ("green" if b>TH_UP else ("red" if b<TH_DN else "grey"))
    return d,(round(a,3),round(b,3),zone)
rows=json.loads(Path("/opt/scalp/data/heatmap_soft.json").read_text())["rows"]
for r in rows:
    d,vals=trend(r.get("S",[]))
    if vals: a,b,z=vals; print(f'{r["sym"]:>5}: {d}  {a}->{b}  {z}')
PY

sep "Top15 aperçu"
"$PY" - <<'PY'
import json
from pathlib import Path
p=Path("/opt/scalp/data/top.json")
if p.exists():
  obj=json.loads(p.read_text())
  rows=obj.get("rows") or obj.get("syms") or []
  print("count =",len(rows)," sample =",rows[:10])
else:
  print("top.json absent")
PY

sep "Bougies 1m récentes (<6 min)"
find "$D/candles" -maxdepth 1 -type f -name '*_1m.json' -mmin -6 -printf '%TY-%Tm-%Td %TH:%TM  %p\n' 2>/dev/null | sort || echo "aucune"

sep "Couche B"
systemctl -q is-active scalp-analyze-b.service && systemctl --no-pager -l status scalp-analyze-b.service -n 0 || echo "service scalp-analyze-b.service: not found"
[ -f /opt/scalp/services/analyze_B.py ] && { echo "-- analyze_B.py présent"; "$PY" /opt/scalp/services/analyze_B.py --dry-run 2>&1 | tail -n +1; } || echo "analyze_B.py: not found"

```

### tools/probe_pipeline_B.sh  
Taille: 1015 B  |  MàJ: 2025-09-17 08:16:45  |  SHA256: f7b48d6765688190

```sh
#!/usr/bin/env bash
set -euo pipefail
PY=/opt/scalp/.venv/bin/python || PY=python3

echo "# Horodatage"; date -Is; uptime

echo -e "\n# Présence des fichiers clés"
ls -lh --time-style=long-iso /opt/scalp/data/heatmap_soft.json /opt/scalp/data/top.json 2>/dev/null || true
ls -lh --time-style=long-iso /opt/scalp/data/candles/*_1m.json 2>/dev/null | tail -n 5 || true

echo -e "\n# Contexte Couche A (extrait)"
$PY - <<'PY'
import json, pathlib, sys
p=pathlib.Path("/opt/scalp/data/heatmap_soft.json")
obj=json.loads(p.read_text()) if p.exists() else {"rows":[]}
for r in obj.get("rows",[])[:5]:
    s=r.get("S") or []
    last=float(s[-1].get("S",0)) if s else 0.0
    print(r["sym"], "S_last=", last, "-> p_buy", round((last+1)/2,2), "p_sell", round((1-last)/2,2), "p_hold", round(1-abs(last),2))
PY

echo -e "\n# Run analyze_B (à blanc + impression)"
$PY /opt/scalp/services/analyze_B.py | sed -n '1,5p'

echo -e "\n# Signals.jsonl (tail)"
tail -n 5 /opt/scalp/data/signals.jsonl 2>/dev/null || echo "(aucun)"

```

### tools/purge_state.sh  
Taille: 1 KB  |  MàJ: 2025-09-17 17:05:54  |  SHA256: 7fe17a5fd7d658d7

```sh
#!/usr/bin/env bash
set -euo pipefail
DATA=/opt/scalp/data
BACK="$DATA/backup_$(date -u +%Y%m%dT%H%M%SZ)"

backup() { # $1=src
  [ -f "$1" ] || return 0
  dst="$BACK/${1#$DATA/}"
  mkdir -p "$(dirname "$dst")"
  cp -a "$1" "$dst"
}

mkdir -p "$BACK"

# stop trader
systemctl stop scalp-paper.path 2>/dev/null || true
systemctl stop scalp-paper.service 2>/dev/null || true

# backups si présents
backup "$DATA/signals.json"
backup "$DATA/positions.json"
backup "$DATA/positions_hist.jsonl"
backup "$DATA/account.json"
backup "$DATA/paper.log"
backup "$DATA/logs/paper.log"

# purge + réinit
: > "$DATA/signals.json"
printf '{"positions":[],"state":{"seen":{},"updated":%s}}\n' "$(date +%s)" > "$DATA/positions.json"
: > "$DATA/positions_hist.jsonl"
printf '{"balance":100,"equity":100,"open_pnl":0,"margin_used":0,"currency":"USDT","updated":%s}\n' "$(date +%s)" > "$DATA/account.json"
: > "$DATA/paper.log" 2>/dev/null || true
mkdir -p "$DATA/logs"; : > "$DATA/logs/paper.log"

# relance du déclencheur
systemctl start scalp-paper.path 2>/dev/null || true

echo "Purge OK. Backup: $BACK"

```

### tools/refresh_bot.sh  
Taille: 242 B  |  MàJ: 2025-09-16 20:04:04  |  SHA256: ffcf0340af607413

```sh
#!/usr/bin/env bash
set -euo pipefail
/opt/scalp/.venv/bin/python /opt/scalp/tools/normalize_json.py || true
systemctl restart scalp-telegram-bot.service
sleep 1
systemctl --no-pager -l status scalp-telegram-bot.service -n 0 | sed -n '1,12p'

```

### tools/refresh_pipeline.sh  
Taille: 823 B  |  MàJ: 2025-09-16 20:54:54  |  SHA256: 915a4681f72b521f

```sh
#!/usr/bin/env bash
set -euo pipefail
log(){ printf "[%(%H:%M:%SZ)T] %s\n" -1 "$*"; }

log "Normalisation JSON"
python3 /opt/scalp/tools/normalize_json.py >/dev/null || true

log "Vérif heatmap"
if ! python3 /opt/scalp/tools/check_heat.py; then
  log "⏳ pipeline refresh: OHLCV + analyze"
  systemctl start scalp-ohlcv.service || true
  sleep 3
  systemctl start scalp-analyze.service || true
  # Patience courte mais visible
  for i in {1..10}; do
    sleep 3
    python3 /opt/scalp/tools/normalize_json.py >/dev/null || true
    if python3 /opt/scalp/tools/check_heat.py >/dev/null; then
      log "✅ heatmap OK"
      break
    fi
    [ $i -eq 10 ] && log "⚠️ encore incomplet (voir journaux services)"
  done
fi

log "Redémarrage bot Telegram"
systemctl restart scalp-telegram-bot.service || true
log "Fini."

```

### tools/relaunch_all.sh  
Taille: 2 KB  |  MàJ: 2025-09-17 11:28:51  |  SHA256: f36b0c26984a6f6e

```sh
#!/usr/bin/env bash
set -euo pipefail

VENV=/opt/scalp/.venv
PY=$VENV/bin/python
export PYTHONPATH=/opt/scalp

echo "== 1) loguru =="
$PY - <<'PY' || true
try:
    import loguru  # noqa
    print("loguru OK")
except Exception as e:
    raise SystemExit(1)
PY
if [ $? -ne 0 ]; then
  . "$VENV/bin/activate"
  pip install --quiet loguru
  echo "✓ loguru installé"
fi

echo "== 2) reset top.json =="
TOP=/opt/scalp/data/top.json
printf '{\n  "updated": null,\n  "assets": []\n}\n' > "$TOP"

echo "== 3) rebuild Top (top_bitget.py) =="
$PY /opt/scalp/services/top_bitget.py
jq -r '.assets|length' "$TOP" 2>/dev/null | xargs -I{} echo "assets: {}"

echo "== 4) OHLCV batch 5m/15m/30m =="
systemctl start scalp-ohlcv.service
systemctl -q is-active scalp-ohlcv.service || true
sleep 2
journalctl -u scalp-ohlcv.service -n 5 --no-pager || true

echo "== 5) analyze A (build heatmap) =="
systemctl start scalp-analyze.service
sleep 2
journalctl -u scalp-analyze.service -n 10 --no-pager || true

echo "== 6) restart Telegram bot =="
systemctl restart scalp-telegram-bot.service
sleep 1
systemctl status scalp-telegram-bot.service --no-pager -l | sed -n '1,12p'

echo "== 7) quick checks =="
# 7a top.json
echo "-- top.json --"
jq -r '{updated,assets_len:(.assets|length)}' "$TOP" 2>/dev/null || cat "$TOP"

# 7b heatmap.json rows
echo "-- heatmap.json --"
H=/opt/scalp/data/heatmap.json
if [ -s "$H" ]; then
  jq -r '("rows=" + ((.rows//[])|length|tostring))' "$H" || true
else
  echo "absent or empty"
fi

# 7c vue /heat (doit renvoyer autre chose que <pre></pre>)
echo "-- render_heatmap smoke --"
$PY - <<'PY'
from bot.views_heat import render_heatmap as RH
t = RH() or ""
print("LEN", len(t), "OK" if (len(t)>20 and "<pre>" not in t) else "BAD")
PY

echo "== Done =="

```

### tools/relaunch_clean.sh  
Taille: 720 B  |  MàJ: 2025-09-17 09:02:44  |  SHA256: 6bbc4568bf24f0af

```sh
#!/usr/bin/env bash
set -euo pipefail
export PYTHONPATH=/opt/scalp

svc=scalp-telegram-bot.service
echo "== restart =="
systemctl restart "$svc"
sleep 1
systemctl is-active "$svc" --quiet || { journalctl -u "$svc" -n 80 --no-pager; exit 1; }

echo "== anti-ghost check =="
/usr/bin/env python3 - <<'PY'
import inspect
from bot.views_heat import render_heatmap
t = render_heatmap() or ""
src = inspect.getsourcefile(render_heatmap) or "?"
print("SRC:", src)
print("LEN:", len(t))
assert "views_heat.py" in src, "Heatmap source mismatch"
assert t.strip() != "<pre></pre>", "Empty <pre></pre> payload"
assert len(t) > 20, "Payload too short"
print("OK ✅")
PY

echo "== last logs =="
journalctl -u "$svc" -n 40 --no-pager

```

### tools/repair_and_restart.sh  
Taille: 5 KB  |  MàJ: 2025-09-16 18:59:28  |  SHA256: 8243bc488d0ee7e9

```sh
#!/usr/bin/env bash
set -euo pipefail
BASE=/opt/scalp
DATA=$BASE/data
SYS=/etc/systemd/system
VENV=$BASE/.venv
PY=$VENV/bin/python
PIP=$VENV/bin/pip
JQ_BIN=$(command -v jq || true)

log(){ printf "\e[1;36m[%s]\e[0m %s\n" "$(date -u +%H:%M:%SZ)" "$*"; }

need_jq(){
  if [ -z "$JQ_BIN" ]; then
    log "jq manquant → installation (apt)"
    apt-get update -y && apt-get install -y jq >/dev/null
    JQ_BIN=$(command -v jq)
  fi
}

ensure_dirs(){
  mkdir -p "$DATA" "$BASE/tools" "$BASE/bot" "$BASE/services" "$BASE/data/candles"
}

ensure_venv(){
  if [ ! -x "$PY" ]; then
    log "Création du venv"
    apt-get update -y >/dev/null
    apt-get install -y python3-venv python3-pip >/dev/null
    python3 -m venv "$VENV"
  fi
  log "MàJ pip + deps de base"
  "$PIP" -q install --upgrade pip >/dev/null
  "$PIP" -q install "aiogram>=2.25,<3" loguru pandas "ccxt>=4.5" >/dev/null || true
}

fix_service_execstart(){
  # forcer ExecStart à utiliser le venv
  sed -i 's#^ExecStart=.*bot_stdlib.*#ExecStart='"$PY"' -m bot.bot_stdlib#' "$SYS/scalp-telegram-bot.service" 2>/dev/null || true
  sed -i 's#^ExecStart=/usr/bin/python3 #ExecStart='"$PY"' #' "$SYS/scalp-ohlcv-1m.service" 2>/dev/null || true
  sed -i 's#^ExecStart=/usr/bin/python3 #ExecStart='"$PY"' #' "$SYS/scalp-analyze.service" 2>/dev/null || true
}

ts_iso(){ date -u +"%Y-%m-%dT%H:%M:%SZ"; }

write_json(){
  # $1=path  $2=json_string
  printf '%s\n' "$2" >"$1"
}

normalize_top(){
  local f="$DATA/top.json"
  local now; now=$(ts_iso)
  if [ -s "$f" ] && $JQ_BIN -e . "$f" >/dev/null 2>&1; then
    # garder seulement 'assets' (sym/vol/vola) + updated
    local syms
    syms=$($JQ_BIN -r '.assets[].sym' "$f" 2>/dev/null | paste -sd',' - || true)
    if [ -n "$syms" ]; then
      local arr="[]"
      IFS=',' read -ra A <<<"$syms"
      for s in "${A[@]}"; do
        arr=$($JQ_BIN -c --arg s "$s" '. + [{"sym":$s,"vol":0,"vola":0}]' <<<"$arr")
      done
      write_json "$f" "$($JQ_BIN -c --argjson a "$arr" --arg u "$now" '{assets:$a,updated:$u}')"
      return
    fi
  fi
  # défaut (15 tickers les plus fréquents si aucun top existant)
  local def='["BTC","ETH","BNB","SOL","XRP","DOGE","AVAX","SUI","PUMP","BAKE","PEPE","ENA","SOMI","ZKC","AVNT"]'
  local arr=$($JQ_BIN -c 'map({sym:.,vol:0,vola:0})' <<<"$def")
  write_json "$f" "$($JQ_BIN -c --argjson a "$arr" --arg u "$now" '{assets:$a,updated:$u}')"
}

normalize_heatmap(){
  local f="$DATA/heatmap.json"
  local now; now=$(ts_iso)
  if [ -s "$f" ]; then
    # certains fichiers contenaient 2 objets concaténés → garder le DERNIER
    local norm
    norm=$($JQ_BIN -cs '.[-1]' "$f" 2>/dev/null || true)
    if [ -n "$norm" ] && [ "$norm" != "null" ]; then
      write_json "$f" "$norm"
      return
    fi
  fi
  # squelette vide basé sur top.json
  local rows
  rows=$($JQ_BIN -c '[inputs.assets[].sym] | .[0]' "$DATA/top.json" 2>/dev/null || true)
  if [ -z "$rows" ]; then rows='["BTC","ETH","ADA"]'; fi
  local out="[]"; for s in $(echo "$rows" | $JQ_BIN -r '.[]'); do
    out=$($JQ_BIN -c --arg s "$s" '. + [{"sym":$s,"5m":"0/0/0","15m":"0/0/0","30m":"0/0/0"}]' <<<"$out")
  done
  write_json "$f" "$($JQ_BIN -c --argjson r "$out" --arg u "$now" '{updated:$u,rows:$r}')"
}

normalize_signals(){
  local f="$DATA/signals.json"
  local now; now=$(ts_iso)
  if [ -s "$f" ] && $JQ_BIN -e . "$f" >/dev/null 2>&1; then
    # normaliser structure en {updated,signals:[...]}
    local sigs; sigs=$($JQ_BIN -c '.signals // []' "$f")
    write_json "$f" "$($JQ_BIN -c --argjson s "$sigs" --arg u "$now" '{updated:$u,signals:$s}')"
  else
    write_json "$f" "$($JQ_BIN -c --arg u "$now" '{updated:$u,signals:[]}')"
  fi
}

normalize_positions_history(){
  local now; now=$(ts_iso)
  for f in "$DATA/positions.json" "$DATA/history.json"; do
    if [ -s "$f" ] && $JQ_BIN -e . "$f" >/dev/null 2>&1; then
      :
    else
      write_json "$f" "$($JQ_BIN -c --arg u "$now" '{updated:$u,rows:[]}')"
    fi
  done
}

stop_services(){
  systemctl stop scalp-telegram-bot.service >/dev/null 2>&1 || true
  systemctl stop scalp-ohlcv.service >/dev/null 2>&1 || true
}

start_services(){
  systemctl daemon-reload
  systemctl restart scalp-telegram-bot.service || true
  systemctl restart scalp-ohlcv.timer || true
  systemctl restart scalp-top15.timer || true
}

status(){
  echo
  systemctl status scalp-telegram-bot.service --no-pager -l | sed -n '1,20p'
  echo
  for f in top heatmap signals positions history; do
    printf "\n--- %s ---\n" "$f"
    $JQ_BIN . "$DATA/$f.json" 2>/dev/null | sed -n '1,60p' || true
  done
}

main(){
  log "Préparation"
  need_jq
  ensure_dirs
  stop_services
  ensure_venv
  fix_service_execstart
  log "Normalisation JSON"
  normalize_top
  normalize_heatmap
  normalize_signals
  normalize_positions_history
  log "Redémarrage services"
  start_services
  log "OK."
  status
}
main "$@"

```

### tools/reset_top_json.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: ee50bbaae2c252e6

```py
#!/opt/scalp/.venv/bin/python
import json, sys, time
from pathlib import Path

BASE = Path("/opt/scalp")
DATA = BASE / "data"
TOP  = DATA / "top.json"
HEAT = DATA / "heatmap.json"
SOFT = DATA / "heatmap_soft.json"

def now():
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

def has_valid_top(p: Path) -> bool:
    try:
        obj = json.loads(p.read_text())
        return isinstance(obj.get("assets"), list)
    except Exception:
        return False

def symbols_from_heatmap() -> list[str]:
    for p in (SOFT, HEAT):
        if p.exists():
            try:
                obj = json.loads(p.read_text())
                rows = obj.get("rows", [])
                syms = []
                for r in rows:
                    s = r.get("sym") or r.get("symbol") or r.get("SYM")
                    if s: syms.append(s)
                return syms
            except Exception:
                pass
    return []

def main():
    force = "--force" in sys.argv
    if TOP.exists() and has_valid_top(TOP) and not force:
        print("top.json already valid (use --force to overwrite)")
        return

    syms = symbols_from_heatmap()
    if not syms:
        print("No symbols found from heatmap; writing minimal top.json")
    assets = [{"sym": s, "vol": 0, "vola": 0} for s in syms]

    obj = {"assets": assets, "updated": now()}
    TOP.write_text(json.dumps(obj, ensure_ascii=False, separators=(',',':')))
    print(f"top.json reset with {len(assets)} assets")

if __name__ == "__main__":
    main()

```

### tools/restart_and_preview.sh  
Taille: 648 B  |  MàJ: 2025-09-17 05:42:28  |  SHA256: 1b555e0de0e0b18d

```sh
#!/usr/bin/env bash
set -euo pipefail
BASE=/opt/scalp
VENV=$BASE/.venv
PY=$VENV/bin/python

log(){ printf "\e[1;36m[%s]\e[0m %s\n" "$(date -u +%H:%M:%SZ)" "$*"; }

log "1) Relance analyse A (Layer A)"
$PY $BASE/analyze/analyze_a_cli.py || true

log "2) Génère nouvelle heatmap softmax (3 derniers S@5m)"
$PY $BASE/services/build_heatmap_softmax.py || true

log "3) Aperçu terminal (rows)"
$BASE/tools/json_view.py $BASE/data/heatmap.json rows | sed -n '1,20p'

log "4) Redémarrage bot Telegram"
systemctl restart scalp-telegram-bot.service || true
sleep 1
systemctl --no-pager status scalp-telegram-bot.service -n 0 | sed -n '1,12p'

log "OK."

```

### tools/rotate_history.sh  
Taille: 182 B  |  MàJ: 2025-09-18 07:49:29  |  SHA256: 2e74d2e62f311bb4

```sh
#!/usr/bin/env bash
set -euo pipefail
D=/opt/scalp/data
F=$D/positions_hist.jsonl
[ -s "$F" ] || exit 0
ym=$(date -u +%Y-%m)
gzip -c "$F" > "$D/positions_hist_$ym.jsonl.gz"
: > "$F"

```

### tools/run_1m_now.sh  
Taille: 638 B  |  MàJ: 2025-09-17 11:10:22  |  SHA256: f0a606d0751a6289

```sh
#!/usr/bin/env bash
set -euo pipefail
export PYTHONPATH=/opt/scalp
/opt/scalp/.venv/bin/python /opt/scalp/services/ohlcv_1m_cli.py
/opt/scalp/.venv/bin/python /opt/scalp/services/agg_1m_to_3m.py
echo "== samples =="
ls -lh --time-style=long-iso /opt/scalp/data/candles/*_{1,3}m.json 2>/dev/null | tail -n 10 || true
sym=$(ls /opt/scalp/data/candles/*_1m.json 2>/dev/null | head -n1)
[ -n "$sym" ] && python3 - <<'PY'
import json,sys, pathlib
p = pathlib.Path(sys.argv[1])
s = json.loads(p.read_text()); t = json.loads(p.with_name(p.name.replace("_1m","_3m")).read_text())
print("1m last 3:", s[-3:])
print("3m last 3:", t[-3:])
PY "$sym"

```

### tools/run_B_pipeline_now.sh  
Taille: 271 B  |  MàJ: 2025-09-17 11:54:34  |  SHA256: dd3cbb4c780e00cd

```sh
#!/usr/bin/env bash
set -euo pipefail
export PYTHONPATH=/opt/scalp
/opt/scalp/.venv/bin/python /opt/scalp/services/analyze_B.py
/opt/scalp/tools/on_Btop_updated.sh
jq -C '.signals[:10]' /opt/scalp/data/signals.json 2>/dev/null || cat /opt/scalp/data/signals.json || true

```

### tools/select_universe_bitget.py  
Taille: 3 KB  |  MàJ: 2025-09-19 19:50:21  |  SHA256: b361f3b687978263

```py
#!/opt/scalp/.venv/bin/python
import os, json, time, math, statistics as st, re
from pathlib import Path
import ccxt

ROOT = Path("/opt/scalp")
DATA = ROOT/"data"
CAND = DATA/"candles"
CAND.mkdir(parents=True, exist_ok=True)

# Fixes par défaut. Ajoute-en via EXTRA_FIXED="SOL/USDT:USDT,XRP/USDT:USDT"
FIXED = {"BTC/USDT:USDT", "ETH/USDT:USDT", "BNB/USDT:USDT"}
FIXED |= {s.strip().upper() for s in os.environ.get("EXTRA_FIXED","").split(",") if s.strip()}

def norm(sym:str) -> str:
    # 'BTC/USDT:USDT' -> 'BTCUSDT'
    return re.sub(r'[^A-Z0-9]', '', sym.upper())

ex = ccxt.bitget({'enableRateLimit': True, 'options': {'defaultType': 'swap'}})

# 1) Marchés éligibles: swap USDT
markets = ex.load_markets()
symbols = [m['symbol'] for m in markets.values() if m.get('swap') and m.get('quote') == 'USDT']

# 2) Volume 24h
tickers = ex.fetch_tickers(symbols)
def vol_usd(t):
    q = t.get('quoteVolume') or 0
    if q: return q
    b = t.get('baseVolume') or 0
    p = t.get('last') or 0
    return b*p

cands = sorted(((s, vol_usd(tickers.get(s, {}))) for s in symbols), key=lambda x: x[1], reverse=True)[:120]

# 3) Volatilité log-retours 1m sur ~12h
def vola(sym):
    try:
        o = ex.fetch_ohlcv(sym, timeframe='1m', limit=720)
        if len(o) < 60: return 0.0
        rets = []
        for i in range(1, len(o)):
            p0, p1 = o[i-1][4], o[i][4]
            if p0 > 0: rets.append(math.log(p1/p0))
        return st.stdev(rets) * math.sqrt(60*24)
    except Exception:
        return 0.0

scored = []
for s, v in cands:
    sig = vola(s)
    scored.append({"symbol": s, "volume_usd": float(v or 0), "vola": float(sig or 0), "score": float((v or 0)*(sig or 0))})
    time.sleep(ex.rateLimit/1000)

# 4) Sélection
fixed = [s for s in FIXED if s in symbols]
dyn = [x["symbol"] for x in sorted(scored, key=lambda x: x["score"], reverse=True) if x["symbol"] not in fixed][:max(0, 15-len(fixed))]
sel = fixed + dyn

# 5) Écritures
DATA.mkdir(exist_ok=True, parents=True)
# universe.txt
(DATA/"universe.txt").write_text("\n".join(sel) + "\n", encoding="utf-8")
# top.json détaillé
out = {
    "fixed": fixed,
    "dynamic": dyn,
    "selected": sel,
    "scored": scored[:50]  # résumé
}
(ROOT/"data/top.json").write_text(json.dumps(out, ensure_ascii=False, indent=2), encoding="utf-8")

# 6) Bootstrap bougies manquantes (jusqu'à 1000×1m)
for s in sel:
    path = CAND/f"{norm(s)}_1m.json"
    if path.exists(): continue
    o = ex.fetch_ohlcv(s, timeframe='1m', limit=1000)
    rows = [{"t":r[0],"o":r[1],"h":r[2],"l":r[3],"c":r[4],"v":r[5]} for r in o]
    path.write_text(json.dumps(rows, ensure_ascii=False), encoding="utf-8")
    time.sleep(ex.rateLimit/1000)

print("universe size:", len(sel))
for s in sel: print(" ", s)

```

### tools/set_bot_commands.py  
Taille: 2 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 186572856d330a31

```py
#!/opt/scalp/.venv/bin/python
import json, re, pathlib, sys, urllib.request

ENV = pathlib.Path("/etc/scalp.env")
RGX = re.compile(r'^\s*([A-Za-z_]\w*)\s*=\s*(.*)\s*$')

def load_token():
    if not ENV.exists():
        sys.exit("ERREUR: /etc/scalp.env introuvable")
    data={}
    for line in ENV.read_text().splitlines():
        m = RGX.match(line)
        if m:
            k,v = m.group(1), m.group(2).strip().strip('"').strip("'")
            data[k]=v
    tok = data.get("TELEGRAM_BOT_TOKEN","").strip()
    if not tok:
        sys.exit("ERREUR: TELEGRAM_BOT_TOKEN manquant dans /etc/scalp.env")
    return tok

def set_commands(token):
    url = f"https://api.telegram.org/bot{token}/setMyCommands"
    # Menu FR minimal demandé
    cmds = [
        {"command":"top",        "description":"Top 15 volume/volatilité"},
        {"command":"heat",       "description":"Heatmap B/H/S (résumé)"},
        {"command":"signal",     "description":"Derniers signaux"},
        {"command":"position",   "description":"Positions ouvertes"},
        {"command":"historique", "description":"Historique des ordres"},
        {"command":"debug",      "description":"Diagnostic rapide"},
    ]
    payload = json.dumps({"commands":cmds,"language_code":"fr"}).encode()
    req = urllib.request.Request(url, data=payload,
                                 headers={"Content-Type":"application/json"})
    with urllib.request.urlopen(req, timeout=15) as r:
        res = json.loads(r.read().decode())
    ok = res.get("ok") and res.get("result") is True
    print("[OK] setMyCommands" if ok else f"[FAIL] {res}")

if __name__ == "__main__":
    set_commands(load_token())

```

### tools/setup_venv.sh  
Taille: 1 KB  |  MàJ: 2025-09-17 06:54:13  |  SHA256: 2ca39d5524a356e8

```sh
#!/usr/bin/env bash
set -euo pipefail
BASE=/opt/scalp
VENV=$BASE/.venv
PY=$VENV/bin/python
PIP=$VENV/bin/pip
REQS=$BASE/requirements.txt

# venv
[ -x "$PY" ] || python3 -m venv "$VENV"
$PY -m pip install -U pip wheel
$PIP install -r "$REQS"

# scripts qui DOIVENT utiliser le venv
for f in \
  $BASE/services/ohlcv_bitget_cli.py \
  $BASE/services/build_softmap.py \
  $BASE/services/build_heatmap_softmax.py \
  $BASE/analyze/analyze_a_cli.py
do
  [ -f "$f" ] || continue
  sed -i '1s|^#!.*python.*$|#!/opt/scalp/.venv/bin/python|' "$f"
  chmod +x "$f"
done

# batch OHLCV → venv
if grep -q 'python3' $BASE/services/run_ohlcv_batch.sh 2>/dev/null; then
  sed -i '1i PY="/opt/scalp/.venv/bin/python"' $BASE/services/run_ohlcv_batch.sh
  sed -i 's/\bpython3\b/$PY/g'                $BASE/services/run_ohlcv_batch.sh
fi
chmod +x $BASE/services/run_ohlcv_batch.sh || true

# systemd bot → venv + PYTHONPATH
mkdir -p /etc/systemd/system/scalp-telegram-bot.service.d
cat >/etc/systemd/system/scalp-telegram-bot.service.d/override.conf <<'OVR'
[Service]
Environment=PYTHONPATH=/opt/scalp
ExecStart=
ExecStart=/opt/scalp/.venv/bin/python -m bot.bot_stdlib
OVR
systemctl daemon-reload

echo "[setup] python: $($PY -c 'import sys;print(sys.executable)')"
echo "[setup] ccxt: $($PY -c 'import ccxt;print(ccxt.__version__)')"

```

### tools/telegram_ping.py  
Taille: 782 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 32bb7e256a1a8b1d

```py
#!/opt/scalp/.venv/bin/python
import os, sys, json, urllib.request
ENV = "/etc/scalp.env"
if os.path.exists(ENV):
    for L in open(ENV):
        if "=" in L and not L.strip().startswith("#"):
            k,v=L.strip().split("=",1); os.environ.setdefault(k.strip(), v.strip())
tok=os.getenv("TELEGRAM_BOT_TOKEN"); chat=os.getenv("TELEGRAM_CHAT_ID")
msg=os.getenv("PING_MSG","SCALP bot prêt ✅")
if not tok or not chat:
    sys.exit("TELEGRAM_BOT_TOKEN/TELEGRAM_CHAT_ID manquants")
url=f"https://api.telegram.org/bot{tok}/sendMessage"
data=json.dumps({"chat_id":chat,"text":msg,"disable_notification":True}).encode()
req=urllib.request.Request(url,data,headers={"Content-Type":"application/json"})
with urllib.request.urlopen(req, timeout=10) as r: print(r.status, r.read()[:120])

```

### tools/test_B.sh  
Taille: 381 B  |  MàJ: 2025-09-17 10:49:30  |  SHA256: 32a4a5db8064ad6c

```sh
#!/usr/bin/env bash
set -euo pipefail
PY=/opt/scalp/.venv/bin/python
echo "== source heatmap =="
ls -lh --time-style=long-iso /opt/scalp/data/heatmap.json || true
echo "== run =="
$PY /opt/scalp/services/analyze_B.py || true
echo "== preview b_top.json =="
jq -C '.count, (.candidates[:10])' /opt/scalp/data/b_top.json 2>/dev/null || head -c 400 /opt/scalp/data/b_top.json || true

```

### tools/test_exec_flow.sh  
Taille: 1 KB  |  MàJ: 2025-09-16 17:51:34  |  SHA256: a63db847fddd9d61

```sh
#!/bin/bash
set -e
SIGNALS=/opt/scalp/data/signals
POS=/opt/scalp/data/positions/positions.json
HIST=/opt/scalp/data/history/history.json

echo "[1] Injection d'un signal fictif..."
cat >$SIGNALS/test_signal.json <<'JSON'
{
  "t_emit": 1737110500,
  "sym": "BTC",
  "tf": "1m",
  "entry_set": "pullback_trend",
  "side": "long",
  "price_entry": 43210.5,
  "sl": 42800.0,
  "tp": 43950.0,
  "size": 0.01
}
JSON

echo "[2] Lancement de l'exécuteur"
/bin/systemctl start scalp-exec.service

echo "[3] Attente 5s pour traitement..."
sleep 5
echo "Positions après exécution:"
jq . $POS || cat $POS

echo "[4] Simulation clôture forcée (SL touché)"
/opt/scalp/.venv/bin/python - <<'PY'
from execution.storage import load_positions, save_positions
import time, json
pos = load_positions()
for p in pos:
    if p.get("status")=="open":
        p["sl"] = p["last_price"] if "last_price" in p else p["entry_price"]*0.99
save_positions(pos)
PY

echo "[5] Déclenche monitor pour appliquer SL"
/bin/systemctl start scalp-positions.service
sleep 2

echo "[6] Positions après monitor:"
jq . $POS || cat $POS

echo "[7] Historique:"
jq . $HIST || cat $HIST

echo "[OK] Test terminé."

```

### tools/test_heat_source.py  
Taille: 484 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 3582def168e5dfbc

```py
#!/opt/scalp/.venv/bin/python
import inspect
from bot.views_heat import render_heatmap

def main():
    txt = render_heatmap() or ""
    src = inspect.getsourcefile(render_heatmap) or "?"
    print("SRC:", src)
    print("LEN:", len(txt))
    assert "views_heat.py" in src, "Heatmap source mismatch"
    assert txt.strip() not in ("", "<pre></pre>"), "Empty <pre></pre> payload"
    assert len(txt) > 20, "Payload too short"
    print("OK ✅")

if __name__ == "__main__":
    main()

```

### tools/test_ohlcv.py  
Taille: 662 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 3bc97684947261e3

```py
#!/opt/scalp/.venv/bin/python
import ccxt, time, sys

try:
    ex = ccxt.bitget({"options":{"defaultType":"swap"}, "enableRateLimit": True})
    ex.load_markets()
except Exception as e:
    sys.exit(f"EINIT: impossible d'initialiser Bitget ({e})")

sym = "BTC/USDT:USDT"
tf  = "5m"

try:
    rows = ex.fetch_ohlcv(sym, timeframe=tf, limit=5)
except Exception as e:
    sys.exit(f"EFETCH: erreur fetch_ohlcv {sym} {tf} ({e})")

print(f"== Dernières bougies {sym} {tf} ==")
for r in rows:
    ts, o, h, l, c, v = r
    print(time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime(ts/1000)),
          f"O={o} H={h} L={l} C={c} V={v}")
print("OK: ccxt Bitget fonctionne")

```

### tools/trade_state.py  
Taille: 3 KB  |  MàJ: 2025-09-19 23:10:21  |  SHA256: dcdb1f343a0c5114

```py
import os, json, time
from pathlib import Path

ROOT   = Path("/opt/scalp")
DATA   = ROOT / "data"
FILES  = {
  "signals":  DATA / "signals.json",
  "pos":      DATA / "positions.json",
  "history":  DATA / "history.json",
}

def _read(p): 
    try: return json.loads(Path(p).read_text())
    except: return [] if str(p).endswith(".json") else {}

def _write(p, obj): Path(p).parent.mkdir(parents=True, exist_ok=True); Path(p).write_text(json.dumps(obj, ensure_ascii=False, indent=2))

def load_all():
    return (_read(FILES["signals"]), _read(FILES["pos"]), _read(FILES["history"]))

def save_all(signals, pos, hist):
    _write(FILES["signals"], signals); _write(FILES["pos"], pos); _write(FILES["history"], hist)

def promote_signals_to_positions(now_ts=None, auto_exec=True, max_new=10):
    """Ajoute les nouveaux signaux en positions 'open' si pas déjà présents (clé sym+side+ts_sig)."""
    signals, pos, hist = load_all()
    now_ts = now_ts or int(time.time())
    added = 0
    if auto_exec:
        # index existants pour éviter doublons
        keys = { (p.get("sym"), p.get("side"), p.get("ts_sig")) for p in pos }
        for s in signals:
            key = (s.get("sym"), s.get("side"), s.get("ts"))
            if key in keys: continue
            pos.append({
              "sym":s.get("sym"), "side":s.get("side"),
              "entry_px":float(s.get("px",0)), "sl":float(s.get("sl",0)), "tp":float(s.get("tp",0)),
              "qty":float(s.get("qty",0)), "lev":int(s.get("lev",1) or 1),
              "ts_open":now_ts, "ts_sig":s.get("ts"), "status":"open"
            })
            added += 1
            if added>=max_new: break
        save_all(signals, pos, hist)
    return added

def close_position(p, exit_px, now_ts=None, reason="exit"):
    now_ts = now_ts or int(time.time())
    side = (p.get("side") or "").upper()
    qty  = float(p.get("qty",0) or 0)
    entry= float(p.get("entry_px",0) or 0)
    mult = 1 if side=="LONG" else -1
    pnl  = (exit_px - entry) * qty * mult
    return {
        "sym":p.get("sym"), "side":side,
        "entry_px":entry, "exit_px":float(exit_px),
        "qty":qty, "lev":int(p.get("lev",1) or 1),
        "ts_open":int(p.get("ts_open",0) or 0), "ts_close":now_ts,
        "pnl":pnl, "reason":reason
    }

def reconcile_with_ccxt(fetch_fn=None):
    """
    Met à jour les positions:
      - si size==0 -> move to history (pnl via last price)
      - si size>0  -> garde 'open'
    fetch_fn(sym) doit retourner dict {size: float, last: float}
    """
    signals, pos, hist = load_all()
    new_pos = []
    closed  = []
    for p in pos:
        info = fetch_fn(p["sym"]) if fetch_fn else None
        if info and abs(float(info.get("size",0)))<1e-9:
            rec = close_position(p, exit_px=float(info.get("last", p["entry_px"])))
            closed.append(rec)
        else:
            new_pos.append(p)
    if closed:
        hist = (hist or []) + closed
    save_all(signals, new_pos, hist)
    return {"open":len(new_pos), "closed":len(closed)}

```

### tools/validate_pipeline.sh  
Taille: 980 B  |  MàJ: 2025-09-17 15:50:11  |  SHA256: 84d100f1276ad83b

```sh
#!/usr/bin/env bash
set -euo pipefail
echo "== A =="
python3 /opt/scalp/services/analyze_A.py >/dev/null || true
jq -r '.updated, "rows=" + ((.rows|length)|tostring)' /opt/scalp/data/heatmap.json

echo "== B =="
python3 /opt/scalp/services/analyze_B.py >/dev/null || true
jq -r '.updated, "assets=" + ((.assets|length)|tostring)' /opt/scalp/data/Btop.json

echo "== 1m/3m services =="
systemctl list-timers | grep -E 'scalp-(ohlcv-1m|agg-3m)@' || true

echo "== Signal factice -> position -> account =="
echo '{"ts":'$(date +%s)',"symbol":"BTC","entry_set":"pullback_trend","side":"long","price_entry":25000,"sl":24500,"tp":25200,"size":0.01}' >> /opt/scalp/data/signals.json
sleep 1
python3 /opt/scalp/services/paper_trade.py
jq -r '"balance=" + (.balance|tostring) + " equity=" + (.equity|tostring) + " open_pnl=" + (.open_pnl|tostring)' /opt/scalp/data/account.json
jq -r '.positions | map(select(.status=="open")) | "open=" + (length|tostring)' /opt/scalp/data/positions.json

```

### tools/view_heatmap.sh  
Taille: 89 B  |  MàJ: 2025-09-16 18:09:09  |  SHA256: e03a4a803015d389

```sh
#!/usr/bin/env bash
exec /opt/scalp/tools/json_view.py /opt/scalp/data/heatmap.json rows

```

### tools/view_history.sh  
Taille: 91 B  |  MàJ: 2025-09-16 18:09:09  |  SHA256: 60e73910ea208e3b

```sh
#!/usr/bin/env bash
exec /opt/scalp/tools/json_view.py /opt/scalp/data/history.json trades

```

### tools/view_positions.sh  
Taille: 96 B  |  MàJ: 2025-09-16 18:09:09  |  SHA256: f91ce296f7dadcdb

```sh
#!/usr/bin/env bash
exec /opt/scalp/tools/json_view.py /opt/scalp/data/positions.json positions

```

### tools/view_signals.sh  
Taille: 92 B  |  MàJ: 2025-09-16 18:09:09  |  SHA256: d38779c99b3b6cf5

```sh
#!/usr/bin/env bash
exec /opt/scalp/tools/json_view.py /opt/scalp/data/signals.json signals

```

### requirements.txt  
Taille: 52 B  |  MàJ: 2025-09-17 06:54:13  |  SHA256: 454a4f23373c4ad8

```txt
ccxt>=4,<5
requests>=2.31
packaging>=23
loguru>=0.7

```


```

### services/agg_1m_to_3m.py  
Taille: 2 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 5bbeeb0bd2c98890

```py
#!/opt/scalp/.venv/bin/python
# Agrège /opt/scalp/data/candles/{SYM}_1m.json -> {SYM}_3m.json
from __future__ import annotations
import argparse, json
from pathlib import Path

DATA = Path("/opt/scalp/data")
CAND = DATA/"candles"

def _read_rows(p:Path):
    if not p.exists(): return []
    try:
        obj=json.loads(p.read_text())
        return obj.get("rows") or obj
    except:
        return []

def _write_rows(p:Path, rows):
    p.parent.mkdir(parents=True, exist_ok=True)
    tmp=p.with_suffix(".tmp")
    tmp.write_text(json.dumps({"rows":rows}, ensure_ascii=False, separators=(",",":")))
    tmp.replace(p)

def agg3(rows1):
    out=[]; buf=[]
    for r in rows1:
        buf.append(r)
        if len(buf)==3:
            ts=buf[-1][0]; o=buf[0][1]
            h=max(x[2] for x in buf); l=min(x[3] for x in buf)
            c=buf[-1][4]; v=sum(x[5] for x in buf)
            out.append([ts,o,h,l,c,v]); buf=[]
    return out

def main():
    ap=argparse.ArgumentParser()
    ap.add_argument("--symbol", action="append")
    args=ap.parse_args()
    # par défaut: dérive depuis les fichiers 1m présents
    if not args.symbol:
        syms=[p.name.split("_")[0] for p in CAND.glob("*_1m.json")]
    else:
        syms=[s.upper() for s in args.symbol]

    for s in syms:
        r1=_read_rows(CAND/f"{s}_1m.json")
        if len(r1)<3: 
            print(f"[agg3] {s} not enough data"); 
            continue
        r3=agg3(r1)
        _write_rows(CAND/f"{s}_3m.json", r3)
        print(f"[agg3] {s} n1={len(r1)} -> n3={len(r3)}")

if __name__=="__main__":
    main()

```

### services/analyze_A.py  
Taille: 4 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: f63d37c4a7b277ec

```py
#!/opt/scalp/.venv/bin/python
# A: calcule S(5m) ∈ [-1,1], conserve 12 valeurs (60m) + snapshots 60/30/15/now
from __future__ import annotations
import csv, json, math, statistics as stats, time, datetime as dt
from pathlib import Path

BASE = Path("/opt/scalp"); DATA = BASE/"data"
C5 = DATA/"candles/5m"
OUT = DATA/"heatmap.json"
TF_LIMIT = 500

def _iso(ts_ms:int)->str:
    return dt.datetime.utcfromtimestamp(ts_ms/1000).strftime("%Y-%m-%dT%H:%M:%SZ")

def _load_universe():
    u = DATA/"universe.txt"
    if u.exists(): return [l.strip().upper() for l in u.read_text().splitlines() if l.strip()]
    return ["BTC","ETH","BNB","SOL","XRP"]

def _load_5m(sym:str):
    p=C5/f"{sym}.csv"; rows=[]
    if not p.exists(): return rows
    with p.open() as f:
        r=csv.reader(f); head=next(r,None)
        def parse(row):
            try: ts=int(row[0]); o,h,l,c,v=map(float,row[1:6]); return [ts,o,h,l,c,v]
            except: return None
        x=parse(head); rows+=([x] if x else [])
        for row in r:
            x=parse(row); rows+=([x] if x else [])
    rows=sorted(rows,key=lambda x:x[0])[-TF_LIMIT:]
    # retire bougie en cours si partielle
    if rows and rows[-1][0]//1000 > int(time.time())-60: rows=rows[:-1]
    return rows

def _ema(vals, n):
    k=2/(n+1); e=vals[0]; out=[e]
    for x in vals[1:]: e=k*x+(1-k)*e; out.append(e)
    return out

def _atr(rows, n=14):
    if len(rows)<n+1: return None
    trs=[]; pc=rows[0][4]
    for i in range(1,len(rows)):
        h,l,c=rows[i][2],rows[i][3],rows[i][4]
        trs.append(max(h-l, abs(h-pc), abs(l-pc))); pc=c
    return sum(trs[-n:])/n

def _atr_pct(rows, n=14):
    a=_atr(rows,n); c=rows[-1][4] if rows else 0
    if not a or c<=0: return None
    return 100*a/c

def _macd_hist(rows, fast=12, slow=26, sig=9):
    closes=[r[4] for r in rows]
    if len(closes)<slow+sig+2: return None
    ef=_ema(closes,fast); es=_ema(closes,slow)
    m=[a-b for a,b in zip(ef[-len(es):], es)]
    s=_ema(m,sig); hist=m[-1]-s[-1]
    look=min(120,len(m)); sigma=stats.pstdev([m[i]-s[i] for i in range(-look,0)]) or 1e-12
    return hist, sigma

def _rsi(rows, n=14):
    if len(rows)<n+1: return None
    gains=losses=0.0
    for i in range(-n,0):
        ch=rows[i][4]-rows[i-1][4]
        gains+=max(ch,0.0); losses+=max(-ch,0.0)
    if gains==0 and losses==0: return 50.0
    if losses==0: return 100.0
    rs=gains/losses; return 100.0-100.0/(1.0+rs)

def _obv_slope(rows, look=20):
    if len(rows)<look+2: return None
    obv=[0.0]
    for i in range(1,len(rows)):
        c0,c1=rows[i-1][4],rows[i][4]; v=rows[i][5]
        if c1>c0: obv.append(obv[-1]+v)
        elif c1<c0: obv.append(obv[-1]-v)
        else: obv.append(obv[-1])
    d=obv[-1]-obv[-1-look]; med=stats.median([abs(x) for x in obv[-look:]]) or 1e-12
    return d, med

def _tanh(x, s): return math.tanh(x/(s or 1e-12))

W={"EMA":0.35,"MACD":0.25,"RSI":0.20,"ADX":0.10,"OBV":0.10}
ATR_GATE=0.12

def _S(rows):
    a=_atr(rows,14); atrp=_atr_pct(rows,14)
    if len(rows)<60 or a is None: return None
    closes=[r[4] for r in rows]
    s_EMA=_tanh(_ema(closes,12)[-1]-_ema(closes,26)[-1], 1.5*a)
    m=_macd_hist(rows);  s_MACD=_tanh(m[0], m[1]) if m else None
    r=_rsi(rows);        s_RSI=max(-1,min(1,(r-50)/50)) if r is not None else None
    s_ADX=max(-1,min(1,((atrp or 0)-20)/20)) if atrp is not None else 0.0
    o=_obv_slope(rows,20); s_OBV=_tanh(o[0], o[1]) if o else None
    w=dict(W)
    if (atrp or 0.0)<ATR_GATE: w["EMA"]*=0.5; w["MACD"]*=0.5
    num=sum(w[k]*v for k,v in (("EMA",s_EMA),("MACD",s_MACD),("RSI",s_RSI),("ADX",s_ADX),("OBV",s_OBV)) if v is not None)
    den=sum(w[k] for k,v in (("EMA",s_EMA),("MACD",s_MACD),("RSI",s_RSI),("ADX",s_ADX),("OBV",s_OBV)) if v is not None) or 1.0
    return max(-1.0,min(1.0,num/den))

def _hist_S(rows, n=12):
    out=[]
    for off in range(n-1,-1,-1):
        sub=rows[:len(rows)-off]
        s=_S(sub)
        if s is None: return []
        out.append(round(s,4))
    return out

def _snap(hist):
    if len(hist)!=12: return None
    return {"60m":hist[0], "30m":hist[6], "15m":hist[9], "now":hist[11]}

def main():
    syms=_load_universe()
    rows_out=[]
    for s in syms:
        r=_load_5m(s)
        if len(r)<60: continue
        hist=_hist_S(r,12)
        if not hist: continue
        rows_out.append({"sym":s, "hist":hist, "snap":_snap(hist)})
    OUT.write_text(json.dumps({"updated":_iso(int(time.time()*1000)),"rows":rows_out},
                              ensure_ascii=False, separators=(",",":")))
    print(f"A: heatmap rows={len(rows_out)}")

if __name__=="__main__": main()

```

### services/analyze_B.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: c3a1b85a6a70f19e

```py
#!/opt/scalp/.venv/bin/python
# B: lit heatmap.json (S), calcule pb/ph/ps, définit ctx, écrit Btop.json
from __future__ import annotations
import json, math, os, time
from pathlib import Path

DATA = Path("/opt/scalp/data")
SRC  = DATA/"heatmap.json"
DST  = DATA/"Btop.json"

TAU = float(os.getenv("SCALP_TAU","0.25"))

def _softmax3(S: float, tau: float):
    x = math.exp(S/tau); invx = math.exp(-S/tau); Z = x + 1.0 + invx
    return x/Z, 1.0/Z, invx/Z  # pb, ph, ps

def _ctx(pb:float, ph:float, ps:float):
    if pb>=0.60: return "bullish"
    if ps>=0.60: return "bearish"
    if 0.40<=ph<=0.60: return "range"
    return None

def main():
    if not SRC.exists():
        DST.write_text(json.dumps({"updated":None,"assets":[]}, ensure_ascii=False)); return
    src=json.loads(SRC.read_text())
    out=[]
    for r in src.get("rows",[]):
        sym=r.get("sym","")
        s_now=float((r.get("snap") or {}).get("now",0.0))
        pb,ph,ps=_softmax3(s_now, TAU)
        ctx=_ctx(pb,ph,ps)
        out.append({"sym":sym,"S":round(s_now,4),
                    "pb":round(pb,4),"ph":round(ph,4),"ps":round(ps,4),
                    "ctx":ctx})
    DATA.joinpath("Btop.json").write_text(
        json.dumps({"updated": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                    "tau": TAU, "assets": out},
                   ensure_ascii=False, separators=(",",":")))
    print(f"B: assets={len(out)} tau={TAU}")

if __name__=="__main__": main()

```

### services/analyze_pipeline.py  
Taille: 182 B  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 243dedd8d5ebd1da

```py
#!/opt/scalp/.venv/bin/python
from pathlib import Path
from loguru import logger
print("Analyze stub: déclenchement reçu")
Path("/opt/scalp/data/last.analysis").write_text("tick")

```

### services/b_triggers.py  
Taille: 4 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: e69bbd3dae23e069

```py
#!/opt/scalp/.venv/bin/python
import json, sys, time
from pathlib import Path
from typing import List, Dict, Any

BASE   = Path("/opt/scalp")
DATA   = BASE / "data"
HEAT_S = DATA / "heatmap_soft.json"   # format récent: rows: [{sym, S:[{t,s},...]}, ...]
HEAT_H = DATA / "heatmap.json"        # fallback: rows: [{sym, '5m':'a/b/c','15m':..., '30m':...}, ...]
TOP    = DATA / "top.json"            # Couche A (NE JAMAIS ÉCRASER)
BTOP   = DATA / "btop.json"           # Couche B (notre sortie)

def _now_iso() -> str:
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

def _last_S_from_soft(row: Dict[str,Any]) -> float|None:
    # heatmap_soft.json → row["S"] = [{t:..., s:...}, ...]
    seq = row.get("S") or row.get("s") or []
    if not seq: return None
    try:
        return float(seq[-1].get("s"))
    except Exception:
        return None

def _est_context(last_s: float) -> str:
    # mapping simple pour la Couche A déjà décidée ailleurs; ici on expose juste une couleur indicative
    if last_s is None:      return "unknown"
    if last_s >=  0.20:     return "bullish"
    if last_s <= -0.20:     return "bearish"
    return "range"

def _parse_ratio(x: str) -> float:
    # "2/2/1" -> score simple (ex: moyenne centrée) pour fallback heatmap.json
    try:
        a,b,c = (int(t) for t in x.split('/'))
        # normalisation grossière sur 0..1 autour de 0 via (-1..+1)
        s = (a - c) / max(1,(a+b+c))
        return float(s)
    except Exception:
        return 0.0

def _last_S_from_hard(row: Dict[str,Any]) -> float|None:
    # Derive un "S" approximatif depuis les 3 TF (5m/15m/30m) quand soft absent
    f5  = _parse_ratio(str(row.get("5m","0/0/0")))
    f15 = _parse_ratio(str(row.get("15m","0/0/0")))
    f30 = _parse_ratio(str(row.get("30m","0/0/0")))
    return round((f5 + f15 + f30)/3, 3)

def load_heat_rows() -> List[Dict[str,Any]]:
    if HEAT_S.exists():
        obj = json.loads(HEAT_S.read_text())
        rows = obj.get("rows", [])
        out  = []
        for r in rows:
            sym = r.get("sym") or r.get("symbol") or r.get("SYM")
            if not sym: continue
            s   = _last_S_from_soft(r)
            out.append({"sym": sym, "S": s, "context": _est_context(s)})
        return out

    if HEAT_H.exists():
        obj = json.loads(HEAT_H.read_text())
        rows = obj.get("rows", [])
        out  = []
        for r in rows:
            sym = r.get("sym") or r.get("symbol") or r.get("SYM")
            if not sym: continue
            s = _last_S_from_hard(r)
            out.append({"sym": sym, "S": s, "context": _est_context(s)})
        return out

    return []

def load_top_syms() -> List[str]:
    # On limite B aux actifs existants dans top.json si présent (ordre conservé)
    try:
        obj = json.loads(TOP.read_text())
        assets = obj.get("assets", [])
        syms = [a.get("sym") for a in assets if a.get("sym")]
        return syms
    except Exception:
        return []

def build_btop():
    rows = load_heat_rows()
    if not rows:
        raise SystemExit("No heatmap rows available")

    # Filtre par top.json si dispo
    top_syms = load_top_syms()
    if top_syms:
        rows = [r for r in rows if r["sym"] in top_syms]

    # Tri par |S| décroissant (les plus ‘marqués’ d’abord)
    rows.sort(key=lambda r: (0.0 if r["S"] is None else abs(r["S"])), reverse=True)

    # Écrit btop.json (sans toucher top.json)
    out = {
        "updated": _now_iso(),
        "source":  "B",
        "rows":    rows,
        "note":    "Couche B selection from heatmap; top.json untouched."
    }
    BTOP.write_text(json.dumps(out, ensure_ascii=False, separators=(',',':')))
    print(f"btop.json written: {len(rows)} rows")

if __name__ == "__main__":
    build_btop()

```

### services/build_heatmap_softmax.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: f5037dcf1c1a4cd9

```py
#!/opt/scalp/.venv/bin/python
# Heatmap viewer: lit uniquement /opt/scalp/data/heatmap.json et sort des entiers 10*S pour 60/30/15/now
import json, time
from pathlib import Path

DATA = Path("/opt/scalp/data")
SRC  = DATA/"heatmap.json"
DST  = DATA/"heatmap_view.json"  # consommé par le front si besoin

def _i10(x: float) -> int:
    # entier de 10*S (ex: 0.83 -> 8, -0.27 -> -2)
    try:
        return int(round(10.0*float(x)))
    except:
        return 0

def main():
    if not SRC.exists():
        DST.write_text(json.dumps({"updated": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()), "rows":[]}, ensure_ascii=False))
        print("viewer: source absente"); return

    src=json.loads(SRC.read_text())
    rows=[]
    for r in src.get("rows", []):
        sym=r.get("sym","")
        snap=r.get("snap") or {}
        rows.append({
            "sym": sym,
            "S_int": {
                "60": _i10(snap.get("60m",0)),
                "30": _i10(snap.get("30m",0)),
                "15": _i10(snap.get("15m",0)),
                "now": _i10(snap.get("now",0)),
            }
        })
    out={"updated": src.get("updated"), "rows": rows}
    DST.write_text(json.dumps(out, ensure_ascii=False, separators=(",",":")))
    print(f"viewer: rows={len(rows)} -> {DST}")
if __name__=="__main__": main()

```

### services/build_softmap.py  
Taille: 2 KB  |  MàJ: 2025-09-19 19:44:04  |  SHA256: 0220c3abd838a8dd

```py
#!/opt/scalp/.venv/bin/python
import json, math, statistics as st
from pathlib import Path

ROOT=Path("/opt/scalp"); DATA=ROOT/"data"; C=DATA/"candles"
OUT=DATA/"heatmap.json"; HIST=DATA/"s_history"
OUT.parent.mkdir(parents=True, exist_ok=True)

def load_candles(sym_code:str):
    # essaie 5m puis 1m
    p5=C/f"{sym_code}_5m.json"; p1=C/f"{sym_code}_1m.json"
    p=p5 if p5.exists() else p1 if p1.exists() else None
    if not p: return []
    try: rows=json.loads(p.read_text())
    except Exception: return []
    # accepte format [{"t":..,"c":..},...] ou [[ts,o,h,l,c,v],...]
    out=[]
    for r in rows:
        if isinstance(r, dict):
            out.append(float(r.get("c", r.get("close", 0)) or 0))
        else:
            out.append(float(r[4]))
    return [x for x in out if x>0]

def series_S(closes:list, win:int=20):
    """ S = z-score des rendements log sur fenêtre glissante """
    if len(closes)<win+2: return []
    rets=[math.log(closes[i]/closes[i-1]) for i in range(1,len(closes))]
    S=[]
    for i in range(win, len(rets)):
        w=rets[i-win:i]
        mu=st.mean(w); sd=st.pstdev(w) or 1e-9
        S.append((rets[i]-mu)/sd)
    return S

def norm(sym:str)->str: 
    # 'BTC/USDT:USDT' -> 'BTCUSDT'
    return ''.join(ch for ch in sym if ch.isalnum()).upper()

# charge universe
U=(DATA/"universe.txt")
syms=[l.strip() for l in U.read_text().splitlines() if l.strip()] if U.exists() else []
rows=[]
for s in syms:
    code=norm(s)
    closes=load_candles(code)
    S=series_S(closes)
    if S:
        rows.append({"sym": code, "S": S[-200:]})  # tronque raisonnablement

obj={"rows": rows, "meta":{"n": len(rows)}}
OUT.write_text(json.dumps(obj, ensure_ascii=False))
# snapshot historique si le dossier existe
if HIST.exists() and HIST.is_dir():
    (HIST/f"heatmap.json").write_text(json.dumps(obj, ensure_ascii=False))
print(f"softmap rows={len(rows)}")

```

### services/exec_signals.py  
Taille: 4 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: f269965a7ea23e0a

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json, time, os
from pathlib import Path

BASE = Path("/opt/scalp")
DATA = BASE/"data"
CAND = DATA/"candles"
SIGF = DATA/"signals.json"
POSF = DATA/"positions.json"
HISTL= DATA/"positions_hist.jsonl"

SLIPPAGE = float(os.getenv("MAX_SLIPPAGE_PCT", "0.002"))  # 0.2%

def _now_iso(): return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

def _read_json(p: Path, default):
    try:
        return json.loads(p.read_text())
    except Exception:
        return default

def _write_atomic(p: Path, obj):
    tmp = p.with_suffix(p.suffix+".tmp")
    tmp.write_text(json.dumps(obj, ensure_ascii=False, separators=(",",":")))
    tmp.replace(p)

def _append_jsonl(p: Path, row: dict):
    with p.open("a", encoding="utf-8") as f:
        f.write(json.dumps(row, ensure_ascii=False)+ "\n")

def _latest_px(sym: str) -> float|None:
    f = CAND/f"{sym}_1m.json"
    if not f.exists(): return None
    try:
        obj = json.loads(f.read_text())
        rows = obj.get("rows", obj) if isinstance(obj, dict) else obj
        if not rows: return None
        return float(rows[-1][4])  # close
    except Exception:
        return None

def _positions() -> list[dict]:
    obj = _read_json(POSF, {})
    return obj.get("positions", []) if isinstance(obj, dict) else []

def _save_positions(rows: list[dict]):
    _write_atomic(POSF, {"updated":_now_iso(),"positions":rows})

def _clear_signals():
    _write_atomic(SIGF, {"updated":_now_iso(),"signals":[]})

def process():
    obj = _read_json(SIGF, {})
    sigs = obj.get("signals", obj if isinstance(obj, list) else [])
    if not sigs: return 0
    pos = _positions()
    handled=0
    for s in sigs:
        sym=str(s.get("sym") or s.get("symbol") or "?").upper()
        side=s.get("side","?")
        px=float(s.get("price_entry") or 0)
        sl=float(s.get("sl") or 0)
        tp=float(s.get("tp") or 0)
        qty=float(s.get("size") or 0)
        lev=int(s.get("leverage") or 0)

        if px<=0 or sl==0 or tp==0 or qty<=0:
            _append_jsonl(HISTL,{
                "timestamp":_now_iso(),"symbol":sym,"side":side,"entry":px,
                "sl":sl,"tp":tp,"size":qty,"leverage":lev,
                "status":"rejected","reason":"invalid_signal"
            })
            handled+=1
            continue

        cur=_latest_px(sym)
        if cur is None:
            _append_jsonl(HISTL,{
                "timestamp":_now_iso(),"symbol":sym,"side":side,"entry":px,
                "sl":sl,"tp":tp,"size":qty,"leverage":lev,
                "status":"rejected","reason":"no_price"
            })
            handled+=1
            continue

        slip=abs(cur-px)/px
        if slip>SLIPPAGE:
            _append_jsonl(HISTL,{
                "timestamp":_now_iso(),"symbol":sym,"side":side,"entry":px,
                "sl":sl,"tp":tp,"size":qty,"leverage":lev,
                "status":"rejected","reason":"slippage","price_now":cur,"slippage":slip
            })
            handled+=1
            continue

        # OK: ouvrir position
        pos_row={
            "timestamp":_now_iso(),"ts_open":int(time.time()),
            "symbol":sym,"side":side,"entry":px,"sl":sl,"tp":tp,
            "size":qty,"leverage":lev,"status":"open","last":cur
        }
        pos.append(pos_row)
        _append_jsonl(HISTL,{**pos_row,"status":"opened"})
        handled+=1

    # maj fichiers
    _save_positions(pos)
    _clear_signals()
    return handled

def main():
    handled=process()
    print(f"[exec] handled={handled}")
    return 0

if __name__=="__main__":
    raise SystemExit(main())

```

### services/fetch_1m_safe.py  
Taille: 946 B  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 4f783bd0c0eb1a1d

```py
#!/opt/scalp/.venv/bin/python
# Placeholder safe: prépare les chemins 1m pour chaque asset du BTop
import json, time
from pathlib import Path

BASE = Path("/opt/scalp")
DATA = BASE / "data"
OUT  = DATA / "candles_1m"
TOPB = DATA / "top_B.json"
LOG  = BASE / "logs" / "fetch_1m_safe.log"
OUT.mkdir(parents=True, exist_ok=True)
LOG.parent.mkdir(parents=True, exist_ok=True)

def log(m): LOG.write_text((LOG.read_text()+m+"\n") if LOG.exists() else m+"\n")

def main():
    if not TOPB.exists():
        log("top_B.json absent -> skip")
        return 0
    tb = json.loads(TOPB.read_text())
    assets = tb.get("assets", [])
    for sym in assets:
        f = OUT / f"{sym}_1m.json"
        if not f.exists():
            f.write_text(json.dumps({"sym": sym, "updated": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()), "rows": []}))
    log(f"prepared {len(assets)} files")
    return 0

if __name__ == "__main__":
    raise SystemExit(main())

```

### services/fetch_ohlcv.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: fdba81b251b62caa

```py
#!/opt/scalp/.venv/bin/python
import os, json, time, pathlib, datetime as dt
from collections import defaultdict

BASE = pathlib.Path("/opt/scalp"); DATA = BASE/"data"; CAND = DATA/"candles"
CAND.mkdir(parents=True, exist_ok=True)

SYMS = json.loads((DATA/"top.json").read_text())["assets"]
SYMS = [a["sym"] for a in SYMS]  # top15
TFS  = ["5m","15m","30m"]

def now_utc():
    return dt.datetime.utcnow().replace(tzinfo=dt.timezone.utc)

def fetch_ccxt(symbol, tf, limit=300):
    # SABLE: stub de données pour démo; branche ccxt plus tard.
    # return list of (ts, open, high, low, close, volume)
    t0 = int(time.time())//60*60
    import random
    out=[]; base=20000+hash(symbol)%10000
    for i in range(limit):
        ts=(t0-(limit-i)*60*(5 if tf=="5m" else 15 if tf=="15m" else 30))*1000
        c=base+random.randint(-200,200)
        h=c+random.randint(0,50); l=c-random.randint(0,50); o=(h+l)//2; v=random.randint(50,200)
        out.append([ts,o,h,l,c,v])
    return out

def write_candles(sym, tf, rows):
    f = CAND/f"{sym}_{tf}.json"
    f.write_text(json.dumps({"sym":sym,"tf":tf,"rows":rows,"updated":now_utc().isoformat().replace("+00:00","Z")}))
    return f

def main():
    for s in SYMS:
        for tf in TFS:
            rows = fetch_ccxt(s, tf, 300)
            write_candles(s, tf, rows)
    (DATA/"candles.updated").write_text(now_utc().isoformat().replace("+00:00","Z"))
    print("OHLCV OK")

if __name__=="__main__": main()

```

### services/ohlcv_1m_cli.py  
Taille: 3 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 74bc840c764bc1d6

```py
#!/opt/scalp/.venv/bin/python
# Collecte OHLCV 1m Bitget -> /opt/scalp/data/candles/{SYM}_1m.json
# Source des symboles: Btop.json (ctx != None). Fallback: universe.txt.

from __future__ import annotations
import argparse, json, time
from pathlib import Path

DATA = Path("/opt/scalp/data")
CAND = DATA/"candles"
BTOP = DATA/"Btop.json"
UNIV = DATA/"universe.txt"

def _safe_write_json_rows(path:Path, rows:list[list[float]]):
    path.parent.mkdir(parents=True, exist_ok=True)
    tmp = path.with_suffix(".tmp")
    tmp.write_text(json.dumps({"rows": rows}, ensure_ascii=False, separators=(",",":")))
    tmp.replace(path)

def _syms_from_btop() -> list[str]:
    if not BTOP.exists(): return []
    try:
        obj=json.loads(BTOP.read_text())
        assets=obj.get("assets", [])
        out=[str(a.get("sym","")).upper() for a in assets if a.get("ctx") is not None]
        return [s for s in out if s]
    except: 
        return []

def _syms_from_universe() -> list[str]:
    if not UNIV.exists(): return []
    out=[]
    for line in UNIV.read_text().splitlines():
        s=line.strip().upper()
        if not s: continue
        if s.startswith("{") and s.endswith("}"):
            try:
                o=json.loads(s); s=(o.get("sym") or o.get("symbol") or "").upper()
            except: s=""
        if s: out.append(s)
    # unique en gardant l'ordre
    seen=set(); uniq=[]
    for s in out:
        if s not in seen:
            seen.add(s); uniq.append(s)
    return uniq

def resolve_symbols(cli_syms:list[str]|None) -> list[str]:
    xs=[s.upper() for s in (cli_syms or []) if isinstance(s,str) and s.strip()]
    if xs: return xs
    btop_syms=_syms_from_btop()
    if btop_syms: return btop_syms
    base=_syms_from_universe()
    return base or ["BTC","ETH"]

def bitget_symbol(sym:str)->str:
    return f"{sym}/USDT:USDT"

def fetch_1m_one(sym:str, limit:int=500)->list[list[float]]:
    import ccxt
    ex=ccxt.bitget()
    mkt=bitget_symbol(sym)
    ohlcv=ex.fetch_ohlcv(mkt, timeframe="1m", limit=limit)
    return [[int(t), float(o), float(h), float(l), float(c), float(v)] for t,o,h,l,c,v in ohlcv]

def main():
    ap=argparse.ArgumentParser()
    ap.add_argument("--symbol", action="append", help="peut être répété; sinon Btop.json ctx!=None")
    ap.add_argument("--limit", type=int, default=500)
    args=ap.parse_args()

    syms=resolve_symbols(args.symbol)
    print(f"[ohlcv_1m] syms={syms}")
    ok=err=0
    for s in syms:
        try:
            rows=fetch_1m_one(s, args.limit)
            _safe_write_json_rows(CAND/f"{s}_1m.json", rows)
            ok+=1
            print(f"[ohlcv_1m] {s} n={len(rows)}")
        except Exception as e:
            err+=1
            print(f"[ohlcv_1m] {s} ERROR {e}")
    print(f"[ohlcv_1m] done ok={ok} err={err}")

if __name__=="__main__":
    main()

```

### services/ohlcv_bitget_batch.py  
Taille: 3 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 0fcf446b56b879f8

```py
#!/opt/scalp/.venv/bin/python
import csv, time, sys
from pathlib import Path
from loguru import logger
import ccxt

DATA = Path("/opt/scalp/data")
CAND = DATA/"candles"
TF_LIST = [("5m", 300), ("15m", 300), ("30m", 300)]

def tf_ms(tf:str)->int:
    n = int(tf[:-1]); unit = tf[-1]
    return n*60_000 if unit=="m" else n*1_000

def last_closed_ts(tf:str)->int:
    # borne supérieure exclu: floor(now, tf)
    ms = int(time.time()*1000)
    size = tf_ms(tf)
    return (ms // size) * size

def write_csv(path:Path, rows):
    path.parent.mkdir(parents=True, exist_ok=True)
    hdr = ["ts","open","high","low","close","volume"]
    if not path.exists():
        with path.open("w", newline="") as f: csv.writer(f).writerow(hdr)
    # on réécrit toutes les données pour simplicité/atomicité
    with path.open("w", newline="") as f:
        w=csv.writer(f); w.writerow(hdr); w.writerows(rows)

def load_csv(path:Path):
    out=[]
    if not path.exists(): return out
    with path.open() as f:
        r=csv.reader(f); next(r, None)
        for row in r:
            if not row: continue
            out.append([int(row[0]), *map(float,row[1:])])
    return out

def merge_keep_limit(old, new, limit):
    # fusion par ts croissant, supprime doublons, garde <= limit dernières
    m={}
    for ts, *rest in old: m[ts]=[ts,*rest]
    for ts, *rest in new: m[ts]=[ts,*rest]
    merged = sorted(m.values(), key=lambda x:x[0])
    return merged[-limit:]

def main():
    try:
        uni = [l.strip() for l in (DATA/"universe.txt").read_text().splitlines() if l.strip()]
    except Exception:
        uni = ["BTC","ETH","BNB","SOL","XRP"]
    try:
        ex = ccxt.bitget({"options":{"defaultType":"swap"}, "enableRateLimit": True})
        ex.load_markets()
    except Exception as e:
        logger.error(f"E_BITGET_INIT: {e}"); sys.exit(21)

    for base in uni:
        sym = f"{base}/USDT:USDT"
        for tf, keep in TF_LIST:
            try:
                rows = ex.fetch_ohlcv(sym, timeframe=tf, limit=keep+5)
            except Exception as e:
                logger.error(f"EFETCH {sym} {tf}: {e}")
                continue
            # filtre: ne prendre que <= bougie close
            up = last_closed_ts(tf)
            rows = [r for r in rows if r[0] < up]
            # merge avec existant puis garde 'keep'
            f = CAND/tf/f"{base}.csv"
            cur = load_csv(f)
            merged = merge_keep_limit(cur, rows, keep)
            write_csv(f, merged)
            # déclenche analyse
            (DATA/"trigger.ohlcv").write_text(str(int(time.time())))
    print("OHLCV batch terminé.")

if __name__ == "__main__":
    main()

```

### services/ohlcv_bitget_cli.py  
Taille: 4 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: ed5042260b2e8eca

```py
#!/opt/scalp/.venv/bin/python
import os, sys, csv, time, json, pathlib
from datetime import datetime
import ccxt

ENV="/etc/scalp.env"
OUT=pathlib.Path("/opt/scalp/data/candles")
TRIGGER=pathlib.Path("/opt/scalp/data/trigger.ohlcv")

# Routine allégée: pas de 1m
TF_LIMIT   = {"5m":300, "15m":200, "30m":200}
TF_SECONDS = {"5m":300, "15m":900, "30m":1800}
FOCUS_1M_LIMIT = 500

def load_env(path=ENV):
    d={}
    if os.path.exists(path):
        for L in open(path):
            L=L.strip()
            if not L or L.startswith("#") or "=" not in L: continue
            k,v=L.split("=",1); d[k.strip()]=v.strip().strip('"').strip("'")
    return d

def req_env(env):
    need=["BITGET_API_KEY","BITGET_API_SECRET","BITGET_PASSPHRASE"]
    miss=[k for k in need if not env.get(k)]
    if miss: raise SystemExit(f"EENV:{','.join(miss)}")

def bitget(env):
    try:
        ex=ccxt.bitget({"apiKey":env.get("BITGET_API_KEY"),
                        "secret":env.get("BITGET_API_SECRET"),
                        "password":env.get("BITGET_PASSPHRASE"),
                        "enableRateLimit":True,
                        "options":{"defaultType":"swap"}})
        ex.load_markets(); return ex
    except ccxt.AuthenticationError as e: raise SystemExit(f"EAUTH:{e}")
    except ccxt.RateLimitExceeded as e:  raise SystemExit(f"ERATE:{e}")
    except ccxt.NetworkError as e:       raise SystemExit(f"ENET:{e}")
    except Exception as e:               raise SystemExit(f"EAPI:{e}")

def to_usdt(sym): return f"{sym.upper().split('/')[0]}/USDT:USDT"
def last_closed_ms(tf, now=None):
    period={"5m":300,"15m":900,"30m":1800,"1m":60}[tf]
    now=int(now or time.time()); return (((now//period)+1)*period - period)*1000

def fetch_one(ex, sym, tf, limit):
    rows=ex.fetch_ohlcv(to_usdt(sym), timeframe=tf, limit=limit)
    cutoff=last_closed_ms(tf)
    return [r[:6] for r in rows if r and int(r[0])<cutoff]

def write_csv(sym, tf, rows):
    dstdir=OUT/tf; dstdir.mkdir(parents=True,exist_ok=True)
    p=dstdir/(sym.upper().split('/')[0]+".csv")
    with p.open("w", newline="") as f:
        w=csv.writer(f); [w.writerow(r) for r in rows]
    return str(p)

def universe():
    u="/opt/scalp/data/universe.txt"
    if os.path.exists(u): return [l.strip().upper() for l in open(u) if l.strip()]
    return ["BTC","ETH","BNB","SOL","XRP","ADA","ARB","DOGE","LINK","LTC","TRX","OP","APT","SUI","TON"][:15]

def main(a):
    if len(a)<2:
        print("usage: ohlcv_bitget_cli.py <5m|15m|30m|focus1m> [COINS CSV]", file=sys.stderr); sys.exit(2)
    mode=a[1]; env=load_env(); req_env(env); ex=bitget(env)

    if mode=="focus1m":
        coins=[s.strip().upper() for s in (a[2] if len(a)>=3 else open("/opt/scalp/data/focus1m.txt").read()).split(",") if s.strip()]
        ok=0; fail=[]
        for c in coins:
            try: rows=fetch_one(ex,c,"1m",FOCUS_1M_LIMIT); write_csv(c,"1m",rows); ok+=1; print(f"OK {c} 1m:{len(rows)}")
            except SystemExit as e: fail.append({"sym":c,"err":str(e)})
            except Exception as e:  fail.append({"sym":c,"err":f"EUNK:{e}"})
        TRIGGER.write_text(str(int(time.time())))
        json.dump({"mode":"focus1m","ok":ok,"failed":fail,"at":datetime.utcnow().strftime("%FT%TZ")},
                  open("/opt/scalp/data/status.json","w"), separators=(",",":"))
        sys.exit(1 if fail else 0)

    tf=mode
    if tf not in TF_LIMIT: raise SystemExit("EARG: tf invalide (5m|15m|30m|focus1m)")
    coins=[s.strip().upper() for s in (a[2] if len(a)>=3 else ",".join(universe())).split(",") if s.strip()]
    ok=0; fail=[]
    for c in coins:
        try: rows=fetch_one(ex,c,tf,TF_LIMIT[tf]); write_csv(c,tf,rows); ok+=1; print(f"OK {c} {tf}:{len(rows)}")
        except SystemExit as e: fail.append({"sym":c,"err":str(e)})
        except Exception as e:  fail.append({"sym":c,"err":f"EUNK:{e}"})
    TRIGGER.write_text(str(int(time.time())))
    json.dump({"tf":tf,"ok":ok,"failed":fail,"at":datetime.utcnow().strftime("%FT%TZ")},
              open("/opt/scalp/data/status.json","w"), separators=(",",":"))
    sys.exit(1 if fail else 0)

if __name__=="__main__": main(sys.argv)

```

### services/on_new_signals.py  
Taille: 2 KB  |  MàJ: 2025-09-19 23:13:47  |  SHA256: 9d74e037655c12c8

```py
import time, json, hashlib, os
from pathlib import Path
from tools.trade_state import promote_signals_to_positions, reconcile_with_ccxt

SIG = Path("/opt/scalp/data/signals.json")
HASH=""
def file_hash(p):
    try: return hashlib.md5(Path(p).read_bytes()).hexdigest()
    except: return ""

def _fetcher():
    k=os.getenv("BITGET_API_KEY"); s=os.getenv("BITGET_API_SECRET"); p=os.getenv("BITGET_PASSPHRASE")
    if not (k and s and p): return None
    try:
        import ccxt
        ex=ccxt.bitget({"apiKey":k,"secret":s,"password":p,"options":{"defaultType":"swap"}}); ex.load_markets()
        def f(sym):
            m=sym.replace("USDT:USDT","/USDT:USDT")
            last=ex.fetch_ticker(m)["last"]
            size=0.0
            try:
                for pos in ex.fetch_positions([m]):
                    if pos.get("symbol")==m: size=float(pos.get("contracts") or 0)
            except: pass
            return {"last":float(last), "size":float(size)}
        return f
    except: return None

fetch=_fetcher()
while True:
    h=file_hash(SIG)
    if h and h!=HASH:
        HASH=h
        # s’assure que chaque signal a un timestamp
        try:
            data=json.loads(SIG.read_text())
            changed=False
            now=int(time.time())
            for s in data:
                if "ts" not in s: s["ts"]=now; changed=True
            if changed: SIG.write_text(json.dumps(data,indent=2))
        except: pass

        added=promote_signals_to_positions(auto_exec=True, max_new=50)
        reconcile_with_ccxt(fetch)
        print(f"[watch] new signals -> promoted={added}")
    time.sleep(2)

```

### services/paper_trade.py  
Taille: 10 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: dde962538c2446b2

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json, time, hashlib, datetime as dt
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple

BASE=Path("/opt/scalp"); DATA=BASE/"data"
SIGF=DATA/"signals.json"; POSF=DATA/"positions.json"; PHIST=DATA/"positions_hist.jsonl"
ACCT=DATA/"account.json"; RISKF=DATA/"risk.json"; CAND=DATA/"candles"; LOGF=DATA/"logs/paper.log"
CURRENCY="USDT"; START_BAL=100.0

# -------- utils --------
def _log(msg:str):
    LOGF.parent.mkdir(parents=True, exist_ok=True)
    LOGF.open("a").write(time.strftime("%Y-%m-%d %H:%M:%S ", time.gmtime())+msg+"\n")

def _read_json(p:Path, d): 
    try: return json.loads(p.read_text())
    except: return d

def _parse_ts(o:Dict[str,Any])->Optional[int]:
    t = o.get("ts") or o.get("timestamp") or o.get("time")
    if t is None: return None
    if isinstance(t,(int,float)): return int(t/1000) if t>1e12 else int(t)
    if isinstance(t,str):
        s=t.strip()
        try:
            if s.endswith("Z"): 
                return int(dt.datetime.strptime(s,"%Y-%m-%dT%H:%M:%SZ").replace(tzinfo=dt.timezone.utc).timestamp())
            return int(dt.datetime.fromisoformat(s.replace("Z","+00:00")).timestamp())
        except: return None
    return None

def _last_price_1m(sym:str)->float|None:
    p=CAND/f"{sym}_1m.json"
    try:
        o=json.loads(p.read_text()); rows=o.get("rows") or o
        return float(rows[-1][4]) if rows else None
    except: return None

# -------- load/save state --------
def _load_state()->Dict[str,Any]:
    s=_read_json(POSF, {"positions":[],"state":{"seen":{}}})
    s.setdefault("positions",[]); s.setdefault("state",{}); s["state"].setdefault("seen",{})
    return s

def _save_state(s:Dict[str,Any]):
    tmp=POSF.with_suffix(".tmp"); tmp.write_text(json.dumps(s, ensure_ascii=False, separators=(",",":"))); tmp.replace(POSF)

def _append_hist(row:Dict[str,Any]):
    PHIST.parent.mkdir(parents=True, exist_ok=True)
    with PHIST.open("a") as f: f.write(json.dumps(row, ensure_ascii=False)+"\n")

def _load_account()->Dict[str,Any]:
    a=_read_json(ACCT, {})
    a.setdefault("balance", START_BAL); a.setdefault("equity", a["balance"])
    a.setdefault("open_pnl", 0.0); a.setdefault("margin_used", 0.0)
    a.setdefault("currency", "USDT"); a.setdefault("updated", int(time.time()))
    return a

def _save_account(a:Dict[str,Any]):
    a["updated"]=int(time.time())
    tmp=ACCT.with_suffix(".tmp"); tmp.write_text(json.dumps(a, ensure_ascii=False, separators=(",",":"))); tmp.replace(ACCT)

def _load_risk()->Dict[str,Any]:
    r=_read_json(RISKF, {})
    r.setdefault("risk_pct", 0.005)
    r.setdefault("default_leverage", 5)
    r.setdefault("max_positions", 3)
    r.setdefault("max_pair_exposure", 0.5)
    r.setdefault("max_margin_util", 0.8)
    r.setdefault("min_notional", {"DEFAULT":10})
    r.setdefault("max_leverage", {"DEFAULT":25})
    return r

# -------- signals reader --------
def _read_signals()->List[Dict[str,Any]]:
    if not SIGF.exists(): return []
    txt=SIGF.read_text().strip()
    out:List[Dict[str,Any]]=[]
    if txt.startswith("[") and txt.endswith("]"):
        try: 
            arr=json.loads(txt)
            return [x for x in arr if isinstance(x,dict)]
        except: pass
    ok=False
    for line in txt.splitlines()[-400:]:
        line=line.strip()
        if not line: continue
        try:
            o=json.loads(line)
            if isinstance(o,dict): out.append(o); ok=True
        except: pass
    if ok: return out
    # extraction streaming basique
    buf=[]; lvl=0; ins=False; esc=False
    for ch in txt:
        if ins:
            buf.append(ch)
            if esc: esc=False
            elif ch=="\\": esc=True
            elif ch=='"': ins=False
            continue
        if ch=='"': ins=True; buf.append(ch); continue
        if ch=='{': lvl+=1; buf.append(ch); continue
        if lvl>0: buf.append(ch)
        if ch=='}' and lvl>0:
            lvl-=1
            if lvl==0:
                try:
                    o=json.loads(''.join(buf)); buf=[]
                    if isinstance(o,dict): out.append(o)
                except: buf=[]
    return out

# -------- sizing + open/close --------
def _sig_id(s:Dict[str,Any])->str:
    ts=_parse_ts(s) or 0
    key=f"{s.get('symbol')}|{s.get('entry_set')}|{s.get('side')}|{ts}"
    return hashlib.sha1(key.encode()).hexdigest()[:16]

def _cap_for(sym:str, caps:Dict[str,Any], key:str, default):
    tbl=caps.get(key) or {}
    return tbl.get(sym, tbl.get("DEFAULT", default))

def _compute_size(s:Dict[str,Any], balance:float, risk:Dict[str,Any])->Tuple[float,float,float,int,str]:
    """retourne (qty, notional, margin, lev, reason_if_reject_or_empty)"""
    sym=str(s["symbol"]).upper()
    pe=float(s["price_entry"]); sl=float(s["sl"])
    dist=abs(pe - sl)
    if dist<=0: return 0,0,0,0,"zero_dist"
    risk_pct=float(risk["risk_pct"])
    R=balance*risk_pct                       # risque fixe en USDT
    qty = float(s.get("size") or (R/dist))   # calc qty si non fournie
    lev_sig = int(s.get("leverage") or risk["default_leverage"])
    lev_cap = int(_cap_for(sym, risk, "max_leverage", 25))
    lev = max(1, min(lev_sig, lev_cap))
    notion = qty*pe
    min_not = float(_cap_for(sym, risk, "min_notional", 10))
    if notion < min_not: 
        # remonte qty au min notionnel
        qty = min_not/pe
        notion = min_not
    margin = notion/lev
    return qty, notion, margin, lev, ""
    
def _open_from_signal(s:Dict[str,Any], acct:Dict[str,Any], risk:Dict[str,Any],
                      open_now:int, by_sym:Dict[str,Any])->Tuple[Optional[Dict[str,Any]],str]:
    sym=s.get("symbol"); side=s.get("side")
    if not sym or side not in ("long","short"): return None,"invalid_side"
    ts=_parse_ts(s) or int(time.time())
    if s.get("price_entry") is None or s.get("sl") is None or s.get("tp") is None: 
        return None,"missing_prices"
    qty, notion, margin, lev, reason = _compute_size(s, float(acct["balance"]), risk)
    if reason: return None, reason
    # contraintes globales
    if open_now >= int(risk["max_positions"]): return None,"max_positions"
    if sym in by_sym: return None,"already_open"
    if notion > float(acct["balance"])*float(risk["max_pair_exposure"]): return None,"pair_exposure"
    if float(acct["margin_used"])+margin > float(acct["balance"])*float(risk["max_margin_util"]): 
        return None,"margin_util"

    pos = {
        "id": _sig_id(s),
        "symbol": str(sym).upper(),
        "side": side,
        "entry": float(s["price_entry"]),
        "sl": float(s["sl"]),
        "tp": float(s["tp"]),
        "size": float(qty),
        "leverage": int(lev),
        "notional": float(notion),
        "margin": float(margin),
        "ts_open": int(ts),
        "setup": s.get("entry_set",""),
        "status": "open",
        "pnl": 0.0
    }
    return pos,""

def _update_close(pos:Dict[str,Any], last:Optional[float])->Tuple[Dict[str,Any], Optional[Dict[str,Any]]]:
    if last is None: return pos, None
    side,e,sl,tp,sz = pos["side"], pos["entry"], pos["sl"], pos["tp"], pos["size"]
    pnl=(last-e)*sz if side=="long" else (e-last)*sz
    pos["pnl"]=round(pnl,6); pos["last"]=last
    hit=None
    if side=="long" and last<=sl: hit=("SL", sl)
    elif side=="long" and last>=tp: hit=("TP", tp)
    elif side=="short" and last>=sl: hit=("SL", sl)
    elif side=="short" and last<=tp: hit=("TP", tp)
    if not hit: return pos, None
    reason, exitp=hit
    closed={"id":pos["id"],"symbol":pos["symbol"],"side":side,"setup":pos.get("setup",""),
            "ts_open":pos["ts_open"],"entry":e,"sl":sl,"tp":tp,"size":sz,"leverage":pos.get("leverage",1),
            "notional":pos.get("notional",sz*e),"margin":pos.get("margin", (sz*e)/max(1,pos.get('leverage',1))),
            "ts_close":int(time.time()),"exit":float(exitp),
            "pnl": (exitp-e)*sz if side=="long" else (e-exitp)*sz,"reason":reason}
    pos["status"]="closed"; pos["ts_close"]=closed["ts_close"]; pos["exit"]=exitp
    return pos, closed

# -------- main --------
def main():
    state=_load_state(); acct=_load_account(); risk=_load_risk()
    pos=state["positions"]; seen=state["state"]["seen"]
    sigs=_read_signals()
    by_sym={p["symbol"]:p for p in pos if p.get("status")=="open"}
    opened=closed_cnt=0; skip_stats={}

    # open
    for s in sigs[-200:]:
        if not isinstance(s,dict): continue
        sid=_sig_id(s)
        if seen.get(sid): continue
        p, why = _open_from_signal(s, acct, risk, sum(1 for x in pos if x.get("status")=="open"), by_sym)
        if p is None:
            seen[sid]=1; skip_stats[why]=skip_stats.get(why,0)+1; continue
        pos.append(p); by_sym[p["symbol"]]=p; seen[sid]=1; opened+=1
        acct["margin_used"]=round(acct.get("margin_used",0.0)+float(p["margin"]),6)

    # update + close
    alive=[]; open_pnl=0.0
    for p in pos:
        if p.get("status")!="open": alive.append(p); continue
        last=_last_price_1m(p["symbol"])
        p,closed=_update_close(p,last)
        alive.append(p)
        if closed:
            _append_hist(closed); closed_cnt+=1
            acct["balance"]=round(float(acct["balance"])+float(closed["pnl"]),6)
            acct["margin_used"]=round(max(0.0, acct.get("margin_used",0.0)-float(closed.get("margin",0.0))),6)
        else:
            open_pnl += float(p.get("pnl",0.0))

    acct["open_pnl"]=round(open_pnl,6)
    acct["equity"]=round(float(acct["balance"])+acct["open_pnl"],6)
    state["positions"]=alive; state["state"]["seen"]=seen; state["state"]["updated"]=int(time.time())
    _save_state(state); _save_account(acct)

    msg = ("opened=%d closed=%d open_now=%d equity=%.2f margin_used=%.2f %s" %
           (opened, closed_cnt, sum(1 for x in alive if x.get("status")=="open"),
            acct["equity"], acct["margin_used"],
            ("skips="+json.dumps(skip_stats,separators=(',',':')) if skip_stats else "")))
    _log(msg); print("[paper] "+msg)

if __name__=="__main__":
    main()

```

### services/positions_watcher.py  
Taille: 4 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 7c7738f87e4f36f8

```py
#!/opt/scalp/.venv/bin/python
from __future__ import annotations
import json, time, os, math
from pathlib import Path
from typing import Any, Dict, List

BASE = Path("/opt/scalp")
DATA = BASE/"data"
CAND = DATA/"candles"
POSF = DATA/"positions.json"
HISTL= DATA/"positions_hist.jsonl"

TICK = float(os.getenv("POS_TICK_SEC","2"))  # période de suivi en secondes

def _now_iso(): return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

def _read_json(p: Path, dflt):
    try: return json.loads(p.read_text())
    except Exception: return dflt

def _write_atomic(p: Path, obj):
    tmp = p.with_suffix(p.suffix+".tmp")
    tmp.write_text(json.dumps(obj, ensure_ascii=False, separators=(",",":")))
    tmp.replace(p)

def _append_jsonl(p: Path, row: dict):
    p.parent.mkdir(parents=True, exist_ok=True)
    with p.open("a", encoding="utf-8") as f:
        f.write(json.dumps(row, ensure_ascii=False) + "\n")

def _latest_px(sym: str) -> float|None:
    f = CAND/f"{sym}_1m.json"
    if not f.exists(): return None
    try:
        obj = json.loads(f.read_text())
        rows = obj.get("rows", obj) if isinstance(obj, dict) else obj
        if not rows: return None
        return float(rows[-1][4])  # close
    except Exception:
        return None

def _pnl(side:str, entry:float, last:float, size:float, lev:int) -> tuple[float,float]:
    if side.lower().startswith("long"):
        pnl_quote = (last - entry) * size * max(lev,1)
        pct = ((last/entry)-1.0) * 100.0 * max(lev,1)
    else:  # short
        pnl_quote = (entry - last) * size * max(lev,1)
        pct = ((entry/last)-1.0) * 100.0 * max(lev,1)
    return float(pnl_quote), float(pct)

def _should_close(side:str, last:float, tp:float, sl:float) -> tuple[bool,str]:
    s = side.lower()
    if s.startswith("long"):
        if last >= tp > 0:  return True, "tp"
        if sl > 0 and last <= sl: return True, "sl"
    else:  # short
        if tp > 0 and last <= tp: return True, "tp"
        if sl > 0 and last >= sl: return True, "sl"
    return False, ""

def _load_positions() -> List[Dict[str,Any]]:
    obj = _read_json(POSF, {})
    rows = obj.get("positions", []) if isinstance(obj, dict) else []
    return [r for r in rows if isinstance(r, dict)]

def _save_positions(rows: List[Dict[str,Any]]):
    _write_atomic(POSF, {"updated": _now_iso(), "positions": rows})

def step_once() -> int:
    rows = _load_positions()
    if not rows: return 0
    out: List[Dict[str,Any]] = []
    closed = 0
    for r in rows:
        sym = str(r.get("symbol") or r.get("sym") or "?").upper()
        side = str(r.get("side",""))
        entry= float(r.get("entry",0) or 0)
        sl   = float(r.get("sl",0) or 0)
        tp   = float(r.get("tp",0) or 0)
        size = float(r.get("size", r.get("qty",0)) or 0)
        lev  = int(r.get("leverage", r.get("lev",1)) or 1)
        if not sym or entry <= 0 or size <= 0:
            # invalide → ignorer dans le book mais pousser en hist pour traçabilité
            _append_jsonl(HISTL, {**r, "timestamp": _now_iso(), "ts_close": int(time.time()),
                                  "status":"rejected", "reason":"invalid_open_position"})
            continue

        last = _latest_px(sym)
        if last is None:
            # pas de prix → garder la position telle quelle
            out.append(r)
            continue

        pnl_quote, pct = _pnl(side, entry, last, size, lev)
        r_upd = {**r,
                 "last": float(last),
                 "pnl": float(pnl_quote),
                 "pnl_pct": float(pct),
                 "ts_update": int(time.time())}

        do_close, reason = _should_close(side, last, tp, sl)
        if do_close:
            row_hist = {
                "timestamp": _now_iso(),
                "ts_open": int(r.get("ts_open") or time.time()),
                "ts_close": int(time.time()),
                "symbol": sym, "side": side,
                "entry": entry, "sl": sl, "tp": tp,
                "exit": float(last),
                "size": size, "leverage": lev,
                "status":"closed", "reason": reason,
                "pnl": float(pnl_quote), "pnl_pct": float(pct)
            }
            _append_jsonl(HISTL, row_hist)
            closed += 1
        else:
            out.append(r_upd)

    _save_positions(out)
    return closed

def main():
    while True:
        try:
            step_once()
        except Exception as e:
            # on continue même si une position pose problème
            pass
        time.sleep(TICK)

if __name__ == "__main__":
    main()

```

### services/promote_min.py  
Taille: 1 KB  |  MàJ: 2025-09-19 23:16:55  |  SHA256: 65818b090e2fd2ba

```py
import json, time, hashlib
from pathlib import Path

SIG = Path("/opt/scalp/data/signals.json")
POS = Path("/opt/scalp/data/positions.json")
HST = Path("/opt/scalp/data/history.json")

def load(p):
    try: return json.loads(p.read_text())
    except: return []

def dump(p, arr):
    p.parent.mkdir(parents=True, exist_ok=True)
    p.write_text(json.dumps(arr, indent=2))

def uid(s):
    base=f"{s.get('sym')}|{s.get('side')}|{s.get('px')}|{s.get('ts')}"
    return hashlib.md5(base.encode()).hexdigest()

def main():
    sigs = load(SIG)
    if not sigs: 
        print("no signals"); return
    # s'assure d'un ts
    now=int(time.time())
    for s in sigs: s.setdefault("ts", now)
    pos  = load(POS)
    live_ids = { p.get("id") for p in pos }
    moved=0
    for s in sigs:
        s["id"]=uid(s); s["status"]="OPEN"
        if s["id"] in live_ids: 
            continue
        pos.append(s); moved+=1
    # vide la file des signaux (on a promu ceux présents)
    dump(POS, pos)
    dump(SIG, [])
    print(f"promoted={moved}, remaining_signals=0")

if __name__ == "__main__":
    main()

```

### services/run_ohlcv_batch.sh  
Taille: 257 B  |  MàJ: 2025-09-19 18:26:16  |  SHA256: b9cf11d92010bbef

```sh
PY=/opt/scalp/.venv/bin/python
PY="/opt/scalp/.venv/bin/python"
#!/usr/bin/env bash
set -euo pipefail
/opt/scalp/services/ohlcv_bitget_cli.py 5m || true
/opt/scalp/services/ohlcv_bitget_cli.py 15m || true
/opt/scalp/services/ohlcv_bitget_cli.py 30m || true

```

### services/signals_B.py  
Taille: 8 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 68815892ab48a0ba

```py
#!/opt/scalp/.venv/bin/python
# Couche B — déclencheurs Pullback/Breakout/Mean-Reversion sur 1m/3m/5m
# Entrées : /opt/scalp/data/Btop.json ; candles/<SYM>_{1m,3m,5m}.json ([t,o,h,l,c,v])
# Sortie  : /opt/scalp/data/signals.json

import json, time, math
from pathlib import Path

BASE = Path("/opt/scalp")
DATA = BASE/"data"
CAND = DATA/"candles"
BTOP = DATA/"Btop.json"
OUT  = DATA/"signals.json"
RISK = DATA/"risk.json"
ACCT = DATA/"account.json"

# ---------- IO ----------
def _read_cand(sym, tf):
    p = CAND/f"{sym}_{tf}.json"
    if not p.exists(): return []
    try:
        rows = json.loads(p.read_text())
        if isinstance(rows, dict):
            rows = rows.get("rows", [])
        return rows[-600:]
    except Exception:
        return []

def _now(): return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

# ---------- indicateurs ----------
def _ema(vals, n):
    k = 2/(n+1); e=None; out=[]
    for v in vals:
        e = v if e is None else (v-e)*k + e
        out.append(e)
    return out

def _rsi(closes, n=7):
    if len(closes)<n+1: return []
    gains=[0]; losses=[0]
    for i in range(1,len(closes)):
        d=closes[i]-closes[i-1]
        gains.append(max(d,0)); losses.append(max(-d,0))
    def _ema_seq(x,n):
        k=2/(n+1); e=None; o=[]
        for v in x:
            e=v if e is None else (v-e)*k+e; o.append(e)
        return o
    ag=_ema_seq(gains,n); al=_ema_seq(losses,n); r=[]
    for g,l in zip(ag,al):
        r.append(100.0 if l==0 else 100.0 - 100.0/(1.0+g/l))
    return r

def _atr(ohlc, n=14):
    if len(ohlc)<n+1: return []
    trs=[]
    for i in range(1,len(ohlc)):
        _,_,h,l,_,c = ohlc[i]
        _,_,ph,pl,_,pc = ohlc[i-1]
        trs.append(max(h-l, abs(h-pc), abs(l-pc)))
    k=2/(n+1); e=None; out=[]
    for tr in trs:
        e=tr if e is None else (tr-e)*k+e; out.append(e)
    return out

def _boll(closes, n=20, k=2.0):
    if len(closes)<n: return ([],[],[])
    mid=[]; up=[]; lo=[]
    for i in range(len(closes)):
        if i+1<n: mid.append(None); up.append(None); lo.append(None); continue
        win=closes[i+1-n:i+1]
        m=sum(win)/n
        sd=(sum((x-m)**2 for x in win)/n)**0.5 * 0.5
        mid.append(m); up.append(m+k*sd); lo.append(m-k*sd)
    return mid,up,lo

def _macd(closes, f=12, s=26, sig=9):
    if not closes: return [],[],[]
    ef=_ema(closes,f); es=_ema(closes,s)
    macd=[a-b for a,b in zip(ef,es)]
    signal=_ema(macd,sig)
    hist=[m-si for m,si in zip(macd,signal)]
    return macd,signal,hist

def _adx(ohlc, n=14):
    if len(ohlc)<n+2: return []
    trs=[]; plus_dm=[]; minus_dm=[]
    for i in range(1,len(ohlc)):
        _,_,h,l,_,_ = ohlc[i]
        _,_,ph,pl,_,_ = ohlc[i-1]
        up=h-ph; dn=pl-l
        plus_dm.append(max(up,0.0) if up>dn and up>0 else 0.0)
        minus_dm.append(max(dn,0.0) if dn>up and dn>0 else 0.0)
        trs.append(max(h-l, abs(h-ohlc[i-1][4]), abs(l-ohlc[i-1][4])))
    def _ema_seq(x,n):
        k=2/(n+1); e=None; o=[]
        for v in x:
            e=v if e is None else (v-e)*k+e; o.append(e)
        return o
    trn=_ema_seq(trs,n); pdi=[]; mdi=[]
    for pd,md,tr in zip(_ema_seq(plus_dm,n), _ema_seq(minus_dm,n), trn):
        if tr==0: pdi.append(0); mdi.append(0)
        else: pdi.append(100*pd/tr); mdi.append(100*md/tr)
    dx=[0 if (a+b)==0 else 100*abs(a-b)/(a+b) for a,b in zip(pdi,mdi)]
    return _ema_seq(dx,n)

def _vwap_sigmal(ohlc, n=20):
    if len(ohlc)<n: return [None]*len(ohlc),[None]*len(ohlc),[None]*len(ohlc)
    tp=[]; pv=[]
    for _,o,h,l,c,v in ohlc:
        typ=(h+l+c)/3; tp.append(typ); pv.append(typ*v)
    vwap=[]; up=[]; lo=[]
    for i in range(len(ohlc)):
        j=max(0, i+1-n)
        wtp=tp[j:i+1]; wv=[x[5] for x in ohlc[j:i+1]]
        wsum=sum(wv) or 1e-9
        v_i=sum(a*b for a,b in zip(wtp,wv))/wsum
        vwap.append(v_i)
        m=sum(wtp)/len(wtp); sd=(sum((x-m)**2 for x in wtp)/len(wtp))**0.5
        up.append(v_i+sd); lo.append(v_i-sd)
    return vwap,up,lo

def _touch(x, a, b):
    return a is not None and b is not None and ((x<=a) or (x>=b))

def _highest(arr, n): return None if len(arr)<n else max(arr[-n:])
def _lowest(arr, n):  return None if len(arr)<n else min(arr[-n:])

# ---------- risk / size / leverage ----------
def _risk_defaults():
    try: r=json.loads(RISK.read_text())
    except Exception: r={}
    rpct=float(r.get("risk_pct_per_trade", r.get("risk_pct", 0.005)))
    lev =int(r.get("default_leverage", 5))
    return rpct, lev

def _equity_value():
    try: a=json.loads(ACCT.read_text()); return float(a.get("equity", a.get("balance", 1000.0)))
    except Exception: return 1000.0

def _qty_from_stop(entry, sl, equity, risk_pct):
    dist=abs(float(entry)-float(sl)) or 1e-9
    return float(f"{(equity*risk_pct)/dist:.6f}")

# ---------- émetteur sécurisé ----------
def _emit(siglist, sym, entry_set, side, price, sl, tp):
    if price is None or sl is None or tp is None:
        print(f"[B] drop {sym}/{entry_set}: None px={price} sl={sl} tp={tp}")
        return
    if any(v==0 for v in (price, sl, tp)):
        print(f"[B] drop {sym}/{entry_set}: zero px={price} sl={sl} tp={tp}")
        return
    rpct, lev = _risk_defaults()
    eq = _equity_value()
    qty = _qty_from_stop(price, sl, eq, rpct)
    siglist.append({
        "timestamp": _now(),
        "t_emit": int(time.time()),
        "symbol": str(sym).upper(),
        "sym":     str(sym).upper(),
        "entry_set": entry_set,
        "rule":      entry_set,
        "side": side,
        "price_entry": round(float(price),8),
        "sl":          round(float(sl),8),
        "tp":          round(float(tp),8),
        "size": float(qty),
        "leverage": int(lev),
    })

# ---------- règles ----------
def _base_move(px, atrv):
    # garde-fou: ATR ne doit pas dépasser 10% du prix
    cap = 0.1*px
    atr_use = None
    if atrv is not None:
        atr_use = atrv if atrv < cap else cap
    return atr_use if atr_use is not None else 0.003*px

def process_symbol(sym, sigs):
    m1=_read_cand(sym,"1m"); m3=_read_cand(sym,"3m"); m5=_read_cand(sym,"5m")
    if len(m1)<50 or len(m3)<50 or len(m5)<50: return

    c1=[x[4] for x in m1]; c3=[x[4] for x in m3]
    rsi1=_rsi(c1,7); ema20=_ema(c1,20)
    vwap,vu,vl=_vwap_sigmal(m1,20)
    mid,bu,bl=_boll(c1,20,2.0)
    _,_,mach=_macd(c3,12,26,9)
    adx=_adx(m5,14)
    atr=_atr(m3,14)

    px=c1[-1]
    atrv=atr[-1] if atr else None
    base=_base_move(px, atrv)

    adxv=adx[-1] if adx else 0.0
    rsi=rsi1[-1] if rsi1 else 50.0
    ema=ema20[-1] if ema20 else px
    up=bu[-1] if bu else None; lo=bl[-1] if bl else None
    vw_up=vu[-1] if vu else None; vw_lo=vl[-1] if vl else None
    hh=_highest(c3,20); ll=_lowest(c3,20)
    macdh=mach[-1] if mach else 0.0

    # Pullback Trend
    if ema and px>=ema and rsi>50 and _touch(px, vw_lo, vw_up):
        _emit(sigs,sym,"pullback_trend","long", px, px-1.2*base, px+1.8*base)
    if ema and px<=ema and rsi<50 and _touch(px, vw_lo, vw_up):
        _emit(sigs,sym,"pullback_trend","short",px, px+1.2*base, px-1.8*base)

    # Breakout
    if adxv>=20 and hh is not None and ll is not None:
        if px>hh and macdh>0:
            _emit(sigs,sym,"breakout","long", px, ll, px + max(px-hh, 1.5*base))
        if px<ll and macdh<0:
            _emit(sigs,sym,"breakout","short",px, hh, px - max(hh-px, 1.5*base))

    # Mean-Reversion
    if up is not None and lo is not None:
        if px<=lo and rsi<35:
            _emit(sigs,sym,"mean_reversion","long", px, px-1.0*base, (mid[-1] if mid else px*1.002))
        if px>=up and rsi>65:
            _emit(sigs,sym,"mean_reversion","short",px, px+1.0*base, (mid[-1] if mid else px*0.998))

# ---------- main ----------
def main():
    if not BTOP.exists(): return 0
    obj=json.loads(BTOP.read_text())
    syms=[a["sym"] for a in obj.get("assets",[])]
    sigs=[]
    for s in syms: process_symbol(s, sigs)
    OUT.write_text(json.dumps({"updated":_now(),"signals":sigs}, ensure_ascii=False, separators=(",",":")))
    print(f"[B] signals: {len(sigs)} -> {OUT}")
    return 0

if __name__=="__main__":
    raise SystemExit(main())

```

### services/top_bitget.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:25:51  |  SHA256: 605d9a5ae319a1c1

```py
#!/opt/scalp/.venv/bin/python
import json, time, sys
from pathlib import Path
from loguru import logger
import ccxt

DATA = Path("/opt/scalp/data")
FIXES = ["BTC","ETH","BNB","SOL","XRP"]

def main():
    try:
        ex = ccxt.bitget({"options":{"defaultType":"swap"}, "enableRateLimit": True})
        ex.load_markets()
        tick = ex.fetch_tickers()
    except Exception as e:
        logger.error(f"E_BITGET: {e}")
        sys.exit(20)

    # scores par volume quote USDT uniquement
    scores = []
    for s, t in tick.items():
        if ":USDT" not in s and "/USDT" not in s: 
            continue
        vol = float(t.get("quoteVolume", 0) or 0)
        base = s.split('/')[0].split(':')[0]
        scores.append((base, vol))
    scores.sort(key=lambda x: x[1], reverse=True)

    # construire la liste finale
    out = []
    seen = set()
    for b in FIXES + [b for b,_ in scores]:
        if b in seen: 
            continue
        seen.add(b)
        out.append(b)
        if len(out) >= 15: 
            break

    DATA.mkdir(parents=True, exist_ok=True)
    (DATA/"universe.txt").write_text("\n".join(out)+"\n")
    obj = {"assets":[{"sym":s,"vol":0,"vola":0} for s in out],
           "updated": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())}
    (DATA/"top.json").write_text(json.dumps(obj, ensure_ascii=False))
    print("TOP15:", out)

if __name__ == "__main__":
    main()

```

### tools/agg_tf3.py  
Taille: 1 KB  |  MàJ: 2025-09-19 20:41:47  |  SHA256: c697a854ae7ab67a

```py
#!/opt/scalp/.venv/bin/python
import json
from pathlib import Path
import math
D=Path("/opt/scalp/data"); C1=D/"candles"; C3=D/"candles_3m"; C3.mkdir(exist_ok=True)
def floor3(ts): return (ts//(3*60_000))*(3*60_000)  # borné à HH:MM:00 multiples de 3
for f in C1.glob("*_1m.json"):
    rows=json.loads(f.read_text())
    out=[]; buf=[]; cur=None
    for r in rows:
        ts=r["t"] if isinstance(r,dict) else r[0]
        b=floor3(ts)
        if cur is None: cur=b
        if b!=cur:
            if buf:
                o=buf[0]; h=max(x["h"] for x in buf); l=min(x["l"] for x in buf)
                c=buf[-1]["c"]; v=sum(x["v"] for x in buf)
                out.append({"t":cur,"o":o["o"],"h":h,"l":l,"c":c,"v":v})
            buf=[]; cur=b
        d={"t":ts,"o":r["o"],"h":r["h"],"l":r["l"],"c":r["c"],"v":r["v"]}
        buf.append(d)
    if buf:
        o=buf[0]; h=max(x["h"] for x in buf); l=min(x["l"] for x in buf)
        c=buf[-1]["c"]; v=sum(x["v"] for x in buf)
        out.append({"t":cur,"o":o["o"],"h":h,"l":l,"c":c,"v":v})
    (C3/f.name.replace("_1m","_3m")).write_text(json.dumps(out,ensure_ascii=False))
print("tf3 done")

```

### tools/bootstrap_ohlcv_bitget.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:58:47  |  SHA256: 726a4ec73eb40fbb

```py
#!/opt/scalp/.venv/bin/python
import ccxt, json, time, re
from pathlib import Path
ROOT=Path("/opt/scalp"); DATA=ROOT/"data"; C=DATA/"candles"
C.mkdir(parents=True, exist_ok=True)

def norm(sym:str)->str:
    # garde lettres et chiffres pour générer <SYM>_1m.json (ex: BTCUSDT)
    return re.sub(r'[^A-Z0-9]', '', sym.upper())

syms=[l.strip() for l in (DATA/"universe.txt").read_text().splitlines() if l.strip()]
ex=ccxt.bitget({'enableRateLimit': True, 'options': {'defaultType': 'swap'}})

now=ex.milliseconds()
for s in syms:
    s = s.upper()
    mkt = norm(s)
    out = C/f"{mkt}_1m.json"
    ohlc=[]
    since=now-1000*60*1000  # ~1000 minutes
    while True:
        batch = ex.fetch_ohlcv(s, timeframe='1m', since=since, limit=1000)
        if not batch: break
        ohlc += batch
        if len(batch) < 1000: break
        since = batch[-1][0] + 60_000
        time.sleep(ex.rateLimit/1000)
    rows=[{"t":r[0],"o":r[1],"h":r[2],"l":r[3],"c":r[4],"v":r[5]} for r in ohlc]
    out.write_text(json.dumps(rows, ensure_ascii=False))
    print(mkt, len(rows))

```

### tools/bot_ensure_service.sh  
Taille: 472 B  |  MàJ: 2025-09-17 20:44:34  |  SHA256: 4df2f4696041c062

```sh
#!/usr/bin/env bash
set -euo pipefail
API="https://api.telegram.org/bot${TELEGRAM_TOKEN:-$TELEGRAM_BOT_TOKEN}"
# stop manuel + webhook propre
pkill -f "python.*bot\.router" 2>/dev/null || true
curl -s "$API/deleteWebhook" >/dev/null || true
# redémarre le service
systemctl restart scalp-telegram-bot.service
systemctl --no-pager status scalp-telegram-bot.service -n 0 || true
# check doublons
pgrep -fa "python.*bot\.router" || echo "OK: une seule instance via systemd"

```

### tools/build_top_from_heatmap.py  
Taille: 415 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: c1437517bc481006

```py
import json
from pathlib import Path
hm=json.loads(Path("/opt/scalp/data/heatmap_soft.json").read_text())
rows=hm.get("rows",[])
order=sorted([(abs(float(r["S"][-1]["S"])) if r.get("S") else 0.0, r["sym"]) for r in rows], reverse=True)
syms=[s for _,s in order][:15]
Path("/opt/scalp/data/top.json").write_text(json.dumps({"rows":syms},separators=(',',':')))
print("top.json écrit avec",len(syms),"symbols:",syms)

```

### tools/check_B.sh  
Taille: 3 KB  |  MàJ: 2025-09-17 12:18:15  |  SHA256: 57b53030a5007f9b

```sh
#!/usr/bin/env bash
set -euo pipefail
DATA=/opt/scalp/data
PYTHON=/opt/scalp/.venv/bin/python
export PYTHONPATH=/opt/scalp

age_min(){ # age_min <file>
  [ -f "$1" ] || { echo "NA"; return; }
  now=$(date +%s); mt=$(stat -c %Y "$1" 2>/dev/null || stat -f %m "$1")
  echo $(( (now-mt)/60 ))
}

echo "== when & host =="
date -Is; uptime
echo

echo "== files =="
ls -lh --time-style=long-iso "$DATA/heatmap.json" "$DATA/Btop.json" 2>/dev/null || true
echo

echo "== Btop summary =="
if [ -f "$DATA/Btop.json" ]; then
  jq '{updated, count: (.assets|length), sample: (.assets[:8])}' "$DATA/Btop.json" || true
else
  echo "Btop.json absent"
fi
echo

echo "== quick context from heatmap =="
$PYTHON - <<'PY'
import json,sys,statistics,datetime
from pathlib import Path
DATA=Path("/opt/scalp/data")
HM=DATA/"heatmap.json"; BT=DATA/"Btop.json"
BAND=0.10; TH_BUY=0.60; TH_SELL=0.60; RNG_MIN,RNG_MAX=0.40,0.60
def probs(seq):
    b=h=s=0
    for x in seq:
        v=float(x.get("S",0))
        if abs(v) < BAND: h+=1
        elif v>0: b+=1
        else: s+=1
    n=max(1,b+h+s)
    return b/n,h/n,s/n
def ctx(pb,ph,ps):
    if pb>=TH_BUY: return "bullish"
    if ps>=TH_SELL: return "bearish"
    if RNG_MIN<=ph<=RNG_MAX: return "range"
    return "none"

if not HM.exists():
    print("heatmap.json absent"); sys.exit(0)

rows=json.loads(HM.read_text()).get("rows",[])
sym_to_seq={ r["sym"]: r.get("S", r.get("seq",[])) for r in rows }
assets=[]
if (BT.exists()):
    assets=json.loads(BT.read_text()).get("assets",[])
if not assets:
    assets=[r["sym"] for r in rows[:8]]

out=[]
for s in assets[:8]:
    seq=sym_to_seq.get(s,[]) or []
    pb,ph,ps=probs(seq[-20:])
    out.append((s, pb,ph,ps, ctx(pb,ph,ps)))
w= max(3, *(len(t[0]) for t in out)) if out else 4
print(f"{'SYM'.ljust(w)}  p_buy  p_hold  p_sell  CTX")
for s,pb,ph,ps,c in out:
    print(f"{s.ljust(w)}  {pb:5.2f}  {ph:5.2f}  {ps:5.2f}  {c}")
PY
echo

echo "== OHLCV freshness (1m / 5m) for first assets =="
if [ -f "$DATA/Btop.json" ]; then
  mapfile -t SYMS < <(jq -r '.assets[:8][]' "$DATA/Btop.json")
else
  mapfile -t SYMS < <(jq -r '.rows[:8][]|.sym' "$DATA/heatmap.json" 2>/dev/null)
fi
for s in "${SYMS[@]:-}"; do
  f1="$DATA/candles/${s}_1m.json"
  f5="$DATA/candles/${s}_5m.json"
  a1=$(age_min "$f1"); a5=$(age_min "$f5")
  echo "- $s  1m: ${a1}min  5m: ${a5}min"
done
echo

echo "== last analyze_B runs (journal) =="
journalctl -u scalp-analyze-b.path -u scalp-analyze-b.service -n 20 --no-pager 2>/dev/null || true
echo

echo "== readiness summary =="
$PYTHON - <<'PY'
import json, os
from pathlib import Path
DATA=Path("/opt/scalp/data")
BT=DATA/"Btop.json"
assets=[]
if BT.exists():
    j=json.loads(BT.read_text()); assets=j.get("assets",[])
print(f"assets_in_Btop={len(assets)} (showing readiness, not signals)")
PY

```

### tools/check_deps.py  
Taille: 875 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 6c9d3a455c54485a

```py
#!/opt/scalp/.venv/bin/python
import importlib
import subprocess
import sys

REQUIRED = {
    "ccxt": ">=4.5.4",
    "aiogram": ">=3.1.0,<3.2.0",
    "loguru": ">=0.7.0",
    "pandas": ">=2.2.0"
}

def ensure_package(pkg, constraint):
    try:
        importlib.import_module(pkg)
        print(f"[OK] {pkg} déjà installé")
    except ImportError:
        print(f"[WARN] {pkg} absent → tentative d’installation…")
        try:
            subprocess.check_call([
                "/opt/scalp/.venv/bin/pip", "install", f"{pkg}{constraint}"
            ])
            print(f"[OK] {pkg} installé")
        except Exception as e:
            print(f"[ERREUR] Impossible d’installer {pkg} ({e})")

if __name__ == "__main__":
    for pkg, constraint in REQUIRED.items():
        ensure_package(pkg, constraint)
    print("[DONE] Vérification dépendances terminée")

```

### tools/check_env.py  
Taille: 132 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: bdedbed9c59dd8f1

```py
#!/opt/scalp/.venv/bin/python
import ccxt, aiogram, pandas, loguru
print("✅ Environnement prêt")
print("ccxt", ccxt.__version__)

```

### tools/check_heat.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 1e9e2a0902d72977

```py
#!/opt/scalp/.venv/bin/python
import json, pathlib, sys, datetime as dt
DATA = pathlib.Path("/opt/scalp/data")
HEAT = DATA/"heatmap.json"; TOP = DATA/"top.json"

def load(p): return json.loads(pathlib.Path(p).read_text(encoding="utf-8"))

def age_minutes(iso):
    try:
        t = dt.datetime.fromisoformat(iso.replace("Z",""))
        return int((dt.datetime.utcnow()-t).total_seconds()//60)
    except Exception: return 10**9

def check():
    top = load(TOP); heat = load(HEAT)
    assets = [a["sym"] for a in top.get("assets", [])]
    rows = heat.get("rows", [])
    errs=[]
    # 15 lignes attendues
    if len(assets)!=15: errs.append(f"top.assets={len(assets)} (attendu 15)")
    if len(rows)!=15: errs.append(f"heat.rows={len(rows)} (attendu 15)")
    # chaque ligne: 3 TF avec b/h/s présents
    for r in rows:
        sym=r.get("sym","?")
        for tf in ("5m","15m","30m"):
            d=r.get(tf, {})
            if not isinstance(d, dict) or not all(k in d for k in ("b","h","s")):
                errs.append(f"{sym} {tf} invalide: {d}")
    # fraîcheur
    a = age_minutes(heat.get("updated",""))
    stale = a>30  # sécurité globale (si global trop ancien)
    return errs, a, stale

if __name__=="__main__":
    errs, age, stale = check()
    print(f"age_min={age}  stale={int(stale)}")
    for e in errs: print("ERR:", e)
    sys.exit(1 if errs or stale else 0)

```

### tools/check_ohlcv_1m.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 286901705840af80

```py
#!/opt/scalp/.venv/bin/python
# Vérifie existence, taille, âge et dernier timestamp des {SYM}_1m.json
import json, time
from pathlib import Path

DATA = Path("/opt/scalp/data")
CAND = DATA/"candles"
UNI  = DATA/"universe.txt"

def load_universe():
    if not UNI.exists(): return []
    return [x.strip().upper() for x in UNI.read_text().splitlines() if x.strip()]

def probe(sym:str):
    p = CAND / f"{sym}_1m.json"
    if not p.exists():
        return f"{sym:<6} MISSING"
    try:
        obj=json.loads(p.read_text())
        rows=obj.get("rows") or obj
        n=len(rows)
        ts = rows[-1][0] if n else None
        age = (time.time() - (ts/1000 if ts else 0)) if ts else None
        return f"{sym:<6} n={n:<5} last_ts={ts or 'None':<13} age_s={int(age) if age else 'NA':<6} path={p}"
    except Exception as e:
        return f"{sym:<6} ERROR {e}"

def main():
    syms=load_universe()
    if not syms:
        print("universe.txt vide"); return
    for s in syms:
        print(probe(s))

if __name__=="__main__":
    main()

```

### tools/diag_B.sh  
Taille: 394 B  |  MàJ: 2025-09-17 10:59:39  |  SHA256: 9f5d453b2f803071

```sh
#!/usr/bin/env bash
set -euo pipefail
D=/opt/scalp/data
echo "== files =="
ls -lh --time-style=long-iso "$D/heatmap.json" "$D/btop.json" 2>/dev/null || true
echo
echo "== run analyze_B =="
/opt/scalp/.venv/bin/python /opt/scalp/services/analyze_B.py || true
echo
echo "== btop preview =="
jq -c '{updated, symbols, n:(.symbols|length)}' "$D/btop.json" 2>/dev/null || cat "$D/btop.json" || true

```

### tools/diag_heat.sh  
Taille: 2 KB  |  MàJ: 2025-09-17 10:15:20  |  SHA256: 2ad25ba1c125b90c

```sh
#!/usr/bin/env bash
set -euo pipefail
export LC_ALL=C

echo "== horodatage & charge =="
date -Is; uptime
echo

echo "== service & python du bot =="
MAINPID=$(systemctl show scalp-telegram-bot.service -p MainPID --value || true)
EXE=$(readlink -f /proc/${MAINPID}/exe 2>/dev/null || true)
echo "MainPID: ${MAINPID}"
echo "python: ${EXE}"
echo

echo "== fichiers clés =="
ls -lh --time-style=long-iso /opt/scalp/data/heatmap_soft.json 2>/dev/null || true
ls -lh --time-style=long-iso /opt/scalp/data/candles/*_5m.json 2>/dev/null | tail -n 6 || true
echo

echo "== PYTHONPATH =="
export PYTHONPATH=/opt/scalp
echo "$PYTHONPATH"
echo

echo "== test source + rendu (views_heat.py) =="
/usr/bin/env python3 - <<'PY'
import inspect, json, pathlib, sys
try:
    from bot.views_heat import render_heatmap
except Exception as e:
    print("IMPORT_ERR:", e); sys.exit(2)

src = inspect.getsourcefile(render_heatmap) or "?"
print("SRC:", src)

p = pathlib.Path("/opt/scalp/data/heatmap_soft.json")
print("JSON exists:", p.exists(), "size:", (p.stat().st_size if p.exists() else 0))
rows = []
if p.exists():
    try:
        obj = json.loads(p.read_text())
        rows = obj.get("rows", [])
        first = rows[0]["sym"] if rows else "-"
        print("rows:", len(rows), "first:", first)
    except Exception as e:
        print("JSON_ERR:", e)

t = render_heatmap() or ""
print("LEN:", len(t))
print("PREVIEW:", (t[:140].encode("utf-8","ignore")))
assert "views_heat.py" in src, "Mismatch source (not bot/views_heat.py)"
assert t.strip() not in ("", "<pre></pre>"), "Empty <pre></pre> payload"
assert len(t) > 20, "Payload too short"
print("OK ✅")
PY
echo

echo "== imports côté bot_stdlib (lecture brute) =="
grep -nE 'from bot\.views_heat|render_heatmap' -n /opt/scalp/bot/bot_stdlib.py || true
echo

echo "== derniers logs systemd =="
journalctl -u scalp-telegram-bot.service --since "15 min ago" --no-pager -n 60 || true

```

### tools/diag_heatmap.py  
Taille: 589 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: ade576310e3a601e

```py
#!/opt/scalp/.venv/bin/python
import json, pathlib, datetime as dt, sys
D=pathlib.Path("/opt/scalp/data")
hm=json.loads((D/"heatmap.json").read_text())
rows=hm.get("rows",[])
ok=len(rows)
bad=[r["sym"] for r in rows if any(tf not in r or r[tf].count("/")!=2 for tf in ("5m","15m","30m"))]
upd=hm.get("updated","")
age=9999
try:
    t=dt.datetime.fromisoformat(upd.replace("Z","+00:00"))
    age=int((dt.datetime.utcnow().replace(tzinfo=dt.timezone.utc)-t).total_seconds()//60)
except: pass
print(f"rows={ok}/15  age={age}m  bad={bad}")
sys.exit(0 if ok==15 and age<=15 and not bad else 1)

```

### tools/diag_refresh.sh  
Taille: 4 KB  |  MàJ: 2025-09-16 20:51:48  |  SHA256: dc8d4a4081cd85b6

```sh
#!/usr/bin/env bash
set -euo pipefail
BASE=/opt/scalp
DATA=$BASE/data
VENv=$BASE/.venv
PY=${VENv}/bin/python || true
log(){ printf "\e[1;36m[%s]\e[0m %s\n" "$(date -u +%H:%M:%SZ)" "$*"; }

need_tools(){
  command -v jq >/dev/null || { log "jq manquant → apt install"; apt-get update -y && apt-get install -y jq >/dev/null; }
}

# --- normalise un JSON possiblement "collé-collé" (2 écritures) ---
normalize_json(){
  f="$1"; tmp="$(mktemp)"
  $PY - <<'PY' "$f" >"$tmp" || { echo "{}"; } 
import sys, json, re, pathlib
p=pathlib.Path(sys.argv[1])
raw=p.read_text(errors="ignore")
# garde uniquement le plus GRAND bloc JSON bien formé
cands=[]
stack=[]
for i,ch in enumerate(raw):
    if ch=='{': stack.append(i)
    elif ch=='}' and stack:
        s=stack.pop(0) if False else stack[-1]  # noop, just keep stack
# cherche en glouton: du 1er '{' au dernier '}'
m=re.search(r'\{.*\}', raw, re.S)
txt = m.group(0) if m else "{}"
obj=json.loads(txt)
print(json.dumps(obj, indent=2, ensure_ascii=False))
PY
  mv "$tmp" "$f"
}

# --- diag d'un fichier heatmap/top -------------------------------
diag_file(){
  f="$1"; key="$2"
  if [ ! -s "$f" ]; then echo "!! $key: fichier absent/vide"; return 1; fi
  if ! jq -e . "$f" >/dev/null 2>&1; then
    echo "!! $key: JSON invalide -> normalisation"; normalize_json "$f"
  fi
  echo "-- $key OK ($(stat -c%s "$f") bytes)"
}

# --- fraicheur heatmap -------------------------------------------
check_fresh(){
  f="$DATA/heatmap.json"
  upd=$(jq -r '.updated // empty' "$f" 2>/dev/null || true)
  if [ -z "${upd:-}" ]; then echo "stale: no 'updated'"; return 9; fi
  # minutes d'âge
  now=$(date -u +%s); ts=$(date -u -d "$upd" +%s 2>/dev/null || echo 0)
  age_min=$(( (now-ts)/60 ))
  echo "updated: $upd (âge ${age_min}m)"
  # seuils (5m pour 5m, 15m pour 15m ; on prend 6m comme garde-fou global)
  [ $age_min -le 6 ] && return 0 || return 9
}

# --- relance pipeline (OHLCV + analyse + heatmap) ----------------
refresh_pipeline(){
  log "Relance OHLCV 5m/15m/30m (service)"
  systemctl start scalp-ohlcv.service || true
  sleep 2
  log "Tentative (analyse/heatmap) si service dispo"
  systemctl start scalp-analyze.service 2>/dev/null || true
  # fallback: si un script de build heatmap existe, on l'appelle
  if [ -x "$BASE/services/build_heatmap.py" ]; then
    "$PY" "$BASE/services/build_heatmap.py" || true
  fi
}

# --- résumé Telegram bot -----------------------------------------
restart_tg(){
  log "Redémarrage bot Telegram"
  systemctl restart scalp-telegram-bot.service || true
  sleep 1
  systemctl --no-pager status scalp-telegram-bot.service -l | sed -n '1,14p'
}

# --- MAIN --------------------------------------------------------
need_tools
log "Normalisation JSON (top/heatmap/signals)"
mkdir -p "$DATA"
for f in "$DATA/top.json" "$DATA/heatmap.json" "$DATA/signals.json"; do
  [ -f "$f" ] && normalize_json "$f" || true
done

diag_file "$DATA/top.json"     "top.json"     || true
diag_file "$DATA/heatmap.json" "heatmap.json" || true
diag_file "$DATA/signals.json" "signals.json" || true

echo "assets(top): $(jq -r '.assets|length' "$DATA/top.json" 2>/dev/null || echo 0)"
echo "rows(heat):  $(jq -r '.rows|length'   "$DATA/heatmap.json" 2>/dev/null || echo 0)"
echo

log "Vérif fraîcheur heatmap"
if check_fresh; then
  log "Heatmap fraîche ✅"
else
  log "Heatmap périmée ⚠️  -> refresh pipeline"
  refresh_pipeline
  log "Re-vérif fraîcheur"
  check_fresh || log "Toujours périmée (voir logs services)."
fi

log "Contrôle cohérence (3 TF par row attendu)"
jq -r '.rows[]|select(.sym!=null)|"\(.sym) => " + ([.["5m"],.["15m"],.["30m"]] | map(if type=="object" then "ok" else "KO" end) | join("/"))' "$DATA/heatmap.json" 2>/dev/null || true

restart_tg
log "Fini."

```

### tools/diag_systemd_1m.sh  
Taille: 970 B  |  MàJ: 2025-09-17 15:07:17  |  SHA256: 345b9b480f1e0ccc

```sh
#!/usr/bin/env bash
# Inspecte timer/service 1m et 3m + derniers logs journalctl
set -euo pipefail
SYMS="${*:-$(cat /opt/scalp/data/universe.txt | awk '{print toupper($0)}')}"
echo "Syms: $SYMS"
echo "== Timers list =="
systemctl list-timers | grep -E 'scalp-(ohlcv-1m|agg-3m)@' || true
for s in $SYMS; do
  echo "---- $s ----"
  systemctl status scalp-ohlcv-1m@${s}.timer --no-pager | sed -n '1,12p'
  systemctl status scalp-ohlcv-1m@${s}.service --no-pager | sed -n '1,25p'
  echo "-- last run exit --"
  systemctl show scalp-ohlcv-1m@${s}.service -p ExecMainStatus -p Result
  echo "-- logs 1m (last 50) --"
  journalctl -u scalp-ohlcv-1m@${s}.service -n 50 --no-pager || true

  echo "-- 3m timer/service --"
  systemctl status scalp-agg-3m@${s}.timer --no-pager | sed -n '1,12p'
  systemctl status scalp-agg-3m@${s}.service --no-pager | sed -n '1,25p'
  echo "-- logs 3m (last 50) --"
  journalctl -u scalp-agg-3m@${s}.service -n 50 --no-pager || true

  echo
done

```

### tools/enable_B_watchers.sh  
Taille: 190 B  |  MàJ: 2025-09-17 11:54:41  |  SHA256: 22c9040991eec6b9

```sh
#!/usr/bin/env bash
set -euo pipefail
systemctl daemon-reload
systemctl enable --now scalp-analyze-b.path
systemctl enable --now scalp-btop-hook.path
systemctl start scalp-analyze-b.service

```

### tools/guard_soft.sh  
Taille: 576 B  |  MàJ: 2025-09-17 07:55:30  |  SHA256: 8493635fa518c286

```sh
#!/usr/bin/env bash
set -u
LOG=/opt/scalp/data/guard_soft.log
SOFT=/opt/scalp/data/heatmap_soft.json
PY=/opt/scalp/.venv/bin/python

ts(){ date -Is; }

# 1) vérifier l’import /heat
if ! grep -q 'render_heatmap as render_heat_soft' /opt/scalp/bot/bot_stdlib.py; then
  echo "$(ts) WARN bad /heat import" >>"$LOG"
fi

# 2) vérifier schéma softmap et reconstruire si vide/HS
if [ ! -s "$SOFT" ] || ! jq -e '.rows|type=="array"' "$SOFT" >/dev/null 2>&1; then
  echo "$(ts) FIX rebuild softmap" >>"$LOG"
  "$PY" /opt/scalp/services/build_softmap.py >/dev/null 2>&1 || true
fi

```

### tools/health_heatmap.sh  
Taille: 430 B  |  MàJ: 2025-09-17 06:54:38  |  SHA256: e6defee79890777c

```sh
#!/usr/bin/env bash
set -e
PY=/opt/scalp/.venv/bin/python
JSON=/opt/scalp/data/heatmap.json
rows=$($PY - <<'PY'
import json,sys,pathlib
p=pathlib.Path("/opt/scalp/data/heatmap.json")
try: print(len(json.loads(p.read_text()).get("rows",[])))
except: print(0)
PY
)
if [ "${rows:-0}" -eq 0 ]; then
  PATH=/opt/scalp/.venv/bin:$PATH /opt/scalp/services/run_ohlcv_batch.sh || true
  $PY /opt/scalp/services/build_softmap.py || true
fi

```

### tools/install_deps.sh  
Taille: 207 B  |  MàJ: 2025-09-16 17:06:23  |  SHA256: 6ab46c638a244fba

```sh
#!/bin/bash
set -e
python3 -m venv /opt/scalp/.venv 2>/dev/null || true
source /opt/scalp/.venv/bin/activate
pip install --upgrade pip
pip install -r /opt/scalp/requirements.txt
echo "[OK] deps installées"

```

### tools/json_view.py  
Taille: 2 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 929b0cc756d36c67

```py
#!/opt/scalp/.venv/bin/python
import sys, json, math
from pathlib import Path

def _is_list_of_dict(x): return isinstance(x, list) and all(isinstance(i, dict) for i in x)
def _is_dict_of_scalars(x): 
    return isinstance(x, dict) and all(not isinstance(v,(list,dict)) for v in x.values())

def _trim(s, n=48):
    s = str(s)
    return s if len(s)<=n else s[:n-1]+"…"

def render_table(rows):
    # collect columns
    cols = set()
    for r in rows: cols |= set(r.keys())
    cols = list(cols)
    # widths
    w = {c:max(len(c), *(len(_trim(r.get(c,""))) for r in rows)) for c in cols}
    # lines
    sep = " ".join("-"*w[c] for c in cols)
    head = " ".join(c.ljust(w[c]) for c in cols)
    out = [head, sep]
    for r in rows:
        out.append(" ".join(_trim(r.get(c,"")).ljust(w[c]) for c in cols))
    return "\n".join(out)

def render_dict(d):
    kmax = max(len(str(k)) for k in d) if d else 1
    lines = []
    for k in sorted(d):
        v = d[k]
        if isinstance(v,(list,dict)):
            v = json.dumps(v, ensure_ascii=False)
        lines.append(f"{str(k).ljust(kmax)} : {v}")
    return "\n".join(lines)

def main():
    if len(sys.argv)<2:
        print("usage: json_view.py <file.json> [jq-filter]", file=sys.stderr); sys.exit(2)
    p = Path(sys.argv[1])
    if not p.exists(): 
        print(f"(à connecter: {p})"); sys.exit(0)
    obj = json.loads(p.read_text(encoding="utf-8"))
    # optional jq-like key path: e.g. rows or signals
    if len(sys.argv) > 2:
        key = sys.argv[2]
        if isinstance(obj, dict) and key in obj: obj = obj[key]
    if _is_list_of_dict(obj):
        print("<pre>"+render_table(obj)+"</pre>")
    elif _is_dict_of_scalars(obj):
        print("<pre>"+render_dict(obj)+"</pre>")
    else:
        # fallback pretty json
        print("<pre>"+json.dumps(obj, ensure_ascii=False, indent=2)+"</pre>")
if __name__=="__main__": main()

```

### tools/make_context.py  
Taille: 890 B  |  MàJ: 2025-09-19 20:41:29  |  SHA256: 4de68f9646096230

```py
#!/opt/scalp/.venv/bin/python
import json, statistics as st
from pathlib import Path
D=Path("/opt/scalp/data"); H=D/"heatmap.json"
if not H.exists(): H=D/"s_history/heatmap.json"
obj=json.loads(H.read_text()); rows=obj.get("rows",obj)

def buck(x): return float(x)
def avg(S,n): 
    S=S[-n:] if len(S)>=n else S
    return st.mean(S) if S else 0.0

ctx={}
for r in rows:
    s=r["sym"]
    s60, s30, s15, snow = map(buck,[avg(r["S"],60),avg(r["S"],30),avg(r["S"],15),r["S"][-1] if r["S"] else 0])
    # règles simples de contexte
    pbuy  = 1.0 if (s60>0 and s30>0 and snow>0) else 0.0
    phold = 1.0 if (s60>0 and abs(snow)<0.5) else 0.0
    psell = 1.0 if (s60<0 and s30<0 and snow<0) else 0.0
    ctx[s]={"S":{"60":s60,"30":s30,"15":s15,"now":snow},"pbuy":pbuy,"phold":phold,"psell":psell}
(D/"context.json").write_text(json.dumps(ctx,ensure_ascii=False))
print("context:",len(ctx))

```

### tools/normalize_json.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 7323e5f84af96b69

```py
#!/opt/scalp/.venv/bin/python
import json, pathlib
D=pathlib.Path("/opt/scalp/data")
# top.json -> ensure {"assets":[...]}
tp=D/"top.json"
try:
    obj=json.loads(tp.read_text())
    if isinstance(obj, dict) and "assets" in obj: pass
    else:
        # si liste brute -> wrap
        if isinstance(obj,list): obj={"assets":[{"sym":s,"vol":0,"vola":0} for s in obj]}
        tp.write_text(json.dumps(obj))
except: pass
# heatmap.json -> force {"updated":,"rows":[{"sym":,"5m":,"15m":,"30m":}]}
hm=D/"heatmap.json"
try:
    o=json.loads(hm.read_text())
    if "rows" in o and isinstance(o["rows"],list) and o["rows"] and isinstance(o["rows"][0],dict): pass
    else: hm.write_text(json.dumps({"updated":"", "rows":[]}))
except: hm.write_text(json.dumps({"updated":"", "rows":[]}))

# signals.json -> liste
sg=D/"signals.json"
try:
    o=json.loads(sg.read_text()); 
    if isinstance(o,dict) and "signals" in o: pass
    else: sg.write_text(json.dumps({"signals":[]}))
except: sg.write_text(json.dumps({"signals":[]}))
print("JSON normalisés.")

```

### tools/normalize_positions.py  
Taille: 836 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: b630357772234e82

```py
#!/opt/scalp/.venv/bin/python
import json, math
from pathlib import Path
DATA=Path("/opt/scalp/data"); POS=DATA/"positions.json"; RISK=DATA/"risk.json"
risk=json.loads(RISK.read_text()) if RISK.exists() else {"default_leverage":5}
obj=json.loads(POS.read_text()) if POS.exists() else {"positions":[]}
chg=0
for p in obj.get("positions",[]):
    if not isinstance(p,dict): continue
    if "leverage" not in p or "notional" not in p or "margin" not in p:
        e=float(p.get("entry",0)); sz=float(p.get("size",0)); lev=int(p.get("leverage") or risk.get("default_leverage",5))
        notion=sz*e; margin= notion/max(1,lev)
        p.setdefault("leverage", lev); p.setdefault("notional", notion); p.setdefault("margin", margin); chg+=1
POS.write_text(json.dumps(obj, ensure_ascii=False, separators=(",",":")))
print(f"backfilled={chg}")

```

### tools/ohlcv_sync.py  
Taille: 3 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 0508bfbf2be45b41

```py
#!/opt/scalp/.venv/bin/python
import os, sys, time, json, pathlib, traceback

DATA = pathlib.Path("/opt/scalp/data")
LOG  = pathlib.Path("/opt/scalp/logs/ohlcv_sync.log")
DATA.mkdir(parents=True, exist_ok=True); LOG.parent.mkdir(parents=True, exist_ok=True)

TF_SECONDS = {"1m":60, "5m":300, "15m":900}

def log(msg):
    ts=time.strftime("%Y-%m-%d %H:%M:%SZ", time.gmtime())
    LOG.write_text((LOG.read_text() if LOG.exists() else "") + f"{ts} {msg}\n")

def next_close(ts:int, period:int)->int:
    return ((ts // period) + 1) * period

def fetch_bitget_ohlcv(symbol:str, tf:str, end_ts:int):
    """
    TODO: brancher l'API Bitget ici. Retour attendu: liste de bougies [ [t, o, h, l, c, v], ... ]
    Contraintes:
      - ne pas retourner une bougie 'partielle' (t < end_ts et t+period > end_ts)
      - timestamps en secondes UNIX
    Pour l’instant, on renvoie un jeu factice pour tester la chaîne.
    """
    period = TF_SECONDS[tf]
    t0 = end_ts - 50*period
    out = []
    px = 100.0
    for k in range(50):
        t = t0 + k*period
        o = px; h = px*1.01; l = px*0.99; c = px*(1.0 + (0.0005 if k%2==0 else -0.0004)); v = 10+k
        out.append([t,o,h,l,c,v]); px = c
    return out

def build_heatmap_from_ohlcv(ohlcv_by_sym_tf:dict)->dict:
    """
    Exemple simple: compte des bougies haussières/baissières sur 50 dernières bougies.
    """
    rows=[]
    for sym, tfs in ohlcv_by_sym_tf.items():
        row={"sym": sym}
        for tf, arr in tfs.items():
            b=h=s=0
            for (_,o,_,_,c,_) in arr[-50:]:
                if c>o: b+=1
                elif c<o: s+=1
                else: h+=1
            row[tf] = {"b":b,"h":h,"s":s}
        rows.append(row)
    return {"updated": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()), "rows": rows}

def main():
    SYMS = os.getenv("SYMS","BTC,ETH,LINK").split(",")
    TFS  = os.getenv("TFS","5m,15m").split(",")
    align = sorted({TF_SECONDS[tf] for tf in TFS})
    now = int(time.time())
    # on s'aligne sur la plus petite période demandée
    wait_to = min(next_close(now, p) for p in align)
    delay = max(0, wait_to - now)
    if delay>0:
        time.sleep(delay + 1)  # +1s pour laisser fermer la bougie à la source
    end = int(time.time()//align[0]*align[0])

    try:
        ohlcv = {}
        for sym in SYMS:
            ohlcv[sym]={}
            for tf in TFS:
                ohlcv[sym][tf]=fetch_bitget_ohlcv(f"{sym}USDT", tf, end)
        # construit heatmap
        heat = build_heatmap_from_ohlcv(ohlcv)
        DATA.joinpath("heatmap.json").write_text(json.dumps(heat, ensure_ascii=False, separators=(",",":")))
        # placeholders pour signals/top si besoin plus tard
        if not DATA.joinpath("signals.json").exists():
            DATA.joinpath("signals.json").write_text('{"signals":[]}')
        if not DATA.joinpath("top.json").exists():
            DATA.joinpath("top.json").write_text('{"assets":[]}')
        log(f"OK update @ {end} for {','.join(TFS)} {','.join(SYMS)}")
    except Exception as e:
        log(f"E-FETCH: {e}\n{traceback.format_exc()}")
        # on n'écrase pas les fichiers existants si erreur

if __name__=="__main__":
    main()

```

### tools/on_Btop_updated.sh  
Taille: 381 B  |  MàJ: 2025-09-17 11:54:14  |  SHA256: 904a6737972943bb

```sh
#!/usr/bin/env bash
# Orchestrateur Couche B déclenché après mise à jour de Btop.json :
# 1) fetch 1m  2) aggregate 1m->3m  3) run signals_B
set -euo pipefail
export PYTHONPATH=/opt/scalp
/opt/scalp/.venv/bin/python /opt/scalp/services/ohlcv_1m_cli.py
/opt/scalp/.venv/bin/python /opt/scalp/services/agg_1m_to_3m.py
/opt/scalp/.venv/bin/python /opt/scalp/services/signals_B.py

```

### tools/on_btop_updated.sh  
Taille: 392 B  |  MàJ: 2025-09-17 10:59:10  |  SHA256: c47d092d83b31c5d

```sh
#!/usr/bin/env bash
set -euo pipefail
log(){ printf "[on_btop] %s\n" "$*"; }
BTOP="/opt/scalp/data/btop.json"
if [[ ! -f "$BTOP" ]]; then
  log "absent ($BTOP)"; exit 0
fi
SYMS=$(jq -r '.symbols[]?' "$BTOP" 2>/dev/null || true)
log "Btop: $(echo "$SYMS" | tr '\n' ' ')"
# TODO: déclencher ici ta collecte 1m pour $SYMS
# Exemple (à adapter):
# systemctl start scalp-ohlcv-1m.service
exit 0

```

### tools/ping_telegram.py  
Taille: 907 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: b2bacfe8bc83739a

```py
#!/opt/scalp/.venv/bin/python
import os, urllib.request, urllib.parse, json, pathlib, re

# Charge /etc/scalp.env
env_file = pathlib.Path("/etc/scalp.env")
data = {}
if env_file.exists():
    RGX = re.compile(r'^\s*([A-Za-z_]\w*)\s*=\s*(.*)\s*$')
    for line in env_file.read_text().splitlines():
        m = RGX.match(line)
        if m: data[m.group(1)] = m.group(2).strip().strip('"').strip("'")

TOKEN = data.get("TELEGRAM_BOT_TOKEN")
CHAT  = data.get("TELEGRAM_CHAT_ID")

if not TOKEN or not CHAT:
    raise SystemExit("❌ TELEGRAM_BOT_TOKEN ou TELEGRAM_CHAT_ID manquant dans /etc/scalp.env")

# Envoi ping
url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
payload = {"chat_id": CHAT, "text": "ping test ✅ (depuis scalp/tools)", "parse_mode": "HTML"}
data = urllib.parse.urlencode(payload).encode()

with urllib.request.urlopen(url, data=data, timeout=20) as r:
    print(r.read().decode())

```

### tools/pretty_heat.py  
Taille: 983 B  |  MàJ: 2025-09-19 20:18:06  |  SHA256: 27722ff047f7e980

```py
#!/opt/scalp/.venv/bin/python
import json, math, datetime as dt
from pathlib import Path

ROOT=Path("/opt/scalp"); D=ROOT/"data"
HP = D/"heatmap.json"
HS = D/"s_history"/"heatmap.json"
p = HP if HP.exists() else HS
obj = json.loads(p.read_text())
rows = obj.get("rows", obj)

# bucket S -> -6..+6
def buck(v): 
    v = max(-6.0, min(6.0, v*3.0))
    return int(round(v))

# ordre: fixes d'abord puis reste
FIX = ["BTCUSDT","ETHUSDT","BNBUSDT","SOLUSDT","XRPUSDT"]
rows.sort(key=lambda r: (0 if r["sym"] in FIX else 1, FIX.index(r["sym"]) if r["sym"] in FIX else r["sym"]))

lines=[]
now = dt.datetime.utcnow().strftime("%H:%M")
lines.append(f"Heatmap {now}")
for i,r in enumerate(rows):
    sym = r["sym"].replace("USDT","")[:4].ljust(4)
    last4 = [buck(x) for x in r["S"][-4:]] if r["S"] else [0,0,0,0]
    txt = " ".join([f"{v:+d}" for v in last4])
    lines.append(f"{sym}  {txt}")
    if (i+1)%5==0 and i+1<len(rows): lines.append("")  # espace visuel

print("\n".join(lines))

```

### tools/pretty_heat_60_30_15_now.py  
Taille: 1 KB  |  MàJ: 2025-09-19 22:17:10  |  SHA256: 8ea47adf2b10c25c

```py
#!/opt/scalp/.venv/bin/python
import json, statistics as st, datetime as dt
from pathlib import Path
D=Path("/opt/scalp/data")
H = D/"heatmap.json"
if not H.exists(): H = D/"s_history"/"heatmap.json"
rows = json.loads(H.read_text()).get("rows", [])
FIX = ["BTCUSDT","ETHUSDT","BNBUSDT"]
top_scores={}
T=D/"top.json"
if T.exists():
  for x in json.loads(T.read_text()).get("scored",[]):
    top_scores[x["symbol"].replace("/USDT:USDT","USDT")] = float(x.get("score",0))
def keyscore(r):
  s=r["sym"]
  return (0, FIX.index(s), 0) if s in FIX else (1, 0, -top_scores.get(s,-1.0))
rows.sort(key=keyscore)

def clamp(v,a,b): return a if v<a else b if v>b else v
def buck(x): return int(round(clamp(x*3.0,-6.0,6.0)))
def mean_tail(S,n): 
  if not S: return 0.0
  k=min(len(S),n); return st.mean(S[-k:])
now=dt.datetime.utcnow().strftime("%H:%M")
out=[f"Heatmap {now}"]; col=[]
for i,r in enumerate(rows,1):
  S=r.get("S") or []
  sym=r["sym"].replace("USDT","")[:5].ljust(5)
  v60,v30,v15,v00 = (buck(mean_tail(S,60)), buck(mean_tail(S,30)), buck(mean_tail(S,15)), buck(S[-1] if S else 0.0))
  col.append(f"{sym} {v60:+d} {v30:+d} {v15:+d} {v00:+d}")
  if i%5==0 or i==len(rows): out.append("\n".join(col)); out.append(""); col=[]
print("\n".join(out).rstrip())

```

### tools/pretty_positions.py  
Taille: 403 B  |  MàJ: 2025-09-19 22:55:25  |  SHA256: 6aee911c57153fba

```py
from pathlib import Path, json
P=Path("/opt/scalp/data/positions.json")
if not P.exists(): print("No position"); raise SystemExit(0)
pos=json.loads(P.read_text())
print("Positions")
for p in pos[:10]:
    sym=p["sym"].replace("USDT:USDT","")
    side="L" if p["side"][0].upper()=="L" else "S"
    print(f"{sym:<6} {side}  qty {p.get('qty',0):.3g}  px {p.get('px',0):.4g}  uPnL {p.get('upnl',0):+.2f}$")

```

### tools/pretty_signals.py  
Taille: 905 B  |  MàJ: 2025-09-19 22:54:55  |  SHA256: 507826703143c81d

```py
from pathlib import Path
import json, math, datetime as dt, pytz
P=Path("/opt/scalp/data/signals.json")
if not P.exists(): print("No signal"); raise SystemExit(0)
s=json.loads(P.read_text())
# on limite et on ordonne par fraîcheur puis score interne si présent
s=sorted(s, key=lambda x: x.get("ts",0), reverse=True)[:8]
# format court
lines=["Signals " + dt.datetime.now(dt.timezone.utc).strftime("%H:%M")]
for x in s:
    sym=x["sym"].replace("USDT:USDT","").replace("USDTUSDT","")
    side="L" if x["side"].upper().startswith("L") else "S"
    px,sl,tp=float(x["px"]),float(x["sl"]),float(x["tp"])
    lev=int(x.get("lev",1)); qty=x.get("qty",0)
    r_tp = (tp-px)/px*100 if side=="L" else (px-tp)/px*100
    r_sl = (sl-px)/px*100 if side=="L" else (px-sl)/px*100
    lines.append(f"{sym:<6} {side} x{lev}  px {px:.4g}  tp {tp:.4g} ({r_tp:+.1f}%)  sl {sl:.4g} ({r_sl:+.1f}%)")
print("\n".join(lines))

```

### tools/pretty_status.py  
Taille: 1 KB  |  MàJ: 2025-09-19 20:23:28  |  SHA256: 095cd4258d1cc8b9

```py
#!/opt/scalp/.venv/bin/python
import json, datetime as dt
from pathlib import Path

p = Path("/opt/scalp/data/status.json")
if not p.exists():
    print("Status: no data")
    raise SystemExit(0)

obj = json.loads(p.read_text())
now = dt.datetime.utcnow().strftime("%H:%M")

# exemple de formatage compact
out = [f"Status {now}  Solde:{obj.get('balance','-')}"]
out.append(f"PnL: {obj.get('pnl_plus',0):+.2f}$ / {obj.get('pnl_minus',0):+.2f}$")

times = obj.get("timeframes", [])
if times:
    header = "Time " + " | ".join([t["tf"] for t in times])
    out.append(header)
    out.append("Nb   " + " | ".join([str(t.get("nb",0)) for t in times]))
    out.append("PnL  " + " | ".join([f"{t.get('pnl',0):+.2f}$" for t in times]))
    out.append("Best " + " | ".join([f"{t.get('best',0):+.2f}$" for t in times]))
    out.append("Coin " + " | ".join([t.get('best_coin','-') for t in times]))
    out.append("Worst"+ " | ".join([f"{t.get('worst',0):+.2f}$" for t in times]))
    out.append("Coin " + " | ".join([t.get('worst_coin','-') for t in times]))

print("\n".join(out))

```

### tools/pretty_top.py  
Taille: 555 B  |  MàJ: 2025-09-19 20:18:18  |  SHA256: 697b2481487cbf6c

```py
#!/opt/scalp/.venv/bin/python
import json, math
from pathlib import Path
p=Path("/opt/scalp/data/top.json")
if not p.exists(): 
    print("{}"); raise SystemExit(0)
obj=json.loads(p.read_text())
sel=obj.get("selected") or []
sc=obj.get("scored") or []
best = sorted(sc, key=lambda x:x.get("score",0), reverse=True)[:10]
def fmt(x): 
    v=float(x)/1e6
    return f"{v:.2f}M"
out=["Top (vol×vola)"]
for i,e in enumerate(best,1):
    sym=e["symbol"].split("/")[0].ljust(5)[:5]
    out.append(f"{i:>2}. {sym} {fmt(e.get('score',0))}")
print("\n".join(out))

```

### tools/pretty_top_names.py  
Taille: 1 KB  |  MàJ: 2025-09-19 22:46:40  |  SHA256: 3cca7f878b9bf4c9

```py
from pathlib import Path
from json import loads
from datetime import datetime

p = Path("/opt/scalp/data/top.json")
data = loads(p.read_text()) if p.exists() else {}
rows = data.get("scored", data if isinstance(data, list) else [])

# tri décroissant volu×vola (score)
rows = sorted(rows, key=lambda x: float(x.get("score", 0)), reverse=True)[:15]

def clean(sym:str)->str:
    s = sym.replace("/USDT:USDT","").replace(":USDT","")
    s = s.split("/")[0]
    return s.upper()

names = [clean(r.get("symbol","")) for r in rows]
# padding à 3 colonnes × 5 lignes
cols, rowsN = 3, 5
grid = [names[i::rowsN] for i in range(rowsN)]  # lignes
# largeur de chaque colonne
colW = [0]*cols
for c in range(cols):
    col = [ names[r*cols+c] for r in range(rowsN) if r*cols+c < len(names) ]
    colW[c] = max(len(x) for x in col) if col else 0

out = [f"Top (vol×vola) {datetime.utcnow():%H:%M}"]
for r in range(rowsN):
    line=[]
    for c in range(cols):
        i = r + c*rowsN
        if i < len(names):
            line.append(names[i].ljust(colW[c]+2))
    out.append("".join(line).rstrip())
print("\n".join(out))

```

### tools/probe_B.sh  
Taille: 2 KB  |  MàJ: 2025-09-17 07:58:03  |  SHA256: d2b5426c69c6d1bd

```sh
#!/usr/bin/env bash
set -euo pipefail
PY=/opt/scalp/.venv/bin/python
D=/opt/scalp/data
log(){ printf "\n# %s\n" "$*"; }

log "Horodatage et charge"
date -Is; uptime

log "Fichiers d'entrée clés"
ls -lh --time-style=long-iso $D/heatmap_soft.json $D/top.json 2>/dev/null || true
ls -lh --time-style=long-iso $D/candles/*_5m.json 2>/dev/null | tail -n 5 || true

log "Aperçu heatmap_soft.json"
$PY - <<'PY'
import json,sys,Pathlib as P
from pathlib import Path
p=Path("/opt/scalp/data/heatmap_soft.json")
if not p.exists(): 
    print("absent"); sys.exit(0)
obj=json.loads(p.read_text())
rows=obj.get("rows",[])
print("rows =",len(rows))
if rows:
    r0=rows[0]
    s=r0.get("S",[])
    print("first sym =",r0.get("sym")," seq_len =",len(s))
    print("last 5 S =", [ round(float(x["S"]),3) for x in s[-5:] ])
    # sanity: ordre temps croissant
    ok=all(s[i]["t"]<=s[i+1]["t"] for i in range(len(s)-1)) if s else True
    print("chronology_ok =",ok)
PY

log "Aperçu TOP"
$PY - <<'PY'
import json,sys
from pathlib import Path
p=Path("/opt/scalp/data/top.json")
if p.exists():
  obj=json.loads(p.read_text())
  rows=obj.get("rows") or obj.get("syms") or []
  print("top count =",len(rows), " sample =", rows[:5])
else:
  print("top.json absent")
PY

log "Service(s) liés à B"
systemctl -q is-active scalp-analyze-b.service && systemctl --no-pager -l status scalp-analyze-b.service -n 0 || echo "service scalp-analyze-b.service: not found"

log "Dry-run analyze_B s'il existe"
if [ -f /opt/scalp/services/analyze_B.py ]; then
  time $PY /opt/scalp/services/analyze_B.py --dry-run 2>&1 | tail -n +1
else
  echo "analyze_B.py: not found"
fi

log "Derniers logs bot"
journalctl -u scalp-telegram-bot.service -n 30 --no-pager || true

```

### tools/probe_pipeline.sh  
Taille: 2 KB  |  MàJ: 2025-09-17 08:09:27  |  SHA256: a6f4343343962af7

```sh
#!/usr/bin/env bash
set -euo pipefail
PY=/opt/scalp/.venv/bin/python
D=/opt/scalp/data
sep(){ printf '\n# %s\n' "$*"; }

sep "Horodatage + charge"; date -Is; uptime

sep "Présence des fichiers clés"
ls -lh --time-style=long-iso "$D/heatmap_soft.json" "$D/top.json" 2>/dev/null || true
ls -lh --time-style=long-iso "$D"/candles/*_5m.json 2>/dev/null | tail -n 5 || true
ls -lh --time-style=long-iso "$D"/candles/*_1m.json 2>/dev/null | tail -n 5 || true

sep "Aperçu heatmap_soft.json + validation schéma + 5 derniers S"
"$PY" - <<'PY'
import json
from pathlib import Path
p=Path("/opt/scalp/data/heatmap_soft.json")
if not p.exists(): print("absent"); raise SystemExit(0)
obj=json.loads(p.read_text()); rows=obj.get("rows",[])
print("rows =",len(rows)); 
if not rows: raise SystemExit(0)
S=rows[0].get("S",[]); print("first sym =",rows[0].get("sym")," seq_len =",len(S))
tail=S[-5:] if len(S)>=5 else S
print("last 5 =",[ round(float(x['S']),3) for x in tail ])
ok=all(S[i]['t']<=S[i+1]['t'] for i in range(len(S)-1)) if S else True
print("chronology_ok =",ok)
PY

sep "Détection tendance locale (derniers 2 points)"
"$PY" - <<'PY'
import json
from pathlib import Path
TH_UP=0.6; TH_DN=-0.6
def trend(seq):
    if len(seq)<2: return "—", None
    a=float(seq[-2]["S"]); b=float(seq[-1]["S"])
    d="▲" if b>a else ("▼" if b<a else "—")
    zone="blue" if -0.4<=b<=0.4 else ("green" if b>TH_UP else ("red" if b<TH_DN else "grey"))
    return d,(round(a,3),round(b,3),zone)
rows=json.loads(Path("/opt/scalp/data/heatmap_soft.json").read_text())["rows"]
for r in rows:
    d,vals=trend(r.get("S",[]))
    if vals: a,b,z=vals; print(f'{r["sym"]:>5}: {d}  {a}->{b}  {z}')
PY

sep "Top15 aperçu"
"$PY" - <<'PY'
import json
from pathlib import Path
p=Path("/opt/scalp/data/top.json")
if p.exists():
  obj=json.loads(p.read_text())
  rows=obj.get("rows") or obj.get("syms") or []
  print("count =",len(rows)," sample =",rows[:10])
else:
  print("top.json absent")
PY

sep "Bougies 1m récentes (<6 min)"
find "$D/candles" -maxdepth 1 -type f -name '*_1m.json' -mmin -6 -printf '%TY-%Tm-%Td %TH:%TM  %p\n' 2>/dev/null | sort || echo "aucune"

sep "Couche B"
systemctl -q is-active scalp-analyze-b.service && systemctl --no-pager -l status scalp-analyze-b.service -n 0 || echo "service scalp-analyze-b.service: not found"
[ -f /opt/scalp/services/analyze_B.py ] && { echo "-- analyze_B.py présent"; "$PY" /opt/scalp/services/analyze_B.py --dry-run 2>&1 | tail -n +1; } || echo "analyze_B.py: not found"

```

### tools/probe_pipeline_B.sh  
Taille: 1015 B  |  MàJ: 2025-09-17 08:16:45  |  SHA256: f7b48d6765688190

```sh
#!/usr/bin/env bash
set -euo pipefail
PY=/opt/scalp/.venv/bin/python || PY=python3

echo "# Horodatage"; date -Is; uptime

echo -e "\n# Présence des fichiers clés"
ls -lh --time-style=long-iso /opt/scalp/data/heatmap_soft.json /opt/scalp/data/top.json 2>/dev/null || true
ls -lh --time-style=long-iso /opt/scalp/data/candles/*_1m.json 2>/dev/null | tail -n 5 || true

echo -e "\n# Contexte Couche A (extrait)"
$PY - <<'PY'
import json, pathlib, sys
p=pathlib.Path("/opt/scalp/data/heatmap_soft.json")
obj=json.loads(p.read_text()) if p.exists() else {"rows":[]}
for r in obj.get("rows",[])[:5]:
    s=r.get("S") or []
    last=float(s[-1].get("S",0)) if s else 0.0
    print(r["sym"], "S_last=", last, "-> p_buy", round((last+1)/2,2), "p_sell", round((1-last)/2,2), "p_hold", round(1-abs(last),2))
PY

echo -e "\n# Run analyze_B (à blanc + impression)"
$PY /opt/scalp/services/analyze_B.py | sed -n '1,5p'

echo -e "\n# Signals.jsonl (tail)"
tail -n 5 /opt/scalp/data/signals.jsonl 2>/dev/null || echo "(aucun)"

```

### tools/purge_state.sh  
Taille: 1 KB  |  MàJ: 2025-09-17 17:05:54  |  SHA256: 7fe17a5fd7d658d7

```sh
#!/usr/bin/env bash
set -euo pipefail
DATA=/opt/scalp/data
BACK="$DATA/backup_$(date -u +%Y%m%dT%H%M%SZ)"

backup() { # $1=src
  [ -f "$1" ] || return 0
  dst="$BACK/${1#$DATA/}"
  mkdir -p "$(dirname "$dst")"
  cp -a "$1" "$dst"
}

mkdir -p "$BACK"

# stop trader
systemctl stop scalp-paper.path 2>/dev/null || true
systemctl stop scalp-paper.service 2>/dev/null || true

# backups si présents
backup "$DATA/signals.json"
backup "$DATA/positions.json"
backup "$DATA/positions_hist.jsonl"
backup "$DATA/account.json"
backup "$DATA/paper.log"
backup "$DATA/logs/paper.log"

# purge + réinit
: > "$DATA/signals.json"
printf '{"positions":[],"state":{"seen":{},"updated":%s}}\n' "$(date +%s)" > "$DATA/positions.json"
: > "$DATA/positions_hist.jsonl"
printf '{"balance":100,"equity":100,"open_pnl":0,"margin_used":0,"currency":"USDT","updated":%s}\n' "$(date +%s)" > "$DATA/account.json"
: > "$DATA/paper.log" 2>/dev/null || true
mkdir -p "$DATA/logs"; : > "$DATA/logs/paper.log"

# relance du déclencheur
systemctl start scalp-paper.path 2>/dev/null || true

echo "Purge OK. Backup: $BACK"

```

### tools/refresh_bot.sh  
Taille: 242 B  |  MàJ: 2025-09-16 20:04:04  |  SHA256: ffcf0340af607413

```sh
#!/usr/bin/env bash
set -euo pipefail
/opt/scalp/.venv/bin/python /opt/scalp/tools/normalize_json.py || true
systemctl restart scalp-telegram-bot.service
sleep 1
systemctl --no-pager -l status scalp-telegram-bot.service -n 0 | sed -n '1,12p'

```

### tools/refresh_pipeline.sh  
Taille: 823 B  |  MàJ: 2025-09-16 20:54:54  |  SHA256: 915a4681f72b521f

```sh
#!/usr/bin/env bash
set -euo pipefail
log(){ printf "[%(%H:%M:%SZ)T] %s\n" -1 "$*"; }

log "Normalisation JSON"
python3 /opt/scalp/tools/normalize_json.py >/dev/null || true

log "Vérif heatmap"
if ! python3 /opt/scalp/tools/check_heat.py; then
  log "⏳ pipeline refresh: OHLCV + analyze"
  systemctl start scalp-ohlcv.service || true
  sleep 3
  systemctl start scalp-analyze.service || true
  # Patience courte mais visible
  for i in {1..10}; do
    sleep 3
    python3 /opt/scalp/tools/normalize_json.py >/dev/null || true
    if python3 /opt/scalp/tools/check_heat.py >/dev/null; then
      log "✅ heatmap OK"
      break
    fi
    [ $i -eq 10 ] && log "⚠️ encore incomplet (voir journaux services)"
  done
fi

log "Redémarrage bot Telegram"
systemctl restart scalp-telegram-bot.service || true
log "Fini."

```

### tools/relaunch_all.sh  
Taille: 2 KB  |  MàJ: 2025-09-17 11:28:51  |  SHA256: f36b0c26984a6f6e

```sh
#!/usr/bin/env bash
set -euo pipefail

VENV=/opt/scalp/.venv
PY=$VENV/bin/python
export PYTHONPATH=/opt/scalp

echo "== 1) loguru =="
$PY - <<'PY' || true
try:
    import loguru  # noqa
    print("loguru OK")
except Exception as e:
    raise SystemExit(1)
PY
if [ $? -ne 0 ]; then
  . "$VENV/bin/activate"
  pip install --quiet loguru
  echo "✓ loguru installé"
fi

echo "== 2) reset top.json =="
TOP=/opt/scalp/data/top.json
printf '{\n  "updated": null,\n  "assets": []\n}\n' > "$TOP"

echo "== 3) rebuild Top (top_bitget.py) =="
$PY /opt/scalp/services/top_bitget.py
jq -r '.assets|length' "$TOP" 2>/dev/null | xargs -I{} echo "assets: {}"

echo "== 4) OHLCV batch 5m/15m/30m =="
systemctl start scalp-ohlcv.service
systemctl -q is-active scalp-ohlcv.service || true
sleep 2
journalctl -u scalp-ohlcv.service -n 5 --no-pager || true

echo "== 5) analyze A (build heatmap) =="
systemctl start scalp-analyze.service
sleep 2
journalctl -u scalp-analyze.service -n 10 --no-pager || true

echo "== 6) restart Telegram bot =="
systemctl restart scalp-telegram-bot.service
sleep 1
systemctl status scalp-telegram-bot.service --no-pager -l | sed -n '1,12p'

echo "== 7) quick checks =="
# 7a top.json
echo "-- top.json --"
jq -r '{updated,assets_len:(.assets|length)}' "$TOP" 2>/dev/null || cat "$TOP"

# 7b heatmap.json rows
echo "-- heatmap.json --"
H=/opt/scalp/data/heatmap.json
if [ -s "$H" ]; then
  jq -r '("rows=" + ((.rows//[])|length|tostring))' "$H" || true
else
  echo "absent or empty"
fi

# 7c vue /heat (doit renvoyer autre chose que <pre></pre>)
echo "-- render_heatmap smoke --"
$PY - <<'PY'
from bot.views_heat import render_heatmap as RH
t = RH() or ""
print("LEN", len(t), "OK" if (len(t)>20 and "<pre>" not in t) else "BAD")
PY

echo "== Done =="

```

### tools/relaunch_clean.sh  
Taille: 720 B  |  MàJ: 2025-09-17 09:02:44  |  SHA256: 6bbc4568bf24f0af

```sh
#!/usr/bin/env bash
set -euo pipefail
export PYTHONPATH=/opt/scalp

svc=scalp-telegram-bot.service
echo "== restart =="
systemctl restart "$svc"
sleep 1
systemctl is-active "$svc" --quiet || { journalctl -u "$svc" -n 80 --no-pager; exit 1; }

echo "== anti-ghost check =="
/usr/bin/env python3 - <<'PY'
import inspect
from bot.views_heat import render_heatmap
t = render_heatmap() or ""
src = inspect.getsourcefile(render_heatmap) or "?"
print("SRC:", src)
print("LEN:", len(t))
assert "views_heat.py" in src, "Heatmap source mismatch"
assert t.strip() != "<pre></pre>", "Empty <pre></pre> payload"
assert len(t) > 20, "Payload too short"
print("OK ✅")
PY

echo "== last logs =="
journalctl -u "$svc" -n 40 --no-pager

```

### tools/repair_and_restart.sh  
Taille: 5 KB  |  MàJ: 2025-09-16 18:59:28  |  SHA256: 8243bc488d0ee7e9

```sh
#!/usr/bin/env bash
set -euo pipefail
BASE=/opt/scalp
DATA=$BASE/data
SYS=/etc/systemd/system
VENV=$BASE/.venv
PY=$VENV/bin/python
PIP=$VENV/bin/pip
JQ_BIN=$(command -v jq || true)

log(){ printf "\e[1;36m[%s]\e[0m %s\n" "$(date -u +%H:%M:%SZ)" "$*"; }

need_jq(){
  if [ -z "$JQ_BIN" ]; then
    log "jq manquant → installation (apt)"
    apt-get update -y && apt-get install -y jq >/dev/null
    JQ_BIN=$(command -v jq)
  fi
}

ensure_dirs(){
  mkdir -p "$DATA" "$BASE/tools" "$BASE/bot" "$BASE/services" "$BASE/data/candles"
}

ensure_venv(){
  if [ ! -x "$PY" ]; then
    log "Création du venv"
    apt-get update -y >/dev/null
    apt-get install -y python3-venv python3-pip >/dev/null
    python3 -m venv "$VENV"
  fi
  log "MàJ pip + deps de base"
  "$PIP" -q install --upgrade pip >/dev/null
  "$PIP" -q install "aiogram>=2.25,<3" loguru pandas "ccxt>=4.5" >/dev/null || true
}

fix_service_execstart(){
  # forcer ExecStart à utiliser le venv
  sed -i 's#^ExecStart=.*bot_stdlib.*#ExecStart='"$PY"' -m bot.bot_stdlib#' "$SYS/scalp-telegram-bot.service" 2>/dev/null || true
  sed -i 's#^ExecStart=/usr/bin/python3 #ExecStart='"$PY"' #' "$SYS/scalp-ohlcv-1m.service" 2>/dev/null || true
  sed -i 's#^ExecStart=/usr/bin/python3 #ExecStart='"$PY"' #' "$SYS/scalp-analyze.service" 2>/dev/null || true
}

ts_iso(){ date -u +"%Y-%m-%dT%H:%M:%SZ"; }

write_json(){
  # $1=path  $2=json_string
  printf '%s\n' "$2" >"$1"
}

normalize_top(){
  local f="$DATA/top.json"
  local now; now=$(ts_iso)
  if [ -s "$f" ] && $JQ_BIN -e . "$f" >/dev/null 2>&1; then
    # garder seulement 'assets' (sym/vol/vola) + updated
    local syms
    syms=$($JQ_BIN -r '.assets[].sym' "$f" 2>/dev/null | paste -sd',' - || true)
    if [ -n "$syms" ]; then
      local arr="[]"
      IFS=',' read -ra A <<<"$syms"
      for s in "${A[@]}"; do
        arr=$($JQ_BIN -c --arg s "$s" '. + [{"sym":$s,"vol":0,"vola":0}]' <<<"$arr")
      done
      write_json "$f" "$($JQ_BIN -c --argjson a "$arr" --arg u "$now" '{assets:$a,updated:$u}')"
      return
    fi
  fi
  # défaut (15 tickers les plus fréquents si aucun top existant)
  local def='["BTC","ETH","BNB","SOL","XRP","DOGE","AVAX","SUI","PUMP","BAKE","PEPE","ENA","SOMI","ZKC","AVNT"]'
  local arr=$($JQ_BIN -c 'map({sym:.,vol:0,vola:0})' <<<"$def")
  write_json "$f" "$($JQ_BIN -c --argjson a "$arr" --arg u "$now" '{assets:$a,updated:$u}')"
}

normalize_heatmap(){
  local f="$DATA/heatmap.json"
  local now; now=$(ts_iso)
  if [ -s "$f" ]; then
    # certains fichiers contenaient 2 objets concaténés → garder le DERNIER
    local norm
    norm=$($JQ_BIN -cs '.[-1]' "$f" 2>/dev/null || true)
    if [ -n "$norm" ] && [ "$norm" != "null" ]; then
      write_json "$f" "$norm"
      return
    fi
  fi
  # squelette vide basé sur top.json
  local rows
  rows=$($JQ_BIN -c '[inputs.assets[].sym] | .[0]' "$DATA/top.json" 2>/dev/null || true)
  if [ -z "$rows" ]; then rows='["BTC","ETH","ADA"]'; fi
  local out="[]"; for s in $(echo "$rows" | $JQ_BIN -r '.[]'); do
    out=$($JQ_BIN -c --arg s "$s" '. + [{"sym":$s,"5m":"0/0/0","15m":"0/0/0","30m":"0/0/0"}]' <<<"$out")
  done
  write_json "$f" "$($JQ_BIN -c --argjson r "$out" --arg u "$now" '{updated:$u,rows:$r}')"
}

normalize_signals(){
  local f="$DATA/signals.json"
  local now; now=$(ts_iso)
  if [ -s "$f" ] && $JQ_BIN -e . "$f" >/dev/null 2>&1; then
    # normaliser structure en {updated,signals:[...]}
    local sigs; sigs=$($JQ_BIN -c '.signals // []' "$f")
    write_json "$f" "$($JQ_BIN -c --argjson s "$sigs" --arg u "$now" '{updated:$u,signals:$s}')"
  else
    write_json "$f" "$($JQ_BIN -c --arg u "$now" '{updated:$u,signals:[]}')"
  fi
}

normalize_positions_history(){
  local now; now=$(ts_iso)
  for f in "$DATA/positions.json" "$DATA/history.json"; do
    if [ -s "$f" ] && $JQ_BIN -e . "$f" >/dev/null 2>&1; then
      :
    else
      write_json "$f" "$($JQ_BIN -c --arg u "$now" '{updated:$u,rows:[]}')"
    fi
  done
}

stop_services(){
  systemctl stop scalp-telegram-bot.service >/dev/null 2>&1 || true
  systemctl stop scalp-ohlcv.service >/dev/null 2>&1 || true
}

start_services(){
  systemctl daemon-reload
  systemctl restart scalp-telegram-bot.service || true
  systemctl restart scalp-ohlcv.timer || true
  systemctl restart scalp-top15.timer || true
}

status(){
  echo
  systemctl status scalp-telegram-bot.service --no-pager -l | sed -n '1,20p'
  echo
  for f in top heatmap signals positions history; do
    printf "\n--- %s ---\n" "$f"
    $JQ_BIN . "$DATA/$f.json" 2>/dev/null | sed -n '1,60p' || true
  done
}

main(){
  log "Préparation"
  need_jq
  ensure_dirs
  stop_services
  ensure_venv
  fix_service_execstart
  log "Normalisation JSON"
  normalize_top
  normalize_heatmap
  normalize_signals
  normalize_positions_history
  log "Redémarrage services"
  start_services
  log "OK."
  status
}
main "$@"

```

### tools/reset_top_json.py  
Taille: 1 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: ee50bbaae2c252e6

```py
#!/opt/scalp/.venv/bin/python
import json, sys, time
from pathlib import Path

BASE = Path("/opt/scalp")
DATA = BASE / "data"
TOP  = DATA / "top.json"
HEAT = DATA / "heatmap.json"
SOFT = DATA / "heatmap_soft.json"

def now():
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

def has_valid_top(p: Path) -> bool:
    try:
        obj = json.loads(p.read_text())
        return isinstance(obj.get("assets"), list)
    except Exception:
        return False

def symbols_from_heatmap() -> list[str]:
    for p in (SOFT, HEAT):
        if p.exists():
            try:
                obj = json.loads(p.read_text())
                rows = obj.get("rows", [])
                syms = []
                for r in rows:
                    s = r.get("sym") or r.get("symbol") or r.get("SYM")
                    if s: syms.append(s)
                return syms
            except Exception:
                pass
    return []

def main():
    force = "--force" in sys.argv
    if TOP.exists() and has_valid_top(TOP) and not force:
        print("top.json already valid (use --force to overwrite)")
        return

    syms = symbols_from_heatmap()
    if not syms:
        print("No symbols found from heatmap; writing minimal top.json")
    assets = [{"sym": s, "vol": 0, "vola": 0} for s in syms]

    obj = {"assets": assets, "updated": now()}
    TOP.write_text(json.dumps(obj, ensure_ascii=False, separators=(',',':')))
    print(f"top.json reset with {len(assets)} assets")

if __name__ == "__main__":
    main()

```

### tools/restart_and_preview.sh  
Taille: 648 B  |  MàJ: 2025-09-17 05:42:28  |  SHA256: 1b555e0de0e0b18d

```sh
#!/usr/bin/env bash
set -euo pipefail
BASE=/opt/scalp
VENV=$BASE/.venv
PY=$VENV/bin/python

log(){ printf "\e[1;36m[%s]\e[0m %s\n" "$(date -u +%H:%M:%SZ)" "$*"; }

log "1) Relance analyse A (Layer A)"
$PY $BASE/analyze/analyze_a_cli.py || true

log "2) Génère nouvelle heatmap softmax (3 derniers S@5m)"
$PY $BASE/services/build_heatmap_softmax.py || true

log "3) Aperçu terminal (rows)"
$BASE/tools/json_view.py $BASE/data/heatmap.json rows | sed -n '1,20p'

log "4) Redémarrage bot Telegram"
systemctl restart scalp-telegram-bot.service || true
sleep 1
systemctl --no-pager status scalp-telegram-bot.service -n 0 | sed -n '1,12p'

log "OK."

```

### tools/rotate_history.sh  
Taille: 182 B  |  MàJ: 2025-09-18 07:49:29  |  SHA256: 2e74d2e62f311bb4

```sh
#!/usr/bin/env bash
set -euo pipefail
D=/opt/scalp/data
F=$D/positions_hist.jsonl
[ -s "$F" ] || exit 0
ym=$(date -u +%Y-%m)
gzip -c "$F" > "$D/positions_hist_$ym.jsonl.gz"
: > "$F"

```

### tools/run_1m_now.sh  
Taille: 638 B  |  MàJ: 2025-09-17 11:10:22  |  SHA256: f0a606d0751a6289

```sh
#!/usr/bin/env bash
set -euo pipefail
export PYTHONPATH=/opt/scalp
/opt/scalp/.venv/bin/python /opt/scalp/services/ohlcv_1m_cli.py
/opt/scalp/.venv/bin/python /opt/scalp/services/agg_1m_to_3m.py
echo "== samples =="
ls -lh --time-style=long-iso /opt/scalp/data/candles/*_{1,3}m.json 2>/dev/null | tail -n 10 || true
sym=$(ls /opt/scalp/data/candles/*_1m.json 2>/dev/null | head -n1)
[ -n "$sym" ] && python3 - <<'PY'
import json,sys, pathlib
p = pathlib.Path(sys.argv[1])
s = json.loads(p.read_text()); t = json.loads(p.with_name(p.name.replace("_1m","_3m")).read_text())
print("1m last 3:", s[-3:])
print("3m last 3:", t[-3:])
PY "$sym"

```

### tools/run_B_pipeline_now.sh  
Taille: 271 B  |  MàJ: 2025-09-17 11:54:34  |  SHA256: dd3cbb4c780e00cd

```sh
#!/usr/bin/env bash
set -euo pipefail
export PYTHONPATH=/opt/scalp
/opt/scalp/.venv/bin/python /opt/scalp/services/analyze_B.py
/opt/scalp/tools/on_Btop_updated.sh
jq -C '.signals[:10]' /opt/scalp/data/signals.json 2>/dev/null || cat /opt/scalp/data/signals.json || true

```

### tools/select_universe_bitget.py  
Taille: 3 KB  |  MàJ: 2025-09-19 19:50:21  |  SHA256: b361f3b687978263

```py
#!/opt/scalp/.venv/bin/python
import os, json, time, math, statistics as st, re
from pathlib import Path
import ccxt

ROOT = Path("/opt/scalp")
DATA = ROOT/"data"
CAND = DATA/"candles"
CAND.mkdir(parents=True, exist_ok=True)

# Fixes par défaut. Ajoute-en via EXTRA_FIXED="SOL/USDT:USDT,XRP/USDT:USDT"
FIXED = {"BTC/USDT:USDT", "ETH/USDT:USDT", "BNB/USDT:USDT"}
FIXED |= {s.strip().upper() for s in os.environ.get("EXTRA_FIXED","").split(",") if s.strip()}

def norm(sym:str) -> str:
    # 'BTC/USDT:USDT' -> 'BTCUSDT'
    return re.sub(r'[^A-Z0-9]', '', sym.upper())

ex = ccxt.bitget({'enableRateLimit': True, 'options': {'defaultType': 'swap'}})

# 1) Marchés éligibles: swap USDT
markets = ex.load_markets()
symbols = [m['symbol'] for m in markets.values() if m.get('swap') and m.get('quote') == 'USDT']

# 2) Volume 24h
tickers = ex.fetch_tickers(symbols)
def vol_usd(t):
    q = t.get('quoteVolume') or 0
    if q: return q
    b = t.get('baseVolume') or 0
    p = t.get('last') or 0
    return b*p

cands = sorted(((s, vol_usd(tickers.get(s, {}))) for s in symbols), key=lambda x: x[1], reverse=True)[:120]

# 3) Volatilité log-retours 1m sur ~12h
def vola(sym):
    try:
        o = ex.fetch_ohlcv(sym, timeframe='1m', limit=720)
        if len(o) < 60: return 0.0
        rets = []
        for i in range(1, len(o)):
            p0, p1 = o[i-1][4], o[i][4]
            if p0 > 0: rets.append(math.log(p1/p0))
        return st.stdev(rets) * math.sqrt(60*24)
    except Exception:
        return 0.0

scored = []
for s, v in cands:
    sig = vola(s)
    scored.append({"symbol": s, "volume_usd": float(v or 0), "vola": float(sig or 0), "score": float((v or 0)*(sig or 0))})
    time.sleep(ex.rateLimit/1000)

# 4) Sélection
fixed = [s for s in FIXED if s in symbols]
dyn = [x["symbol"] for x in sorted(scored, key=lambda x: x["score"], reverse=True) if x["symbol"] not in fixed][:max(0, 15-len(fixed))]
sel = fixed + dyn

# 5) Écritures
DATA.mkdir(exist_ok=True, parents=True)
# universe.txt
(DATA/"universe.txt").write_text("\n".join(sel) + "\n", encoding="utf-8")
# top.json détaillé
out = {
    "fixed": fixed,
    "dynamic": dyn,
    "selected": sel,
    "scored": scored[:50]  # résumé
}
(ROOT/"data/top.json").write_text(json.dumps(out, ensure_ascii=False, indent=2), encoding="utf-8")

# 6) Bootstrap bougies manquantes (jusqu'à 1000×1m)
for s in sel:
    path = CAND/f"{norm(s)}_1m.json"
    if path.exists(): continue
    o = ex.fetch_ohlcv(s, timeframe='1m', limit=1000)
    rows = [{"t":r[0],"o":r[1],"h":r[2],"l":r[3],"c":r[4],"v":r[5]} for r in o]
    path.write_text(json.dumps(rows, ensure_ascii=False), encoding="utf-8")
    time.sleep(ex.rateLimit/1000)

print("universe size:", len(sel))
for s in sel: print(" ", s)

```

### tools/set_bot_commands.py  
Taille: 2 KB  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 186572856d330a31

```py
#!/opt/scalp/.venv/bin/python
import json, re, pathlib, sys, urllib.request

ENV = pathlib.Path("/etc/scalp.env")
RGX = re.compile(r'^\s*([A-Za-z_]\w*)\s*=\s*(.*)\s*$')

def load_token():
    if not ENV.exists():
        sys.exit("ERREUR: /etc/scalp.env introuvable")
    data={}
    for line in ENV.read_text().splitlines():
        m = RGX.match(line)
        if m:
            k,v = m.group(1), m.group(2).strip().strip('"').strip("'")
            data[k]=v
    tok = data.get("TELEGRAM_BOT_TOKEN","").strip()
    if not tok:
        sys.exit("ERREUR: TELEGRAM_BOT_TOKEN manquant dans /etc/scalp.env")
    return tok

def set_commands(token):
    url = f"https://api.telegram.org/bot{token}/setMyCommands"
    # Menu FR minimal demandé
    cmds = [
        {"command":"top",        "description":"Top 15 volume/volatilité"},
        {"command":"heat",       "description":"Heatmap B/H/S (résumé)"},
        {"command":"signal",     "description":"Derniers signaux"},
        {"command":"position",   "description":"Positions ouvertes"},
        {"command":"historique", "description":"Historique des ordres"},
        {"command":"debug",      "description":"Diagnostic rapide"},
    ]
    payload = json.dumps({"commands":cmds,"language_code":"fr"}).encode()
    req = urllib.request.Request(url, data=payload,
                                 headers={"Content-Type":"application/json"})
    with urllib.request.urlopen(req, timeout=15) as r:
        res = json.loads(r.read().decode())
    ok = res.get("ok") and res.get("result") is True
    print("[OK] setMyCommands" if ok else f"[FAIL] {res}")

if __name__ == "__main__":
    set_commands(load_token())

```

### tools/setup_venv.sh  
Taille: 1 KB  |  MàJ: 2025-09-17 06:54:13  |  SHA256: 2ca39d5524a356e8

```sh
#!/usr/bin/env bash
set -euo pipefail
BASE=/opt/scalp
VENV=$BASE/.venv
PY=$VENV/bin/python
PIP=$VENV/bin/pip
REQS=$BASE/requirements.txt

# venv
[ -x "$PY" ] || python3 -m venv "$VENV"
$PY -m pip install -U pip wheel
$PIP install -r "$REQS"

# scripts qui DOIVENT utiliser le venv
for f in \
  $BASE/services/ohlcv_bitget_cli.py \
  $BASE/services/build_softmap.py \
  $BASE/services/build_heatmap_softmax.py \
  $BASE/analyze/analyze_a_cli.py
do
  [ -f "$f" ] || continue
  sed -i '1s|^#!.*python.*$|#!/opt/scalp/.venv/bin/python|' "$f"
  chmod +x "$f"
done

# batch OHLCV → venv
if grep -q 'python3' $BASE/services/run_ohlcv_batch.sh 2>/dev/null; then
  sed -i '1i PY="/opt/scalp/.venv/bin/python"' $BASE/services/run_ohlcv_batch.sh
  sed -i 's/\bpython3\b/$PY/g'                $BASE/services/run_ohlcv_batch.sh
fi
chmod +x $BASE/services/run_ohlcv_batch.sh || true

# systemd bot → venv + PYTHONPATH
mkdir -p /etc/systemd/system/scalp-telegram-bot.service.d
cat >/etc/systemd/system/scalp-telegram-bot.service.d/override.conf <<'OVR'
[Service]
Environment=PYTHONPATH=/opt/scalp
ExecStart=
ExecStart=/opt/scalp/.venv/bin/python -m bot.bot_stdlib
OVR
systemctl daemon-reload

echo "[setup] python: $($PY -c 'import sys;print(sys.executable)')"
echo "[setup] ccxt: $($PY -c 'import ccxt;print(ccxt.__version__)')"

```

### tools/telegram_ping.py  
Taille: 782 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 32bb7e256a1a8b1d

```py
#!/opt/scalp/.venv/bin/python
import os, sys, json, urllib.request
ENV = "/etc/scalp.env"
if os.path.exists(ENV):
    for L in open(ENV):
        if "=" in L and not L.strip().startswith("#"):
            k,v=L.strip().split("=",1); os.environ.setdefault(k.strip(), v.strip())
tok=os.getenv("TELEGRAM_BOT_TOKEN"); chat=os.getenv("TELEGRAM_CHAT_ID")
msg=os.getenv("PING_MSG","SCALP bot prêt ✅")
if not tok or not chat:
    sys.exit("TELEGRAM_BOT_TOKEN/TELEGRAM_CHAT_ID manquants")
url=f"https://api.telegram.org/bot{tok}/sendMessage"
data=json.dumps({"chat_id":chat,"text":msg,"disable_notification":True}).encode()
req=urllib.request.Request(url,data,headers={"Content-Type":"application/json"})
with urllib.request.urlopen(req, timeout=10) as r: print(r.status, r.read()[:120])

```

### tools/test_B.sh  
Taille: 381 B  |  MàJ: 2025-09-17 10:49:30  |  SHA256: 32a4a5db8064ad6c

```sh
#!/usr/bin/env bash
set -euo pipefail
PY=/opt/scalp/.venv/bin/python
echo "== source heatmap =="
ls -lh --time-style=long-iso /opt/scalp/data/heatmap.json || true
echo "== run =="
$PY /opt/scalp/services/analyze_B.py || true
echo "== preview b_top.json =="
jq -C '.count, (.candidates[:10])' /opt/scalp/data/b_top.json 2>/dev/null || head -c 400 /opt/scalp/data/b_top.json || true

```

### tools/test_exec_flow.sh  
Taille: 1 KB  |  MàJ: 2025-09-16 17:51:34  |  SHA256: a63db847fddd9d61

```sh
#!/bin/bash
set -e
SIGNALS=/opt/scalp/data/signals
POS=/opt/scalp/data/positions/positions.json
HIST=/opt/scalp/data/history/history.json

echo "[1] Injection d'un signal fictif..."
cat >$SIGNALS/test_signal.json <<'JSON'
{
  "t_emit": 1737110500,
  "sym": "BTC",
  "tf": "1m",
  "entry_set": "pullback_trend",
  "side": "long",
  "price_entry": 43210.5,
  "sl": 42800.0,
  "tp": 43950.0,
  "size": 0.01
}
JSON

echo "[2] Lancement de l'exécuteur"
/bin/systemctl start scalp-exec.service

echo "[3] Attente 5s pour traitement..."
sleep 5
echo "Positions après exécution:"
jq . $POS || cat $POS

echo "[4] Simulation clôture forcée (SL touché)"
/opt/scalp/.venv/bin/python - <<'PY'
from execution.storage import load_positions, save_positions
import time, json
pos = load_positions()
for p in pos:
    if p.get("status")=="open":
        p["sl"] = p["last_price"] if "last_price" in p else p["entry_price"]*0.99
save_positions(pos)
PY

echo "[5] Déclenche monitor pour appliquer SL"
/bin/systemctl start scalp-positions.service
sleep 2

echo "[6] Positions après monitor:"
jq . $POS || cat $POS

echo "[7] Historique:"
jq . $HIST || cat $HIST

echo "[OK] Test terminé."

```

### tools/test_heat_source.py  
Taille: 484 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 3582def168e5dfbc

```py
#!/opt/scalp/.venv/bin/python
import inspect
from bot.views_heat import render_heatmap

def main():
    txt = render_heatmap() or ""
    src = inspect.getsourcefile(render_heatmap) or "?"
    print("SRC:", src)
    print("LEN:", len(txt))
    assert "views_heat.py" in src, "Heatmap source mismatch"
    assert txt.strip() not in ("", "<pre></pre>"), "Empty <pre></pre> payload"
    assert len(txt) > 20, "Payload too short"
    print("OK ✅")

if __name__ == "__main__":
    main()

```

### tools/test_ohlcv.py  
Taille: 662 B  |  MàJ: 2025-09-19 18:26:09  |  SHA256: 3bc97684947261e3

```py
#!/opt/scalp/.venv/bin/python
import ccxt, time, sys

try:
    ex = ccxt.bitget({"options":{"defaultType":"swap"}, "enableRateLimit": True})
    ex.load_markets()
except Exception as e:
    sys.exit(f"EINIT: impossible d'initialiser Bitget ({e})")

sym = "BTC/USDT:USDT"
tf  = "5m"

try:
    rows = ex.fetch_ohlcv(sym, timeframe=tf, limit=5)
except Exception as e:
    sys.exit(f"EFETCH: erreur fetch_ohlcv {sym} {tf} ({e})")

print(f"== Dernières bougies {sym} {tf} ==")
for r in rows:
    ts, o, h, l, c, v = r
    print(time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime(ts/1000)),
          f"O={o} H={h} L={l} C={c} V={v}")
print("OK: ccxt Bitget fonctionne")

```

### tools/trade_state.py  
Taille: 3 KB  |  MàJ: 2025-09-19 23:10:21  |  SHA256: dcdb1f343a0c5114

```py
import os, json, time
from pathlib import Path

ROOT   = Path("/opt/scalp")
DATA   = ROOT / "data"
FILES  = {
  "signals":  DATA / "signals.json",
  "pos":      DATA / "positions.json",
  "history":  DATA / "history.json",
}

def _read(p): 
    try: return json.loads(Path(p).read_text())
    except: return [] if str(p).endswith(".json") else {}

def _write(p, obj): Path(p).parent.mkdir(parents=True, exist_ok=True); Path(p).write_text(json.dumps(obj, ensure_ascii=False, indent=2))

def load_all():
    return (_read(FILES["signals"]), _read(FILES["pos"]), _read(FILES["history"]))

def save_all(signals, pos, hist):
    _write(FILES["signals"], signals); _write(FILES["pos"], pos); _write(FILES["history"], hist)

def promote_signals_to_positions(now_ts=None, auto_exec=True, max_new=10):
    """Ajoute les nouveaux signaux en positions 'open' si pas déjà présents (clé sym+side+ts_sig)."""
    signals, pos, hist = load_all()
    now_ts = now_ts or int(time.time())
    added = 0
    if auto_exec:
        # index existants pour éviter doublons
        keys = { (p.get("sym"), p.get("side"), p.get("ts_sig")) for p in pos }
        for s in signals:
            key = (s.get("sym"), s.get("side"), s.get("ts"))
            if key in keys: continue
            pos.append({
              "sym":s.get("sym"), "side":s.get("side"),
              "entry_px":float(s.get("px",0)), "sl":float(s.get("sl",0)), "tp":float(s.get("tp",0)),
              "qty":float(s.get("qty",0)), "lev":int(s.get("lev",1) or 1),
              "ts_open":now_ts, "ts_sig":s.get("ts"), "status":"open"
            })
            added += 1
            if added>=max_new: break
        save_all(signals, pos, hist)
    return added

def close_position(p, exit_px, now_ts=None, reason="exit"):
    now_ts = now_ts or int(time.time())
    side = (p.get("side") or "").upper()
    qty  = float(p.get("qty",0) or 0)
    entry= float(p.get("entry_px",0) or 0)
    mult = 1 if side=="LONG" else -1
    pnl  = (exit_px - entry) * qty * mult
    return {
        "sym":p.get("sym"), "side":side,
        "entry_px":entry, "exit_px":float(exit_px),
        "qty":qty, "lev":int(p.get("lev",1) or 1),
        "ts_open":int(p.get("ts_open",0) or 0), "ts_close":now_ts,
        "pnl":pnl, "reason":reason
    }

def reconcile_with_ccxt(fetch_fn=None):
    """
    Met à jour les positions:
      - si size==0 -> move to history (pnl via last price)
      - si size>0  -> garde 'open'
    fetch_fn(sym) doit retourner dict {size: float, last: float}
    """
    signals, pos, hist = load_all()
    new_pos = []
    closed  = []
    for p in pos:
        info = fetch_fn(p["sym"]) if fetch_fn else None
        if info and abs(float(info.get("size",0)))<1e-9:
            rec = close_position(p, exit_px=float(info.get("last", p["entry_px"])))
            closed.append(rec)
        else:
            new_pos.append(p)
    if closed:
        hist = (hist or []) + closed
    save_all(signals, new_pos, hist)
    return {"open":len(new_pos), "closed":len(closed)}

```

### tools/validate_pipeline.sh  
Taille: 980 B  |  MàJ: 2025-09-17 15:50:11  |  SHA256: 84d100f1276ad83b

```sh
#!/usr/bin/env bash
set -euo pipefail
echo "== A =="
python3 /opt/scalp/services/analyze_A.py >/dev/null || true
jq -r '.updated, "rows=" + ((.rows|length)|tostring)' /opt/scalp/data/heatmap.json

echo "== B =="
python3 /opt/scalp/services/analyze_B.py >/dev/null || true
jq -r '.updated, "assets=" + ((.assets|length)|tostring)' /opt/scalp/data/Btop.json

echo "== 1m/3m services =="
systemctl list-timers | grep -E 'scalp-(ohlcv-1m|agg-3m)@' || true

echo "== Signal factice -> position -> account =="
echo '{"ts":'$(date +%s)',"symbol":"BTC","entry_set":"pullback_trend","side":"long","price_entry":25000,"sl":24500,"tp":25200,"size":0.01}' >> /opt/scalp/data/signals.json
sleep 1
python3 /opt/scalp/services/paper_trade.py
jq -r '"balance=" + (.balance|tostring) + " equity=" + (.equity|tostring) + " open_pnl=" + (.open_pnl|tostring)' /opt/scalp/data/account.json
jq -r '.positions | map(select(.status=="open")) | "open=" + (length|tostring)' /opt/scalp/data/positions.json

```

### tools/view_heatmap.sh  
Taille: 89 B  |  MàJ: 2025-09-16 18:09:09  |  SHA256: e03a4a803015d389

```sh
#!/usr/bin/env bash
exec /opt/scalp/tools/json_view.py /opt/scalp/data/heatmap.json rows

```

### tools/view_history.sh  
Taille: 91 B  |  MàJ: 2025-09-16 18:09:09  |  SHA256: 60e73910ea208e3b

```sh
#!/usr/bin/env bash
exec /opt/scalp/tools/json_view.py /opt/scalp/data/history.json trades

```

### tools/view_positions.sh  
Taille: 96 B  |  MàJ: 2025-09-16 18:09:09  |  SHA256: f91ce296f7dadcdb

```sh
#!/usr/bin/env bash
exec /opt/scalp/tools/json_view.py /opt/scalp/data/positions.json positions

```

### tools/view_signals.sh  
Taille: 92 B  |  MàJ: 2025-09-16 18:09:09  |  SHA256: d38779c99b3b6cf5

```sh
#!/usr/bin/env bash
exec /opt/scalp/tools/json_view.py /opt/scalp/data/signals.json signals

```

### project_dump/tree-20250920-083747.txt  
Taille: 6 KB  |  MàJ: 2025-09-20 08:37:47  |  SHA256: ccfc86c1f525db98

```txt
# TREE — 20250920-083747

Chemins relatifs à la racine du repo.

[.]
  bot_runner.py  |     5 KB | 2025-09-19 23:11:05
  bumppush.py  |    15 KB | 2025-09-20 08:34:01
  requirements.txt  |     52 B | 2025-09-17 06:54:13
[execution]
  bitget_client.py  |    752 B | 2025-09-19 18:25:51
  executor.py  |     4 KB | 2025-09-19 18:25:51
  monitor.py  |     3 KB | 2025-09-19 18:25:51
  price_feed.py  |     1 KB | 2025-09-19 18:25:51
  storage.py  |     1 KB | 2025-09-19 18:25:51
[services]
  agg_1m_to_3m.py  |     2 KB | 2025-09-19 18:25:51
  analyze_A.py  |     4 KB | 2025-09-19 18:25:51
  analyze_B.py  |     1 KB | 2025-09-19 18:25:51
  analyze_pipeline.py  |    182 B | 2025-09-19 18:25:51
  b_triggers.py  |     4 KB | 2025-09-19 18:25:51
  build_heatmap_softmax.py  |     1 KB | 2025-09-19 18:25:51
  build_softmap.py  |     2 KB | 2025-09-19 19:44:04
  exec_signals.py  |     4 KB | 2025-09-19 18:25:51
  fetch_1m_safe.py  |    946 B | 2025-09-19 18:25:51
  fetch_ohlcv.py  |     1 KB | 2025-09-19 18:25:51
  ohlcv_1m_cli.py  |     3 KB | 2025-09-19 18:25:51
  ohlcv_bitget_batch.py  |     3 KB | 2025-09-19 18:25:51
  ohlcv_bitget_cli.py  |     4 KB | 2025-09-19 18:25:51
  on_new_signals.py  |     2 KB | 2025-09-19 23:13:47
  paper_trade.py  |    10 KB | 2025-09-19 18:25:51
  positions_watcher.py  |     4 KB | 2025-09-19 18:25:51
  promote_min.py  |     1 KB | 2025-09-19 23:16:55
  run_ohlcv_batch.sh  |    257 B | 2025-09-19 18:26:16
  signals_B.py  |     8 KB | 2025-09-19 18:25:51
  top_bitget.py  |     1 KB | 2025-09-19 18:25:51
[lib]
  errors.py  |    266 B | 2025-09-19 18:25:51
[tools]
  agg_tf3.py  |     1 KB | 2025-09-19 20:41:47
  bootstrap_ohlcv_bitget.py  |     1 KB | 2025-09-19 18:58:47
  bot_ensure_service.sh  |    472 B | 2025-09-17 20:44:34
  build_top_from_heatmap.py  |    415 B | 2025-09-19 18:26:09
  check_B.sh  |     3 KB | 2025-09-17 12:18:15
  check_deps.py  |    875 B | 2025-09-19 18:26:09
  check_env.py  |    132 B | 2025-09-19 18:26:09
  check_heat.py  |     1 KB | 2025-09-19 18:26:09
  check_ohlcv_1m.py  |     1 KB | 2025-09-19 18:26:09
  diag_B.sh  |    394 B | 2025-09-17 10:59:39
  diag_heat.sh  |     2 KB | 2025-09-17 10:15:20
  diag_heatmap.py  |    589 B | 2025-09-19 18:26:09
  diag_refresh.sh  |     4 KB | 2025-09-16 20:51:48
  diag_systemd_1m.sh  |    970 B | 2025-09-17 15:07:17
  enable_B_watchers.sh  |    190 B | 2025-09-17 11:54:41
  guard_soft.sh  |    576 B | 2025-09-17 07:55:30
  health_heatmap.sh  |    430 B | 2025-09-17 06:54:38
  install_deps.sh  |    207 B | 2025-09-16 17:06:23
  json_view.py  |     2 KB | 2025-09-19 18:26:09
  make_context.py  |    890 B | 2025-09-19 20:41:29
  normalize_json.py  |     1 KB | 2025-09-19 18:26:09
  normalize_positions.py  |    836 B | 2025-09-19 18:26:09
  ohlcv_sync.py  |     3 KB | 2025-09-19 18:26:09
  on_Btop_updated.sh  |    381 B | 2025-09-17 11:54:14
  on_btop_updated.sh  |    392 B | 2025-09-17 10:59:10
  ping_telegram.py  |    907 B | 2025-09-19 18:26:09
  pretty_heat.py  |    983 B | 2025-09-19 20:18:06
  pretty_heat_60_30_15_now.py  |     1 KB | 2025-09-19 22:17:10
  pretty_positions.py  |    403 B | 2025-09-19 22:55:25
  pretty_signals.py  |    905 B | 2025-09-19 22:54:55
  pretty_status.py  |     1 KB | 2025-09-19 20:23:28
  pretty_top.py  |    555 B | 2025-09-19 20:18:18
  pretty_top_names.py  |     1 KB | 2025-09-19 22:46:40
  probe_B.sh  |     2 KB | 2025-09-17 07:58:03
  probe_pipeline.sh  |     2 KB | 2025-09-17 08:09:27
  probe_pipeline_B.sh  |   1015 B | 2025-09-17 08:16:45
  purge_state.sh  |     1 KB | 2025-09-17 17:05:54
  refresh_bot.sh  |    242 B | 2025-09-16 20:04:04
  refresh_pipeline.sh  |    823 B | 2025-09-16 20:54:54
  relaunch_all.sh  |     2 KB | 2025-09-17 11:28:51
  relaunch_clean.sh  |    720 B | 2025-09-17 09:02:44
  repair_and_restart.sh  |     5 KB | 2025-09-16 18:59:28
  reset_top_json.py  |     1 KB | 2025-09-19 18:26:09
  restart_and_preview.sh  |    648 B | 2025-09-17 05:42:28
  rotate_history.sh  |    182 B | 2025-09-18 07:49:29
  run_1m_now.sh  |    638 B | 2025-09-17 11:10:22
  run_B_pipeline_now.sh  |    271 B | 2025-09-17 11:54:34
  select_universe_bitget.py  |     3 KB | 2025-09-19 19:50:21
  set_bot_commands.py  |     2 KB | 2025-09-19 18:26:09
  setup_venv.sh  |     1 KB | 2025-09-17 06:54:13
  telegram_ping.py  |    782 B | 2025-09-19 18:26:09
  test_B.sh  |    381 B | 2025-09-17 10:49:30
  test_exec_flow.sh  |     1 KB | 2025-09-16 17:51:34
  test_heat_source.py  |    484 B | 2025-09-19 18:26:09
  test_ohlcv.py  |    662 B | 2025-09-19 18:26:09
  trade_state.py  |     3 KB | 2025-09-19 23:10:21
  validate_pipeline.sh  |    980 B | 2025-09-17 15:50:11
  view_heatmap.sh  |     89 B | 2025-09-16 18:09:09
  view_history.sh  |     91 B | 2025-09-16 18:09:09
  view_positions.sh  |     96 B | 2025-09-16 18:09:09
  view_signals.sh  |     92 B | 2025-09-16 18:09:09
[bin]
  dump_and_push.sh  |     4 KB | 2025-09-17 05:10:42
  dump_and_reset.sh  |     2 KB | 2025-09-17 05:13:48
[analyze]
  __init__.py  |     29 B | 2025-09-19 18:26:09
  analyze_a_cli.py  |    283 B | 2025-09-19 18:26:09
  b_triggers.py  |    14 KB | 2025-09-19 18:26:09
  indicators_advanced.py  |     4 KB | 2025-09-19 18:26:09
  layer_a.py  |     2 KB | 2025-09-19 18:49:54
  run_triggers_cli.py  |     2 KB | 2025-09-19 20:41:56
[bot]
  __init__.py  |      0 B | 2025-09-19 18:26:09
  _keyboard_patch.py  |    670 B | 2025-09-19 18:26:09
  bot_stdlib.py  |     2 KB | 2025-09-19 18:26:09
  commands_wire.py  |    978 B | 2025-09-19 18:26:09
  env_simple.py  |    469 B | 2025-09-19 18:26:09
  json_util.py  |     1 KB | 2025-09-19 18:26:09
  mod_heatmap.py  |     1 KB | 2025-09-19 18:26:09
  mod_signals.py  |    865 B | 2025-09-19 18:26:09
  mod_top.py  |    503 B | 2025-09-19 18:26:09
  router.py  |     3 KB | 2025-09-19 18:26:09
  singleton.py  |    477 B | 2025-09-19 18:26:09
  views.py  |     2 KB | 2025-09-19 18:26:09
  views_account.py  |    909 B | 2025-09-19 18:26:09
  views_btop.py  |     1 KB | 2025-09-19 18:26:09
  views_heat.py  |     2 KB | 2025-09-19 18:26:09
  views_history.py  |     3 KB | 2025-09-19 18:26:09
  views_menu.py  |    309 B | 2025-09-19 18:26:09
  views_positions.py  |     3 KB | 2025-09-19 18:26:09
  views_signals.py  |    969 B | 2025-09-19 18:26:09
  views_top_patch.py  |     1 KB | 2025-09-19 18:26:09
[bot/lib]
  __init__.py  |      0 B | 2025-09-19 18:26:09
[project_dump]
[project_dump/slim]

```

### requirements.txt  
Taille: 52 B  |  MàJ: 2025-09-17 06:54:13  |  SHA256: 454a4f23373c4ad8

```txt
ccxt>=4,<5
requests>=2.31
packaging>=23
loguru>=0.7

```

