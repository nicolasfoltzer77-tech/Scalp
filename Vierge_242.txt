# ===== SCALP PROJECT DUMP =====
# 2026-02-13 09:49:44 UTC
# Root: /opt/scalp

========== TREE ==========
/opt/scalp/dp.sh                                                                         3218 2026-01-07 11:18:06.253166316 +0100
/opt/scalp/project/agent_github_readonly.py                                              3822 2026-02-13 09:30:19.823309440 +0100
/opt/scalp/project/bin/agg_3m_from_1m.sh                                                 1182 2025-11-12 13:37:13.902457360 +0100
/opt/scalp/project/bin/apply_market_score.sh                                              233 2026-01-03 20:08:28.732022255 +0100
/opt/scalp/project/bin/check_ticks_schema.sh                                              581 2026-01-03 13:21:56.151229404 +0100
/opt/scalp/project/bin/check_universe_sources.sh                                          700 2026-01-03 15:57:05.561055706 +0100
/opt/scalp/project/bin/closer_clean.sh                                                    230 2025-10-31 12:42:57.348097711 +0100
/opt/scalp/project/bin/dash.sh                                                           1551 2025-10-31 13:04:23.699099491 +0100
/opt/scalp/project/bin/dash_oa_age.sh                                                     320 2025-12-20 18:31:10.729365022 +0100
/opt/scalp/project/bin/dash_ob_feat.sh                                                   2269 2025-11-26 13:39:53.075827846 +0100
/opt/scalp/project/bin/dash_ob_feat_coin.sh                                              1277 2025-11-15 15:37:58.956108726 +0100
/opt/scalp/project/bin/dash_ofcr.sh                                                       387 2025-11-17 20:51:03.724520947 +0100
/opt/scalp/project/bin/dash_pipeline_health.sh                                            621 2025-11-19 09:36:03.317484515 +0100
/opt/scalp/project/bin/dash_ws_age.sh                                                     331 2025-11-19 09:35:47.481462029 +0100
/opt/scalp/project/bin/follower_clean.sh                                                  236 2025-10-31 12:26:25.059199562 +0100
/opt/scalp/project/bin/gest_checker.sh                                                    186 2025-11-17 16:51:18.726866398 +0100
/opt/scalp/project/bin/maint_ohlcv.sh                                                     845 2025-11-12 13:49:15.015239620 +0100
/opt/scalp/project/bin/oa_health.sh                                                       418 2025-11-05 20:06:08.395688113 +0100
/opt/scalp/project/bin/ob_aggregate_3m.sh                                                 790 2025-11-12 17:29:03.507453212 +0100
/opt/scalp/project/bin/ob_check.sh                                                        259 2025-10-30 08:14:25.694016732 +0100
/opt/scalp/project/bin/ob_freshness.sh                                                    967 2025-11-15 09:57:02.846778683 +0100
/opt/scalp/project/bin/ofcr_dashboard.sh                                                 4582 2025-11-29 14:34:41.002958724 +0100
/opt/scalp/project/bin/opener_clean.sh                                                    235 2025-10-31 12:22:06.630898758 +0100
/opt/scalp/project/bin/pnl_live.py                                                       3352 2025-12-02 17:18:10.144981423 +0100
/opt/scalp/project/bin/recorder_clean.sh                                                  237 2025-10-31 12:51:33.860668329 +0100
/opt/scalp/project/bin/run_a_ctx.sh                                                       113 2025-11-27 20:06:19.231897795 +0100
/opt/scalp/project/bin/run_a_feat.sh                                                      103 2025-11-27 20:09:34.164056354 +0100
/opt/scalp/project/bin/run_b_feat.sh                                                      335 2025-11-26 11:14:51.763521936 +0100
/opt/scalp/project/bin/run_oa.sh                                                           97 2025-11-27 20:09:27.672051060 +0100
/opt/scalp/project/bin/run_ob.sh                                                          554 2025-11-26 17:27:10.910489057 +0100
/opt/scalp/project/bin/run_universe.sh                                                    282 2026-01-03 13:13:05.518717558 +0100
/opt/scalp/project/bin/start_follower.sh                                                  411 2025-12-04 17:31:51.418880236 +0100
/opt/scalp/project/bin/start_ticks.sh                                                     322 2025-12-04 16:53:35.315387253 +0100
/opt/scalp/project/bin/stop_ticks.sh                                                      220 2025-12-04 16:53:42.275394538 +0100
/opt/scalp/project/bin/t_db_clean.sh                                                      649 2025-11-19 10:57:47.035539863 +0100
/opt/scalp/project/bin/t_db_reset_full.sh                                                 674 2025-11-19 10:58:48.371660789 +0100
/opt/scalp/project/bin/t_ticks.sh                                                         117 2025-10-30 14:42:24.525733094 +0100
/opt/scalp/project/bin/ticks_loop.sh                                                      442 2025-12-04 13:53:45.629865856 +0100
/opt/scalp/project/bin/u_universe.sh                                                       89 2025-10-28 20:36:25.969060690 +0100
/opt/scalp/project/bin/upgrade_universe_sources.sh                                       2779 2026-01-03 16:01:28.573316849 +0100
/opt/scalp/project/data/market_sql/market_score.sql                                      2299 2026-01-03 20:09:38.900089621 +0100
/opt/scalp/project/data/schema_ref.sql                                                  42096 2026-02-13 10:49:44.772144390 +0100
/opt/scalp/project/mfe_raw.txt                                                              0 2026-02-12 20:47:00.586153582 +0100
/opt/scalp/project/requirements.txt                                                       113 2025-10-30 08:19:30.318294376 +0100
/opt/scalp/project/scripts/A_analyse.py                                                  1619 2026-01-03 16:31:38.843149627 +0100
/opt/scalp/project/scripts/A_config.py                                                    336 2025-10-28 22:19:44.465383115 +0100
/opt/scalp/project/scripts/A_ctx.py                                                      3886 2025-11-29 11:15:15.224135497 +0100
/opt/scalp/project/scripts/A_ctx_dash.py                                                 2061 2026-01-06 19:57:23.111357036 +0100
/opt/scalp/project/scripts/A_feat.py                                                     4591 2025-11-27 12:56:54.456104514 +0100
/opt/scalp/project/scripts/A_feat_builder.py                                             5415 2026-01-03 16:32:14.967169621 +0100
/opt/scalp/project/scripts/A_feat_incremental.py                                         5165 2025-11-27 20:04:03.567788073 +0100
/opt/scalp/project/scripts/B_feat_builder.py                                            13962 2025-11-28 12:51:03.565529828 +0100
/opt/scalp/project/scripts/B_feat_builder_incremental.py                                 7496 2026-01-03 16:33:32.091215648 +0100
/opt/scalp/project/scripts/H_aggregate.py                                                3572 2026-01-02 16:24:56.817709428 +0100
/opt/scalp/project/scripts/H_perf.py                                                     2240 2025-10-28 22:19:44.465383115 +0100
/opt/scalp/project/scripts/H_score.py                                                     368 2025-10-28 22:19:44.465383115 +0100
/opt/scalp/project/scripts/OA_ohlcv.py                                                   4495 2026-01-03 16:25:01.370755266 +0100
/opt/scalp/project/scripts/OA_ohlcv_A.py                                                 3451 2026-01-03 16:25:26.994781538 +0100
/opt/scalp/project/scripts/OA_sync.py                                                    3124 2026-01-03 16:25:58.406813751 +0100
/opt/scalp/project/scripts/OB_collect.py                                                 4690 2026-01-03 16:29:05.887006066 +0100
/opt/scalp/project/scripts/T_ticks.py                                                    2242 2026-01-03 17:23:28.846025256 +0100
/opt/scalp/project/scripts/T_ticks_debug.py                                              1378 2025-10-30 12:41:26.768642739 +0100
/opt/scalp/project/scripts/T_ticks_test_raw.py                                           1250 2025-10-30 12:43:49.868791255 +0100
/opt/scalp/project/scripts/U_universe.py                                                  583 2026-01-03 16:01:28.557316832 +0100
/opt/scalp/project/scripts/WS_candles_to_wsdb.py                                         4714 2026-01-03 16:32:54.115192443 +0100
/opt/scalp/project/scripts/WS_multi_candles.py                                           3397 2026-01-03 16:29:36.291037269 +0100
/opt/scalp/project/scripts/analytics.py                                                  4587 2025-12-07 14:07:46.567814176 +0100
/opt/scalp/project/scripts/analytics_historical.py                                       3755 2025-12-07 12:43:39.800260104 +0100
/opt/scalp/project/scripts/audit_partial.py                                              1586 2025-12-25 11:52:14.270494548 +0100
/opt/scalp/project/scripts/audit_triggers.py                                             4876 2025-12-28 15:55:55.614539533 +0100
/opt/scalp/project/scripts/budget.py                                                     6163 2026-01-20 21:22:53.280816896 +0100
/opt/scalp/project/scripts/budget_updater.py                                             3836 2025-11-08 10:36:43.054525766 +0100
/opt/scalp/project/scripts/check_atr_consistency.py                                      1336 2026-01-13 18:07:39.715440638 +0100
/opt/scalp/project/scripts/closer.py                                                     6524 2026-02-12 17:26:23.001132822 +0100
/opt/scalp/project/scripts/coin_classify.py                                               851 2026-01-20 13:38:36.194275347 +0100
/opt/scalp/project/scripts/ctx_macro.py                                                  7128 2026-01-06 23:12:08.428478966 +0100
/opt/scalp/project/scripts/dec_atr.py                                                    2495 2026-01-22 14:09:58.551467765 +0100
/opt/scalp/project/scripts/dec_atr_fast.py                                               2606 2026-01-22 14:18:10.920112570 +0100
/opt/scalp/project/scripts/dec_atr_map.py                                                 547 2026-01-22 13:50:34.430062056 +0100
/opt/scalp/project/scripts/dec_atr_slow.py                                                831 2026-01-22 13:50:27.230051635 +0100
/opt/scalp/project/scripts/dec_ctx.py                                                     514 2026-01-22 12:11:47.363832784 +0100
/opt/scalp/project/scripts/dec_market.py                                                  826 2026-01-22 12:12:01.587848186 +0100
/opt/scalp/project/scripts/dec_ticks_mirror.py                                            842 2026-02-10 14:12:57.520196925 +0100
/opt/scalp/project/scripts/dec_ticks_writer.py                                            910 2025-12-29 18:10:11.110398322 +0100
/opt/scalp/project/scripts/dec_writer.py                                                 2759 2026-01-22 14:11:39.671577953 +0100
/opt/scalp/project/scripts/exec.py                                                      16251 2026-02-12 19:39:28.418223793 +0100
/opt/scalp/project/scripts/exec_ack_upgrade.py                                           1932 2026-02-11 12:38:17.231267158 +0100
/opt/scalp/project/scripts/exec_market.py                                                1409 2026-01-20 19:18:20.257878040 +0100
/opt/scalp/project/scripts/exec_market_adapter.py                                        2550 2026-02-11 12:32:34.762890627 +0100
/opt/scalp/project/scripts/exec_price.py                                                 1213 2026-02-11 12:32:48.518905755 +0100
/opt/scalp/project/scripts/exec_slippage.py                                              1001 2026-02-11 12:33:01.322919837 +0100
/opt/scalp/project/scripts/feature_loader.py                                             1521 2025-12-08 12:08:29.754253016 +0100
/opt/scalp/project/scripts/fetch_contracts.py                                            3324 2025-12-05 18:05:58.061033410 +0100
/opt/scalp/project/scripts/fix_opener_db.py                                              4215 2026-01-10 20:36:18.682006822 +0100
/opt/scalp/project/scripts/follower.py                                                   3291 2026-02-12 15:27:40.003143791 +0100
/opt/scalp/project/scripts/follower_advanced.py                                          2437 2026-01-17 22:26:20.278957374 +0100
/opt/scalp/project/scripts/follower_arm_levels.py                                        1283 2026-01-17 21:39:58.291307850 +0100
/opt/scalp/project/scripts/follower_decide.py                                            2060 2026-02-12 14:55:51.884520509 +0100
/opt/scalp/project/scripts/follower_decide_guard.py                                       385 2026-01-27 17:04:27.739306302 +0100
/opt/scalp/project/scripts/follower_from_exec.py                                         3452 2026-01-26 21:28:04.234334396 +0100
/opt/scalp/project/scripts/follower_fsm_guard.py                                          231 2026-01-25 14:53:02.732153248 +0100
/opt/scalp/project/scripts/follower_fsm_status.py                                        2240 2026-01-18 09:00:30.838521901 +0100
/opt/scalp/project/scripts/follower_fsm_sync.py                                          2491 2026-02-12 11:30:54.769589702 +0100
/opt/scalp/project/scripts/follower_ingest.py                                            1481 2026-01-26 09:45:16.835037413 +0100
/opt/scalp/project/scripts/follower_live_view.py                                         6517 2026-01-14 21:48:42.175680744 +0100
/opt/scalp/project/scripts/follower_purge_closed.py                                       562 2026-01-18 14:17:38.881240404 +0100
/opt/scalp/project/scripts/follower_pyramide_guard.py                                    2682 2026-01-20 13:55:50.432536287 +0100
/opt/scalp/project/scripts/follower_sync_mfemae.py                                       2175 2026-01-26 09:19:47.809713175 +0100
/opt/scalp/project/scripts/follower_sync_steps.py                                        1024 2026-01-25 14:56:17.044336089 +0100
/opt/scalp/project/scripts/follower_timeout.py                                           1541 2026-01-25 14:14:31.257977537 +0100
/opt/scalp/project/scripts/gen_schema_ref.sh                                              920 2025-11-18 18:06:26.735109460 +0100
/opt/scalp/project/scripts/gest.py                                                       7034 2026-02-11 11:10:01.845453864 +0100
/opt/scalp/project/scripts/gest_from_closer.py                                           1378 2026-01-26 13:36:57.947093513 +0100
/opt/scalp/project/scripts/gest_from_follower.py                                         1347 2026-01-27 15:06:12.324752680 +0100
/opt/scalp/project/scripts/gest_from_follower_follow.py                                  1305 2026-01-26 14:04:00.833099569 +0100
/opt/scalp/project/scripts/gest_from_opener.py                                           1399 2026-01-26 13:37:05.471098464 +0100
/opt/scalp/project/scripts/gest_from_triggers.py                                         1233 2026-01-29 10:07:50.074755990 +0100
/opt/scalp/project/scripts/gest_ingest_triggers.py                                       2822 2026-01-18 10:06:49.872674294 +0100
/opt/scalp/project/scripts/gest_purge.py                                                  798 2026-01-18 08:45:37.417993978 +0100
/opt/scalp/project/scripts/ingest_triggers_to_gest.py                                    3574 2026-01-01 14:34:23.060575943 +0100
/opt/scalp/project/scripts/list_opened_coins.sh                                           233 2025-12-12 11:29:28.262524258 +0100
/opt/scalp/project/scripts/maemfe.py                                                     4588 2025-12-29 20:46:29.765821007 +0100
/opt/scalp/project/scripts/market_collector.py                                           6329 2026-01-04 20:06:19.436778248 +0100
/opt/scalp/project/scripts/mfe_mae.py                                                    5658 2026-01-05 15:36:56.774425422 +0100
/opt/scalp/project/scripts/monitor_snapshot.py                                           5803 2026-01-09 13:26:52.230687479 +0100
/opt/scalp/project/scripts/monitor_snapshot_5m.py                                        3905 2026-01-04 07:52:26.078621505 +0100
/opt/scalp/project/scripts/opener.py                                                     1375 2026-02-11 19:42:11.230576219 +0100
/opt/scalp/project/scripts/opener_adapt.py                                               1009 2026-01-21 14:19:33.346190643 +0100
/opt/scalp/project/scripts/opener_contracts.py                                            655 2026-01-25 13:12:12.150466328 +0100
/opt/scalp/project/scripts/opener_from_exec.py                                           2551 2026-02-11 12:22:13.198206338 +0100
/opt/scalp/project/scripts/opener_ingest_open.py                                         5574 2026-02-11 10:49:22.503938824 +0100
/opt/scalp/project/scripts/opener_pyramide.py                                            5051 2026-02-12 11:05:45.989836380 +0100
/opt/scalp/project/scripts/opener_pyramide_ingest.py                                     1554 2026-01-18 12:02:40.008830599 +0100
/opt/scalp/project/scripts/opener_sizing.py                                              1634 2026-02-11 10:39:53.871275025 +0100
/opt/scalp/project/scripts/orderflow.py                                                  5591 2025-12-06 17:24:40.904290825 +0100
/opt/scalp/project/scripts/prove_ohlcv_20_vs_next.py                                     2314 2026-01-03 14:52:17.221299766 +0100
/opt/scalp/project/scripts/recorder.py                                                   6559 2026-01-17 16:47:51.923494171 +0100
/opt/scalp/project/scripts/recorder_analyse.py                                           4947 2026-01-21 15:27:45.027126478 +0100
/opt/scalp/project/scripts/recorder_analyse_capture.py                                   2553 2026-01-19 20:56:04.886740416 +0100
/opt/scalp/project/scripts/recorder_analyse_exit_failure.py                              5292 2026-01-22 16:05:15.313957041 +0100
/opt/scalp/project/scripts/recorder_analyse_extremes.py                                  3410 2026-01-19 20:39:15.606071182 +0100
/opt/scalp/project/scripts/recorder_analyse_steps.py                                     1142 2026-01-19 20:34:24.853790777 +0100
/opt/scalp/project/scripts/recorder_analyse_uid.py                                       3548 2026-01-21 19:58:58.921611740 +0100
/opt/scalp/project/scripts/recorder_detect_golden.py                                     3829 2026-01-15 18:13:44.749440643 +0100
/opt/scalp/project/scripts/snap_gest_writer.py                                           1868 2025-12-30 09:11:44.228982755 +0100
/opt/scalp/project/scripts/ticks.py                                                      6391 2026-01-20 16:33:39.873101661 +0100
/opt/scalp/project/scripts/trade_check.py                                                8380 2026-01-25 11:07:37.503472725 +0100
/opt/scalp/project/scripts/trade_check_worst2.sh                                          261 2026-01-25 11:08:00.323492977 +0100
/opt/scalp/project/scripts/triggers.py                                                   5070 2026-02-10 14:05:36.631631703 +0100
/opt/scalp/project/scripts/universe_audit_ccxt.py                                        3296 2026-01-03 16:01:28.497316772 +0100
/opt/scalp/project/scripts/universe_collector.py                                         3055 2026-01-03 13:22:10.603245328 +0100
/opt/scalp/project/scripts/universe_probe_bitget.py                                      4893 2026-01-03 13:50:55.221392137 +0100
/opt/scalp/project/scripts/universe_probe_ccxt.py                                        4580 2026-01-03 14:44:13.216853984 +0100
/opt/scalp/project/scripts/universe_runner.py                                            2075 2026-01-03 13:13:05.498717542 +0100
/opt/scalp/project/scripts/universe_seed_ccxt.py                                         1985 2026-01-03 14:59:35.889662223 +0100
/opt/scalp/project/scripts/universe_tradable_runner.py                                   4230 2026-01-03 15:39:00.355955108 +0100
/opt/scalp/project/scripts/upgrade_views_analysis_steps.py                               4016 2026-01-17 17:15:25.251325505 +0100
/opt/scalp/project/scripts/w_ticks.py                                                    3378 2025-12-08 18:02:37.332701035 +0100
/opt/scalp/project/scripts/wticks.py                                                     3322 2025-12-08 20:00:09.179334731 +0100
/opt/scalp/project/upgrade_add_qty_snapshot.sql                                            68 2026-02-12 14:45:40.572389591 +0100

========== FILE CONTENT ==========

----- FILE: /opt/scalp/dp.sh -----
#!/usr/bin/env bash
set -euo pipefail

# ---------- CONFIG ----------
ROOT="/opt/scalp"
DUMP_DIR="${ROOT}/dump"
mkdir -p "$DUMP_DIR"
TS="$(date +'%Y%m%d_%H%M%S')"
OUT="${DUMP_DIR}/scalp_full_${TS}.txt"
MAX_FILE_SIZE_KB="${MAX_FILE_SIZE_KB:-1024}"

# ---------- GIT ENV ----------
[ -f /etc/scalp.env ] && . /etc/scalp.env
: "${GIT_USERNAME:?}"
: "${GIT_TOKEN:?}"
GIT_BRANCH="${GIT_BRANCH:-main}"
GIT_EMAIL_USE="${GIT_EMAIL:-${GIT_USERNAME}@users.noreply.github.com}"
REMOTE_URL="https://${GIT_HOST:-github.com}/${GIT_OWNER:-$GIT_USERNAME}/${GIT_REPO:-Scalp}.git"

# ---------- HEADER ----------
{
  echo "# ===== SCALP PROJECT DUMP ====="
  echo "# $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
  echo "# Root: $ROOT"
  echo
  echo "========== TREE =========="
} > "$OUT"

find "$ROOT" -type f \
  -not -path '*/.git/*' -not -path '*/venv/*' \
  -not -path '*/dump/*' -not -path '*/logs/*' \
  -size -"${MAX_FILE_SIZE_KB}"k \
  \( -name '*.py' -o -name '*.sh' -o -name '*.conf' -o -name '*.sql' -o -name '*.txt' \) |
  sort | while IFS= read -r f; do
    sz=$(stat -c%s "$f" 2>/dev/null || echo 0)
    mt=$(stat -c%y "$f" 2>/dev/null || echo unknown)
    printf "%-80s %12s %s\n" "$f" "$sz" "$mt" >> "$OUT"
done

{
  echo
  echo "========== FILE CONTENT =========="
} >> "$OUT"

find "$ROOT" -type f \
  -not -path '*/.git/*' -not -path '*/venv/*' \
  -not -path '*/dump/*' -not -path '*/logs/*' \
  -size -"${MAX_FILE_SIZE_KB}"k \
  \( -name '*.py' -o -name '*.sh' -o -name '*.conf' -o -name '*.sql' -o -name '*.txt' \) |
  sort | while IFS= read -r f; do
    echo -e "\n----- FILE: $f -----" >> "$OUT"
    cat "$f" 2>/dev/null >> "$OUT" || true
done

# ---------- DATABASE STRUCTURE (finale compl√®te) ----------
{
  echo
  echo "========== DATABASE STRUCTURE =========="
} >> "$OUT"

for DB_PATH in /opt/scalp/project/data/*.db; do
  [ -s "$DB_PATH" ] || continue
  echo -e "\n----- DATABASE: $DB_PATH -----" >> "$OUT"

  {
    echo "-- TABLES --"
    sqlite3 -readonly "$DB_PATH" ".tables" 2>/dev/null || echo "(locked or unreadable)"
    echo

    for T in $(sqlite3 -readonly "$DB_PATH" ".tables" 2>/dev/null); do
      echo "[TABLE: $T]"
      sqlite3 -readonly "$DB_PATH" "PRAGMA table_info($T);" 2>/dev/null || true
      echo
    done

    echo "-- VIEWS --"
    sqlite3 -readonly "$DB_PATH" "SELECT name, sql FROM sqlite_master WHERE type='view' ORDER BY name;" 2>/dev/null || echo "(no views)"
    echo

    echo "-- INDEXES --"
    sqlite3 -readonly "$DB_PATH" "SELECT name, sql FROM sqlite_master WHERE type='index' ORDER BY name;" 2>/dev/null || echo "(no indexes)"
    echo

    echo "-- TRIGGERS --"
    sqlite3 -readonly "$DB_PATH" "SELECT name, sql FROM sqlite_master WHERE type='trigger' ORDER BY name;" 2>/dev/null || echo "(no triggers)"
    echo
  } >> "$OUT"
done

# ---------- GIT PUSH ----------
cd "$ROOT"
git rev-parse --is-inside-work-tree >/dev/null 2>&1 || git init -q .
git config user.name "$GIT_USERNAME"
git config user.email "$GIT_EMAIL_USE"
git remote get-url origin >/dev/null 2>&1 || git remote add origin "$REMOTE_URL"

git add -f "$OUT"
git commit -m "dump ${TS}" || true
AUTH_URL="https://${GIT_USERNAME}:${GIT_TOKEN}@${REMOTE_URL#https://}"
git push -f "$AUTH_URL" HEAD:"$GIT_BRANCH"

----- FILE: /opt/scalp/project/agent_github_readonly.py -----
#!/usr/bin/env python3
"""
Agent GitHub READ-ONLY pour analyse de Pull Requests.
- Lecture diff / patch PR
- Lecture m√©tadonn√©es PR
- AUCUNE √©criture possible

Configuration via /etc/scalp.env
"""

import os
from fastapi import FastAPI, HTTPException
import requests

# =========================
# Chargement env
# =========================
ENV_FILE = "/etc/scalp.env"

if os.path.exists(ENV_FILE):
    with open(ENV_FILE, "r") as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith("#") or "=" not in line:
                continue
            k, v = line.split("=", 1)
            os.environ[k] = v.strip().strip('"')

GIT_TOKEN = os.environ.get("GIT_TOKEN")
GIT_USERNAME = os.environ.get("GIT_USERNAME")
GIT_BRANCH = os.environ.get("GIT_BRANCH", "main")
GIT_HOST = os.environ.get("GIT_HOST", "github.com")
GIT_OWNER = os.environ.get("GIT_OWNER")
GIT_REPO = os.environ.get("GIT_REPO")

if not all([GIT_TOKEN, GIT_OWNER, GIT_REPO]):
    raise RuntimeError("Configuration GitHub incompl√®te dans /etc/scalp.env")

# =========================
# HTTP config
# =========================
BASE_API = f"https://api.{GIT_HOST}"

HEADERS_JSON = {
    "Authorization": f"Bearer {GIT_TOKEN}",
    "Accept": "application/vnd.github+json",
    "User-Agent": "scalp-pr-agent-readonly",
}

HEADERS_DIFF = {
    "Authorization": f"Bearer {GIT_TOKEN}",
    "Accept": "application/vnd.github.v3.diff",
    "User-Agent": "scalp-pr-agent-readonly",
}

HEADERS_PATCH = {
    "Authorization": f"Bearer {GIT_TOKEN}",
    "Accept": "application/vnd.github.v3.patch",
    "User-Agent": "scalp-pr-agent-readonly",
}

# =========================
# App
# =========================
app = FastAPI(
    title="Scalp GitHub PR Read-Only Agent",
    version="1.0.0",
    description="Agent interm√©diaire GitHub READ-ONLY (diff / metadata PR)",
)

# =========================
# Utils
# =========================
def gh_get(url: str, headers: dict):
    r = requests.get(url, headers=headers, timeout=15)
    if r.status_code != 200:
        raise HTTPException(
            status_code=r.status_code,
            detail=f"GitHub API error: {r.text}",
        )
    return r

# =========================
# Endpoints
# =========================
@app.get("/health")
def health():
    return {
        "status": "ok",
        "owner": GIT_OWNER,
        "repo": GIT_REPO,
        "branch": GIT_BRANCH,
        "mode": "read-only",
    }


@app.get("/pr/meta")
def pr_meta(pr: int):
    """
    M√©tadonn√©es PR (JSON)
    """
    url = f"{BASE_API}/repos/{GIT_OWNER}/{GIT_REPO}/pulls/{pr}"
    r = gh_get(url, HEADERS_JSON)
    return r.json()


@app.get("/pr/diff")
def pr_diff(pr: int):
    """
    Diff brut PR
    """
    url = f"{BASE_API}/repos/{GIT_OWNER}/{GIT_REPO}/pulls/{pr}"
    r = gh_get(url, HEADERS_DIFF)
    return r.text


@app.get("/pr/patch")
def pr_patch(pr: int):
    """
    Patch brut PR
    """
    url = f"{BASE_API}/repos/{GIT_OWNER}/{GIT_REPO}/pulls/{pr}"
    r = gh_get(url, HEADERS_PATCH)
    return r.text


@app.get("/pr/files")
def pr_files(pr: int):
    """
    Liste fichiers modifi√©s PR
    """
    url = f"{BASE_API}/repos/{GIT_OWNER}/{GIT_REPO}/pulls/{pr}/files"
    r = gh_get(url, HEADERS_JSON)
    return r.json()


@app.get("/branch/head")
def branch_head():
    """
    SHA du HEAD de la branche principale
    """
    url = f"{BASE_API}/repos/{GIT_OWNER}/{GIT_REPO}/branches/{GIT_BRANCH}"
    r = gh_get(url, HEADERS_JSON)
    return {
        "branch": GIT_BRANCH,
        "sha": r.json().get("commit", {}).get("sha"),
    }

# =========================
# Main
# =========================
if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "agent_github_readonly:app",
        host="0.0.0.0",
        port=8000,
        reload=False,
    )

----- FILE: /opt/scalp/project/bin/agg_3m_from_1m.sh -----
#!/usr/bin/env bash
set -euo pipefail
DB="/opt/scalp/project/data/ob.db"

# S√©curit√©: v√©rifier que la base n'est pas verrouill√©e
if lsof "$DB" | grep -q ob.db; then
  echo "‚ùå ob.db en cours d'utilisation. Ferme les processus avant d'agr√©ger."
  lsof "$DB"
  exit 1
fi

sqlite3 "$DB" <<'SQL'
PRAGMA busy_timeout=5000;

-- (Optionnel mais recommand√© si non cr√©√©s) Index pour acc√©l√©rer l'agr√©gation
-- CREATE INDEX IF NOT EXISTS idx_ohlcv_1m_inst_ts ON ohlcv_1m(instId, ts);

-- Nettoyage 3m
DELETE FROM ohlcv_3m;

-- Agr√©gation 1m -> 3m sans fonctions analytiques (compat SQLite 3.37)
WITH g AS (
  SELECT
    instId,
    (ts/180000)*180000 AS ts3,
    MIN(ts) AS ts_min,
    MAX(ts) AS ts_max,
    MAX(h) AS h,
    MIN(l) AS l,
    SUM(v) AS v
  FROM ohlcv_1m
  GROUP BY instId, ts3
)
INSERT INTO ohlcv_3m(instId, ts, o, h, l, c, v)
SELECT
  g.instId,
  g.ts3 AS ts,
  (SELECT o FROM ohlcv_1m WHERE instId=g.instId AND ts=g.ts_min) AS o,
  g.h,
  g.l,
  (SELECT c FROM ohlcv_1m WHERE instId=g.instId AND ts=g.ts_max) AS c,
  g.v
FROM g;

-- V√©rification
SELECT '3m' AS tf, COUNT(*) AS rows, datetime(MAX(ts)/1000,'unixepoch','localtime') AS last_ts
FROM ohlcv_3m;
SQL

----- FILE: /opt/scalp/project/bin/apply_market_score.sh -----
#!/usr/bin/env bash
set -e

ROOT="/opt/scalp/project"
DB="$ROOT/data/market.db"
SQL="$ROOT/data/market_sql/market_score.sql"

echo "[INFO] Applying MARKET SCORE SQL ‚Üí $DB"
sqlite3 "$DB" < "$SQL"
echo "[OK] v_market_scored created"

----- FILE: /opt/scalp/project/bin/check_ticks_schema.sh -----
#!/usr/bin/env bash
set -euo pipefail

DB="/opt/scalp/project/data/t.db"

echo "=== TABLES ==="
sqlite3 "$DB" ".tables"

echo
echo "=== ticks schema ==="
sqlite3 "$DB" "PRAGMA table_info(ticks);"

echo
echo "=== ticks sample ==="
sqlite3 "$DB" <<'SQL'
.headers on
.mode column
SELECT instId, lastPr, ts_ms
FROM ticks
ORDER BY ts_ms DESC
LIMIT 5;
SQL

echo
echo "=== ticks time range ==="
sqlite3 "$DB" <<'SQL'
SELECT
  datetime(MIN(ts_ms)/1000,'unixepoch','localtime') AS first_ts,
  datetime(MAX(ts_ms)/1000,'unixepoch','localtime') AS last_ts,
  COUNT(*) AS rows
FROM ticks;
SQL

----- FILE: /opt/scalp/project/bin/check_universe_sources.sh -----
#!/usr/bin/env bash
set -euo pipefail

ROOT="/opt/scalp/project"

echo "[INFO] Searching for any SQL selecting from legacy 'universe' table ..."
echo

# Show any occurrence (case-insensitive) in common filetypes
grep -RIn --binary-files=without-match \
  --include="*.py" --include="*.sh" --include="*.sql" --include="*.yaml" --include="*.yml" \
  -E "\bFROM[[:space:]]+universe\b|\bfrom[[:space:]]+universe\b" \
  "${ROOT}" || true

echo
echo "[INFO] Searching for direct references to 'u.db' universe table usage (heuristic) ..."
echo

grep -RIn --binary-files=without-match \
  --include="*.py" --include="*.sh" \
  -E "data/u\.db|/data/u\.db|DB_U|FROM[[:space:]]+universe;" \
  "${ROOT}" || true

----- FILE: /opt/scalp/project/bin/closer_clean.sh -----
#!/usr/bin/env bash
set -euo pipefail
DB="/opt/scalp/project/data/closer.db"
sqlite3 "$DB" "DELETE FROM trades_close WHERE ts_close < (strftime('%s','now')-7200)*1000;"
sqlite3 "$DB" "VACUUM;"
echo "[CLEANER] closer.db compacted"

----- FILE: /opt/scalp/project/bin/dash.sh -----
#!/usr/bin/env bash
set -euo pipefail

DATA="/opt/scalp/project/data"
LOG="/opt/scalp/project/logs/dash.log"
now_s=$(date +%s)
ts_now="$(date '+%Y-%m-%d %H:%M:%S')"
printf "\n===== SCALP PIPE HEALTH %s =====\n" "$(date '+%H:%M:%S')" | tee -a "$LOG"

check_db() {
    local name="$1" file="$2" table="$3" ts_col="$4"
    if [[ ! -f "$file" ]]; then
        printf "%-10s ‚ùå no DB found\n" "$name" | tee -a "$LOG"
        return
    fi
    local count ts_last age_s h m s age_hms status
    count=$(sqlite3 "$file" "SELECT COUNT(*) FROM $table;")
    ts_last=$(sqlite3 "$file" "SELECT MAX($ts_col)/1000 FROM $table;")
    [[ -z "$ts_last" || "$ts_last" == "0" ]] && ts_last=$now_s
    age_s=$(( now_s - ${ts_last%.*:-0} ))
    h=$((age_s/3600)); m=$(( (age_s%3600)/60 )); s=$((age_s%60))
    age_hms=$(printf "%02dh%02dm%02ds" "$h" "$m" "$s")

    if (( age_s < 10 )); then status="‚úÖ"
    elif (( age_s < 60 )); then status="‚ö†Ô∏è"
    else status="‚ùå"
    fi

    printf "%-10s %s  %4s recs | last=%s | age=%s\n" \
        "$name" "$status" "$count" "$(date '+%H:%M:%S' -d @$ts_last 2>/dev/null || date -r "$ts_last" '+%H:%M:%S')" "$age_hms" \
        | tee -a "$LOG"
}

check_db "opener"   "$DATA/opener.db"   "trades_open_init" "ts_create"
check_db "follower" "$DATA/follower.db" "trades_follow"    "ts_update"
check_db "closer"   "$DATA/closer.db"   "trades_close"     "ts_close"
check_db "recorder" "$DATA/recorder.db" "trades_record"    "ts_record"

printf "==============================================\n" | tee -a "$LOG"
echo "" >> "$LOG"

----- FILE: /opt/scalp/project/bin/dash_oa_age.sh -----
#!/bin/bash
DB=/opt/scalp/project/data/oa.db

echo "===== OA AGE ====="
for tf in 5 15 30; do
  table="ohlcv_${tf}m"
  row=$(sqlite3 $DB "SELECT MAX(ts) FROM $table")
  if [ -z "$row" ]; then
    echo "${tf}m : no data"
    continue
  fi
  age=$(( $(date +%s%3N) - row ))
  echo "${tf}m : last_ts=$row age_ms=$age"
done

----- FILE: /opt/scalp/project/bin/dash_ob_feat.sh -----
#!/usr/bin/env bash
set -euo pipefail

DB_OB="/opt/scalp/project/data/ob.db"
DB_B="/opt/scalp/project/data/b.db"

age() {
  ts_ms="$1"
  now_ms=$(($(date +%s) * 1000))
  echo $(( (now_ms - ts_ms) / 1000 ))
}

print_block() {
  local label="$1"
  echo "---- [$label] ----"
}

print_row() {
  local tf="$1"
  local rows="$2"
  local last_ts="$3"
  if [[ -z "$last_ts" || "$last_ts" == "0" ]]; then
      age_s="n/a"
  else
      age_s=$(age "$last_ts")
  fi
  printf "%-3s | rows=%-6s age=%4ss\n" "$tf" "$rows" "$age_s"
}

echo "==========================================="
echo "      MINI DASH ‚Äî OB + FEAT (1m/3m/5m)"
echo "==========================================="

### OB ###
print_block "OB OHLCV"

for tf in 1m 3m 5m; do
    table="ohlcv_${tf}"
    rows=$(sqlite3 "$DB_OB" "SELECT COUNT(*) FROM $table;")
    last_ts=$(sqlite3 "$DB_OB" "SELECT MAX(ts) FROM $table;")
    print_row "$tf" "$rows" "$last_ts"
done

### FEAT ###
print_block "FEAT"

for tf in 1m 3m 5m; do
    table="feat_${tf}"
    rows=$(sqlite3 "$DB_B" "SELECT COUNT(*) FROM $table;")
    last_ts=$(sqlite3 "$DB_B" "SELECT MAX(ts) FROM $table;")
    print_row "$tf" "$rows" "$last_ts"
done

### STATUS ###
echo "---- [STATUS] ----"

ok=true
msg=""

# seuils
S1=120
S3=180
S5=300

check_tf() {
  local tf="$1"
  local ob_age="$2"
  local ft_age="$3"
  local max="$4"

  if (( ob_age > max )); then ok=false; msg="$msg ‚ö†Ô∏è OB ${tf} lag (${ob_age} s)\n"; fi
  if (( ft_age > max )); then ok=false; msg="$msg ‚ö†Ô∏è FEAT ${tf} lag (${ft_age} s)\n"; fi
}

ob1=$(age "$(sqlite3 "$DB_OB" "SELECT IFNULL(MAX(ts),0) FROM ohlcv_1m;")")
ft1=$(age "$(sqlite3 "$DB_B" "SELECT IFNULL(MAX(ts),0) FROM feat_1m;")")

ob3=$(age "$(sqlite3 "$DB_OB" "SELECT IFNULL(MAX(ts),0) FROM ohlcv_3m;")")
ft3=$(age "$(sqlite3 "$DB_B" "SELECT IFNULL(MAX(ts),0) FROM feat_3m;")")

ob5=$(age "$(sqlite3 "$DB_OB" "SELECT IFNULL(MAX(ts),0) FROM ohlcv_5m;")")
ft5=$(age "$(sqlite3 "$DB_B" "SELECT IFNULL(MAX(ts),0) FROM feat_5m;")")

check_tf 1m "$ob1" "$ft1" "$S1"
check_tf 3m "$ob3" "$ft3" "$S3"
check_tf 5m "$ob5" "$ft5" "$S5"

if $ok; then
    echo "üü¢ OK"
else
    echo -e "$msg"
fi

echo "==========================================="
echo "             FIN MINI DASH"
echo "==========================================="


----- FILE: /opt/scalp/project/bin/dash_ob_feat_coin.sh -----
#!/usr/bin/env bash
set -euo pipefail

COIN="${1:-BTC/USDT}"

DB_OB="/opt/scalp/project/data/ob.db"
DB_B="/opt/scalp/project/data/b.db"

echo "====================================================="
echo "        DASH OB + FEAT ‚Äî $COIN (1m / 3m / 5m)"
echo "====================================================="

for TF in 1m 3m 5m; do
    echo
    echo "-------------------- OHLCV $TF ----------------------"
    sqlite3 -readonly "$DB_OB" <<SQL
.headers on
.mode column
SELECT ts,
       datetime(ts/1000,'unixepoch','localtime') AS local,
       o,h,l,c,v
FROM ohlcv_${TF}
WHERE instId='${COIN}'
ORDER BY ts DESC
LIMIT 10;
SQL

    echo
    echo "-------------------- FEAT $TF ------------------------"
    sqlite3 -readonly "$DB_B" <<SQL
.headers on
.mode column
SELECT ts,
       datetime(ts/1000,'unixepoch','localtime') AS local,
       c,
       ema12, ema26,
       macd, macdsignal, macdhist,
       rsi14_1m AS rsi,
       atr14  AS atr,
       bb_mid, bb_up, bb_low, bb_width,
       mom, roc, slope_ema12_1m AS slope,
       ctx
FROM feat_${TF}
WHERE instId='${COIN}'
ORDER BY ts DESC
LIMIT 10;
SQL

done

echo "====================================================="
echo "                       END"
echo "====================================================="

----- FILE: /opt/scalp/project/bin/dash_ofcr.sh -----
#!/usr/bin/env bash

echo "===== OFCR DASH ====="
echo
echo "--- STATES ---"
sqlite3 /opt/scalp/project/data/gest.db "
SELECT state, COUNT(*) FROM trades_all GROUP BY state;
"

echo
echo "--- LAST 10 ---"
sqlite3 /opt/scalp/project/data/gest.db "
SELECT trade_uid, instId, side, state, datetime(ts_update/1000,'unixepoch','localtime')
FROM trades_all
ORDER BY ts_update DESC LIMIT 10;
"

----- FILE: /opt/scalp/project/bin/dash_pipeline_health.sh -----
#!/bin/bash

echo "===== PIPELINE HEALTH (WS ‚Üí OA ‚Üí FEAT ‚Üí CTX) ====="

echo
/opt/scalp/project/bin/dash_ws_age.sh

echo
/opt/scalp/project/bin/dash_oa_age.sh

echo
echo "FEAT latest:"
sqlite3 /opt/scalp/project/data/a.db \
  "SELECT tf, datetime(MAX(ts)/1000,'unixepoch','localtime') FROM feat_5m UNION ALL
   SELECT tf, datetime(MAX(ts)/1000,'unixepoch','localtime') FROM feat_15m UNION ALL
   SELECT tf, datetime(MAX(ts)/1000,'unixepoch','localtime') FROM feat_30m;"

echo
echo "CTX latest:"
sqlite3 /opt/scalp/project/data/a.db \
  "SELECT datetime(MAX(ts_update)/1000,'unixepoch','localtime') FROM ctx_cache;"

----- FILE: /opt/scalp/project/bin/dash_ws_age.sh -----
#!/bin/bash
DB=/opt/scalp/project/data/ws.db

echo "===== WS CANDLES AGE ====="
for tf in 5 15 30; do
  table="ws_ohlcv_${tf}m"
  row=$(sqlite3 $DB "SELECT MAX(ts) FROM $table")
  if [ -z "$row" ]; then
    echo "${tf}m : no data"
    continue
  fi
  age=$(( $(date +%s%3N) - row ))
  echo "${tf}m : last_ts=$row age_ms=$age"
done

----- FILE: /opt/scalp/project/bin/follower_clean.sh -----
#!/usr/bin/env bash
set -euo pipefail
DB="/opt/scalp/project/data/follower.db"
sqlite3 "$DB" "DELETE FROM trades_follow WHERE ts_update < (strftime('%s','now')-7200)*1000;"
sqlite3 "$DB" "VACUUM;"
echo "[CLEANER] follower.db compacted"

----- FILE: /opt/scalp/project/bin/gest_checker.sh -----
#!/usr/bin/env bash
sqlite3 /opt/scalp/project/data/gest.db "
SELECT trade_uid,instId,side,state,datetime(ts_update/1000,'unixepoch') FROM trades_all ORDER BY ts_update DESC LIMIT 20;
"

----- FILE: /opt/scalp/project/bin/maint_ohlcv.sh -----
#!/usr/bin/env bash
set -euo pipefail
DB="/opt/scalp/project/data/ob.db"
LOG="/opt/scalp/project/logs/maint_ohlcv.log"
echo "[$(date '+%F %T')] START maintenance" >>"$LOG"

# --- Nettoyage (max rows) ---
sqlite3 "$DB" <<'SQL'
DELETE FROM ohlcv_1m WHERE ts NOT IN (
  SELECT ts FROM ohlcv_1m ORDER BY ts DESC LIMIT 450
);
DELETE FROM ohlcv_3m WHERE ts NOT IN (
  SELECT ts FROM ohlcv_3m ORDER BY ts DESC LIMIT 150
);
DELETE FROM ohlcv_5m WHERE ts NOT IN (
  SELECT ts FROM ohlcv_5m ORDER BY ts DESC LIMIT 150
);
VACUUM;
SQL

echo "[$(date '+%F %T')] CLEAN OK" >>"$LOG"

# --- R√©-agr√©gation 3m ---
bash /opt/scalp/project/bin/agg_3m_from_1m.sh >>"$LOG" 2>&1 || echo "agg_3m fail" >>"$LOG"

# --- V√©rification fra√Æcheur ---
bash /opt/scalp/project/bin/check_ohlcv_freshness.sh >>"$LOG" 2>&1

echo "[$(date '+%F %T')] DONE maintenance" >>"$LOG"

----- FILE: /opt/scalp/project/bin/oa_health.sh -----
#!/usr/bin/env bash
set -euo pipefail
DB="/opt/scalp/project/data/oa.db"

age_s=$(sqlite3 "$DB" "SELECT (strftime('%s','now') - MAX(ts)/1000) FROM ohlcv_5m;")
printf '[OA_HEALTH] last 5m age: %.1fs\n' "$age_s"

if (( $(echo "$age_s > 120" | bc -l) )); then
  echo "[OA_HEALTH] ‚ùå OHLCV_5m too old ($age_s s) ‚Üí restarting OA"
  systemctl restart scalp-oa.service
else
  echo "[OA_HEALTH] ‚úÖ OA fresh ($age_s s)"
fi

----- FILE: /opt/scalp/project/bin/ob_aggregate_3m.sh -----
#!/usr/bin/env bash
set -euo pipefail
DB="/opt/scalp/project/data/ob.db"
LOCK="/var/lock/ob_agg3m.lock"
LOG="/opt/scalp/project/logs/ob_agg3m.log"

exec /usr/bin/flock -n "$LOCK" bash -c "
  echo \"\$(date '+%F %T') [AGG3M] Start aggregation\" >> \$LOG
  sqlite3 \$DB '
    DELETE FROM ohlcv_3m;
    INSERT INTO ohlcv_3m (instId, ts, o, h, l, c, v)
    SELECT instId,
           (ts/180000)*180000 AS ts_group,
           first_value(o) OVER w AS o,
           MAX(h) OVER w AS h,
           MIN(l) OVER w AS l,
           last_value(c) OVER w AS c,
           SUM(v) OVER w AS v
    FROM ohlcv_1m
    WINDOW w AS (PARTITION BY instId, (ts/180000) ORDER BY ts ROWS BETWEEN 2 PRECEDING AND CURRENT ROW)
    GROUP BY instId, ts_group;
  '
  echo \"\$(date '+%F %T') [AGG3M] Done\" >> \$LOG
"

----- FILE: /opt/scalp/project/bin/ob_check.sh -----
#!/usr/bin/env bash
sqlite3 /opt/scalp/project/data/ob.db <<'SQL'
.headers on
.mode column
SELECT instId,
       COUNT(*) AS n,
       datetime(MAX(ts)/1000,'unixepoch','localtime') AS last_ts
FROM ohlcv_1m
GROUP BY instId
ORDER BY last_ts DESC
LIMIT 10;
SQL

----- FILE: /opt/scalp/project/bin/ob_freshness.sh -----
#!/usr/bin/env bash
set -euo pipefail

DB_OB="/opt/scalp/project/data/ob.db"

# TF -> (table:limit_age)
declare -A TF_TABLES=(
    ["1m"]="ohlcv_1m:60"
    ["3m"]="ohlcv_3m:180"
    ["5m"]="ohlcv_5m:300"
)

now_ms=$(($(date +%s) * 1000))

echo "=== LAST OB CANDLES USED ==="
printf "%-3s %-19s %-7s %s\n" "tf" "last_ts" "age_s" "status"
echo "--  -------------------  -------  -------"

for tf in 1m 3m 5m; do
    entry="${TF_TABLES[$tf]}"
    table="${entry%%:*}"
    limit="${entry##*:}"

    last_ts=$(sqlite3 "$DB_OB" "SELECT MAX(ts) FROM $table;")

    if [[ -z "$last_ts" || "$last_ts" == "NULL" ]]; then
        printf "%-3s %-19s %-7s %s\n" "$tf" "---" "---" "‚ùå"
        continue
    fi

    age=$(( (now_ms - last_ts) / 1000 ))
    last_human=$(date -d "@$((last_ts / 1000))" +"%Y-%m-%d %H:%M:%S")

    status="‚ö†Ô∏è"
    if (( age < limit )); then
        status="‚úÖ"
    fi

    printf "%-3s %-19s %-7d %s\n" "$tf" "$last_human" "$age" "$status"
done


----- FILE: /opt/scalp/project/bin/ofcr_dashboard.sh -----
#!/usr/bin/env bash

ROOT="/opt/scalp/project"
DB_G="$ROOT/data/gest.db"
DB_S="$ROOT/data/signals.db"
DB_O="$ROOT/data/opener.db"
DB_F="$ROOT/data/follower.db"
DB_C="$ROOT/data/closer.db"
DB_R="$ROOT/data/recorder.db"
DB_B="$ROOT/data/budget.db"

divider="------------------------------------------------------------"

echo ""
echo "============================================================"
echo "                SCALP ‚Äî OFCR PIPELINE DASHBOARD"
echo "============================================================"
echo ""

# ---------------------------------------------------------
# STATUS COUNT
# ---------------------------------------------------------
echo "[1] GEST ‚Äî Trades status count:"
sqlite3 "$DB_G" "
.headers off
.mode column
SELECT status, COUNT(*) 
FROM trades 
GROUP BY status 
ORDER BY status;
"
echo "$divider"

# ---------------------------------------------------------
# LAST SIGNALS
# ---------------------------------------------------------
echo "[2] Last signals:"
sqlite3 "$DB_S" "
.headers on
.mode column
SELECT uid, instId, side,
       reason, ctx,
       score_B,
       datetime(ts_signal/1000,'unixepoch','localtime') AS ts
FROM v_for_gest
ORDER BY ts_signal DESC
LIMIT 8;
"
echo "$divider"

# ---------------------------------------------------------
# OPENER VIEW
# ---------------------------------------------------------
echo "[3] Opener ‚Üí GEST:"
sqlite3 "$DB_O" "
.headers on
.mode column
SELECT *
FROM v_opener_for_gest
ORDER BY ts_open DESC
LIMIT 8;
"
echo "$divider"

# ---------------------------------------------------------
# FOLLOWER VIEW
# ---------------------------------------------------------
echo "[4] Follower ‚Üí GEST:"
sqlite3 "$DB_F" "
.headers on
.mode column
SELECT *
FROM v_follower_for_gest
ORDER BY ts_follow DESC
LIMIT 8;
"
echo "$divider"

# ---------------------------------------------------------
# CLOSER VIEW
# ---------------------------------------------------------
echo "[5] Closer ‚Üí GEST:"
sqlite3 "$DB_C" "
.headers on
.mode column
SELECT *
FROM v_for_closer
ORDER BY ts_close DESC
LIMIT 8;
"
echo "$divider"

# ---------------------------------------------------------
# RECORDER VIEW
# ---------------------------------------------------------
echo "[6] Recorder ‚Üí GEST:"
sqlite3 "$DB_G" "
.headers on
.mode column
SELECT *
FROM v_for_recorder
ORDER BY ts_close DESC
LIMIT 8;
"
echo "$divider"

# ---------------------------------------------------------
# LAST TRADES BY STAGE
# ---------------------------------------------------------
echo "[7] Trades by status:"
echo "NEW:"
sqlite3 "$DB_G" "
.headers off
.mode column
SELECT uid, instId,
       datetime(ts_signal/1000,'unixepoch','localtime')
FROM trades
WHERE status='new'
ORDER BY ts_signal DESC LIMIT 5;
"

echo ""
echo "OPENED:"
sqlite3 "$DB_G" "
SELECT uid, instId,
       entry, qty,
       datetime(ts_open/1000,'unixepoch','localtime')
FROM trades
WHERE status='opened'
ORDER BY ts_open DESC LIMIT 5;
"

echo ""
echo "FOLLOW:"
sqlite3 "$DB_G" "
SELECT uid, instId,
       sl_be, sl_trail, tp_dyn,
       datetime(ts_follow/1000,'unixepoch','localtime')
FROM trades
WHERE status='follow'
ORDER BY ts_follow DESC LIMIT 5;
"

echo ""
echo "TO_CLOSE:"
sqlite3 "$DB_G" "
SELECT uid, instId,
       price_to_close, reason_close,
       datetime(ts_follow/1000,'unixepoch','localtime')
FROM trades
WHERE status='to_close'
ORDER BY ts_follow DESC LIMIT 5;
"

echo ""
echo "CLOSED:"
sqlite3 "$DB_G" "
SELECT uid, instId,
       price_close, pnl,
       datetime(ts_close/1000,'unixepoch','localtime')
FROM trades
WHERE status='closed'
ORDER BY ts_close DESC LIMIT 5;
"

echo ""
echo "RECORDED:"
sqlite3 "$DB_G" "
SELECT uid, instId,
       pnl,
       datetime(ts_sync_close/1000,'unixepoch','localtime')
FROM trades
WHERE status='recorded'
ORDER BY ts_sync_close DESC LIMIT 5;
"
echo "$divider"

# ---------------------------------------------------------
# COHERENCE CHECK (TIMELINES)
# ---------------------------------------------------------
echo "[8] Timeline coherence check (ts_signal < ts_open < ts_follow < ts_close < ts_sync_close):"
sqlite3 "$DB_G" "
.headers on
.mode column
SELECT uid, instId,
       (ts_open     > ts_signal)     AS ok_open,
       (ts_follow   > ts_open)       AS ok_follow,
       (ts_close    > ts_follow)     AS ok_close,
       (ts_sync_close > ts_close)    AS ok_sync
FROM trades
WHERE status IN ('opened','follow','to_close','closed','recorded')
ORDER BY ts_signal DESC
LIMIT 20;
"
echo "$divider"

echo "DASHBOARD COMPLETED"
echo "============================================================"

----- FILE: /opt/scalp/project/bin/opener_clean.sh -----
#!/usr/bin/env bash
set -euo pipefail
DB="/opt/scalp/project/data/opener.db"
sqlite3 "$DB" "DELETE FROM trades_open_init WHERE ts_create < (strftime('%s','now')-7200)*1000;"
sqlite3 "$DB" "VACUUM;"
echo "[CLEANER] opener.db compacted"

----- FILE: /opt/scalp/project/bin/pnl_live.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3, time, os

DB_G = "/opt/scalp/project/data/gest.db"
DB_T = "/opt/scalp/project/data/t.db"
DB_F = "/opt/scalp/project/data/follower.db"

def conn(path):
    c = sqlite3.connect(path, timeout=2, isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=2000;")
    return c

# ---------------------------------------
# TICKS
# ---------------------------------------
def get_ticks():
    con = conn(DB_T)
    rows = con.execute("SELECT instId, lastPr FROM v_ticks_latest;").fetchall()
    con.close()
    return {inst: price for inst, price in rows}

# ---------------------------------------
# TRADES EN COURS (gest)
# ---------------------------------------
def get_trades():
    con = conn(DB_G)
    rows = con.execute("""
    SELECT uid, instId, side, entry, qty, lev, margin, ts_open, status
    FROM trades
    WHERE status='opened' OR status='follow';
    """).fetchall()
    con.close()
    return rows

# ---------------------------------------
# SL/TP dynamiques (follower)
# ---------------------------------------
def get_dyn(uid):
    con = conn(DB_F)
    row = con.execute("""
        SELECT sl_be, sl_trail, tp_dyn, price_to_close
        FROM trades_follow
        WHERE uid=? AND status='follow'
        LIMIT 1;
    """,(uid,)).fetchone()
    con.close()

    if row is None:
        return None, None, None, None
    return row

# ---------------------------------------
# PNL
# ---------------------------------------
def compute_pnl(side, entry, qty, last):
    if last is None:
        return 0.0, 0.0

    if side == "buy":
        pnl = (last - entry) * qty
    else:
        pnl = (entry - last) * qty

    pct = (pnl / (entry * qty) * 100) if entry > 0 else 0
    return pnl, pct


# ---------------------------------------
# MAIN LOOP ‚Äî refresh 1s
# ---------------------------------------
def main():

    while True:
        os.system("clear")

        ticks = get_ticks()
        trades = get_trades()

        print("")
        print("==============================================")
        print("          TRADES EN COURS ‚Äî PnL LIVE          ")
        print("==============================================\n")

        print("{:23} {:10} {:5} {:10} {:10} {:10} {:10} {:10}".format(
            "uid", "instId", "side", "last", "pnl_usdt",
            "pnl_pct", "sl_dyn", "tp_dyn"
        ))
        print("-"*95)

        for uid, instId, side, entry, qty, lev, margin, ts_open, status in trades:

            inst_plain = instId.replace("/", "")
            last = ticks.get(inst_plain)

            pnl_usdt, pnl_pct = compute_pnl(side, entry, qty, last)

            sl_be, sl_trail, tp_dyn, price_to_close = get_dyn(uid)

            # sl_dyn = sl_trail (s'il existe), sinon sl_be
            sl_dyn = sl_trail if sl_trail else sl_be

            print("{:23} {:10} {:5} {:10.4f} {:10.4f} {:10.2f} {:10} {:10}".format(
                uid,
                instId,
                side,
                last if last else 0,
                pnl_usdt,
                pnl_pct,
                f"{sl_dyn:.4f}" if sl_dyn else "-",
                f"{tp_dyn:.4f}" if tp_dyn else "-"
            ))

        print("\n(rafra√Æchissement : 1 seconde)")
        time.sleep(1)


if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/bin/recorder_clean.sh -----
#!/usr/bin/env bash
set -euo pipefail
DB="/opt/scalp/project/data/recorder.db"
sqlite3 "$DB" "DELETE FROM trades_record WHERE ts_record < (strftime('%s','now')-86400)*1000;"
sqlite3 "$DB" "VACUUM;"
echo "[CLEANER] recorder.db compacted"

----- FILE: /opt/scalp/project/bin/run_a_ctx.sh -----
#!/usr/bin/env bash
set -euo pipefail
cd /opt/scalp/project/scripts
/opt/scalp/project/venv/bin/python3 A_ctx.py

----- FILE: /opt/scalp/project/bin/run_a_feat.sh -----
#!/bin/bash
set -e
cd /opt/scalp/project/scripts
/opt/scalp/project/venv/bin/python3 A_feat_builder.py

----- FILE: /opt/scalp/project/bin/run_b_feat.sh -----
#!/usr/bin/env bash
set -euo pipefail

LOG="/opt/scalp/project/logs/b_feat.log"
echo "===== B_FEAT $(date '+%Y-%m-%d %H:%M:%S') =====" >> "$LOG"

# Activer le bon dossier scripts et le bon Python
cd /opt/scalp/project/scripts

/opt/scalp/project/venv/bin/python3 B_feat_builder.py >> "$LOG" 2>&1

echo "===== END FEAT =====" >> "$LOG"

----- FILE: /opt/scalp/project/bin/run_oa.sh -----
#!/bin/bash
set -e
cd /opt/scalp/project/scripts
/opt/scalp/project/venv/bin/python3 OA_ohlcv.py

----- FILE: /opt/scalp/project/bin/run_ob.sh -----
#!/usr/bin/env bash
set -euo pipefail

ROOT="/opt/scalp/project"
VENV="$ROOT/venv/bin/python3"

LOG_OB="$ROOT/logs/ob_collect.log"
LOG_B="$ROOT/logs/b_feat.log"

echo "===== OB $(date '+%Y-%m-%d %H:%M:%S') =====" >> "$LOG_OB"

cd "$ROOT/scripts"

# 1) OB COLLECT (1m / 3m / 5m + purge)
$VENV OB_collect.py >> "$LOG_OB" 2>&1

echo "===== END OB =====" >> "$LOG_OB"


# 2) B FEAT BUILDER (juste apr√®s OB)
echo "===== B_FEAT $(date '+%Y-%m-%d %H:%M:%S') =====" >> "$LOG_B"

$VENV B_feat_builder.py >> "$LOG_B" 2>&1

echo "===== END FEAT =====" >> "$LOG_B"

----- FILE: /opt/scalp/project/bin/run_universe.sh -----
#!/usr/bin/env bash
set -euo pipefail

CONF="${UNIVERSE_CONF:-/opt/scalp/project/conf/universe.conf.yaml}"
PY="/opt/scalp/project/venv/bin/python3"

export UNIVERSE_CONF="$CONF"

$PY /opt/scalp/project/scripts/universe_collector.py
$PY /opt/scalp/project/scripts/universe_runner.py

----- FILE: /opt/scalp/project/bin/start_follower.sh -----
#!/bin/bash
LOG="/opt/scalp/project/logs/follower.log"

echo "[start_follower] Stopping existing follower‚Ä¶"
pkill -f follower.py 2>/dev/null || true
sleep 1

echo "[start_follower] Starting follower‚Ä¶"
nohup python3 /opt/scalp/project/scripts/follower.py >> "$LOG" 2>&1 &

sleep 1
echo "[start_follower] Running:"
ps aux | grep follower.py | grep -v grep

echo "[start_follower] Tail log:"
tail -n 10 "$LOG"

----- FILE: /opt/scalp/project/bin/start_ticks.sh -----
#!/bin/bash
echo "[start_ticks] Stopping existing instances‚Ä¶"
 /opt/scalp/project/bin/stop_ticks.sh

echo "[start_ticks] Starting ticks.py‚Ä¶"
nohup python3 /opt/scalp/project/scripts/ticks.py \
     > /opt/scalp/project/logs/ticks.log 2>&1 &

sleep 1
echo "[start_ticks] Running:"
ps aux | grep ticks.py | grep -v grep

----- FILE: /opt/scalp/project/bin/stop_ticks.sh -----
#!/bin/bash
echo "[stop_ticks] Stopping ticks.py‚Ä¶"

pkill -TERM -f "/opt/scalp/project/scripts/ticks.py"
sleep 0.5
pkill -KILL -f "/opt/scalp/project/scripts/ticks.py"

echo "[stop_ticks] All ticks processes stopped."

----- FILE: /opt/scalp/project/bin/t_db_clean.sh -----
#!/usr/bin/env bash
set -euo pipefail

DB="/opt/scalp/project/data/t.db"

echo "===== CLEAN t.db WAL ($(date '+%F %T')) ====="

# Stop tick service
systemctl stop scalp-ticks.service 2>/dev/null || true
sleep 1

echo "[1] WAL FILES BEFORE"
ls -lh ${DB}*

echo "[2] CHECKPOINT WAL"
sqlite3 "$DB" "PRAGMA wal_checkpoint(FULL);"

echo "[3] Disable WAL"
sqlite3 "$DB" "PRAGMA journal_mode=DELETE;"

echo "[4] VACUUM (compact file)"
sqlite3 "$DB" "VACUUM;"

echo "[5] Re-enable WAL"
sqlite3 "$DB" "PRAGMA journal_mode=WAL;"

echo "[6] WAL FILES AFTER"
ls -lh ${DB}*

echo "===== CLEAN DONE ====="

systemctl start scalp-ticks.service 2>/dev/null || true

----- FILE: /opt/scalp/project/bin/t_db_reset_full.sh -----
#!/usr/bin/env bash
set -euo pipefail

DB="/opt/scalp/project/data/t.db"

echo "===== FULL RESET t.db ($(date '+%F %T')) ====="

systemctl stop scalp-ticks.service 2>/dev/null || true
sleep 1

echo "[1] Size BEFORE"
ls -lh ${DB}*

echo "[2] DELETE ALL ticks"
sqlite3 "$DB" "DELETE FROM ticks;"

echo "[3] CHECKPOINT WAL"
sqlite3 "$DB" "PRAGMA wal_checkpoint(FULL);"

echo "[4] Disable WAL"
sqlite3 "$DB" "PRAGMA journal_mode=DELETE;"

echo "[5] VACUUM"
sqlite3 "$DB" "VACUUM;"

echo "[6] Re-enable WAL"
sqlite3 "$DB" "PRAGMA journal_mode=WAL;"

echo "[7] Size AFTER"
ls -lh ${DB}*

echo "===== FULL RESET DONE ====="

systemctl start scalp-ticks.service 2>/dev/null || true

----- FILE: /opt/scalp/project/bin/t_ticks.sh -----
#!/usr/bin/env bash
set -euo pipefail
cd /opt/scalp/project
source venv/bin/activate
exec python3 scripts/T_ticks.py

----- FILE: /opt/scalp/project/bin/ticks_loop.sh -----
#!/bin/bash

ROOT="/opt/scalp/project"
cd "$ROOT"

LOG="$ROOT/logs/ticks_loop.log"
PY="$ROOT/venv/bin/python3"
SCRIPT="$ROOT/scripts/ticks.py"

echo "[ticks-loop] Starting infinite supervisor..." >> "$LOG"

while true; do
    echo "[ticks-loop] Launching ticks.py at $(date)" >> "$LOG"
    nice -n 10 $PY $SCRIPT >> "$LOG" 2>&1
    EXITCODE=$?
    echo "[ticks-loop] ticks.py exited with code $EXITCODE at $(date)" >> "$LOG"
    sleep 1
done

----- FILE: /opt/scalp/project/bin/u_universe.sh -----
#!/bin/bash
cd /opt/scalp/project
source venv/bin/activate
python3 scripts/U_universe.py

----- FILE: /opt/scalp/project/bin/upgrade_universe_sources.sh -----
#!/usr/bin/env bash
set -euo pipefail

ROOT="/opt/scalp/project"

MODE="${1:-}"
APPLY=0
if [[ "${MODE}" == "--apply" ]]; then
  APPLY=1
fi

TS="$(date +%Y%m%d_%H%M%S)"
BACKUP_DIR="${ROOT}/logs/universe_upgrade_backups_${TS}"
mkdir -p "${BACKUP_DIR}"

# Cibles: principalement Python (SQL embarqu√©). Tu peux √©tendre si besoin.
INCLUDES=( "*.py" "*.sh" "*.sql" "*.yaml" "*.yml" )

echo "[INFO] Root: ${ROOT}"
echo "[INFO] Backup dir: ${BACKUP_DIR}"
echo "[INFO] Mode: $([[ ${APPLY} -eq 1 ]] && echo APPLY || echo DRY-RUN)"
echo

# 1) Liste des occurrences exactes (avant)
echo "[INFO] Searching occurrences of 'FROM v_universe_tradable' (case-insensitive) ..."
FOUND_FILES=()
while IFS= read -r -d '' f; do
  if grep -RIn --binary-files=without-match -E "\bFROM[[:space:]]+universe\b|\bfrom[[:space:]]+universe\b" "$f" >/dev/null 2>&1; then
    FOUND_FILES+=("$f")
  fi
done < <(find "${ROOT}" -type f \( -name "*.py" -o -name "*.sh" -o -name "*.sql" -o -name "*.yaml" -o -name "*.yml" \) -print0)

if [[ ${#FOUND_FILES[@]} -eq 0 ]]; then
  echo "[OK] No occurrences found. Nothing to do."
  exit 0
fi

echo "[INFO] Files to modify (matched): ${#FOUND_FILES[@]}"
printf '%s\n' "${FOUND_FILES[@]}"
echo

# 2) DRY-RUN: afficher les lignes concern√©es
echo "[INFO] Preview matches:"
for f in "${FOUND_FILES[@]}"; do
  echo "----- ${f} -----"
  grep -nE "\bFROM[[:space:]]+universe\b|\bfrom[[:space:]]+universe\b" "${f}" || true
done
echo

if [[ ${APPLY} -ne 1 ]]; then
  echo "[INFO] DRY-RUN only. Re-run with --apply to perform modifications."
  exit 0
fi

# 3) APPLY: backup + replace
echo "[INFO] Applying replacements with backups ..."
for f in "${FOUND_FILES[@]}"; do
  # backup (preserve path structure)
  rel="${f#${ROOT}/}"
  mkdir -p "${BACKUP_DIR}/$(dirname "${rel}")"
  cp -a "${f}" "${BACKUP_DIR}/${rel}"

  # Replace only "FROM v_universe_tradable" (case-insensitive), preserving the "FROM"/"from" token as typed.
  perl -0777 -i -pe 's/(\bFROM\s+)universe\b/${1}v_universe_tradable/gi; s/(\bfrom\s+)universe\b/${1}v_universe_tradable/gi;' "${f}"
done

echo "[OK] Applied. Backups stored in: ${BACKUP_DIR}"
echo

# 4) Sanity check after
echo "[INFO] Post-check: remaining occurrences of 'FROM v_universe_tradable' ..."
REMAINING=0
for f in "${FOUND_FILES[@]}"; do
  if grep -nE "\bFROM[[:space:]]+universe\b|\bfrom[[:space:]]+universe\b" "${f}" >/dev/null 2>&1; then
    echo "[WARN] Still found in: ${f}"
    grep -nE "\bFROM[[:space:]]+universe\b|\bfrom[[:space:]]+universe\b" "${f}" || true
    REMAINING=1
  fi
done

if [[ ${REMAINING} -eq 0 ]]; then
  echo "[OK] No remaining 'FROM v_universe_tradable' patterns in previously matched files."
else
  echo "[WARN] Some occurrences remain. Inspect the warnings above (may be multi-line SQL / unusual formatting)."
fi

----- FILE: /opt/scalp/project/data/market_sql/market_score.sql -----
-- ============================================================
-- SCALP :: MARKET SCORE
-- ============================================================
-- Source : v_market_latest
-- Produit : v_market_scored
-- Usage   : OPENER (sizing), AUDIT, DEBUG
-- ============================================================

CREATE VIEW IF NOT EXISTS v_market_scored AS
SELECT
  instId,

  -- ==========================================================
  -- RAW MARKET DATA
  -- ==========================================================
  ts,
  last,
  ticks_5s,
  spread_bps,
  vol_norm,
  volume_24h,
  staleness_ms,
  spread_ok,
  liquidity_ok,

  -- ==========================================================
  -- SCORES
  -- ==========================================================

  -- Activity (0‚Äì40)
  MIN(40, ticks_5s * 4) AS ticks_score,

  -- Cost (0‚Äì30)
  MAX(0, 30 - spread_bps * 6) AS spread_score,

  -- Volatility (0‚Äì30)
  CASE
    WHEN vol_norm BETWEEN 0.25 AND 0.80 THEN 30
    WHEN vol_norm BETWEEN 0.10 AND 0.25 THEN 20
    WHEN vol_norm > 0.80              THEN 20
    WHEN vol_norm < 0.10              THEN 10
    ELSE 0
  END AS vol_score,

  -- ==========================================================
  -- TOTAL SCORE (0‚Äì100)
  -- ==========================================================
  (
    MIN(40, ticks_5s * 4)
    + MAX(0, 30 - spread_bps * 6)
    + CASE
        WHEN vol_norm BETWEEN 0.25 AND 0.80 THEN 30
        WHEN vol_norm BETWEEN 0.10 AND 0.25 THEN 20
        WHEN vol_norm > 0.80              THEN 20
        WHEN vol_norm < 0.10              THEN 10
        ELSE 0
      END
  ) AS market_score,

  -- ==========================================================
  -- RISK FACTOR (0.30 ‚Üí 1.00)
  -- ==========================================================
  MAX(
    0.30,
    MIN(
      1.00,
      (
        (
          MIN(40, ticks_5s * 4)
          + MAX(0, 30 - spread_bps * 6)
          + CASE
              WHEN vol_norm BETWEEN 0.25 AND 0.80 THEN 30
              WHEN vol_norm BETWEEN 0.10 AND 0.25 THEN 20
              WHEN vol_norm > 0.80              THEN 20
              WHEN vol_norm < 0.10              THEN 10
              ELSE 0
            END
        ) / 100.0
      )
    )
  ) AS market_risk_factor

FROM v_market_latest;

----- FILE: /opt/scalp/project/data/schema_ref.sql -----
-- === SCHEMA GLOBAL SCALP ===
-- G√©n√©r√© le 2026-02-13 10:49:44

-- --- oa.db ---
CREATE TABLE ohlcv_15m (
    instId TEXT NOT NULL,
    ts INTEGER NOT NULL,
    open REAL,
    high REAL,
    low REAL,
    close REAL,
    volume REAL,
    PRIMARY KEY (instId, ts)
)
CREATE TABLE ohlcv_30m (
    instId TEXT NOT NULL,
    ts INTEGER NOT NULL,
    open REAL,
    high REAL,
    low REAL,
    close REAL,
    volume REAL,
    PRIMARY KEY (instId, ts)
)
CREATE TABLE ohlcv_5m (
    instId TEXT NOT NULL,
    ts INTEGER NOT NULL,
    open REAL,
    high REAL,
    low REAL,
    close REAL,
    volume REAL,
    PRIMARY KEY (instId, ts)
)
CREATE TABLE sqlite_sequence(name,seq)
CREATE VIEW v_ohlcv_15m_latest AS
SELECT *
FROM ohlcv_15m
WHERE ts IN (
    SELECT ts FROM ohlcv_15m AS o2
    WHERE o2.instId = ohlcv_15m.instId
    ORDER BY ts DESC
    LIMIT 150
)
CREATE VIEW v_ohlcv_30m_latest AS
SELECT *
FROM ohlcv_30m
WHERE ts IN (
    SELECT ts FROM ohlcv_30m AS o2
    WHERE o2.instId = ohlcv_30m.instId
    ORDER BY ts DESC
    LIMIT 150
)
CREATE VIEW v_ohlcv_5m_latest AS
SELECT *
FROM ohlcv_5m
WHERE ts IN (
    SELECT ts FROM ohlcv_5m AS o2
    WHERE o2.instId = ohlcv_5m.instId
    ORDER BY ts DESC
    LIMIT 150
)

-- --- a.db ---
CREATE TABLE ctx_A (
    instId TEXT PRIMARY KEY,
    ts_updated INTEGER,

    trend_5m   TEXT,
    trend_15m  TEXT,
    trend_30m  TEXT,

    score_5m   REAL,
    score_15m  REAL,
    score_30m  REAL,

    score_final REAL,

    p_buy  REAL,
    p_sell REAL,
    p_hold REAL,

    ctx TEXT
, score_A REAL DEFAULT 0.5)
CREATE TABLE feat_15m (
    instId TEXT,
    ts INTEGER,
    o REAL, h REAL, l REAL, c REAL, v REAL,
    ema9 REAL,
    ema21 REAL,
    ema50 REAL,
    macd REAL,
    macdsignal REAL,
    macdhist REAL,
    rsi REAL,
    atr REAL,
    PRIMARY KEY(instId, ts)
)
CREATE TABLE feat_30m (
    instId TEXT,
    ts INTEGER,
    o REAL, h REAL, l REAL, c REAL, v REAL,
    ema9 REAL,
    ema21 REAL,
    ema50 REAL,
    macd REAL,
    macdsignal REAL,
    macdhist REAL,
    rsi REAL,
    atr REAL,
    PRIMARY KEY(instId, ts)
)
CREATE TABLE feat_5m (
    instId TEXT,
    ts INTEGER,
    o REAL, h REAL, l REAL, c REAL, v REAL,
    ema9 REAL,
    ema21 REAL,
    ema50 REAL,
    macd REAL,
    macdsignal REAL,
    macdhist REAL,
    rsi REAL,
    atr REAL,
    PRIMARY KEY(instId, ts)
)
CREATE TABLE ohlcv_15m (
    instId TEXT,
    ts INTEGER,
    o REAL, h REAL, l REAL, c REAL, v REAL,
    PRIMARY KEY(instId, ts)
)
CREATE TABLE ohlcv_30m (
    instId TEXT,
    ts INTEGER,
    o REAL, h REAL, l REAL, c REAL, v REAL,
    PRIMARY KEY(instId, ts)
)
CREATE TABLE ohlcv_5m (
    instId TEXT,
    ts INTEGER,
    o REAL, h REAL, l REAL, c REAL, v REAL,
    PRIMARY KEY(instId, ts)
)
CREATE VIEW v_atr_context AS
WITH
-- ------------------------------------------------------------
-- DERNIER ATR 5m
-- ------------------------------------------------------------
a5 AS (
    SELECT
        f.instId,
        f.atr       AS atr_5m,
        f.ts        AS ts_5m
    FROM feat_5m f
    JOIN (
        SELECT instId, MAX(ts) AS ts
        FROM feat_5m
        GROUP BY instId
    ) m
      ON f.instId = m.instId
     AND f.ts     = m.ts
),

-- ------------------------------------------------------------
-- DERNIER ATR 15m
-- ------------------------------------------------------------
a15 AS (
    SELECT
        f.instId,
        f.atr       AS atr_15m,
        f.ts        AS ts_15m
    FROM feat_15m f
    JOIN (
        SELECT instId, MAX(ts) AS ts
        FROM feat_15m
        GROUP BY instId
    ) m
      ON f.instId = m.instId
     AND f.ts     = m.ts
),

-- ------------------------------------------------------------
-- DERNIER ATR 30m
-- ------------------------------------------------------------
a30 AS (
    SELECT
        f.instId,
        f.atr       AS atr_30m,
        f.ts        AS ts_30m
    FROM feat_30m f
    JOIN (
        SELECT instId, MAX(ts) AS ts
        FROM feat_30m
        GROUP BY instId
    ) m
      ON f.instId = m.instId
     AND f.ts     = m.ts
)

-- ------------------------------------------------------------
-- CONTEXTE FINAL
-- ------------------------------------------------------------
SELECT
    a5.instId,

    a5.atr_5m,
    a15.atr_15m,
    a30.atr_30m,

    CASE
        WHEN a15.atr_15m > 0 THEN a5.atr_5m / a15.atr_15m
        ELSE NULL
    END AS ratio_5m_15m,

    CASE
        WHEN a30.atr_30m > 0 THEN a5.atr_5m / a30.atr_30m
        ELSE NULL
    END AS ratio_5m_30m,

    (strftime('%s','now')*1000 - a5.ts_5m) AS age_ms

FROM a5
LEFT JOIN a15 ON a5.instId = a15.instId
LEFT JOIN a30 ON a5.instId = a30.instId
CREATE VIEW v_atr_context_test AS
WITH
atr_5m AS (
    SELECT instId, atr, ts
    FROM feat_5m
),
atr_15m AS (
    SELECT instId, atr, ts
    FROM feat_15m
),
atr_30m AS (
    SELECT instId, atr, ts
    FROM feat_30m
),
joined AS (
    SELECT
        a5.instId,
        a5.atr  AS atr_5m,
        a15.atr AS atr_15m,
        a30.atr AS atr_30m,
        a5.ts   AS ts_5m
    FROM atr_5m a5
    LEFT JOIN atr_15m a15
        ON a15.instId = a5.instId
       AND a15.ts = (
            SELECT MAX(ts)
            FROM feat_15m
            WHERE instId = a5.instId
        )
    LEFT JOIN atr_30m a30
        ON a30.instId = a5.instId
       AND a30.ts = (
            SELECT MAX(ts)
            FROM feat_30m
            WHERE instId = a5.instId
        )
)
SELECT
    instId,
    atr_5m,
    atr_15m,
    atr_30m,
    CASE
        WHEN atr_15m > 0 THEN atr_5m / atr_15m
        ELSE NULL
    END AS ratio_5m_15m,
    CASE
        WHEN atr_30m > 0 THEN atr_5m / atr_30m
        ELSE NULL
    END AS ratio_5m_30m,
    (strftime('%s','now') * 1000 - ts_5m) AS age_ms
FROM joined
CREATE VIEW v_atr_latest_15m AS
SELECT
    f.instId,
    f.atr      AS atr_15m,
    f.ts       AS ts_15m,
    (strftime('%s','now')*1000 - f.ts) AS age_15m_ms
FROM feat_15m f
JOIN (
    SELECT instId, MAX(ts) AS ts
    FROM feat_15m
    GROUP BY instId
) last
ON f.instId = last.instId
AND f.ts = last.ts
CREATE VIEW v_atr_latest_30m AS
SELECT
    f.instId,
    f.atr      AS atr_30m,
    f.ts       AS ts_30m,
    (strftime('%s','now')*1000 - f.ts) AS age_30m_ms
FROM feat_30m f
JOIN (
    SELECT instId, MAX(ts) AS ts
    FROM feat_30m
    GROUP BY instId
) last
ON f.instId = last.instId
AND f.ts = last.ts
CREATE VIEW v_atr_latest_5m AS
SELECT
    f.instId,
    f.atr      AS atr_5m,
    f.ts       AS ts_5m,
    (strftime('%s','now')*1000 - f.ts) AS age_5m_ms
FROM feat_5m f
JOIN (
    SELECT instId, MAX(ts) AS ts
    FROM feat_5m
    GROUP BY instId
) last
ON f.instId = last.instId
AND f.ts = last.ts
CREATE VIEW v_ctx_latest AS
SELECT
    o.instId                         AS instId,
    o.ctx                            AS ctx,
    o.score_final                    AS score_C,
    o.ts                             AS ts_updated
FROM v_ctx_overview o
CREATE VIEW v_ctx_market_stats AS
SELECT
    COUNT(*)                                AS ctx_tested,
    SUM(ctx_ok)                             AS ctx_ok,

    SUM(ctx = 'bullish')                    AS bull_total,
    SUM(ctx = 'bullish' AND ctx_ok = 1)     AS bull_ok,

    SUM(ctx = 'bearish')                    AS bear_total,
    SUM(ctx = 'bearish' AND ctx_ok = 1)     AS bear_ok,

    SUM(ctx NOT IN ('bullish','bearish'))   AS flat_total,
    SUM(ctx NOT IN ('bullish','bearish') AND ctx_ok = 1) AS flat_ok
FROM v_ctx_signal_market_ok
CREATE VIEW v_ctx_overview AS
SELECT
    instId,
    DATETIME(ts_updated/1000,'unixepoch','localtime') AS ts,
    score_5m,
    score_15m,
    score_30m,
    score_final,
    CASE
        WHEN score_final IS NOT NULL THEN
            ROUND( exp(score_final/0.35)
                / (exp(score_final/0.35) + 1 + exp(-score_final/0.35)), 6 )
    END AS p_buy,
    CASE
        WHEN score_final IS NOT NULL THEN
            ROUND( exp(-score_final/0.35)
                / (exp(score_final/0.35) + 1 + exp(-score_final/0.35)), 6 )
    END AS p_sell,
    CASE
        WHEN score_final IS NOT NULL THEN
            ROUND( 1
                - (exp(score_final/0.35)
                   / (exp(score_final/0.35) + 1 + exp(-score_final/0.35)))
                - (exp(-score_final/0.35)
                   / (exp(score_final/0.35) + 1 + exp(-score_final/0.35))), 6 )
    END AS p_hold,
    ctx
FROM ctx_A
ORDER BY instId
CREATE VIEW v_ctx_signal AS
WITH base AS (
    SELECT
        c.instId,
        c.ctx,                -- bullish / bearish / flat
        c.score_C,
        c.ts_updated,
        a.atr_5m,
        a.atr_15m,
        a.atr_30m,
        a.ratio_5m_15m,
        a.ratio_5m_30m,
        a.age_ms
    FROM v_ctx_latest c
    LEFT JOIN v_atr_context a
        ON a.instId = c.instId
),
vol AS (
    SELECT *,
        CASE
            WHEN ratio_5m_15m IS NULL THEN 'UNKNOWN'
            WHEN ratio_5m_15m < 0.55 THEN 'COMPRESS'
            WHEN ratio_5m_15m > 1.30 THEN 'EXPAND'
            ELSE 'NORMAL'
        END AS vol_regime
    FROM base
)
SELECT
    instId,
    ctx,
    score_C,
    ts_updated,

    CASE
        WHEN ctx='bullish' AND score_C >  0.30 THEN 'buy'
        WHEN ctx='bearish' AND score_C < -0.30 THEN 'sell'
        ELSE NULL
    END AS side,

    CASE
        WHEN ctx IN ('bullish','bearish') AND ABS(score_C) >= 0.30 THEN 1
        ELSE 0
    END AS ctx_ok,

    atr_5m,
    atr_15m,
    atr_30m,
    ratio_5m_15m,
    ratio_5m_30m,
    vol_regime,

    CASE
        WHEN ctx IN ('bullish','bearish')
         AND ABS(score_C) >= 0.30
         AND vol_regime != 'UNKNOWN'
        THEN 1
        ELSE 0
    END AS ctx_ok_final,

    age_ms
FROM vol
CREATE VIEW v_ctx_signal_market_ok AS
SELECT
    c.instId,
    c.ctx,
    c.score_C,
    c.side,
    c.ctx_ok,
    c.ts_updated
FROM snap_ctx c
WHERE c.instId IN (
    SELECT instId
    FROM market_latest
    WHERE
        -- flags stricts market
        staleness_ms <= 1000
        AND ticks_5s >= 5
        AND spread_bps <= 5.0
)
CREATE VIEW v_ohlcv_freshness AS
SELECT
    instId,
    MAX(ts) AS ts,
    (strftime('%s','now') * 1000 - MAX(ts)) AS age_ms
FROM ohlcv_5m
GROUP BY instId

-- --- ob.db ---
CREATE TABLE feat_1m (
            instId TEXT NOT NULL,
            ts INTEGER NOT NULL,
            open REAL, high REAL, low REAL, close REAL, vol REAL,
            PRIMARY KEY(instId, ts)
        )
CREATE TABLE feat_3m (
            instId TEXT NOT NULL,
            ts INTEGER NOT NULL,
            open REAL, high REAL, low REAL, close REAL, vol REAL,
            PRIMARY KEY(instId, ts)
        )
CREATE TABLE feat_5m (
            instId TEXT NOT NULL,
            ts INTEGER NOT NULL,
            open REAL, high REAL, low REAL, close REAL, vol REAL,
            PRIMARY KEY(instId, ts)
        )
CREATE TABLE ohlcv_1m (
    instId TEXT NOT NULL,
    ts     INTEGER NOT NULL,
    o REAL, h REAL, l REAL, c REAL, v REAL,
    PRIMARY KEY(instId, ts)
)
CREATE TABLE ohlcv_3m (
    instId TEXT NOT NULL,
    ts     INTEGER NOT NULL,
    o REAL, h REAL, l REAL, c REAL, v REAL,
    PRIMARY KEY(instId, ts)
)
CREATE TABLE ohlcv_5m (
    instId TEXT NOT NULL,
    ts     INTEGER NOT NULL,
    o REAL, h REAL, l REAL, c REAL, v REAL,
    PRIMARY KEY(instId, ts)
)

-- --- b.db ---
CREATE TABLE feat_1m (
    instId TEXT,
    ts INTEGER,
    o REAL, h REAL, l REAL, c REAL, v REAL,
    ema9 REAL, ema12 REAL, ema21 REAL, ema26 REAL, ema50 REAL,
    macd REAL, macdsignal REAL, macdhist REAL,
    rsi REAL, atr REAL,
    bb_mid REAL, bb_std REAL, bb_up REAL, bb_low REAL, bb_width REAL,
    mom REAL, roc REAL, slope REAL,
    ctx TEXT, plus_di REAL, minus_di REAL, adx REAL,
    PRIMARY KEY(instId, ts)
)
CREATE TABLE feat_3m(
  instId TEXT,
  ts INT,
  o REAL,
  h REAL,
  l REAL,
  c REAL,
  v REAL,
  ema9 REAL,
  ema12 REAL,
  ema21 REAL,
  ema26 REAL,
  ema50 REAL,
  macd REAL,
  macdsignal REAL,
  macdhist REAL,
  rsi REAL,
  atr REAL,
  bb_mid REAL,
  bb_std REAL,
  bb_up REAL,
  bb_low REAL,
  bb_width REAL,
  mom REAL,
  roc REAL,
  slope REAL,
  ctx TEXT
, plus_di REAL, minus_di REAL, adx REAL)
CREATE TABLE feat_5m(
  instId TEXT,
  ts INT,
  o REAL,
  h REAL,
  l REAL,
  c REAL,
  v REAL,
  ema9 REAL,
  ema12 REAL,
  ema21 REAL,
  ema26 REAL,
  ema50 REAL,
  macd REAL,
  macdsignal REAL,
  macdhist REAL,
  rsi REAL,
  atr REAL,
  bb_mid REAL,
  bb_std REAL,
  bb_up REAL,
  bb_low REAL,
  bb_width REAL,
  mom REAL,
  roc REAL,
  slope REAL,
  ctx TEXT
, plus_di REAL, minus_di REAL, adx REAL)
CREATE VIEW v_atr_context AS
WITH
atr1 AS (
    SELECT instId, atr AS atr_1m, age_ms
    FROM v_feat_1m
),
atr3 AS (
    SELECT instId, atr AS atr_3m
    FROM v_feat_3m
),
atr5 AS (
    SELECT instId, atr AS atr_5m
    FROM v_feat_5m
),
rng AS (
    SELECT instId, compression_ok
    FROM v_range_1m
)
SELECT
    a1.instId,

    -- ATR par horizon
    a1.atr_1m,
    a3.atr_3m,
    a5.atr_5m,

    -- Ratios ATR (guards division)
    CASE
        WHEN a3.atr_3m > 0 THEN a1.atr_1m / a3.atr_3m
        ELSE NULL
    END AS ratio_1m_3m,

    CASE
        WHEN a5.atr_5m > 0 THEN a1.atr_1m / a5.atr_5m
        ELSE NULL
    END AS ratio_1m_5m,

    CASE
        WHEN a5.atr_5m > 0 THEN a3.atr_3m / a5.atr_5m
        ELSE NULL
    END AS ratio_3m_5m,

    -- Compression / contexte
    r.compression_ok,

    -- Fra√Æcheur
    a1.age_ms

FROM atr1 a1
LEFT JOIN atr3 a3 ON a1.instId = a3.instId
LEFT JOIN atr5 a5 ON a1.instId = a5.instId
LEFT JOIN rng  r  ON a1.instId = r.instId
CREATE VIEW v_feat_1m AS
SELECT
  f.instId,
  f.ts,
  f.o,
  f.h,
  f.l,
  f.c,
  f.v,
  f.ema9,
  f.ema12,
  f.ema21,
  f.ema26,
  f.ema50,
  f.macd,
  f.macdsignal,
  f.macdhist,
  f.rsi,
  f.atr,
  f.bb_mid,
  f.bb_std,
  f.bb_up,
  f.bb_low,
  f.bb_width,
  f.mom,
  f.roc,
  f.slope,
  f.ctx,
  f.plus_di,
  f.minus_di,
  f.adx,
  (strftime('%s','now')*1000 - f.ts) AS age_ms
FROM feat_1m f
JOIN (
  SELECT instId, MAX(ts) AS ts
  FROM feat_1m
  GROUP BY instId
) last
ON f.instId = last.instId
AND f.ts = last.ts
CREATE VIEW v_feat_3m AS
SELECT *,
       (strftime('%s','now')*1000 - ts) AS age_ms
FROM feat_3m
CREATE VIEW v_feat_5m AS
SELECT *,
       (strftime('%s','now')*1000 - ts) AS age_ms
FROM feat_5m
CREATE VIEW v_range_1m AS
WITH w AS (
  SELECT
    instId,
    ts,
    MAX(h) OVER win AS high_20,
    MIN(l) OVER win AS low_20,
    atr,
    bb_width,
    AVG(bb_width) OVER win AS bb_width_avg,
    ROW_NUMBER() OVER (PARTITION BY instId ORDER BY ts DESC) AS rn
  FROM feat_1m
  WINDOW win AS (
    PARTITION BY instId
    ORDER BY ts
    ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
  )
)
SELECT
  instId,
  ts,
  high_20,
  low_20,
  atr,
  bb_width,
  CASE
    WHEN bb_width_avg IS NOT NULL
     AND bb_width < bb_width_avg * 0.85
    THEN 1
    ELSE 0
  END AS compression_ok
FROM w
WHERE rn = 1

-- --- budget.db ---
CREATE TABLE balance (
    id INTEGER PRIMARY KEY CHECK (id = 1),
    balance_usdt REAL NOT NULL
)
CREATE TABLE budget_exposure (
    uid TEXT PRIMARY KEY,
    notional_engaged REAL NOT NULL,
    ts_update INTEGER NOT NULL
)
CREATE TABLE budget_state (
    id INTEGER PRIMARY KEY CHECK (id = 1),
    equity REAL NOT NULL,
    margin_used REAL NOT NULL,
    free_balance REAL NOT NULL,
    exposure REAL NOT NULL,
    ts_ms INTEGER NOT NULL
)
CREATE TABLE sqlite_sequence(name,seq)
CREATE VIEW v_balance AS
SELECT balance_usdt
FROM balance
WHERE id = 1
CREATE VIEW v_budget_overview AS
SELECT
  ROUND(balance,6) AS balance,
  ROUND(margin,6)  AS margin,
  ROUND(pnl_real,6) AS pnl_real,
  datetime(ts_update,'unixepoch','localtime') AS last_update
FROM budget_state
CREATE VIEW v_exposure AS
SELECT
    instId,
    ROUND(SUM(CASE WHEN type='margin' THEN amount ELSE 0 END),6) AS margin,
    ROUND(SUM(CASE WHEN type='pnl_real' THEN amount ELSE 0 END),6) AS pnl_real
FROM ledger
GROUP BY instId
ORDER BY ABS(margin) DESC

-- --- gest.db ---
CREATE TABLE exec_snapshot (
    uid             TEXT NOT NULL,
    exec_type       TEXT NOT NULL,
    side            TEXT NOT NULL,
    qty             REAL NOT NULL,
    price_exec      REAL NOT NULL,
    ts_exec         INTEGER NOT NULL,
    step            INTEGER NOT NULL,
    PRIMARY KEY (uid, exec_type, step)
)
CREATE TABLE gest (
    uid TEXT PRIMARY KEY,
    instId TEXT NOT NULL,
    side TEXT NOT NULL,

    ts_signal INTEGER NOT NULL,
    price_signal REAL DEFAULT 0,
    atr_signal REAL DEFAULT 0,

    reason TEXT,
    entry_reason TEXT,
    type_signal TEXT,

    score_C REAL,
    score_S REAL,
    score_H REAL,

    entry REAL,
    qty REAL,
    lev REAL,
    margin REAL,

    ts_open INTEGER,
    sl_init REAL,
    tp_init REAL,

    ts_follow INTEGER,
    sl_be REAL,
    sl_trail REAL,
    tp_dyn REAL,

    price_to_close REAL,
    ts_close INTEGER,
    price_close REAL,
    reason_close TEXT,
    ctx_close TEXT,
    price_exec_close REAL,

    pnl REAL,
    pnl_pct REAL,
    fee REAL,
    fee_total REAL,
    pnl_net REAL,

    wt_delta_t_ms INTEGER,
    wt_delta_price_pct REAL,
    wt_peak_ts INTEGER,
    wt_peak_price REAL,

    status TEXT NOT NULL,
    ts_status_update INTEGER
, instId_raw TEXT, strength REAL, ctx TEXT, atr REAL, of_imbalance REAL, confluence REAL, ts_created INTEGER, ts_updated INTEGER, skipped_reason TEXT, fire INTEGER DEFAULT 0, score_of     REAL, score_mo     REAL, score_br     REAL, score_force  REAL, qty_open REAL, pnl_realized REAL, qty_to_close REAL, close_step INTEGER DEFAULT 0, mfe_price REAL, mfe_ts INTEGER, mae_price REAL, mae_ts INTEGER, qty_in_exec      REAL DEFAULT 0, qty_out_exec     REAL DEFAULT 0, qty_open_exec    REAL DEFAULT 0, avg_entry_price  REAL, avg_exit_price   REAL, fee_total_exec   REAL DEFAULT 0, last_exec_step   INTEGER DEFAULT 0, fsm_state TEXT, qty_in REAL DEFAULT 0, qty_out REAL DEFAULT 0, fee_exec_total REAL DEFAULT 0, ts_first_open INTEGER, ts_last_close INTEGER, step INTEGER NOT NULL DEFAULT 0, nb_partial INTEGER DEFAULT 0, nb_pyramide INTEGER DEFAULT 0, nb_pyramide_post_partial INTEGER DEFAULT 0, last_partial_price REAL, last_partial_ts INTEGER, last_pyramide_price REAL, last_pyramide_ts INTEGER, mfe_local REAL, mae_local REAL, vwap_local REAL, cooldown_partial_ts INTEGER, cooldown_pyramide_ts INTEGER, regime TEXT, score_M REAL, mfe_atr REAL, mae_atr REAL, mfe_atr_partial REAL, mfe_atr_pyramide REAL, golden INTEGER DEFAULT 0, golden_ts INTEGER, first_partial_ts INTEGER, first_partial_mfe_atr REAL, first_pyramide_ts INTEGER, last_pyramide_mfe_atr REAL, last_action_ts INTEGER, last_emit_status, last_emit_ts, trigger_type TEXT, dec_mode TEXT, momentum_ok INTEGER DEFAULT 0, prebreak_ok INTEGER DEFAULT 0, pullback_ok INTEGER DEFAULT 0, compression_ok INTEGER DEFAULT 0, dec_ctx TEXT, dec_score_C REAL, ratio_to_open REAL, ratio_to_add  REAL, ratio_to_close REAL)
CREATE VIEW v_active_coins AS
SELECT DISTINCT
    instId
FROM gest
WHERE status IN (
    'armed',
    'fire',
    'opened',
    'follow',
    'to_close'
)
AND instId IS NOT NULL
CREATE VIEW v_exec_agg AS
SELECT
    uid,

    SUM(CASE
        WHEN exec_type IN ('open','pyramide')
        THEN qty ELSE 0 END) AS qty_in,

    SUM(CASE
        WHEN exec_type IN ('partial','close')
        THEN qty ELSE 0 END) AS qty_out,

    SUM(CASE
        WHEN exec_type IN ('open','pyramide')
        THEN qty * price_exec ELSE 0 END)
      / NULLIF(
          SUM(CASE
              WHEN exec_type IN ('open','pyramide')
              THEN qty ELSE 0 END),
          0
        ) AS avg_entry_price,

    SUM(CASE
        WHEN exec_type IN ('partial','close')
        THEN qty * price_exec ELSE 0 END)
      / NULLIF(
          SUM(CASE
              WHEN exec_type IN ('partial','close')
              THEN qty ELSE 0 END),
          0
        ) AS avg_exit_price,

    SUM(fee) AS fee_total,

    MIN(ts_exec) AS ts_first_exec,
    MAX(ts_exec) AS ts_last_exec,

    MAX(step) AS last_step

FROM exec
GROUP BY uid
CREATE VIEW v_exec_close_agg AS
SELECT
    uid,
    SUM(qty)                          AS qty_out_exec,
    SUM(qty * price_exec)             AS cash_out_exec,
    CASE
        WHEN SUM(qty) > 0
        THEN SUM(qty * price_exec) / SUM(qty)
        ELSE NULL
    END                               AS avg_exit_price,
    MAX(ts_exec)                      AS ts_last_exec,
    MAX(CASE WHEN exec_type='close' THEN 1 ELSE 0 END) AS has_close
FROM exec_snapshot
WHERE exec_type IN ('partial','close')
GROUP BY uid
CREATE VIEW v_exec_monitoring AS
SELECT
    uid,
    side,
    qty_open,
    avg_price_open,
    last_exec_type,
    last_step,
    last_price_exec,
    last_ts_exec
FROM v_exec_position
CREATE VIEW v_follower_monitoring AS
SELECT
    uid,
    mfe_price,
    mae_price,
    sl_trail,
    tp_dyn,
    atr_signal
FROM follower
WHERE status = 'follow'
CREATE VIEW v_gest AS
SELECT *
FROM gest
ORDER BY ts_signal DESC
CREATE VIEW v_gest_fsm AS
SELECT
    g.*,

    p.qty_open,
    p.avg_entry_price,
    p.avg_exit_price,
    p.fee_total,

    CASE
        WHEN g.status IN ('partial_done','pyramid_done') THEN 'follow'
        ELSE g.status
    END AS fsm_state

FROM gest g
LEFT JOIN v_position p ON p.uid = g.uid
CREATE VIEW v_gest_monitoring AS
SELECT
    uid,
    instId,
    side,
    entry,
    qty,
    status,
    ts_open
FROM gest
WHERE status IN (
    'open_req',
    'open_done',
    'follow',
    'partial_req',
    'partial_done',
    'pyramide_req',
    'pyramide_done',
    'close_req'
)
CREATE VIEW v_gest_open_inst AS
SELECT DISTINCT instId
FROM gest
WHERE status IN (
  'open_req',
  'open_done',
  'follow',
  'partial_done',
  'pyramide_done'
)
CREATE VIEW v_gest_status_count AS
SELECT
    status,
    COUNT(*) AS cnt
FROM gest
GROUP BY status
CREATE VIEW v_position AS
SELECT
    g.uid,
    g.instId,
    g.side,

    e.qty_in,
    e.qty_out,
    (e.qty_in - e.qty_out) AS qty_open,

    e.avg_entry_price,
    e.avg_exit_price,
    e.fee_total,

    e.ts_first_exec AS ts_first_open,
    e.ts_last_exec  AS ts_last_close,

    CASE
        WHEN (e.qty_in - e.qty_out) <= 1e-8
        THEN 'closed'
        ELSE 'open'
    END AS position_state,

    g.status AS fsm_state,
    g.ts_status_update

FROM gest g
LEFT JOIN v_exec_agg e USING(uid)
CREATE VIEW v_status AS
SELECT uid, fsm_state AS status
FROM v_gest_fsm
CREATE VIEW v_ticks_monitoring AS
SELECT
    instId,
    lastPr
FROM v_ticks_latest

-- --- h.db ---
CREATE TABLE h_stats (
    setup_hash TEXT PRIMARY KEY,

    instId TEXT,
    side TEXT,
    ctx TEXT,
    regime TEXT,
    tf_ref TEXT,
    time_bucket TEXT,
    score_C_bucket TEXT,
    score_S_bucket TEXT,

    n_trades INTEGER,
    win_rate REAL,
    expectancy REAL,
    avg_pnl REAL,
    profit_factor REAL,
    max_dd REAL,

    score_H REAL,

    ts_last_update INTEGER
)
CREATE VIEW v_score_h AS
SELECT
    instId,
    side,
    ctx,
    regime,
    tf_ref,
    time_bucket,
    score_C_bucket,
    score_S_bucket,
    score_H,
    n_trades,
    expectancy,
    ts_last_update
FROM h_stats

-- --- t.db ---
CREATE TABLE sqlite_sequence(name,seq)
CREATE TABLE ticks (
  instId TEXT PRIMARY KEY,
  lastPr REAL NOT NULL,
  ts_ms  INTEGER NOT NULL
, bidPr REAL, askPr REAL, spread_bps REAL)
CREATE TABLE ticks_hist (
  id     INTEGER PRIMARY KEY AUTOINCREMENT,
  instId TEXT NOT NULL,
  lastPr REAL NOT NULL,
  ts_ms  INTEGER NOT NULL
, bidPr REAL, askPr REAL, spread_bps REAL)
CREATE TABLE ticks_latest (
  instId TEXT PRIMARY KEY,
  lastPr REAL NOT NULL,
  ts_ms  INTEGER NOT NULL
)
CREATE VIEW v_exec_monitoring AS
SELECT
    uid,
    side,
    qty_open,
    avg_price_open,
    last_exec_type,
    last_step,
    last_price_exec,
    last_ts_exec
FROM v_exec_position
CREATE VIEW v_follower_monitoring AS
SELECT
    uid,
    mfe_price,
    mae_price,
    sl_trail,
    tp_dyn,
    atr_signal
FROM follower
WHERE status = 'follow'
CREATE VIEW v_gest_monitoring AS
SELECT
    uid,
    instId,
    side,
    entry,
    qty,
    status,
    ts_open
FROM gest
WHERE status IN (
    'open_req',
    'open_done',
    'follow',
    'partial_req',
    'partial_done',
    'pyramide_req',
    'pyramide_done',
    'close_req'
)
CREATE VIEW v_ticks_latest AS
SELECT th.instId,
       th.bidPr,
       th.askPr,
       th.lastPr,
       th.ts_ms
FROM ticks_hist th
JOIN (
    SELECT instId, MAX(ts_ms) AS max_ts
    FROM ticks_hist
    GROUP BY instId
) m
ON th.instId = m.instId AND th.ts_ms = m.max_ts
CREATE VIEW v_ticks_latest_spread AS
SELECT
    instId,
    lastPr,
    bidPr,
    askPr,
    spread_bps,
    ts_ms
FROM ticks
CREATE VIEW v_ticks_monitoring AS
SELECT
    instId,
    lastPr
FROM v_ticks_latest

-- --- u.db ---
-- (absent) u.db

-- --- triggers.db ---
CREATE TABLE trig_state (
    instId       TEXT PRIMARY KEY,
    last_ts      REAL,
    last_price   REAL,
    last_side    TEXT,
    last_uid     TEXT
)
CREATE TABLE triggers (
    uid           TEXT PRIMARY KEY,
    instId        TEXT NOT NULL,
    side          TEXT NOT NULL,

    entry_reason  TEXT NOT NULL,          -- ex: ORDERFLOW+MOMENTUM+BREAKOUT

    score_of      REAL NOT NULL,           -- [-1;+1]
    score_mo      REAL NOT NULL,
    score_br      REAL NOT NULL,
    score_force   REAL NOT NULL,           -- [0;1]

    price         REAL NOT NULL,
    atr           REAL NOT NULL,

    ts            INTEGER NOT NULL,
    status        TEXT NOT NULL             -- armed | fire | consumed
, ts_fire      INTEGER, ttl_ms       INTEGER, expires_at   INTEGER, validated    INTEGER DEFAULT 0, ts_validated INTEGER, mfe_early    REAL, mae_early    REAL, phase TEXT DEFAULT 'armed', fire_reason TEXT, ctx TEXT, score_ctx REAL, pos_in_range REAL, momentum_1 REAL, momentum_acc REAL, rsi REAL, adx REAL, macdhist REAL, bb_width REAL, armed_tick_count INTEGER DEFAULT 0, regime TEXT, range_high REAL, range_low REAL, armed_ticks INTEGER DEFAULT 0, pattern TEXT, ts_arm INTEGER, ts_expire INTEGER, score_M REAL, score_H REAL, trigger_type TEXT, momentum_ok INTEGER, prebreak_ok INTEGER, pullback_ok INTEGER, compression_ok INTEGER, dec_score_C REAL, dec_mode TEXT, extra_ctx, ts_created)
CREATE VIEW v_triggers_ctx_ok AS
SELECT
    t.*
FROM triggers t
WHERE t.instId IN (
    SELECT instId
    FROM snap_ctx
    WHERE ctx_ok = 1
)
CREATE VIEW v_triggers_fired AS
SELECT *
FROM triggers
WHERE status='fire'
CREATE VIEW v_triggers_latest AS
SELECT t.*
FROM triggers t
JOIN (
    SELECT instId, side, MAX(ts) AS max_ts
    FROM triggers
    GROUP BY instId, side
) last
ON t.instId = last.instId
AND t.side   = last.side
AND t.ts     = last.max_ts

-- --- signals.db ---
-- (absent) signals.db

-- --- opener.db ---
CREATE TABLE "opener" (
    uid TEXT NOT NULL,
    instId TEXT NOT NULL,
    side TEXT NOT NULL,
    qty REAL NOT NULL,
    lev REAL NOT NULL,
    ts_open INTEGER,
    price_exec_open REAL,
    status TEXT NOT NULL,
    exec_type TEXT NOT NULL,
    step INTEGER NOT NULL, ratio REAL, qty_raw REAL, qty_norm REAL, reject_reason TEXT,
    PRIMARY KEY (uid, exec_type, step)
)
CREATE TABLE "opener_backup_1768073835" (
    uid TEXT,
    instId TEXT,
    side TEXT,
    qty REAL,
    lev REAL,
    ts_open INTEGER,
    price_exec_open REAL,
    status TEXT,
    exec_type TEXT,
    step INTEGER,
    reason TEXT,
    PRIMARY KEY (uid, exec_type, step)
)
CREATE VIEW v_opener AS SELECT * FROM opener

-- --- follower.db ---
CREATE TABLE follower(
    uid TEXT PRIMARY KEY,
    ts_follow INTEGER DEFAULT 0,
    sl_be REAL DEFAULT 0,
    sl_trail REAL DEFAULT 0,
    tp_dyn REAL DEFAULT 0,
    atr_signal REAL DEFAULT 0,
    status TEXT NOT NULL DEFAULT 'follow'
, reason_close TEXT, price_to_close REAL, qty_to_close REAL, close_step INTEGER DEFAULT 0, mfe_price REAL, mfe_ts INTEGER, mae_price REAL, mae_ts INTEGER, reason TEXT, ts_decision INTEGER, nb_partial INTEGER DEFAULT 0, nb_pyramide INTEGER DEFAULT 0, nb_pyramide_post_partial INTEGER DEFAULT 0, last_partial_price REAL, last_partial_ts INTEGER, last_pyramide_price REAL, last_pyramide_ts INTEGER, mfe_local REAL, mae_local REAL, vwap_local REAL, cooldown_partial_ts INTEGER, cooldown_pyramide_ts INTEGER, regime TEXT DEFAULT 'scalp', qty_ratio REAL, step INTEGER DEFAULT 0, ensure_step_column INTEGER DEFAULT 0, mfe_atr REAL DEFAULT 0.0, mae_atr REAL DEFAULT 0.0, last_pyramide_mfe_atr REAL DEFAULT 0.0, last_partial_mfe_atr REAL DEFAULT 0.0, last_action_ts INTEGER DEFAULT 0, golden INTEGER NOT NULL DEFAULT 0, golden_ts INTEGER, sl_be_price REAL, sl_be_atr REAL, sl_be_ts INTEGER, sl_trail_active INTEGER DEFAULT 0, sl_trail_start_atr REAL, sl_trail_ts INTEGER, tp_dyn_atr REAL, tp_dyn_ts INTEGER, first_partial_ts INTEGER, first_partial_mfe_atr REAL, first_pyramide_ts INTEGER, last_decision_ts, instId TEXT, side TEXT, ratio_opened REAL DEFAULT 0.0, ratio_to_open REAL, ratio_to_close REAL, ratio_closed REAL DEFAULT 0, ratio_exposed REAL DEFAULT 0, trade_free INTEGER DEFAULT 0, req_step INTEGER DEFAULT 0, done_step INTEGER DEFAULT 0, qty_to_close_ratio REAL DEFAULT 0.0, qty_to_add_ratio REAL DEFAULT 0.0, ts_updated INTEGER, ratio_to_add REAL DEFAULT NULL, qty_open_snapshot REAL DEFAULT 0.0, qty_open REAL DEFAULT 0.0, avg_price_open REAL, last_exec_type TEXT, last_step INTEGER, last_price_exec REAL, last_ts_exec INTEGER)
CREATE VIEW trades_follow AS
SELECT
    uid,
    instId,
    side,
    status,
    mfe_atr     AS mfe,
    atr_signal  AS atr,
    nb_pyramide,
    last_pyramide_price,
    last_pyramide_ts,
    cooldown_pyramide_ts,
    step        AS pyramide_inflight_step,
    last_action_ts AS ts_update
FROM follower
CREATE VIEW v_follower AS
SELECT
    uid,
    ts_follow,
    sl_be,
    sl_trail,
    tp_dyn,
    status
FROM follower
CREATE VIEW v_follower_monitoring AS
SELECT
    uid,
    mfe_price,
    mae_price,
    sl_trail,
    tp_dyn,
    atr_signal
FROM follower
WHERE status = 'follow'
CREATE VIEW v_follower_state AS
SELECT
    uid,
    instId,
    side,
    status,
    step,

    -- ratios
    qty_ratio,
    qty_to_close_ratio,
    qty_to_add_ratio,

    -- FSM
    req_step,
    done_step,

    -- AGE
    (strftime('%s','now') - ts_follow / 1000) AS age_s,

    -- MFE / MAE
    mfe_atr,
    mae_atr,

    -- COUNTERS
    nb_partial,
    nb_pyramide,

    -- ‚úÖ EXEC MATERIALIS√â
    qty_open,
    avg_price_open,
    last_exec_type,
    last_step,
    last_price_exec,
    last_ts_exec

FROM follower
CREATE VIEW v_gest_monitoring AS
SELECT
    uid,
    instId,
    side,
    entry,
    qty,
    status,
    ts_open
FROM gest
WHERE status IN (
    'open_req',
    'open_done',
    'follow',
    'partial_req',
    'partial_done',
    'pyramide_req',
    'pyramide_done',
    'close_req'
)
CREATE VIEW v_ticks_monitoring AS
SELECT
    instId,
    lastPr
FROM v_ticks_latest

-- --- closer.db ---
CREATE TABLE closer (
    uid         TEXT    NOT NULL,
    exec_type   TEXT    NOT NULL,         -- 'partial' | 'close'
    side        TEXT    NOT NULL,
    qty         REAL    NOT NULL,
    price_exec  REAL,                     -- ‚¨ÖÔ∏è NULL autoris√© (IMPORTANT)
    fee         REAL    DEFAULT 0.0,
    step        INTEGER DEFAULT 0,
    reason      TEXT,
    ts_exec     INTEGER NOT NULL,
    status      TEXT    NOT NULL,         -- *_stdby | *_done
    instId      TEXT,
    close_step  INTEGER DEFAULT 0, ratio REAL, qty_raw REAL, qty_norm REAL, reject_reason TEXT,
    PRIMARY KEY (uid, exec_type, step)
)
CREATE TABLE trades_close (
    uid       TEXT PRIMARY KEY,
    instId    TEXT NOT NULL,
    price_exec REAL NOT NULL,
    ts_exec    INTEGER NOT NULL
)
CREATE VIEW v_closer AS
SELECT
    uid,
    instId,
    exec_type,
    side,
    qty,
    price_exec,
    fee,
    step,
    close_step,
    status,
    ts_exec
FROM closer
CREATE VIEW v_closer_for_gest AS
SELECT
    uid,
    ts_exec      AS ts_close,
    price_exec   AS price_close,
    NULL         AS pnl_usdt,
    NULL         AS pnl_pct,
    'closed'     AS status,
    NULL         AS reason_close
FROM trades_close
ORDER BY ts_exec ASC

-- --- recorder.db ---
CREATE TABLE recorder (
    uid TEXT PRIMARY KEY,
    instId TEXT NOT NULL,
    side TEXT NOT NULL,

    ts_signal INTEGER NOT NULL,
    price_signal REAL NOT NULL,
    entry_reason TEXT,
    type_signal TEXT,
    score_C REAL,
    score_S REAL,

    ts_open INTEGER,
    entry REAL,
    qty REAL,
    lev REAL,
    margin REAL,

    ts_close INTEGER,
    price_close REAL,
    reason_close TEXT,

    pnl REAL,
    pnl_pct REAL,
    pnl_net REAL,
    fee REAL,

    ctx_close TEXT,

    -- wticks analytics
    wt_delta_t_ms INTEGER,
    wt_delta_price_pct REAL,
    wt_peak_ts INTEGER,
    wt_peak_price REAL,

    ts_recorded INTEGER NOT NULL
, fee_total REAL DEFAULT 0, score_of    REAL, score_mo    REAL, score_br    REAL, score_force REAL, mfe_price REAL, mfe_ts INTEGER, mae_price REAL, mae_ts INTEGER, pnl_realized REAL, close_steps INTEGER, atr_signal REAL, price_exec_close REAL, score_H REAL, score_M REAL, nb_partial INTEGER DEFAULT 0, nb_pyramide INTEGER DEFAULT 0, mfe_atr REAL DEFAULT 0.0, mae_atr REAL DEFAULT 0.0, golden INTEGER DEFAULT 0, golden_ts INTEGER, last_action_ts INTEGER, last_pyramide_mfe_atr REAL, first_partial_mfe_atr REAL, trigger_type TEXT, dec_mode TEXT, momentum_ok INTEGER DEFAULT 0, prebreak_ok INTEGER DEFAULT 0, pullback_ok INTEGER DEFAULT 0, compression_ok INTEGER DEFAULT 0, dec_ctx TEXT, dec_score_C REAL)
CREATE TABLE recorder_steps (
    uid              TEXT NOT NULL,
    step             INTEGER NOT NULL,

    exec_type        TEXT,          -- open / partial / pyramide / close
    reason           TEXT,          -- SL_BE / SL_TRAIL / TP_DYN / SL_HARD / ‚Ä¶

    price_exec       REAL,
    qty_exec         REAL,
    ts_exec          INTEGER,

    sl_be            REAL,
    sl_trail         REAL,
    tp_dyn           REAL,

    mfe_atr          REAL,
    mae_atr          REAL,
    golden           INTEGER,

    PRIMARY KEY (uid, step)
)
CREATE VIEW v_edge_coin AS
WITH step_final AS (
    SELECT
        uid,
        MAX(step) AS step
    FROM recorder_steps
    GROUP BY uid
)
SELECT
    r.instId,
    COUNT(*) AS n_trades,
    AVG(r.pnl_realized) AS exp,
    SUM(CASE WHEN r.pnl_realized > 0 THEN r.pnl_realized ELSE 0 END)
        / NULLIF(-SUM(CASE WHEN r.pnl_realized < 0 THEN r.pnl_realized ELSE 0 END),0)
        AS pf,
    AVG(r.nb_pyramide) AS avg_pyramide,
    AVG(r.nb_partial)  AS avg_partial
FROM recorder r
JOIN step_final sf ON sf.uid = r.uid
WHERE sf.step >= 2
GROUP BY r.instId
CREATE VIEW v_rec_exit_perf AS
SELECT
  reason_close             AS exit_type,
  COUNT(*)                 AS n,
  AVG(pnl_realized)        AS exp,
  AVG(mfe_atr)             AS mfe_atr,
  AVG(mae_atr)             AS mae_atr,
  SUM(golden)              AS golden_n
FROM recorder
GROUP BY reason_close
CREATE VIEW v_rec_golden_perf AS
SELECT
  golden,
  COUNT(*)          AS n,
  AVG(pnl_realized) AS exp,
  AVG(mfe_atr)      AS mfe_atr,
  AVG(mae_atr)      AS mae_atr
FROM recorder
GROUP BY golden
CREATE VIEW v_rec_perf_exit_context AS
    SELECT
        r.reason_close         AS exit_type,
        COUNT(*)               AS n,
        AVG(r.pnl_realized)    AS exp,
        AVG(r.mfe_atr)         AS mfe,
        AVG(r.mae_atr)         AS mae,
        SUM(r.golden)          AS golden
    FROM recorder r
    GROUP BY r.reason_close
CREATE VIEW v_rec_perf_step_context AS
    SELECT
        r.close_steps          AS step,
        COUNT(*)               AS n,
        AVG(r.pnl_realized)    AS exp,
        AVG(r.mfe_atr)         AS mfe,
        AVG(r.mae_atr)         AS mae,
        SUM(r.golden)          AS golden
    FROM recorder r
    GROUP BY r.close_steps
CREATE VIEW v_rec_step_exit_perf AS
SELECT
  close_steps              AS step,
  reason_close             AS exit_type,
  COUNT(*)                 AS n,
  AVG(pnl_realized)        AS exp,
  SUM(CASE WHEN pnl_realized > 0 THEN pnl_realized ELSE 0 END)
    / NULLIF(ABS(SUM(CASE WHEN pnl_realized < 0 THEN pnl_realized ELSE 0 END)),0) AS pf,
  AVG(mfe_atr)             AS mfe_atr,
  AVG(mae_atr)             AS mae_atr,
  SUM(golden)              AS golden_n
FROM recorder
GROUP BY close_steps, reason_close
CREATE VIEW v_rec_step_perf AS
SELECT
  close_steps              AS step,
  COUNT(*)                 AS n,
  AVG(pnl_realized)        AS exp,
  AVG(mfe_atr)             AS mfe_atr,
  AVG(mae_atr)             AS mae_atr,
  SUM(golden)              AS golden_n
FROM recorder
GROUP BY close_steps
CREATE VIEW v_recorder AS
SELECT
    uid,
    ts_recorded
FROM recorder
CREATE VIEW v_recorder_dominant_detector AS
SELECT *,
CASE
    WHEN score_of >= score_mo AND score_of >= score_br THEN 'ORDERFLOW'
    WHEN score_mo >= score_of AND score_mo >= score_br THEN 'MOMENTUM'
    WHEN score_br >= score_of AND score_br >= score_mo THEN 'BREAKOUT'
    ELSE 'MIXED'
END AS dominant_detector
FROM recorder
CREATE VIEW v_recorder_duration AS
SELECT
    uid,
    instId,
    side,
    entry,
    price_close,
    pnl,
    pnl_pct,
    pnl_net,
    reason_close,
    ts_open,
    ts_close,
    (ts_close - ts_open) / 1000.0 AS dur_s,

    CASE
        WHEN (ts_close - ts_open) < 500 THEN '0‚Äì0.5s'
        WHEN (ts_close - ts_open) < 1000 THEN '0.5‚Äì1s'
        WHEN (ts_close - ts_open) < 3000 THEN '1‚Äì3s'
        WHEN (ts_close - ts_open) < 5000 THEN '3‚Äì5s'
        WHEN (ts_close - ts_open) < 10000 THEN '5‚Äì10s'
        WHEN (ts_close - ts_open) < 30000 THEN '10‚Äì30s'
        WHEN (ts_close - ts_open) < 60000 THEN '30‚Äì60s'
        WHEN (ts_close - ts_open) < 120000 THEN '1‚Äì2m'
        WHEN (ts_close - ts_open) < 300000 THEN '2‚Äì5m'
        WHEN (ts_close - ts_open) < 600000 THEN '5‚Äì10m'
        WHEN (ts_close - ts_open) < 1800000 THEN '10‚Äì30m'
        ELSE '>30m'
    END AS dur_bucket,

    CASE WHEN pnl > 0 THEN 1 ELSE 0 END AS is_win,
    CASE WHEN pnl < 0 THEN 1 ELSE 0 END AS is_loss
FROM recorder
WHERE ts_open IS NOT NULL
  AND ts_close IS NOT NULL
CREATE VIEW v_recorder_for_gest AS
SELECT
  uid, status, ts_record
FROM trades_record
WHERE status='recorded'
ORDER BY ts_record DESC
CREATE VIEW v_recorder_score_ranges AS
SELECT *,
CASE
    WHEN score_force < 0.6 THEN '<0.6'
    WHEN score_force < 0.7 THEN '0.6-0.7'
    WHEN score_force < 0.8 THEN '0.7-0.8'
    ELSE '>0.8'
END AS force_bucket
FROM recorder
CREATE VIEW v_recorder_stats_by_duration AS
SELECT
    dur_bucket,
    COUNT(*) AS trades,
    SUM(is_win) AS wins,
    SUM(is_loss) AS losses,
    ROUND(100.0 * SUM(is_win) / COUNT(*), 2) AS winrate_pct,
    ROUND(SUM(pnl), 6) AS pnl_total,
    ROUND(AVG(pnl), 6) AS pnl_avg,
    ROUND(AVG(pnl_pct), 4) AS pct_avg,
    ROUND(AVG(dur_s), 3) AS dur_avg_s
FROM v_recorder_duration
GROUP BY dur_bucket
ORDER BY dur_avg_s
CREATE VIEW v_recorder_steps AS
SELECT
    rs.uid,
    rs.step,

    rs.exec_type,
    rs.reason,

    rs.price_exec,
    rs.qty_exec,
    rs.ts_exec,

    rs.sl_be,
    rs.sl_trail,
    rs.tp_dyn,

    rs.mfe_atr,
    rs.mae_atr,
    rs.golden,

    r.type_signal,
    r.dec_mode,
    r.instId,
    r.side,
    r.entry,
    r.atr_signal,

    r.pnl_realized,
    r.ts_open,
    r.ts_close

FROM recorder_steps rs
JOIN recorder r
  ON r.uid = rs.uid
CREATE VIEW v_score_H_source AS
SELECT
  instId,
  side,
  entry_reason,
  COUNT(*)                                   AS n,
  AVG(pnl_net > 0)                           AS winrate,
  AVG(pnl_net)                               AS expectancy,
  AVG(ABS(mae_price))                        AS risk,
  AVG(mfe_price)                             AS quality
FROM recorder
WHERE pnl_net IS NOT NULL
GROUP BY instId, side, entry_reason
CREATE VIEW v_trade_stats AS
SELECT
    r.uid,
    r.instId,
    r.side,

    r.entry,
    r.price_close,
    r.qty,

    r.pnl,
    r.pnl_net,
    r.fee_total,

    -- ------------------------------------------------------------------------
    -- Temps
    -- ------------------------------------------------------------------------
    r.ts_open,
    r.ts_close,
    (r.ts_close - r.ts_open) / 1000.0 AS duration_s,

    -- ------------------------------------------------------------------------
    -- Scores
    -- ------------------------------------------------------------------------
    r.score_C,
    r.score_of,
    r.score_mo,
    r.score_br,
    r.score_force,

    -- ------------------------------------------------------------------------
    -- MFE / MAE absolus
    -- ------------------------------------------------------------------------
    r.mfe_price,
    r.mae_price,

    -- ------------------------------------------------------------------------
    -- MFE / MAE normalis√©s en prix
    -- (ATR manquant = neutralis√©)
    -- ------------------------------------------------------------------------
    CASE
        WHEN r.entry > 0 THEN
            (r.mfe_price - r.entry) / r.entry
        ELSE NULL
    END AS mfe_pct,

    CASE
        WHEN r.entry > 0 THEN
            (r.entry - r.mae_price) / r.entry
        ELSE NULL
    END AS mae_pct,

    -- ------------------------------------------------------------------------
    -- Efficacit√© de sortie
    -- % du MFE r√©ellement captur√©
    -- ------------------------------------------------------------------------
    CASE
        WHEN r.mfe_price IS NOT NULL
         AND r.entry IS NOT NULL
         AND r.price_close IS NOT NULL
         AND ABS(r.mfe_price - r.entry) > 0
        THEN
            (r.price_close - r.entry)
            / (r.mfe_price - r.entry)
        ELSE NULL
    END AS exit_efficiency,

    -- ------------------------------------------------------------------------
    -- Flags structurels
    -- ------------------------------------------------------------------------
    CASE
        WHEN r.close_steps > 0 THEN 1 ELSE 0
    END AS has_partial,

    CASE
        WHEN r.qty IS NOT NULL
         AND r.qty > 0
         AND r.qty < (
             SELECT MAX(qty) FROM recorder r2 WHERE r2.uid = r.uid
         )
        THEN 1 ELSE 0
    END AS has_pyramid,

    r.close_steps,
    r.entry_reason,
    r.type_signal,

    r.ts_recorded

FROM recorder r
CREATE VIEW v_trades_analyse AS
SELECT
    uid,
    instId,
    side,
    reason AS reason_signal,
    reason_close,
    price_signal,
    atr_signal,
    score_A,
    score_B,
    ts_open,
    ts_close,
    entry,
    price_close,
    sl_init,
    tp_init,
    sl_be,
    sl_trail,
    tp_dyn,
    price_to_close,
    pnl
FROM trades_record
ORDER BY ts_open ASC

-- === FIN ===

----- FILE: /opt/scalp/project/mfe_raw.txt -----

----- FILE: /opt/scalp/project/requirements.txt -----
ccxt>=4.2.0
pandas>=2.0.0
numpy>=1.24.0
requests>=2.31.0
python-dateutil>=2.8.2
aiohttp>=3.9.0
matplotlib>=3.8.0

----- FILE: /opt/scalp/project/scripts/A_analyse.py -----
#!/usr/bin/env python3
import sqlite3, math, time

DB_A = "/opt/scalp/project/data/a.db"
DB_U = "/opt/scalp/project/data/universe.db"
DB_OB = "/opt/scalp/project/data/ob.db"
TF = "5m"

def softmax(x):
    e = [math.exp(i) for i in x]
    s = sum(e)
    return [v/s for v in e]

def get_universe():
    con = sqlite3.connect(DB_U)
    rows = con.execute("SELECT instId FROM v_universe_tradable ORDER BY instId").fetchall()
    con.close()
    return [r[0] for r in rows]

def load_ob(inst):
    con = sqlite3.connect(DB_OB)
    row = con.execute(f"SELECT rsi FROM ob_{TF} WHERE instId=? ORDER BY ts DESC LIMIT 1", (inst,)).fetchone()
    con.close()
    return row[0] if row else None

def compute_ctx(rsi):
    if rsi < 30: return "bullish"
    if rsi > 70: return "bearish"
    if 45 <= rsi <= 55: return "range"
    return "none"

def compute_score_A(ctx):
    if ctx == "bullish": return 0.8
    if ctx == "bearish": return -0.8
    if ctx == "range": return 0.0
    return 0.0

def run():
    insts = get_universe()
    now = int(time.time()*1000)
    out = []

    for inst in insts:
        rsi = load_ob(inst)
        if rsi is None:
            continue
        ctx = compute_ctx(rsi)
        score_A = compute_score_A(ctx)
        p_buy, p_sell = softmax([score_A, -score_A])
        out.append((inst, now, 0.0, score_A, p_buy, p_sell, ctx))

    con = sqlite3.connect(DB_A)
    con.execute("DELETE FROM ctx_a_latest")
    con.executemany("INSERT INTO ctx_a_latest(instId,ts,score_U,score_A,p_buy,p_sell,ctx) VALUES (?,?,?,?,?,?,?)", out)
    con.commit()
    con.close()

if __name__ == "__main__":
    run()

----- FILE: /opt/scalp/project/scripts/A_config.py -----
#!/usr/bin/env python3

# DB paths
DB_A  = "/opt/scalp/project/data/a.db"
DB_OB = "/opt/scalp/project/data/ob.db"
DB_OA = "/opt/scalp/project/data/oa.db"
DB_U  = "/opt/scalp/project/data/u.db"

# TF used
TF_SHORT = "5m"
TF_MED   = "15m"
TF_LONG  = "30m"

# Weights for score (softmax later)
W_SHORT = 0.50
W_MED   = 0.30
W_LONG  = 0.20

----- FILE: /opt/scalp/project/scripts/A_ctx.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3, pandas as pd, numpy as np, time, logging

ROOT="/opt/scalp/project"
DB_A=f"{ROOT}/data/a.db"
LOG=f"{ROOT}/logs/a_ctx.log"

logging.basicConfig(
    filename=LOG,
    level=logging.INFO,
    format="%(asctime)s A_CTX %(levelname)s %(message)s"
)
log=logging.getLogger("A_CTX")

# -------------------------------------------------------------
# DB
# -------------------------------------------------------------
def conn():
    c=sqlite3.connect(DB_A,timeout=5,isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=3000;")
    return c

# -------------------------------------------------------------
# Softmax tri-classe
# -------------------------------------------------------------
def softmax_3(x,tau=0.35):
    e_pos=np.exp(x/tau)
    e_neg=np.exp(-x/tau)
    denom=e_pos+1+e_neg
    return e_pos/denom, e_neg/denom, 1 - (e_pos+e_neg)/denom

# -------------------------------------------------------------
# Score TF (ema / macd / rsi)
# -------------------------------------------------------------
def compute_tf_score(row):
    # ema trend replacement (ema21 vs ema50)
    s_ema = np.tanh((row["ema21"] - row["ema50"]) / (row["atr"]*3 + 1e-9))

    # macd hist signal
    s_macd = np.tanh(row["macdhist"] / (abs(row["macdhist"])+1e-9))

    # rsi normalis√©
    s_rsi = (row["rsi"] - 50) / 50

    # pond√©rations pro et simple
    w_ema = 0.45
    w_macd = 0.35
    w_rsi = 0.20

    S = (
        w_ema*s_ema +
        w_macd*s_macd +
        w_rsi*s_rsi
    ) / (w_ema+w_macd+w_rsi)

    return float(S)

# -------------------------------------------------------------
# MAIN
# -------------------------------------------------------------
def main():
    log.info("A_CTX START")

    c = conn()

    tf_map = {
        "5m":  ("feat_5m",  0.20),
        "15m": ("feat_15m", 0.30),
        "30m": ("feat_30m", 0.50)
    }

    # Charger les derni√®res valeurs par TF
    dfs={}
    for tf,(table,_) in tf_map.items():
        dfs[tf]=pd.read_sql_query(
            f"""
            SELECT instId, ts, o,h,l,c,v,
                   ema9,ema21,ema50,
                   macd,macdsignal,macdhist,
                   rsi,atr
            FROM {table}
            WHERE ts=(SELECT MAX(ts) FROM {table})
            """,
            c
        )

    # Merge sur la base 30m (r√©f√©rence)
    merged = dfs["30m"][["instId"]].copy()
    for tf,df in dfs.items():
        df=df.add_suffix(f"_{tf}")
        df=df.rename(columns={f"instId_{tf}":"instId"})
        merged=merged.merge(df,on="instId",how="inner")

    out=[]

    for _,row in merged.iterrows():
        inst=row["instId"]

        # Compute score for each TF
        scores={}
        for tf,_ in tf_map.items():
            r=row.filter(regex=f"_{tf}$")
            r.index = r.index.str.replace(f"_{tf}","")
            scores[tf]=compute_tf_score(r)

        # Multi-TF
        S_final = (
            scores["5m"]*0.20 +
            scores["15m"]*0.30 +
            scores["30m"]*0.50
        )

        # softmax tri class
        p_buy, p_sell, p_hold = softmax_3(S_final)

        if p_buy>=0.60:
            ctx="bullish"
        elif p_sell>=0.60:
            ctx="bearish"
        else:
            ctx="flat"

        log.info(f"{inst} ctx={ctx} S={S_final:.4f}")

        out.append((
            inst,
            int(time.time()*1000),
            scores["5m"], scores["15m"], scores["30m"],
            S_final,
            p_buy, p_sell, p_hold,
            ctx
        ))

    # write DB
    c.executemany("""
    INSERT OR REPLACE INTO ctx_A (
        instId, ts_updated,
        score_5m, score_15m, score_30m,
        score_final,
        p_buy, p_sell, p_hold,
        ctx
    )
    VALUES (?,?,?,?,?,?,?,?,?,?)
    """, out)

    log.info("A_CTX DONE")

if __name__=="__main__":
    main()

----- FILE: /opt/scalp/project/scripts/A_ctx_dash.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3
from datetime import datetime

DB = "/opt/scalp/project/data/a.db"

def conn():
    return sqlite3.connect(DB, timeout=3)

def fmt_ts_ms(ts_ms):
    if ts_ms is None:
        return "n/a"
    try:
        return datetime.fromtimestamp(ts_ms / 1000).strftime("%Y-%m-%d %H:%M:%S")
    except Exception:
        return str(ts_ms)

def main():
    c = conn()

    # On lit directement ctx_A (photo actuelle compl√®te)
    rows = c.execute("""
        SELECT instId,
               ctx,
               score_final,
               ts_updated,
               score_5m,
               score_15m,
               score_30m
        FROM ctx_A
        ORDER BY score_final DESC;
    """).fetchall()

    if not rows:
        print("===== CTX DASH (A) =====")
        print("Aucun contexte disponible (ctx_A vide).")
        return

    # Synth√®se par cat√©gorie
    nb_bull = sum(1 for r in rows if r[1] == "bullish")
    nb_bear = sum(1 for r in rows if r[1] == "bearish")
    nb_flat = sum(1 for r in rows if r[1] == "flat")

    print("===== CTX DASH (A) =====\n")

    print("--- Synth√®se ---")
    print(" nb_bullish  nb_bearish  nb_flat")
    print(f"{nb_bull:>11}{nb_bear:>12}{nb_flat:>9}\n")

    print("--- Exemples (2 par cat√©gorie) ---")
    print("   type   instId      score_final")

    # Top 2 bullish
    bulls = [r for r in rows if r[1] == "bullish"][:5]
    for instId, ctx, score_final, *_ in bulls:
        print(f"bullish {instId:<8} {score_final}")

    # Top 2 bearish
    bears = [r for r in rows if r[1] == "bearish"][:5]
    for instId, ctx, score_final, *_ in bears:
        print(f"bearish {instId:<8} {score_final}")

    # Top 2 flat
    flats = [r for r in rows if r[1] == "flat"][:2]
    for instId, ctx, score_final, *_ in flats:
        print(f"flat    {instId:<8} {score_final}")

    print("\n--- Contexte complet ---")
    print("  instId           ts_local              ctx     score_final   score_5m     score_15m    score_30m")

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/A_feat.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3, logging, time
import numpy as np
import pandas as pd

ROOT = "/opt/scalp/project"
DB_OA = f"{ROOT}/data/oa.db"
DB_A  = f"{ROOT}/data/a.db"
LOG   = f"{ROOT}/logs/a_feat.log"

logging.basicConfig(
    filename=LOG,
    level=logging.INFO,
    format="%(asctime)s A_FEAT %(levelname)s %(message)s"
)
log = logging.getLogger("A_FEAT")

# ==========================================================
# DB
# ==========================================================
def conn(path):
    c = sqlite3.connect(path, timeout=10, isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=5000;")
    return c

# ==========================================================
# INDICATEURS
# ==========================================================
def ema(series, period):
    return series.ewm(span=period, adjust=False).mean()

def rsi(series, period=14):
    delta = series.diff()
    up = delta.clip(lower=0)
    down = -delta.clip(upper=0)
    rs = up.rolling(period).mean() / down.rolling(period).mean()
    return 100 - 100 / (1 + rs)

def macd_line(c, fast=12, slow=26):
    return ema(c, fast) - ema(c, slow)

def atr(df, period=14):
    tr = np.maximum(df["h"] - df["l"],
                    np.maximum((df["h"] - df["c"].shift()).abs(),
                               (df["l"] - df["c"].shift()).abs()))
    return tr.rolling(period).mean()

def bollinger(c, period=20, mult=2):
    mid = c.rolling(period).mean()
    std = c.rolling(period).std()
    up = mid + mult * std
    low = mid - mult * std
    return mid, up, low

# ==========================================================
# LOAD OA OHLCV
# ==========================================================
def load_ohlcv(tf):
    table = f"ohlcv_{tf}"
    co = conn(DB_OA)
    df = pd.read_sql_query(f"SELECT * FROM {table} ORDER BY instId, ts", co)
    co.close()
    return df

# ==========================================================
# BUILD FEAT
# ==========================================================
def build_tf(df, tf, coa):
    """
    df : OHLCV complet (5m/15m/30m)
    coa : connexion a.db
    """
    log.info(f"TF {tf}: start")

    feats_table = f"feat_{tf}"

    # Table
    coa.execute(f"""
    CREATE TABLE IF NOT EXISTS {feats_table}(
        instId TEXT,
        ts INTEGER,
        o REAL, h REAL, l REAL, c REAL, v REAL,
        ema21 REAL, ema50 REAL,
        rsi REAL,
        macd REAL,
        atr REAL,
        bb_mid REAL, bb_up REAL, bb_low REAL,
        ctx TEXT,
        PRIMARY KEY(instId, ts)
    );
    """)

    insts = df["instId"].unique()

    for inst in insts:
        d = df[df.instId == inst].copy()
        if len(d) < 60:
            continue

        d["ema21"] = ema(d["c"], 21)
        d["ema50"] = ema(d["c"], 50)
        d["rsi"]   = rsi(d["c"], 14)
        d["macd"]  = macd_line(d["c"])
        d["atr"]   = atr(d)
        d["bb_mid"], d["bb_up"], d["bb_low"] = bollinger(d["c"])

        # soft context baseline
        ctx = []
        for i in range(len(d)):
            if d["ema21"].iloc[i] > d["ema50"].iloc[i]:
                ctx.append("bullish")
            elif d["ema21"].iloc[i] < d["ema50"].iloc[i]:
                ctx.append("bearish")
            else:
                ctx.append("neutral")
        d["ctx"] = ctx

        rows = d[[
            "instId","ts","o","h","l","c","v",
            "ema21","ema50","rsi","macd","atr",
            "bb_mid","bb_up","bb_low","ctx"
        ]].values.tolist()

        coa.executemany(
            f"INSERT OR REPLACE INTO {feats_table} VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)",
            rows
        )

        # purge
        cut = coa.execute(
            f"SELECT ts FROM {feats_table} WHERE instId=? ORDER BY ts DESC LIMIT 1 OFFSET 150",
            (inst,)
        ).fetchone()
        if cut:
            cutoff = cut[0]
            coa.execute(
                f"DELETE FROM {feats_table} WHERE instId=? AND ts < ?",
                (inst, cutoff)
            )

    log.info(f"TF {tf}: done")

# ==========================================================
# MAIN
# ==========================================================
def main():
    log.info("A_FEAT START")

    coa = conn(DB_A)

    # load OA
    df5  = load_ohlcv("5m")
    df15 = load_ohlcv("15m")
    df30 = load_ohlcv("30m")

    # compute 3 TF
    build_tf(df5,  "5m",  coa)
    build_tf(df15, "15m", coa)
    build_tf(df30, "30m", coa)

    coa.commit()
    coa.close()

    log.info("A_FEAT DONE")

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/A_feat_builder.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3
import pandas as pd
import numpy as np
import ta
import logging

ROOT   = "/opt/scalp/project"
DB_U   = f"{ROOT}/data/universe.db"
DB_OA  = f"{ROOT}/data/oa.db"
DB_A   = f"{ROOT}/data/a.db"
LOG    = f"{ROOT}/logs/a_feat_builder.log"

logging.basicConfig(
    filename=LOG,
    level=logging.INFO,
    format="%(asctime)s A_FEAT %(levelname)s %(message)s"
)
log = logging.getLogger("A_FEAT")

# -------------------------------------------------------------
# DB
# -------------------------------------------------------------
def conn(path):
    c = sqlite3.connect(path, timeout=5, isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=3000;")
    return c

# -------------------------------------------------------------
# INDICATEURS ROBUSTES
# -------------------------------------------------------------
def compute_indicators(df):
    MIN_ROWS = 20

    if len(df) < MIN_ROWS:
        df = df.copy()
        df["ema9"]  = np.nan
        df["ema21"] = np.nan
        df["ema50"] = np.nan
        df["macd"]       = np.nan
        df["macdsignal"] = np.nan
        df["macdhist"]   = np.nan
        df["rsi"] = np.nan
        df["atr"] = np.nan
        return df

    df["ema9"]  = ta.trend.EMAIndicator(df["c"], window=9).ema_indicator()
    df["ema21"] = ta.trend.EMAIndicator(df["c"], window=21).ema_indicator()
    df["ema50"] = ta.trend.EMAIndicator(df["c"], window=50).ema_indicator()

    macd = ta.trend.MACD(df["c"])
    df["macd"]       = macd.macd()
    df["macdsignal"] = macd.macd_signal()
    df["macdhist"]   = macd.macd_diff()

    df["rsi"] = ta.momentum.RSIIndicator(df["c"], window=14).rsi()

    try:
        df["atr"] = ta.volatility.average_true_range(
            df["h"], df["l"], df["c"], window=14
        )
    except Exception as e:
        log.warning(f"ATR error ‚Üí NaN: {e}")
        df["atr"] = np.nan

    return df

# -------------------------------------------------------------
# LOAD OHLCV OA
# -------------------------------------------------------------
def load_ohlcv(instId, tf):
    table = f"ohlcv_{tf}"
    sql = f"""
        SELECT
            ts,
            open  AS o,
            high  AS h,
            low   AS l,
            close AS c,
            volume AS v
        FROM {table}
        WHERE instId = ?
        ORDER BY ts ASC
    """
    c = conn(DB_OA)
    df = pd.read_sql_query(sql, c, params=(instId,))
    if df.empty:
        return None

    df.set_index("ts", inplace=True)
    return df

# -------------------------------------------------------------
# PURGE FEAT_xm
# -------------------------------------------------------------
def purge_feat(tf):
    table = f"feat_{tf}"
    c = conn(DB_A)

    insts = c.execute(f"SELECT DISTINCT instId FROM {table}").fetchall()

    for (instId,) in insts:
        try:
            rows = c.execute(f"""
                SELECT ts FROM {table}
                WHERE instId=?
                ORDER BY ts DESC
                LIMIT 150
            """, (instId,)).fetchall()

            if len(rows) < 150:
                continue

            oldest_keep = rows[-1][0]

            c.execute(f"""
                DELETE FROM {table}
                WHERE instId=? AND ts < ?
            """, (instId, oldest_keep))

        except Exception as e:
            log.error(f"purge {instId} {tf} error: {e}")

# -------------------------------------------------------------
# SAVE FEATURES
# -------------------------------------------------------------
def save_features(instId, tf, df):
    table = f"feat_{tf}"
    df2 = df.copy()
    df2 = df2.reset_index()  # ts devient colonne
    df2["instId"] = instId

    df2 = df2[[
        "instId", "ts",
        "o", "h", "l", "c", "v",
        "ema9", "ema21", "ema50",
        "macd", "macdsignal", "macdhist",
        "rsi", "atr"
    ]]

    c = conn(DB_A)

    # Remplacement propre ‚Üí √©vite le blocage PK
    for row in df2.itertuples(index=False, name=None):
        try:
            c.execute(f"""
                INSERT OR REPLACE INTO {table}(
                    instId, ts,
                    o,h,l,c,v,
                    ema9,ema21,ema50,
                    macd,macdsignal,macdhist,
                    rsi,atr
                ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)
            """, row)
        except Exception as e:
            log.error(f"{instId} {tf} insert error: {e}")

# -------------------------------------------------------------
# MAIN
# -------------------------------------------------------------
def main():
    log.info("A_FEAT START")

    cu = conn(DB_U)
    insts = [x[0] for x in cu.execute(
        "SELECT instId FROM v_universe_tradable ORDER BY instId"
    ).fetchall()]

    for inst in insts:
        for tf in ("5m", "15m", "30m"):

            try:
                df = load_ohlcv(inst, tf)
                if df is None or df.empty:
                    log.warning(f"{inst} {tf}: NO OHLCV")
                    continue

                df_feat = compute_indicators(df)
                save_features(inst, tf, df_feat)
                log.info(f"{inst} {tf}: FEAT OK")

            except Exception as e:
                log.error(f"{inst} {tf}: ERROR {e}")

    # PURGE
    for tf in ("5m", "15m", "30m"):
        purge_feat(tf)

    log.info("A_FEAT END")

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/A_feat_incremental.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3, logging, time
import pandas as pd
import numpy as np

ROOT = "/opt/scalp/project"
DB_A  = f"{ROOT}/data/a.db"
LOG   = f"{ROOT}/logs/a_feat.log"

logging.basicConfig(
    filename=LOG,
    level=logging.INFO,
    format="%(asctime)s A_FEAT %(levelname)s %(message)s"
)
log = logging.getLogger("A_FEAT")

# ==========================================================
# DB
# ==========================================================
def conn():
    c = sqlite3.connect(DB_A, timeout=5, isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=3000;")
    return c

# ==========================================================
# INDICATORS
# ==========================================================
def ema(series, span):
    return series.ewm(span=span, adjust=False).mean()

def rsi(series, period=14):
    delta = series.diff()
    gain = delta.clip(lower=0).rolling(period).mean()
    loss = (-delta.clip(upper=0)).rolling(period).mean()
    rs = gain / loss
    return 100 - (100 / (1 + rs))

def atr(df, period=14):
    high_low = df["h"] - df["l"]
    high_close = (df["h"] - df["c"].shift()).abs()
    low_close = (df["l"] - df["c"].shift()).abs()
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    return tr.rolling(period).mean()

def macd(df):
    ema12 = ema(df["c"], 12)
    ema26 = ema(df["c"], 26)
    macd_line = ema12 - ema26
    signal = ema(macd_line, 9)
    hist = macd_line - signal
    return macd_line, signal, hist

def bollinger(df, period=20):
    mid = df["c"].rolling(period).mean()
    std = df["c"].rolling(period).std()
    up = mid + 2 * std
    low = mid - 2 * std
    width = (up - low) / mid
    return mid, up, low, width

# ==========================================================
# PURGE
# ==========================================================
H = 500
L = 150

def purge_table(co, table, inst):
    cnt = co.execute(f"SELECT COUNT(*) FROM {table} WHERE instId=?", (inst,)).fetchone()[0]
    if cnt <= H:
        return
    rows = co.execute(
        f"SELECT ts FROM {table} WHERE instId=? ORDER BY ts DESC LIMIT ? OFFSET ?",
        (inst, H, L)
    ).fetchall()
    if not rows:
        return
    cutoff = rows[-1][0]
    co.execute(f"DELETE FROM {table} WHERE instId=? AND ts < ?", (inst, cutoff))
    log.info(f"{inst} PURGE {table}: kept {H}")

# ==========================================================
# BUILD FEATURES FOR ONE TF
# ==========================================================
def build_tf(co, tf):
    ohlcv = f"ohlcv_{tf}"
    feat  = f"feat_{tf}"

    coins = [r[0] for r in co.execute(f"SELECT DISTINCT instId FROM {ohlcv}")]
    for inst in coins:

        df = pd.read_sql_query(
            f"SELECT * FROM {ohlcv} WHERE instId=? ORDER BY ts ASC",
            co,
            params=(inst,)
        )

        if len(df) < 50:
            continue

        df["ema9"]  = ema(df["c"], 9)
        df["ema20"] = ema(df["c"], 20)
        df["ema50"] = ema(df["c"], 50)
        df["rsi"]   = rsi(df["c"])
        df["atr"]   = atr(df)
        df["macd"], df["macdsignal"], df["macdhist"] = macd(df)
        df["bb_mid"], df["bb_up"], df["bb_low"], df["bb_width"] = bollinger(df)
        df["mom"]   = df["c"].diff(10)
        df["roc"]   = df["c"].pct_change(10)
        df["slope"] = df["c"].rolling(20).apply(lambda x: np.polyfit(range(len(x)), x, 1)[0])

        last_ts_feat = co.execute(f"SELECT MAX(ts) FROM {feat} WHERE instId=?", (inst,)).fetchone()[0]
        last_ts_feat = last_ts_feat if last_ts_feat else 0

        new_df = df[df["ts"] > last_ts_feat]
        if new_df.empty:
            continue

        insert_rows = []
        for _, r in new_df.iterrows():
            insert_rows.append((
                inst, int(r.ts),
                float(r.o), float(r.h), float(r.l), float(r.c), float(r.v),
                float(r.ema9), float(r.ema20), float(r.ema50),
                float(r.rsi) if not np.isnan(r.rsi) else None,
                float(r.atr) if not np.isnan(r.atr) else None,
                float(r.macd), float(r.macdsignal), float(r.macdhist),
                float(r.bb_mid), float(r.bb_up), float(r.bb_low), float(r.bb_width),
                float(r.mom) if not np.isnan(r.mom) else None,
                float(r.roc) if not np.isnan(r.roc) else None,
                float(r.slope) if not np.isnan(r.slope) else None
            ))

        co.executemany(
            f"""
            INSERT OR REPLACE INTO {feat} VALUES (
              ?, ?, ?,?,?,?,?, 
              ?,?,?,?,?,
              ?,?,?,?,
              ?,?,?,?,
              ?,?,?
            )
            """,
            insert_rows
        )

        log.info(f"{inst} {tf} ‚Üí {len(insert_rows)}")
        purge_table(co, feat, inst)

# ==========================================================
# MAIN
# ==========================================================
def main():
    log.info("A_FEAT START")
    co = conn()

    for tf in ["5m", "15m", "30m"]:
        build_tf(co, tf)

    log.info("A_FEAT DONE")


if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/B_feat_builder.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
B_feat_builder.py (HYBRIDE)
- Incremental si OB OK
- Full si trou, reset, lag, oversize, incoh√©rence
- Purge : 1m=450, 3m=150, 5m=150
- 100% align√© sur les 29 colonnes r√©elles de feat_xm (b.db)
"""

import sqlite3, time, logging, math, statistics

ROOT="/opt/scalp/project"
DB_OB=f"{ROOT}/data/ob.db"
DB_B =f"{ROOT}/data/b.db"
LOG  =f"{ROOT}/logs/b_feat.log"

logging.basicConfig(
    filename=LOG,
    level=logging.INFO,
    format="%(asctime)s B_FEAT %(levelname)s %(message)s"
)
log=logging.getLogger("B_FEAT")

# =====================================================================================
# DB UTIL
# =====================================================================================

def conn(db):
    c=sqlite3.connect(db, timeout=5, isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA synchronous=NORMAL;")
    c.execute("PRAGMA busy_timeout=3000;")
    return c

# =====================================================================================
# INDICATEURS
# =====================================================================================

def ema(values, period):
    if len(values)<period:
        return [None]*len(values)
    k=2/(period+1)
    out=[None]*(period-1)
    s=sum(values[:period])/period
    out.append(s)
    for v in values[period:]:
        s=v*k + s*(1-k)
        out.append(s)
    return out

def rsi(values, period=14):
    if len(values)<period+1:
        return [None]*len(values)
    deltas=[values[i]-values[i-1] for i in range(1,len(values))]
    gains=[max(d,0) for d in deltas]
    losses=[abs(min(d,0)) for d in deltas]
    avg_gain=sum(gains[:period])/period
    avg_loss=sum(losses[:period])/period
    rsis=[None]*(period)
    for i in range(period, len(deltas)):
        avg_gain=(avg_gain*(period-1)+gains[i])/period
        avg_loss=(avg_loss*(period-1)+losses[i])/period
        rs = avg_gain/avg_loss if avg_loss!=0 else float("inf")
        rsis.append(100 - 100/(1+rs))
    return [None] + rsis

def atr(high, low, close, period=14):
    if len(high)<period+1:
        return [None]*len(high)
    trs=[None]
    for i in range(1,len(high)):
        trs.append(max(high[i]-low[i], abs(high[i]-close[i-1]), abs(low[i]-close[i-1])))
    out=[None]*period
    s=sum(trs[1:period+1])/period
    out.append(s)
    k=1/period
    for t in trs[period+1:]:
        s=s + k*(t-s)
        out.append(s)
    return out

def macd_line(values, fast=12, slow=26, signal=9):
    if len(values)<slow:
        return [None]*len(values), [None]*len(values), [None]*len(values)
    e_fast=ema(values,fast)
    e_slow=ema(values,slow)
    macd=[None if e_fast[i] is None or e_slow[i] is None else e_fast[i]-e_slow[i] for i in range(len(values))]
    valid=[m for m in macd if m is not None]
    sig=ema(valid,signal)
    sig=[None]*(len(macd)-len(sig)) + sig
    hist=[None if macd[i] is None or sig[i] is None else macd[i]-sig[i] for i in range(len(values))]
    return macd, sig, hist

def bollinger(values, period=20, std_mult=2):
    if len(values)<period:
        return ([None]*len(values),)*5
    mid=[None]*(period-1)
    stdv=[None]*(period-1)
    up=[None]*(period-1)
    low=[None]*(period-1)
    for i in range(period-1, len(values)):
        window=values[i-period+1:i+1]
        m=statistics.mean(window)
        s=statistics.pstdev(window)
        mid.append(m)
        stdv.append(s)
        up.append(m+std_mult*s)
        low.append(m-std_mult*s)
    width=[None if mid[i] is None else (up[i]-low[i]) for i in range(len(values))]
    return mid, stdv, up, low, width

def momentum(values, period=10):
    if len(values)<period:
        return [None]*len(values)
    return [None]*period + [values[i]-values[i-period] for i in range(period,len(values))]

def roc(values, period=10):
    if len(values)<period:
        return [None]*len(values)
    res=[None]*period
    for i in range(period, len(values)):
        if values[i-period]!=0:
            res.append((values[i]/values[i-period]-1)*100)
        else:
            res.append(None)
    return res

def variance(x):
    m=sum(x)/len(x)
    return sum((xi-m)**2 for xi in x)/len(x)

def covariance(x,y):
    mx=sum(x)/len(x)
    my=sum(y)/len(y)
    return sum((x[i]-mx)*(y[i]-my) for i in range(len(x)))/len(x)

def slope(values, period=12):
    if len(values)<period:
        return [None]*len(values)
    out=[None]*period
    x=list(range(period))
    for i in range(period, len(values)):
        w=values[i-period+1:i+1]
        m=covariance(x,w)/variance(x)
        out.append(m)
    return out

def adx(high, low, close, period=14):
    if len(high)<period+2:
        return ([None]*len(high),)*3

    plus_dm=[None]
    minus_dm=[None]
    tr=[None]

    for i in range(1,len(high)):
        up=high[i]-high[i-1]
        dn=low[i-1]-low[i]
        plus_dm.append(up if up>dn and up>0 else 0)
        minus_dm.append(dn if dn>up and dn>0 else 0)
        tr.append(max(high[i]-low[i], abs(high[i]-close[i-1]), abs(low[i]-close[i-1])))

    spdm=[None]*period
    smdm=[None]*period
    strr=[None]*period

    spdm.append(sum(plus_dm[1:period+1]))
    smdm.append(sum(minus_dm[1:period+1]))
    strr.append(sum(tr[1:period+1]))

    for i in range(period+1, len(high)):
        spdm.append(spdm[-1] - (spdm[-1]/period) + plus_dm[i])
        smdm.append(smdm[-1] - (smdm[-1]/period) + minus_dm[i])
        strr.append(strr[-1] - (strr[-1]/period) + tr[i])

    pdi=[None]*period
    mdi=[None]*period
    dx =[None]*period

    for i in range(period, len(high)):
        trval=strr[i]
        if trval and trval!=0:
            p=100*(spdm[i]/trval)
            m=100*(smdm[i]/trval)
        else:
            p,m=None,None
        pdi.append(p)
        mdi.append(m)
        if p is not None and m is not None and (p+m)!=0:
            dx.append(abs(p-m)/(p+m)*100)
        else:
            dx.append(None)

    if len(dx)<period*2:
        adx_line=[None]*len(high)
    else:
        val=sum([d for d in dx[period:] if d is not None])/period
        adx_line=[None]*(period*2)
        adx_line.append(val)
        for d in dx[period+1:]:
            val=((period-1)*val + d)/period if d is not None else val
            adx_line.append(val)
        while len(adx_line)<len(high):
            adx_line.append(None)

    while len(pdi)<len(high):    pdi.append(None)
    while len(mdi)<len(high):    mdi.append(None)
    while len(adx_line)<len(high): adx_line.append(None)

    return pdi, mdi, adx_line

# =====================================================================================
# OB CONSISTENCY CHECKS
# =====================================================================================

def check_ob(con, table, tf_sec, max_age, max_rows):
    cur=con.cursor()
    count=cur.execute(f"SELECT COUNT(*) FROM {table}").fetchone()[0]
    if count==0:
        return False,"EMPTY"

    if (table=="ohlcv_1m" and count>1500) or (table!="ohlcv_1m" and count>500):
        return False,"OVERSIZE"

    ts_last=cur.execute(f"SELECT MAX(ts) FROM {table}").fetchone()[0]
    age=(int(time.time()*1000)-ts_last)/1000
    if age>max_age:
        return False,f"LAG {age}s"

    rows=cur.execute(f"SELECT ts FROM {table} ORDER BY ts").fetchall()
    ts=[x[0] for x in rows]
    expected=tf_sec*1000
    gaps=0
    for i in range(1,len(ts)):
        if ts[i]-ts[i-1] != expected:
            gaps+=1
        if gaps>1:
            return False,f"TROU {gaps}"

    return True,"OK"

# =====================================================================================
# FEATURE GENERATOR
# =====================================================================================

def build_features(ts,o,h,l,c,v):
    ema9v  = ema(c,9)
    ema12v = ema(c,12)
    ema21v = ema(c,21)
    ema26v = ema(c,26)
    ema50v = ema(c,50)

    macd_l,macd_s,macd_h = macd_line(c)
    rsi14 = rsi(c,14)
    atr14 = atr(h,l,c,14)
    bb_mid,bb_std,bb_up,bb_low,bb_width = bollinger(c)
    mom10 = momentum(c,10)
    roc10 = roc(c,10)
    slope12 = slope(c,12)
    plus_di,minus_di,adx_line = adx(h,l,c,14)

    ctx=[None]*len(ts)

    return list(zip(
        ts,o,h,l,c,v,
        ema9v,ema12v,ema21v,ema26v,ema50v,
        macd_l,macd_s,macd_h,
        rsi14,atr14,
        bb_mid,bb_std,bb_up,bb_low,bb_width,
        mom10,roc10,slope12,
        ctx,
        plus_di,minus_di,adx_line
    ))

# =====================================================================================
# FULL MODE
# =====================================================================================

def run_full():
    log.info("[FULL] rebuild complet")
    con_ob=conn(DB_OB)
    con_b =conn(DB_B)
    cur_b=con_b.cursor()

    cfg=[
        ("ohlcv_1m","feat_1m",450),
        ("ohlcv_3m","feat_3m",150),
        ("ohlcv_5m","feat_5m",150),
    ]

    for table_ob, table_feat, keep in cfg:
        log.info(f"[FULL] rebuild {table_feat}")

        rows=con_ob.execute(f"""
            SELECT instId, ts, o,h,l,c,v
            FROM {table_ob}
            ORDER BY instId, ts
        """).fetchall()

        if not rows:
            log.warning(f"[FULL] aucun data OB pour {table_ob}")
            continue

        cur_b.execute(f"DELETE FROM {table_feat}")

        # Regrouper par instId
        insts={}
        for instId,ts,o,h,l,c,v in rows:
            insts.setdefault(instId,{"ts":[],"o":[],"h":[],"l":[],"c":[],"v":[]})
            insts[instId]["ts"].append(ts)
            insts[instId]["o"].append(o)
            insts[instId]["h"].append(h)
            insts[instId]["l"].append(l)
            insts[instId]["c"].append(c)
            insts[instId]["v"].append(v)

        for instId,dd in insts.items():
            feat=build_features(dd["ts"],dd["o"],dd["h"],dd["l"],dd["c"],dd["v"])
            data=[(instId,)+x for x in feat]

            cur_b.executemany(f"""
                INSERT OR REPLACE INTO {table_feat}(
                    instId, ts, o,h,l,c,v,
                    ema9,ema12,ema21,ema26,ema50,
                    macd,macdsignal,macdhist,
                    rsi,atr,
                    bb_mid,bb_std,bb_up,bb_low,bb_width,
                    mom,roc,slope,
                    ctx,
                    plus_di,minus_di,adx
                ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)
            """, data)

        # purge
        cur_b.execute(f"""
            DELETE FROM {table_feat}
            WHERE ts NOT IN (
                SELECT ts FROM {table_feat}
                ORDER BY ts DESC LIMIT {keep}
            )
        """)

    con_b.commit()
    con_b.close()
    con_ob.close()
    log.info("[FULL] OK")

# =====================================================================================
# INCREMENTAL MODE
# =====================================================================================

def run_incr():
    log.info("[INCR] start")
    con_ob=conn(DB_OB)
    con_b =conn(DB_B)
    cur_b=con_b.cursor()

    cfg=[
        ("ohlcv_1m","feat_1m"),
        ("ohlcv_3m","feat_3m"),
        ("ohlcv_5m","feat_5m"),
    ]

    for table_ob, table_feat in cfg:
        last_ts=cur_b.execute(f"SELECT MAX(ts) FROM {table_feat}").fetchone()[0]
        if last_ts is None:
            log.warning(f"[INCR] {table_feat} vide ‚Üí FULL")
            con_b.close()
            con_ob.close()
            return False

        new=con_ob.execute(f"""
            SELECT instId, ts, o,h,l,c,v
            FROM {table_ob}
            WHERE ts > ?
            ORDER BY instId, ts
        """,(last_ts,)).fetchall()

        if not new:
            log.info(f"[INCR] {table_feat} aucune nouvelle bougie")
            continue

        insts={}
        for instId,ts,o,h,l,c,v in new:
            insts.setdefault(instId,{"ts":[],"o":[],"h":[],"l":[],"c":[],"v":[]})
            insts[instId]["ts"].append(ts)
            insts[instId]["o"].append(o)
            insts[instId]["h"].append(h)
            insts[instId]["l"].append(l)
            insts[instId]["c"].append(c)
            insts[instId]["v"].append(v)

        for instId,dd in insts.items():
            feat=build_features(dd["ts"],dd["o"],dd["h"],dd["l"],dd["c"],dd["v"])
            data=[(instId,)+x for x in feat]

            cur_b.executemany(f"""
                INSERT OR REPLACE INTO {table_feat}(
                    instId, ts, o,h,l,c,v,
                    ema9,ema12,ema21,ema26,ema50,
                    macd,macdsignal,macdhist,
                    rsi,atr,
                    bb_mid,bb_std,bb_up,bb_low,bb_width,
                    mom,roc,slope,
                    ctx,
                    plus_di,minus_di,adx
                ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)
            """, data)

    con_b.commit()
    con_b.close()
    con_ob.close()
    log.info("[INCR] OK")
    return True

# =====================================================================================
# MAIN
# =====================================================================================

def main():
    t0=time.time()
    log.info("===== B_FEAT START =====")

    con_ob=conn(DB_OB)

    checks=[
        ("ohlcv_1m",60,120,1500),
        ("ohlcv_3m",180,300,500),
        ("ohlcv_5m",300,300,500),
    ]

    for table, tf_sec, max_age, max_rows in checks:
        ok,reason=check_ob(con_ob,table,tf_sec,max_age,max_rows)
        if not ok:
            log.warning(f"[CHECK] {table} KO ‚Üí {reason} ‚Üí FULL")
            con_ob.close()
            run_full()
            log.info(f"===== B_FEAT END (FULL) {time.time()-t0:.3f}s =====")
            return

    con_ob.close()

    # try incremental
    if not run_incr():
        log.warning("[MAIN] incr KO ‚Üí FULL")
        run_full()
        log.info(f"===== B_FEAT END (FULL) {time.time()-t0:.3f}s =====")
        return

    log.info(f"===== B_FEAT END (INCR) {time.time()-t0:.3f}s =====")

if __name__=="__main__":
    main()

----- FILE: /opt/scalp/project/scripts/B_feat_builder_incremental.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3, time, logging, statistics
import math

ROOT = "/opt/scalp/project"
DB_OB = f"{ROOT}/data/ob.db"
DB_B  = f"{ROOT}/data/b.db"
DB_U  = f"{ROOT}/data/universe.db"

LOG = f"{ROOT}/logs/b_feat.log"
logging.basicConfig(
    filename=LOG,
    level=logging.INFO,
    format="%(asctime)s B_FEAT %(levelname)s %(message)s"
)
log = logging.getLogger("B_FEAT")

# ---------------------------------------------------------
# DB
# ---------------------------------------------------------
def conn(path):
    c = sqlite3.connect(path, timeout=5, isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=3000;")
    return c

# ---------------------------------------------------------
# LOAD UNIVERSE
# ---------------------------------------------------------
def load_universe():
    cu = conn(DB_U)
    xs = [r[0] for r in cu.execute("SELECT instId FROM v_universe_tradable;")]
    cu.close()
    return xs

# ---------------------------------------------------------
# LAST TS IN FEAT
# ---------------------------------------------------------
def last_ts_feat(co_b, table, inst):
    r = co_b.execute(
        f"SELECT MAX(ts) FROM {table} WHERE instId=?",
        (inst,)
    ).fetchone()
    return r[0] if r and r[0] else 0


# ---------------------------------------------------------
# GET NEW ROWS ONLY
# ---------------------------------------------------------
def load_ohlcv_incremental(tf, inst, last_ts):
    table = f"ohlcv_{tf}"
    co = conn(DB_OB)
    rows = co.execute(
        f"SELECT ts,o,h,l,c,v FROM {table} WHERE instId=? AND ts>? ORDER BY ts ASC",
        (inst, last_ts)
    ).fetchall()
    co.close()
    return rows


# ---------------------------------------------------------
# INDICATORS
# ---------------------------------------------------------
def ema(series, period):
    if len(series) < period:
        return None
    k = 2 / (period + 1)
    ema_val = series[0]
    for price in series[1:]:
        ema_val = price * k + ema_val * (1 - k)
    return ema_val

def rsi(prices, period=14):
    if len(prices) < period + 1:
        return None
    gains = []
    losses = []
    for i in range(1, period + 1):
        diff = prices[-i] - prices[-i - 1]
        if diff >= 0:
            gains.append(diff)
        else:
            losses.append(-diff)
    avg_gain = sum(gains) / period
    avg_loss = sum(losses) / period if sum(losses) != 0 else 0.0000001
    rs = avg_gain / avg_loss
    return 100 - (100 / (1 + rs))

def atr(highs, lows, closes, period=14):
    if len(highs) < period + 1:
        return None
    trs = []
    for i in range(1, period + 1):
        prev = closes[-i - 1]
        tr = max(
            highs[-i] - lows[-i],
            abs(highs[-i] - prev),
            abs(lows[-i] - prev)
        )
        trs.append(tr)
    return sum(trs) / period

def adx(highs, lows, closes, period=14):
    if len(highs) < period + 2:
        return None, None, None
    plus_dm = []
    minus_dm = []
    tr_list = []
    for i in range(1, period + 1):
        up = highs[-i] - highs[-i - 1]
        dn = lows[-i - 1] - lows[-i]
        plus_dm.append(up if up > dn and up > 0 else 0)
        minus_dm.append(dn if dn > up and dn > 0 else 0)
        tr = max(
            highs[-i] - lows[-i],
            abs(highs[-i] - closes[-i - 1]),
            abs(lows[-i] - closes[-i - 1])
        )
        tr_list.append(tr)
    atr_v = sum(tr_list) / period
    if atr_v == 0:
        return None, None, None
    plus_di = (sum(plus_dm) / atr_v) * 100
    minus_di = (sum(minus_dm) / atr_v) * 100
    dx = abs(plus_di - minus_di) / (plus_di + minus_di + 1e-6) * 100
    adx_v = dx
    return plus_di, minus_di, adx_v

# ---------------------------------------------------------
# COMPUTE FEAT ROW
# ---------------------------------------------------------
def compute_feat(rows):
    if len(rows) < 30:
        return None

    closes = [r[4] for r in rows]
    highs  = [r[2] for r in rows]
    lows   = [r[3] for r in rows]

    ema9  = ema(closes[-9:], 9)
    ema12 = ema(closes[-12:], 12)
    ema21 = ema(closes[-21:], 21)
    ema26 = ema(closes[-26:], 26)
    ema50 = ema(closes[-50:], 50)

    macd = (ema12 - ema26) if ema12 and ema26 else None
    macdsig = None
    macdhist = None

    rsi_v = rsi(closes, 14)
    atr_v = atr(highs, lows, closes, 14)

    bb_mid = statistics.mean(closes[-20:]) if len(closes) >= 20 else None
    bb_std = statistics.pstdev(closes[-20:]) if len(closes) >= 20 else None
    bb_up  = bb_mid + 2 * bb_std if bb_mid and bb_std else None
    bb_low = bb_mid - 2 * bb_std if bb_mid and bb_std else None
    bb_width = (bb_up - bb_low) if bb_up and bb_low else None

    # momentum
    mom = closes[-1] - closes[-10] if len(closes) >= 10 else None
    roc = (closes[-1] / closes[-10] - 1) * 100 if len(closes) >= 10 else None

    # slope
    slope = (closes[-1] - closes[-5]) / 5 if len(closes) >= 5 else None

    # ctx dummy
    ctx = "unknown"

    plus_di, minus_di, adx_v = adx(highs, lows, closes)

    return (
        rows[-1][0],   # ts
        rows[-1][1], rows[-1][2], rows[-1][3], rows[-1][4], rows[-1][5],  # o,h,l,c,v
        ema9, ema12, ema21, ema26, ema50,
        macd, macdsig, macdhist,
        rsi_v, atr_v,
        bb_mid, bb_std, bb_up, bb_low, bb_width,
        mom, roc, slope,
        ctx,
        plus_di, minus_di, adx_v
    )


# ---------------------------------------------------------
# PURGE
# ---------------------------------------------------------
def purge(co_b, table, inst, H, L):
    cnt = co_b.execute(
        f"SELECT COUNT(*) FROM {table} WHERE instId=?",
        (inst,)
    ).fetchone()[0]

    if cnt <= H:
        return

    rows = co_b.execute(
        f"SELECT ts FROM {table} WHERE instId=? ORDER BY ts DESC LIMIT ? OFFSET ?",
        (inst, H, L)
    ).fetchall()

    if not rows:
        return

    cutoff = rows[-1][0]

    co_b.execute(
        f"DELETE FROM {table} WHERE instId=? AND ts < ?",
        (inst, cutoff)
    )

# ---------------------------------------------------------
# MAIN
# ---------------------------------------------------------
def main():
    log.info("B_FEAT START")

    coins = load_universe()
    co_b  = conn(DB_B)

    for inst in coins:
        for tf in ("1m", "3m", "5m"):
            table = f"feat_{tf}"
            last = last_ts_feat(co_b, table, inst)
            ohlcv = load_ohlcv_incremental(tf, inst, last)

            if not ohlcv:
                continue

            # Build rolling windows
            buf = []
            inserted = 0

            for r in ohlcv:
                buf.append(r)
                if len(buf) > 200:
                    buf.pop(0)
                feat = compute_feat(buf)
                if feat:
                    try:
                        co_b.execute(
                            f"INSERT INTO {table} VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)",
                            (inst,) + feat
                        )
                        inserted += 1
                    except Exception as e:
                        log.error(f"{inst} {tf} FAIL {e}")

            log.info(f"{inst} {tf} ‚Üí {inserted}")

            # purge
            if tf == "1m":
                purge(co_b, table, inst, 1500, 450)
            else:
                purge(co_b, table, inst, 500, 150)

    log.info("B_FEAT DONE")

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/H_aggregate.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3
import math
import time
import hashlib

DB_REC = "/opt/scalp/project/data/recorder.db"
DB_H   = "/opt/scalp/project/data/h.db"

ROLLING_MAX = 200
MIN_TRADES  = 5

# -----------------------------
# Utils
# -----------------------------
def conn(path, ro=False):
    uri = f"file:{path}?mode=ro" if ro else path
    c = sqlite3.connect(uri, uri=ro, timeout=5)
    c.execute("PRAGMA busy_timeout=5000;")
    return c

def bucket_score(x):
    if x is None: return "mid"
    if x < 0.2: return "vlow"
    if x < 0.4: return "low"
    if x < 0.6: return "mid"
    if x < 0.8: return "high"
    return "vhigh"

def time_bucket(ts_ms):
    t = time.gmtime(ts_ms / 1000)
    wd = t.tm_wday  # 0=lundi
    h  = t.tm_hour

    if wd >= 5:
        return "weekend"
    if wd == 0 and h < 12:
        return "mon_am"
    if wd == 0:
        return "mon_pm"
    if wd == 4 and h < 12:
        return "fri_am"
    if wd == 4:
        return "fri_pm"
    return "wk_mid"

def setup_hash(parts):
    return hashlib.sha1("|".join([str(p) for p in parts]).encode()).hexdigest()

def sigmoid(x):
    return 1 / (1 + math.exp(-x)) if x is not None else 0.5

def clamp(x, lo=0.0, hi=1.0):
    return max(lo, min(hi, x))

# -----------------------------
# Main
# -----------------------------
def main():

    r = conn(DB_REC, ro=True)
    h = conn(DB_H)

    rows = r.execute("""
        SELECT
            instId,
            side,
            ctx_close,
            score_C,
            score_S,
            pnl_net,
            ts_open,
            ts_close
        FROM recorder
        WHERE ts_recorded IS NOT NULL
          AND pnl_net IS NOT NULL
        ORDER BY ts_close DESC
    """).fetchall()

    buckets = {}

    for instId, side, ctx, sc, ss, pnl, ts_open, ts_close in rows:

        if ts_open is None or pnl is None:
            continue

        tb  = time_bucket(ts_open)
        scb = bucket_score(sc)
        ssb = bucket_score(ss)

        # regime, tf_ref volontairement absents (NULL)
        key = (instId, side, ctx, None, None, tb, scb, ssb)
        buckets.setdefault(key, []).append(pnl)

        if len(buckets[key]) >= ROLLING_MAX:
            continue

    now = int(time.time() * 1000)

    for key, pnls in buckets.items():
        if len(pnls) < MIN_TRADES:
            continue

        wins   = [p for p in pnls if p > 0]
        losses = [p for p in pnls if p < 0]

        n = len(pnls)
        win_rate = len(wins) / n
        avg_pnl  = sum(pnls) / n
        expectancy = avg_pnl
        pf = (sum(wins) / abs(sum(losses))) if losses else 3.0

        dd = 0
        peak = 0
        cum = 0
        for p in pnls:
            cum += p
            peak = max(peak, cum)
            dd = min(dd, cum - peak)
        max_dd = abs(dd)

        win_n = clamp(win_rate)
        exp_n = sigmoid(expectancy)
        pf_n  = math.tanh(pf / 3)

        raw  = 0.4 * win_n + 0.4 * exp_n + 0.2 * pf_n
        conf = min(1.0, math.log(n + 1) / math.log(50))
        score_H = clamp(raw * conf)

        shash = setup_hash(key)

        h.execute("""
            INSERT OR REPLACE INTO h_stats VALUES (
                ?,?,?,?,?,?,?,?,
                ?,?,?,?,?,?,
                ?,?
            )
        """, (
            shash,
            *key,
            n,
            win_rate,
            expectancy,
            avg_pnl,
            pf,
            max_dd,
            score_H,
            now
        ))

    h.commit()
    r.close()
    h.close()

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/H_perf.py -----
#!/usr/bin/env python3
import sqlite3, time, statistics, logging, sys
from pathlib import Path

LOG = "/opt/scalp/project/logs/H_perf.log"
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(message)s",
    handlers=[logging.FileHandler(LOG), logging.StreamHandler(sys.stdout)]
)

DB_CLOSED = "/opt/scalp/project/data/x_closed.db"
DB_H = "/opt/scalp/project/data/h.db"

def connect_db(path):
    con = sqlite3.connect(path, timeout=30, isolation_level=None)
    con.execute("PRAGMA journal_mode=WAL;")
    con.execute("PRAGMA synchronous=NORMAL;")
    con.execute("PRAGMA busy_timeout=5000;")
    return con

def ensure_closed_schema():
    con = connect_db(DB_CLOSED)
    con.execute("""
        CREATE TABLE IF NOT EXISTS positions_closed(
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            instId TEXT, side TEXT, entry REAL, exit REAL,
            sl REAL, tp REAL, pnl REAL, reason TEXT,
            ts_open INTEGER, ts_close INTEGER
        )
    """)
    con.close()

def migrate_h():
    con = connect_db(DB_H)
    con.execute("""
        CREATE TABLE IF NOT EXISTS score_H(
            instId TEXT PRIMARY KEY,
            avg_pnl REAL,
            winrate REAL,
            trades INTEGER,
            last_update INTEGER
        )
    """)
    con.close()

def compute_score():
    ensure_closed_schema()
    con_c = connect_db(DB_CLOSED)
    rows = con_c.execute("SELECT instId, pnl FROM positions_closed").fetchall()
    con_c.close()
    if not rows:
        logging.info("Aucun trade clos, pas de calcul.")
        return
    data = {}
    for inst,pnl in rows:
        data.setdefault(inst,[]).append(pnl)
    con_h = connect_db(DB_H)
    for inst,vals in data.items():
        avg = statistics.mean(vals)
        winrate = sum(1 for v in vals if v>0)/len(vals)
        con_h.execute("""
            INSERT OR REPLACE INTO score_H(instId,avg_pnl,winrate,trades,last_update)
            VALUES(?,?,?,?,?)
        """,(inst,avg,winrate,len(vals),int(time.time()*1000)))
    con_h.close()
    logging.info(f"Scores H mis √† jour pour {len(data)} instruments.")

def main(argv):
    migrate_h()
    compute_score()

if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))

----- FILE: /opt/scalp/project/scripts/H_score.py -----
#!/usr/bin/env python3
import sqlite3, time

DB_H="/opt/scalp/project/data/x_history.db"

def latest_H():
    con=sqlite3.connect(DB_H)
    row=con.execute("SELECT score_H FROM v_H_latest").fetchone()
    con.close()
    return float(row[0]) if row and row[0] else 0.0

def run():
    h=latest_H()
    print(f"[H] score_H={h:.3f}")

if __name__=="__main__":
    run()

----- FILE: /opt/scalp/project/scripts/OA_ohlcv.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3
import time
import logging
import traceback
import ccxt

ROOT = "/opt/scalp/project"
DB_U  = f"{ROOT}/data/universe.db"
DB_OA = f"{ROOT}/data/oa.db"
LOG   = f"{ROOT}/logs/oa_ohlcv.log"

logging.basicConfig(
    filename=LOG,
    level=logging.INFO,
    format="%(asctime)s OA %(levelname)s %(message)s"
)
log = logging.getLogger("OA")

# ============================================================
# DB
# ============================================================
def conn(path):
    c = sqlite3.connect(path, timeout=5, isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA synchronous=NORMAL;")
    c.execute("PRAGMA busy_timeout=3000;")
    return c

# ============================================================
# EXCHANGE
# ============================================================
exchange = ccxt.bitget({
    "options": {"defaultType": "swap"},
})

# Map TF ‚Üí minutes
TF_MAP = {
    "5m": 5,
    "15m": 15,
    "30m": 30,
}

# ============================================================
# LOAD UNIVERSE
# ============================================================
def load_universe():
    cu = conn(DB_U)
    rows = cu.execute("SELECT instId FROM v_universe_tradable ORDER BY instId").fetchall()
    return [r[0] for r in rows]

# ============================================================
# FETCH OHLCV FROM EXCHANGE
# ============================================================
def fetch_ohlcv(instId, tf):
    """
    Retourne une liste de bougies CCXT :
      [ts_ms, open, high, low, close, volume]
    """
    try:
        candles = exchange.fetch_ohlcv(instId.replace("/",""), timeframe=tf)
        if not candles:
            return []
        return candles
    except Exception as e:
        log.error(f"{instId} {tf} fetch error: {e}")
        return []

# ============================================================
# SAVE OHLCV ‚Üí oa.db
# ============================================================
def save_candles(instId, tf, candles):
    """
    candles = liste CCXT format standard
    """
    if not candles:
        return 0

    table = f"ohlcv_{tf}"
    c = conn(DB_OA)

    cnt = 0
    for row in candles:
        ts = int(row[0])  # timestamp en ms
        o = float(row[1])
        h = float(row[2])
        l = float(row[3])
        pc = float(row[4])
        v = float(row[5])

        # IMP√âRATIF : emp√™cher ts NULL
        if ts <= 0:
            continue

        try:
            c.execute(f"""
                INSERT OR REPLACE INTO {table}(
                    instId, ts, open, high, low, close, volume
                ) VALUES (?,?,?,?,?,?,?)
            """, (instId, ts, o, h, l, pc, v))
            cnt += 1
        except Exception as e:
            log.error(f"{instId} {tf} insert error: {e}")

    return cnt

# ============================================================
# PURGE : garder les 150 derni√®res bougies
# ============================================================
def purge_tf(tf):
    table = f"ohlcv_{tf}"
    c = conn(DB_OA)

    insts = c.execute(f"SELECT DISTINCT instId FROM {table}").fetchall()
    for (instId,) in insts:
        try:
            # R√©cup√®re tous les ts tri√©s descendant
            rows = c.execute(f"""
                SELECT ts FROM {table}
                WHERE instId=?
                ORDER BY ts DESC
                LIMIT 150
            """, (instId,)).fetchall()

            if len(rows) < 150:
                continue

            oldest_keep = rows[-1][0]  # ts du 150√®me

            c.execute(f"""
                DELETE FROM {table}
                WHERE instId=? AND ts < ?
            """, (instId, oldest_keep))

        except Exception as e:
            log.error(f"purge {instId} {tf} error: {e}")

# ============================================================
# MAIN
# ============================================================
def main():
    log.info("OA START")

    insts = load_universe()

    for instId in insts:
        for tf in ("5m", "15m", "30m"):
            candles = fetch_ohlcv(instId, tf)
            n = save_candles(instId, tf, candles)
            log.info(f"{instId} {tf} ‚Üí {n} candles")

    # PURGE
    for tf in ("5m", "15m", "30m"):
        purge_tf(tf)

    log.info("OA END")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        log.error(f"FATAL: {e}")
        log.error(traceback.format_exc())

----- FILE: /opt/scalp/project/scripts/OA_ohlcv_A.py -----
#!/usr/bin/env python3
import time
import sqlite3
import ccxt
from datetime import datetime

DB_U  = "/opt/scalp/project/data/universe.db"
DB_OA = "/opt/scalp/project/data/oa.db"

TF_MS = {
    "5m":  5  * 60 * 1000,
    "15m": 15 * 60 * 1000,
    "30m": 30 * 60 * 1000
}

TABLE = {
    "5m":  "ohlcv_5m",
    "15m": "ohlcv_15m",
    "30m": "ohlcv_30m"
}

###############################################################################
# DB helpers
###############################################################################
def load_universe():
    c = sqlite3.connect(DB_U)
    rows = c.execute("SELECT instId FROM v_universe_tradable ORDER BY instId").fetchall()
    c.close()
    return [r[0] for r in rows]

def conn_oa():
    c = sqlite3.connect(DB_OA, timeout=10)
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA synchronous=NORMAL;")
    return c

###############################################################################
# CCXT fetch
###############################################################################
EX = ccxt.bitget({"options":{"defaultType":"swap"}})

def fetch_missing(instId, tf, since_ts):
    market = instId.replace("/", "")
    try:
        return EX.fetch_ohlcv(market, timeframe=tf, since=since_ts, limit=5)
    except Exception as e:
        print(f"[OA] CCXT error {instId} {tf}: {e}")
        return []

###############################################################################
# Insert rows
###############################################################################
def insert_row(con, tf, instId, ts, o, h, l, c, v):
    con.execute(
        f"INSERT OR REPLACE INTO {TABLE[tf]}(instId, ts, open, high, low, close, volume)"
        f" VALUES (?,?,?,?,?,?,?)",
        (instId, ts, o, h, l, c, v)
    )

###############################################################################
# Main OA logic
###############################################################################
def sync_inst(con, instId):
    now = int(time.time() * 1000)

    for tf, tf_ms in TF_MS.items():

        row = con.execute(
            f"SELECT ts FROM {TABLE[tf]} WHERE instId=? ORDER BY ts DESC LIMIT 1",
            (instId,)
        ).fetchone()

        last_ts = row[0] if row else (now - tf_ms * 10)

        # Fetch only the missing window
        ohlcv = fetch_missing(instId, tf, last_ts)
        if not ohlcv:
            continue

        for ts, o, h, l, c, v in ohlcv:

            # Normaliser timestamp (s√©curit√©)
            if ts < 10**11:   # seconde ‚Üí millisecondes
                ts = ts * 1000

            # Validation strict millisecondes
            if ts > now + 3600 * 1000:
                print(f"[OA] WARNING {instId} {tf} future-ts={ts}")
                continue

            if ts > last_ts:
                insert_row(con, tf, instId, ts, o, h, l, c, v)
                print(f"[OA] {instId} {tf} synced ts={ts}")

###############################################################################
# Entrypoint
###############################################################################
def main():
    t0 = time.time()

    universe = load_universe()
    con = conn_oa()

    for instId in universe:
        try:
            sync_inst(con, instId)
        except Exception as e:
            print(f"[OA] ERROR {instId}: {e}")

    con.commit()
    con.close()

    print(f"[OA] Sync OK in {time.time() - t0:.3f}s")

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/OA_sync.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import ccxt, sqlite3, time, logging, traceback

ROOT = "/opt/scalp/project"
DB_OA = f"{ROOT}/data/oa.db"
DB_U  = f"{ROOT}/data/universe.db"

LOG = f"{ROOT}/logs/oa.log"

logging.basicConfig(
    filename=LOG,
    level=logging.INFO,
    format="%(asctime)s OA %(levelname)s %(message)s"
)
log = logging.getLogger("OA")

# ------------------------------------------------------
# DB
# ------------------------------------------------------
def conn(path):
    c = sqlite3.connect(path, timeout=30, isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA synchronous=NORMAL;")
    c.execute("PRAGMA busy_timeout=5000;")
    return c

# ------------------------------------------------------
# PURGE : only if >500 --> keep 150
# ------------------------------------------------------
def purge_if_needed(c, table):
    n = c.execute(f"SELECT COUNT(*) FROM {table};").fetchone()[0]
    if n > 500:
        c.execute(f"""
            DELETE FROM {table}
            WHERE ts NOT IN (
                SELECT ts FROM {table}
                ORDER BY ts DESC
                LIMIT 150
            );
        """)
        log.info(f"Purged {table}: {n} -> 150")

# ------------------------------------------------------
# FETCH INCREMENTAL
# ------------------------------------------------------
def fetch_incremental(exchange, instId, tf, table):
    c = conn(DB_OA)

    # get last ts
    row = c.execute(f"SELECT MAX(ts) FROM {table} WHERE instId=?;", (instId,)).fetchone()
    last_ts = row[0] if row and row[0] else None

    ms_tf = {
        "5m":  5 * 60 * 1000,
        "15m": 15 * 60 * 1000,
        "30m": 30 * 60 * 1000
    }[tf]

    since = last_ts + ms_tf if last_ts else int(time.time()*1000) - (150 * ms_tf)

    try:
        ohlcv = exchange.fetch_ohlcv(instId, timeframe=tf, since=since, limit=500)
    except Exception as e:
        log.error(f"{instId} fetch error {tf}: {e}")
        return 0

    n_inserted = 0
    for ts, o, h, l, cl, v in ohlcv:
        try:
            c.execute(f"""
                INSERT OR IGNORE INTO {table}(instId, ts, open, high, low, close, volume)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (instId, ts, o, h, l, cl, v))
            n_inserted += 1
        except Exception as e:
            log.error(f"Insert error {instId} {tf} {ts}: {e}")

    purge_if_needed(c, table)
    return n_inserted

# ------------------------------------------------------
# MAIN
# ------------------------------------------------------
def main():
    log.info("START OA_SYNC")

    cU = conn(DB_U)
    insts = [r[0] for r in cU.execute("SELECT instId FROM v_universe_tradable;").fetchall()]

    exchange = ccxt.bitget({"options": {"defaultType": "swap"}})

    for inst in insts:
        for tf, table in [
            ("5m",  "ohlcv_5m"),
            ("15m", "ohlcv_15m"),
            ("30m", "ohlcv_30m")
        ]:
            n = fetch_incremental(exchange, inst, tf, table)
            log.info(f"{inst} {tf} ‚Üí {n} new")

    log.info("END OA_SYNC")

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/OB_collect.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3
import ccxt
import logging
import time

ROOT = "/opt/scalp/project"
DB_OB = f"{ROOT}/data/ob.db"
DB_U  = f"{ROOT}/data/universe.db"
LOG   = f"{ROOT}/logs/ob_collect.log"

logging.basicConfig(
    filename=LOG,
    level=logging.INFO,
    format="%(asctime)s OB_COLLECT %(levelname)s %(message)s"
)
log = logging.getLogger("OB_COLLECT")

# ==========================================================
# DB
# ==========================================================
def conn(path):
    c = sqlite3.connect(path, timeout=10, isolation_level=None)
    c.execute("PRAGMA busy_timeout=5000;")
    return c

def load_universe():
    cu = conn(DB_U)
    xs = [r[0] for r in cu.execute("SELECT instId FROM v_universe_tradable;")]
    cu.close()
    return xs

def last_ts(conn, table, inst):
    try:
        r = conn.execute(
            f"SELECT ts FROM {table} WHERE instId=? ORDER BY ts DESC LIMIT 1",
            (inst,)
        ).fetchone()
        return r[0] if r else 0
    except:
        return 0

# ==========================================================
# FETCH CCXT
# ==========================================================
EX = ccxt.bitget()

def fetch_tf(inst, tf, limit=200):
    try:
        symbol = inst.replace("/", "")
        rows = EX.fetch_ohlcv(symbol, timeframe=tf, limit=limit)
        return [(ts, o, h, l, c, v) for ts,o,h,l,c,v in rows]
    except Exception as e:
        log.error(f"{inst} {tf} FAIL {e}")
        return []

# ==========================================================
# AGGREGATION 3m
# ==========================================================
def aggregate_3m(conn):
    conn.execute("""
    INSERT OR REPLACE INTO ohlcv_3m(instId, ts, o, h, l, c, v)
    SELECT instId,
           (ts/180000)*180000 AS ts,
           FIRST_VALUE(o) OVER w,
           MAX(h)          OVER w,
           MIN(l)          OVER w,
           LAST_VALUE(c)   OVER w,
           SUM(v)          OVER w
    FROM ohlcv_1m
    WINDOW w AS (
        PARTITION BY instId, (ts/180000)
        ORDER BY ts
        ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING
    );
    """)

# ==========================================================
# PURGE OB
# ==========================================================
PURGE_1M_HIGH = 1500
PURGE_1M_LOW  = 450

PURGE_HIGH = 500
PURGE_LOW  = 150

def purge_ob(conn, tf, inst):
    table = f"ohlcv_{tf}"

    r = conn.execute(f"SELECT COUNT(*) FROM {table} WHERE instId=?", (inst,)).fetchone()
    if not r:
        return
    count = r[0]

    if tf == "1m":
        H = PURGE_1M_HIGH
        L = PURGE_1M_LOW
    else:
        H = PURGE_HIGH
        L = PURGE_LOW

    if count <= H:
        return

    rows = conn.execute(
        f"SELECT ts FROM {table} WHERE instId=? ORDER BY ts DESC LIMIT ? OFFSET ?",
        (inst, H, L)
    ).fetchall()

    if not rows:
        return

    cutoff = rows[-1][0]

    conn.execute(
        f"DELETE FROM {table} WHERE instId=? AND ts < ?",
        (inst, cutoff)
    )

    log.info(f"{inst} PURGE {table}: kept {H}, deleted older")


# ==========================================================
# MAIN
# ==========================================================
def main():
    log.info("OB START")

    co = conn(DB_OB)
    coins = load_universe()

    for inst in coins:

        # -------------------------------
        # 1m incremental
        # -------------------------------
        last = last_ts(co, "ohlcv_1m", inst)
        rows = fetch_tf(inst, "1m")
        new_1m = [r for r in rows if r[0] > last]

        if new_1m:
            co.executemany(
                "INSERT INTO ohlcv_1m VALUES (?,?,?,?,?,?,?)",
                [(inst,) + r for r in new_1m]
            )

        log.info(f"{inst} new1m={len(new_1m)}")

        # purge 1m
        purge_ob(co, "1m", inst)

        # -------------------------------
        # 5m incremental
        # -------------------------------
        last = last_ts(co, "ohlcv_5m", inst)
        rows = fetch_tf(inst, "5m")
        new_5m = [r for r in rows if r[0] > last]

        if new_5m:
            co.executemany(
                "INSERT INTO ohlcv_5m VALUES (?,?,?,?,?,?,?)",
                [(inst,) + r for r in new_5m]
            )

        log.info(f"{inst} new5m={len(new_5m)}")

        # purge 5m
        purge_ob(co, "5m", inst)

    # -------------------------------
    # 3m aggregation
    # -------------------------------
    try:
        aggregate_3m(co)
        log.info("3m aggregation OK")
    except Exception as e:
        log.error(f"3m aggregation FAIL {e}")

    log.info("OB DONE")


if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/T_ticks.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import asyncio
import json
import logging
import sqlite3
import time
import websockets

ROOT = "/opt/scalp/project"
DB_TICKS = f"{ROOT}/data/t.db"
DB_UNIVERSE = f"{ROOT}/data/universe.db"
LOG = f"{ROOT}/logs/ticks.log"

# ‚úÖ BON ENDPOINT WS BITGET (V2)
WS_URL = "wss://ws.bitget.com/v2/ws/public"

logging.basicConfig(
    filename=LOG,
    level=logging.INFO,
    format="%(asctime)s TICKS %(levelname)s %(message)s"
)
log = logging.getLogger("TICKS")

def conn(path):
    c = sqlite3.connect(path, timeout=30, isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA synchronous=NORMAL;")
    c.execute("PRAGMA busy_timeout=5000;")
    return c

def load_universe():
    cu = conn(DB_UNIVERSE)
    rows = cu.execute("SELECT instId FROM v_universe_tradable").fetchall()
    return [r[0] for r in rows]

def canon(inst):
    return inst.replace("/", "")

async def run():
    insts = load_universe()
    if not insts:
        log.error("Universe vide")
        return

    args = [{
        "instType": "USDT-FUTURES",
        "channel": "ticker",
        "instId": canon(inst)
    } for inst in insts]

    sub = {"op": "subscribe", "args": args}

    log.info(f"WS connect, subscribing {len(args)} symbols")

    async with websockets.connect(WS_URL, ping_interval=20, ping_timeout=10) as ws:
        await ws.send(json.dumps(sub))
        log.info("SUBSCRIBE SENT")

        c = conn(DB_TICKS)

        async for msg in ws:
            data = json.loads(msg)

            if "data" not in data:
                continue

            for d in data["data"]:
                inst_raw = d.get("instId")
                last = float(d.get("lastPr"))
                ts = int(d.get("ts"))

                inst = inst_raw.replace("USDT", "/USDT")

                c.execute(
                    "INSERT INTO ticks(instId, instId_s, lastPr, ts_ms) VALUES (?,?,?,?)",
                    (inst, inst, last, ts)
                )

def main():
    log.info("START TICKS WS")
    while True:
        try:
            asyncio.run(run())
        except Exception as e:
            log.error(f"WS error: {e}")
            time.sleep(5)

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/T_ticks_debug.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import asyncio, json, websockets, datetime, re

WS_URL = "wss://ws.bitget.com/mix/v1/stream"

# liste restreinte pour test
INSTRUMENTS = ["BTCUSDT", "ETHUSDT", "BNBUSDT"]

async def listen():
    async with websockets.connect(WS_URL, ping_interval=20) as ws:
        subs = []
        for inst in INSTRUMENTS:
            subs.append({
                "op": "subscribe",
                "args": [f"ticker:{inst}_UMCBL"]
            })
        for s in subs:
            await ws.send(json.dumps(s))
        print("Subscriptions sent:", subs)

        count = 0
        while True:
            msg = await ws.recv()
            ts = datetime.datetime.now().strftime("%H:%M:%S")
            print(f"\n[{ts}] RAW:", msg[:200])  # tronqu√© si long

            # test parsing brut
            try:
                clean = re.search(r'\{.*\}', msg)
                obj = json.loads(clean.group(0)) if clean else None
                if obj:
                    ticker = obj.get("data", [{}])[0]
                    inst = ticker.get("symbol", "?")
                    last = ticker.get("last", "?")
                    print(f"‚Üí Parsed {inst} = {last}")
            except Exception as e:
                print("‚ö†Ô∏è Parse error:", e)

            count += 1
            if count >= 5:
                break

asyncio.run(listen())

----- FILE: /opt/scalp/project/scripts/T_ticks_test_raw.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import asyncio, json, time, websockets

WS_URL = "wss://ws.bitget.com/v2/ws/public"
INSTRUMENTS = ["BTCUSDT", "ETHUSDT", "BNBUSDT"]

async def test():
    async with websockets.connect(WS_URL, ping_interval=None) as ws:
        subs = [{"instType": "USDT-FUTURES", "channel": "ticker", "instId": i} for i in INSTRUMENTS]
        msg = {"op": "subscribe", "args": subs}
        await ws.send(json.dumps(msg))
        print("‚úÖ Sent:", msg)

        async def pinger():
            while True:
                await asyncio.sleep(10)
                await ws.send('{"op":"ping"}')
        asyncio.create_task(pinger())

        while True:
            raw = await ws.recv()
            ts = time.strftime("%H:%M:%S")
            print(f"\n[{ts}] RAW ‚Üí", raw[:250])

            try:
                data = json.loads(raw)
                if "data" in data:
                    for d in data["data"]:
                        inst = d.get("instId")
                        pr   = d.get("lastPr")
                        if inst and pr:
                            print(f"‚Üí Parsed {inst} = {pr}")
            except Exception as e:
                print("‚ö†Ô∏è Parse error:", e)

asyncio.run(test())

----- FILE: /opt/scalp/project/scripts/U_universe.py -----
import ccxt, sqlite3

DBU = "/opt/scalp/project/data/u.db"
TOP = 20

exchange = ccxt.bitget()
markets = exchange.load_markets()

perps = []
for s,info in markets.items():
    if info.get('swap',False) and info['quote'] == 'USDT':
        inst = s.replace(":USDT","")  # -> BTC/USDT:USDT ‚Üí BTC/USDT
        perps.append(inst)

perps = perps[:TOP]

con = sqlite3.connect(DBU, timeout=5)
con.execute("DELETE FROM v_universe_tradable;")
for inst in perps:
    con.execute("INSERT OR IGNORE INTO universe(instId) VALUES (?)", (inst,))
con.commit()
con.close()

print("[U] OK :", perps)

----- FILE: /opt/scalp/project/scripts/WS_candles_to_wsdb.py -----
#!/usr/bin/env python3
import asyncio
import json
import sqlite3
import websockets
import time
from datetime import datetime

WS_URL = "wss://ws.bitget.com/v2/ws/public"

DB_WS = "/opt/scalp/project/data/ws.db"
DB_U  = "/opt/scalp/project/data/universe.db"

TF = {
    "candle5m":  5  * 60 * 1000,
    "candle15m": 15 * 60 * 1000,
    "candle30m": 30 * 60 * 1000
}

###############################################################################
# DB Helpers
###############################################################################
def load_universe():
    conn = sqlite3.connect(DB_U)
    rows = conn.execute("SELECT instId FROM v_universe_tradable ORDER BY instId;").fetchall()
    conn.close()
    return [r[0] for r in rows]

def wsdb_conn():
    conn = sqlite3.connect(DB_WS, timeout=10, isolation_level=None)
    conn.execute("PRAGMA journal_mode=WAL;")
    conn.execute("PRAGMA synchronous=NORMAL;")
    return conn

###############################################################################
# WS Subscription builder
###############################################################################
def build_sub(universe):
    args = []
    for instId in universe:
        args.append({"instType":"USDT-FUTURES","channel":"candle5m","instId":instId})
        args.append({"instType":"USDT-FUTURES","channel":"candle15m","instId":instId})
        args.append({"instType":"USDT-FUTURES","channel":"candle30m","instId":instId})
    return {"op":"subscribe", "args":args}

###############################################################################
# Insert into WS DB (closed candles only)
###############################################################################
def insert_ws_candle(conn, table, instId, ts, o, h, l, c, v):
    conn.execute(
        f"""
        INSERT OR REPLACE INTO {table}(instId, ts, open, high, low, close, volume)
        VALUES (?,?,?,?,?,?,?)
        """,
        (instId, ts, o, h, l, c, v)
    )

###############################################################################
# Main WebSocket loop
###############################################################################
async def run_ws():
    universe = load_universe()
    sub = build_sub(universe)

    ws_conn = wsdb_conn()

    while True:
        try:
            print("[WS] Connecting...")
            async with websockets.connect(
                WS_URL,
                ping_interval=None,
                ping_timeout=None,
                close_timeout=1
            ) as ws:

                print("[WS] Connected, subscribing‚Ä¶")
                await ws.send(json.dumps(sub))

                async def keep_alive():
                    while True:
                        await asyncio.sleep(15)
                        try:
                            await ws.send(json.dumps({"event":"ping"}))
                        except:
                            break

                asyncio.create_task(keep_alive())

                while True:
                    raw = await ws.recv()
                    data = json.loads(raw)

                    # Skip ping/pong
                    if isinstance(data, dict) and data.get("event") in ("ping","pong"):
                        continue

                    if "arg" not in data or "data" not in data:
                        continue

                    channel = data["arg"]["channel"]
                    instId  = data["arg"]["instId"]
                    rows    = data["data"]

                    if channel not in TF:
                        continue

                    tf_ms = TF[channel]
                    table = f"ws_ohlcv_{channel.replace('candle','')}"  # candle5m -> ws_ohlcv_5m

                    for k in rows:
                        ts = int(k[0])

                        # Only take closed candles
                        if ts % tf_ms != 0:
                            continue

                        o = float(k[1])
                        h = float(k[2])
                        l = float(k[3])
                        c = float(k[4])
                        v = float(k[5])

                        insert_ws_candle(ws_conn, table, instId, ts, o, h, l, c, v)

                        print(
                            f"[WS] CLOSED {channel} {instId} "
                            f"ts={ts} o={o} h={h} l={l} c={c} v={v}"
                        )

        except Exception as e:
            print(f"[WS] Error: {e}, retry in 5s‚Ä¶")
            await asyncio.sleep(5)

###############################################################################
# Entrypoint
###############################################################################
if __name__ == "__main__":
    asyncio.run(run_ws())

----- FILE: /opt/scalp/project/scripts/WS_multi_candles.py -----
#!/usr/bin/env python3
import asyncio
import json
import websockets
import sqlite3
import time

WS_URL = "wss://ws.bitget.com/v2/ws/public"
DB_U = "/opt/scalp/project/data/universe.db"

# Timeframes in ms for identifying CLOSED candles
TF = {
    "candle5m":  5 * 60 * 1000,
    "candle15m": 15 * 60 * 1000,
    "candle30m": 30 * 60 * 1000
}

################################################################
# Load universe from u.db
################################################################
def load_universe():
    conn = sqlite3.connect(DB_U)
    rows = conn.execute("SELECT instId FROM v_universe_tradable ORDER BY instId;").fetchall()
    conn.close()
    return [r[0] for r in rows]


################################################################
# Build subscription message
################################################################
def build_sub(universe):
    args = []
    for inst in universe:
        args.append({"instType":"USDT-FUTURES","channel":"candle5m","instId":inst})
        args.append({"instType":"USDT-FUTURES","channel":"candle15m","instId":inst})
        args.append({"instType":"USDT-FUTURES","channel":"candle30m","instId":inst})
    return {"op":"subscribe","args":args}


################################################################
# Core WS loop
################################################################
async def ws_loop():
    universe = load_universe()
    sub = build_sub(universe)

    while True:
        try:
            print("[WS] Connecting...")
            async with websockets.connect(WS_URL, ping_interval=20) as ws:
                print("[WS] Connected, subscribing‚Ä¶")
                await ws.send(json.dumps(sub))

                while True:
                    raw = await ws.recv()
                    data = json.loads(raw)

                    # Ignore heartbeats
                    if isinstance(data, dict) and data.get("event") in ("ping","pong"):
                        continue

                    # Only candle messages
                    if "arg" not in data or "data" not in data:
                        continue

                    channel = data["arg"].get("channel")
                    inst    = data["arg"].get("instId")
                    rows    = data["data"]

                    if channel not in TF:
                        continue

                    tf_ms = TF[channel]

                    # Process each kline
                    for k in rows:
                        ts     = int(k[0])
                        open_  = float(k[1])
                        high   = float(k[2])
                        low    = float(k[3])
                        close  = float(k[4])
                        volume = float(k[5])

                        # === FILTER: closed candles only ===
                        if ts % tf_ms != 0:
                            continue

                        print(f"[{channel}] CLOSED {inst}  ts={ts}  "
                              f"open={open_} high={high} low={low} "
                              f"close={close} vol={volume}")

        except Exception as e:
            print(f"[WS] Error: {e}, retry in 5s‚Ä¶")
            await asyncio.sleep(5)


################################################################
# Entry point
################################################################
if __name__ == "__main__":
    asyncio.run(ws_loop())

----- FILE: /opt/scalp/project/scripts/analytics.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3, time, traceback

DB_A = "/opt/scalp/project/data/analytics.db"
DB_R = "/opt/scalp/project/data/recorder.db"

def conn(path):
    c = sqlite3.connect(path, timeout=5, isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    return c

# -------------------------------------------------------------------
# FETCH RECORDED TRADES (base historique)
# -------------------------------------------------------------------
def load_trades():
    c = conn(DB_R)
    rows = c.execute("""
        SELECT
            instId,
            side,
            reason,
            ctx,
            score_A,
            score_B,
            atr_signal,
            pnl_net,
            ts_signal
        FROM trades_recorded
        WHERE status = 'recorded';
    """).fetchall()

    trades = []
    for r in rows:
        inst, side, reason, ctx_dir, scoreA, scoreB, atr, pnl, ts = r

        # Buckets
        scoreC_bucket = (
            'strong' if scoreA >= 0.70 else
            'weak' if scoreA <= 0.30 else
            'mid'
        )

        scoreS_bucket = (
            'strong' if scoreB >= 0.70 else
            'weak' if scoreB <= 0.30 else
            'mid'
        )

        if atr <= 0.5:
            atr_bucket = 'low'
        elif atr <= 1.5:
            atr_bucket = 'mid'
        else:
            atr_bucket = 'high'

        # hour + weekday
        hour = int((ts // 1000) % 86400 // 3600)
        if 2 <= hour <= 10:
            hour_bucket = 1
        elif 11 <= hour <= 16:
            hour_bucket = 2
        elif 17 <= hour <= 22:
            hour_bucket = 3
        else:
            hour_bucket = 4

        weekday = int((ts // 1000) % (7*86400) // 86400)
        weekday_bucket = (
            'weekend' if weekday in (5,6) else
            'fri' if weekday == 4 else
            'mon' if weekday == 0 else
            'tue_thu'
        )

        trades.append((
            inst, side, reason, ctx_dir,
            scoreC_bucket, scoreS_bucket,
            atr_bucket, pnl, hour_bucket,
            weekday_bucket
        ))

    return trades

# -------------------------------------------------------------------
# COMPUTE SCORES
# -------------------------------------------------------------------
def compute_scores(trades):
    agg = {}

    for inst, side, reason, ctx, cB, sB, atrB, pnl, hB, wdB in trades:
        key = (inst, side, reason, ctx, cB, sB, atrB, hB, wdB)

        if key not in agg:
            agg[key] = {"wins": 0, "count": 0, "pnl_sum": 0}

        agg[key]["count"] += 1
        agg[key]["pnl_sum"] += pnl
        if pnl > 0:
            agg[key]["wins"] += 1

    rows = []
    ts_now = int(time.time() * 1000)

    for key, stats in agg.items():
        inst, side, reason, ctx, cB, sB, atrB, hB, wdB = key
        win_rate = stats["wins"] / stats["count"]
        pnl_avg  = stats["pnl_sum"] / stats["count"]

        score_H = 0.5 * win_rate + 0.5 * max(0, pnl_avg)
        score_H = max(0, min(score_H, 1))

        # booster directionnel simple
        if ctx == 'bullish' and side == 'buy':
            score_dir = 1.05
        elif ctx == 'bearish' and side == 'sell':
            score_dir = 1.05
        else:
            score_dir = 0.95

        score_H_final = max(0, min(score_H * score_dir, 1))

        rows.append((
            inst, side, reason,
            ctx, cB, sB,
            atrB, None, hB, wdB,
            win_rate, pnl_avg,
            score_H, score_H_final,
            ts_now
        ))

    return rows

# -------------------------------------------------------------------
# SAVE TO DB
# -------------------------------------------------------------------
def save(rows):
    c = conn(DB_A)
    c.executemany("""
        INSERT OR REPLACE INTO historical_scores (
            instId, side, reason,
            ctx_dir, score_C_bucket, score_S_bucket,
            atr_bucket, of_bucket,
            hour_bucket, weekday_bucket,
            win_rate, pnl_avg,
            score_H, score_H_final,
            ts_updated
        )
        VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?);
    """, rows)

# -------------------------------------------------------------------
# MAIN
# -------------------------------------------------------------------
def main():
    try:
        trades = load_trades()
        rows = compute_scores(trades)
        save(rows)
        print(f"OK analytics: {len(rows)} rows updated")
    except Exception as e:
        print("ERR analytics", e, traceback.format_exc())

if __name__ == "__main__":
    main()


----- FILE: /opt/scalp/project/scripts/analytics_historical.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3, time
from statistics import mean

DB_REC = "/opt/scalp/project/data/recorder.db"
DB_A   = "/opt/scalp/project/data/analytics.db"

def conn(path):
    c = sqlite3.connect(path, timeout=3, isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    return c

# --------------------------------------------------------------------
# BUCKETS
# --------------------------------------------------------------------
def bucket_ctx(ctx, score_A):
    if ctx in ("bullish", "bearish", "flat"):
        return ctx
    return "unknown"

def bucket_hour(ts_open):
    from datetime import datetime
    h = datetime.utcfromtimestamp(ts_open/1000).hour
    if 0 <= h < 6:   return 0
    if 6 <= h < 12:  return 1
    if 12 <= h < 18: return 2
    return 3

def bucket_weekday(ts_open):
    from datetime import datetime
    wd = datetime.utcfromtimestamp(ts_open/1000).weekday()
    if wd in (1,2,3): return "tue_thu"
    if wd == 4:       return "fri"
    if wd in (5,6):   return "weekend"
    return "mon"

def bucket_atr(atr_value):
    if atr_value is None: return "unknown"
    if atr_value < 0.005: return "low"
    if atr_value < 0.015: return "mid"
    return "high"

def bucket_of(of_strength):
    if of_strength is None: return "unknown"
    if of_strength < 0.33:  return "weak"
    if of_strength < 0.66:  return "mid"
    return "strong"

# --------------------------------------------------------------------
# MAIN : CALCUL H
# --------------------------------------------------------------------
def compute_historical():
    cR = conn(DB_REC)
    cA = conn(DB_A)

    rows = cR.execute("""
        SELECT
            instId, side, reason,
            pnl_net, pnl_pct,
            ctx, score_A,
            ts_open,
            atr_signal
        FROM trades_recorded
        WHERE status='recorded'
    """).fetchall()

    groups = {}
    for instId, side, reason, pnl_net, pnl_pct, ctx, score_A, ts_open, atr_signal in rows:
        key = (instId, side, reason)
        if key not in groups:
            groups[key] = {
                "pnls": [],
                "pct": [],
                "ctx": [],
                "ts": [],
                "atr": []
            }
        groups[key]["pnls"].append(pnl_net)
        groups[key]["pct"].append(pnl_pct)
        groups[key]["ctx"].append((ctx, score_A))
        groups[key]["ts"].append(ts_open)
        groups[key]["atr"].append(atr_signal)

    cA.execute("DELETE FROM historical_scores;")

    now = int(time.time()*1000)

    for (instId, side, reason), g in groups.items():

        wins = [p for p in g["pnls"] if p > 0]
        win_rate = len(wins) / len(g["pnls"])

        pnl_avg = mean(g["pct"]) if g["pct"] else 0.0

        score_H = 0.5*win_rate + 0.5*(pnl_avg/0.01)
        if score_H < 0: score_H = 0
        if score_H > 1: score_H = 1

        ctx, scoreA = g["ctx"][-1]
        ctx_dir = bucket_ctx(ctx, scoreA)

        ts_ref = g["ts"][-1]
        hour_b = bucket_hour(ts_ref)
        wd_b   = bucket_weekday(ts_ref)

        atr_ref = g["atr"][-1]
        atr_b = bucket_atr(atr_ref)

        of_b = "unknown"

        cA.execute("""
            INSERT INTO historical_scores(
                instId, side, reason,
                win_rate, pnl_avg, score_H,
                ctx_dir, hour_bucket, weekday_bucket,
                atr_bucket, of_bucket,
                ts_updated
            ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?)
        """, (
            instId, side, reason,
            win_rate, pnl_avg, score_H,
            ctx_dir, hour_b, wd_b,
            atr_b, of_b,
            now
        ))

    cA.commit()
    cA.close()
    cR.close()

if __name__ == "__main__":
    compute_historical()

----- FILE: /opt/scalp/project/scripts/audit_partial.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SCALP ‚Äî AUDIT PARTIAL (ROBUSTE)
Lecture seule ‚Äî tol√©rant aux sch√©mas r√©els
"""

import sqlite3
import sys
from pathlib import Path

ROOT = Path("/opt/scalp/project")

DBS = {
    "gest":     ROOT / "data/gest.db",
    "follower": ROOT / "data/follower.db",
    "closer":   ROOT / "data/closer.db",
    "exec":     ROOT / "data/exec.db",
}

def conn(p):
    c = sqlite3.connect(str(p))
    c.row_factory = sqlite3.Row
    return c

def table_columns(c, table):
    return [r["name"] for r in c.execute(f"PRAGMA table_info({table})")]

def dump(title, rows):
    print(f"\n=== {title} ===")
    if not rows:
        print("(vide)")
        return
    for r in rows:
        print(dict(r))

def safe_select(c, table, uid):
    cols = table_columns(c, table)
    if "uid" not in cols:
        return []

    sql = f"SELECT {', '.join(cols)} FROM {table} WHERE uid=?"
    return c.execute(sql, (uid,)).fetchall()

def audit(uid: str):
    print("\n==============================")
    print(f"AUDIT UID : {uid}")
    print("==============================")

    for name, db in DBS.items():
        with conn(db) as c:
            try:
                rows = safe_select(c, name, uid)
                dump(name.upper(), rows)
            except Exception as e:
                print(f"\n=== {name.upper()} ===")
                print(f"[ERREUR] {e}")

    print("\n--- FIN AUDIT ---\n")

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Usage: audit_partial.py <UID>")
        sys.exit(1)

    audit(sys.argv[1])

----- FILE: /opt/scalp/project/scripts/audit_triggers.py -----
#!/usr/bin/env python3
import sqlite3
import sys
import time
from datetime import datetime

DB_TRIG   = "data/triggers.db"
DB_TICKS  = "data/t.db"
DB_OB     = "data/ob.db"
DB_CTX    = "data/a.db"
DB_AUDIT  = "data/audit_triggers.db"

WINDOW_MS_DEFAULT = 20000

# -----------------------------------------------------------------------------
def connect(path):
    return sqlite3.connect(path, timeout=30)

# -----------------------------------------------------------------------------
def load_ctx():
    """
    v_ctx_latest:
      instId | ctx | score_C | ts_updated
    """
    c = connect(DB_CTX)
    rows = c.execute("""
        SELECT instId, ctx, score_C
        FROM v_ctx_latest
    """).fetchall()
    c.close()
    return {r[0]: (r[1], r[2]) for r in rows}

# -----------------------------------------------------------------------------
def compute_mfe_mae_from_ticks(inst, side, price_entry, ts0, window_ms):
    c = connect(DB_TICKS)
    rows = c.execute("""
        SELECT lastPr
        FROM ticks_hist
        WHERE instId = ?
          AND ts_ms BETWEEN ? AND ?
    """, (inst.replace('/',''), ts0, ts0 + window_ms)).fetchall()
    c.close()

    if not rows:
        return None, None

    prices = [r[0] for r in rows]

    if side == "buy":
        mfe = max(prices) - price_entry
        mae = min(prices) - price_entry
    else:
        mfe = price_entry - min(prices)
        mae = price_entry - max(prices)

    return mfe, mae

# -----------------------------------------------------------------------------
def compute_mfe_mae_from_ohlcv(inst, side, price_entry, ts0, window_ms):
    c = connect(DB_OB)
    rows = c.execute("""
        SELECT h, l
        FROM ohlcv_1m
        WHERE instId = ?
          AND ts BETWEEN ? AND ?
    """, (inst, ts0, ts0 + window_ms)).fetchall()
    c.close()

    if not rows:
        return 0.0, 0.0

    highs = [r[0] for r in rows]
    lows  = [r[1] for r in rows]

    if side == "buy":
        mfe = max(highs) - price_entry
        mae = min(lows)  - price_entry
    else:
        mfe = price_entry - min(lows)
        mae = price_entry - max(highs)

    return mfe, mae

# -----------------------------------------------------------------------------
def outcome_from_mfe_mae(mfe, mae):
    if mfe > 0 and abs(mfe) > abs(mae):
        return "WIN"
    if mae < 0 and abs(mae) > abs(mfe):
        return "LOSS"
    return "FLAT"

# -----------------------------------------------------------------------------
def audit(reset=False):
    ca = connect(DB_AUDIT)
    ct = connect(DB_TRIG)

    if reset:
        ca.execute("DELETE FROM audit_triggers")
        ca.commit()

    ctx_map = load_ctx()

    rows = ct.execute("""
        SELECT
          uid,
          instId,
          side,
          status,
          price,
          atr,
          ts,
          ts_fire,
          ttl_ms,
          validated
        FROM triggers
        WHERE status = 'fire'
    """).fetchall()

    inserted = 0

    for r in rows:
        uid, inst, side, status, price, atr, ts, ts_fire, ttl_ms, validated = r
        if not ts_fire:
            continue

        window_ms = ttl_ms or WINDOW_MS_DEFAULT
        life_ms   = window_ms

        mfe, mae = compute_mfe_mae_from_ticks(inst, side, price, ts_fire, window_ms)

        if mfe is None:
            mfe, mae = compute_mfe_mae_from_ohlcv(inst, side, price, ts_fire, window_ms)

        outcome = outcome_from_mfe_mae(mfe, mae)

        ctx, score_ctx = ctx_map.get(inst, (None, None))

        ca.execute("""
            INSERT OR IGNORE INTO audit_triggers (
              uid, instId, side, trigger_status,
              price_entry, atr,
              mfe, mae, outcome,
              entry_price,
              mfe_atr, mae_atr,
              ts_trigger,
              window_ms, validated,
              mfe_early, mae_early,
              ttl_ms, life_ms,
              outcome_early,
              ctx, score_ctx
            ) VALUES (
              ?,?,?,?,?,?,
              ?,?,?,?,
              ?,?,
              ?,?,
              ?,?,
              ?,?,
              ?,?,
              ?,?
            )
        """, (
            uid, inst, side, status,
            price, atr or 0.0,
            mfe or 0.0, mae or 0.0, outcome,
            price,
            (mfe/atr) if atr else 0.0,
            (mae/atr) if atr else 0.0,
            ts_fire,
            window_ms, validated or 0,
            mfe or 0.0, mae or 0.0,
            ttl_ms or window_ms,
            life_ms,
            outcome,
            ctx, score_ctx
        ))

        if ca.total_changes > 0:
            inserted += 1

    ca.commit()
    ca.close()
    ct.close()

    print(f"[OK] audit_triggers rows inserted: {inserted}")

# -----------------------------------------------------------------------------
if __name__ == "__main__":
    audit("--reset" in sys.argv)

----- FILE: /opt/scalp/project/scripts/budget.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SCALP ‚Äî BUDGET AGGREGATOR (CANON)

R√îLE STRICT :
- SEUL writer de budget.db
- lit exec.db + recorder.db + balance
- mat√©rialise l'√©tat du capital
- AUCUN ATTACH
- AUCUNE vue inter-DB
- SQLITE SAFE

BOUCLE ~1 Hz
"""

import sqlite3
import time
import logging
import traceback
from pathlib import Path

# ============================================================
# PATHS
# ============================================================

ROOT = Path("/opt/scalp/project")

DB_EXEC    = ROOT / "data/exec.db"
DB_REC     = ROOT / "data/recorder.db"
DB_BUDGET  = ROOT / "data/budget.db"

LOG = ROOT / "logs/budget.log"
LOOP_SLEEP = 1.0

# ============================================================
# LOG
# ============================================================

logging.basicConfig(
    filename=str(LOG),
    level=logging.INFO,
    format="%(asctime)s BUDGET %(levelname)s %(message)s"
)
log = logging.getLogger("BUDGET")

# ============================================================
# UTILS
# ============================================================

def now_ms():
    return int(time.time() * 1000)

def conn(p, ro=False):
    uri = f"file:{p}?mode=ro" if ro else str(p)
    c = sqlite3.connect(uri, uri=ro, timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

# ============================================================
# INIT SCHEMA
# ============================================================

def init_budget_db():
    b = conn(DB_BUDGET)
    b.executescript("""
    CREATE TABLE IF NOT EXISTS budget_state (
        id INTEGER PRIMARY KEY CHECK (id = 1),
        equity REAL NOT NULL,
        margin_used REAL NOT NULL,
        free_balance REAL NOT NULL,
        risk_ratio REAL NOT NULL,
        pnl_realized REAL NOT NULL,
        fee_total REAL NOT NULL,
        ts_update INTEGER NOT NULL
    );

    CREATE TABLE IF NOT EXISTS budget_exposure (
        uid TEXT PRIMARY KEY,
        notional_engaged REAL NOT NULL,
        ts_update INTEGER NOT NULL
    );
    """)
    b.commit()
    b.close()

# ============================================================
# CORE
# ============================================================

def recompute_budget():
    ts = now_ms()

    e = conn(DB_EXEC, ro=True)
    r = conn(DB_REC,  ro=True)
    b = conn(DB_BUDGET)

    # --------------------------------------------------------
    # BALANCE INITIALE
    # --------------------------------------------------------
    row = b.execute("SELECT balance_usdt FROM balance WHERE id=1").fetchone()
    if not row:
        raise RuntimeError("balance_usdt manquant dans budget.db")

    balance_init = float(row["balance_usdt"])

    # --------------------------------------------------------
    # PNL R√âALIS√â (RECORDER)
    # --------------------------------------------------------
    row = r.execute("""
        SELECT COALESCE(SUM(pnl_realized), 0.0) AS pnl
        FROM recorder
    """).fetchone()

    pnl_realized = float(row["pnl"])

    # --------------------------------------------------------
    # FEES TOTALES (EXEC)
    # --------------------------------------------------------
    row = e.execute("""
        SELECT COALESCE(SUM(fee), 0.0) AS fee
        FROM exec
    """).fetchone()

    fee_total = float(row["fee"])

    # --------------------------------------------------------
    # EXPOSITION PAR UID (EXEC)
    # --------------------------------------------------------
    exposures = {}
    for row in e.execute("""
        SELECT uid,
               SUM(ABS(qty * price_exec)) AS notional
        FROM exec
        WHERE exec_type IN ('open','pyramide')
        GROUP BY uid
    """):
        exposures[row["uid"]] = float(row["notional"] or 0.0)

    # --------------------------------------------------------
    # MARGIN UTILIS√âE
    # --------------------------------------------------------
    margin_used = sum(exposures.values())

    # --------------------------------------------------------
    # EQUITY / FREE / RISK
    # --------------------------------------------------------
    equity = balance_init + pnl_realized - fee_total
    free_balance = equity - margin_used
    risk_ratio = (margin_used / equity) if equity > 0 else 0.0

    # --------------------------------------------------------
    # WRITE budget_exposure
    # --------------------------------------------------------
    b.execute("DELETE FROM budget_exposure")
    for uid, notion in exposures.items():
        b.execute("""
            INSERT INTO budget_exposure(uid, notional_engaged, ts_update)
            VALUES (?,?,?)
        """, (uid, notion, ts))

    # --------------------------------------------------------
    # WRITE budget_state (UPSERT)
    # --------------------------------------------------------
    b.execute("""
        INSERT INTO budget_state(
            id, equity, margin_used, free_balance,
            risk_ratio, pnl_realized, fee_total, ts_update
        ) VALUES (1,?,?,?,?,?,?,?)
        ON CONFLICT(id) DO UPDATE SET
            equity=excluded.equity,
            margin_used=excluded.margin_used,
            free_balance=excluded.free_balance,
            risk_ratio=excluded.risk_ratio,
            pnl_realized=excluded.pnl_realized,
            fee_total=excluded.fee_total,
            ts_update=excluded.ts_update
    """, (
        equity, margin_used, free_balance,
        risk_ratio, pnl_realized, fee_total, ts
    ))

    b.commit()
    e.close(); r.close(); b.close()

    log.info(
        "equity=%.2f free=%.2f margin=%.2f risk=%.2f",
        equity, free_balance, margin_used, risk_ratio
    )

# ============================================================
# MAIN
# ============================================================

def main():
    log.info("[START] budget aggregator")
    init_budget_db()

    while True:
        try:
            recompute_budget()
        except Exception:
            log.error("[ERR]\n%s", traceback.format_exc())
        time.sleep(LOOP_SLEEP)

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/budget_updater.py -----
#!/usr/bin/env python3
import sqlite3, time, logging, sys
from pathlib import Path

DB_BUDGET  = Path("/opt/scalp/project/data/budget.db")
DB_OPENER  = Path("/opt/scalp/project/data/opener.db")
DB_CLOSER  = Path("/opt/scalp/project/data/closer.db")
DB_REC     = Path("/opt/scalp/project/data/recorder.db")
LOG        = "/opt/scalp/project/logs/budget.log"

# -----------------------------------------------------
def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s BUDGET %(levelname)s %(message)s",
        handlers=[logging.FileHandler(LOG), logging.StreamHandler(sys.stdout)],
        force=True,
    )

# -----------------------------------------------------
def connect(path):
    c = sqlite3.connect(path, timeout=30, isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=5000;")
    return c

# -----------------------------------------------------
def get_margin_engaged(con_o):
    """Somme de la marge estim√©e sur les positions ouvertes/pending."""
    try:
        res = con_o.execute("""
            SELECT SUM(entry * qty / leverage)
            FROM trades_open_init
            WHERE status IN ('pending','open');
        """).fetchone()[0]
        return round(res or 0.0, 4)
    except Exception:
        return 0.0

def get_pnl_real(con_r):
    """Somme du PnL r√©alis√© total depuis l‚Äôhistorique."""
    try:
        res = con_r.execute("SELECT SUM(pnl_net) FROM trades_recorded;").fetchone()[0]
        if res is None:
            res = con_r.execute("SELECT SUM(pnl) FROM trades_recorded;").fetchone()[0]
        return round(res or 0.0, 4)
    except Exception:
        return 0.0

def get_capital_initial(con_b):
    """Capital initial du budget (si non encore pr√©sent, cr√©e 1000 USDT)."""
    con_b.execute("""
        CREATE TABLE IF NOT EXISTS budget_state(
            id INTEGER PRIMARY KEY CHECK (id=1),
            balance REAL DEFAULT 1000.0,
            margin REAL DEFAULT 0.0,
            pnl_real REAL DEFAULT 0.0,
            ts_update INTEGER
        );
    """)
    con_b.commit()
    row = con_b.execute("SELECT balance FROM budget_state WHERE id=1;").fetchone()
    if not row:
        con_b.execute("INSERT OR REPLACE INTO budget_state(id,balance,margin,pnl_real,ts_update) VALUES (1,1000.0,0.0,0.0,strftime('%s','now'));")
        con_b.commit()
        return 1000.0
    return float(row[0])

# -----------------------------------------------------
def update_budget():
    con_b = connect(DB_BUDGET)
    con_o = connect(DB_OPENER)
    con_r = connect(DB_REC)

    capital = get_capital_initial(con_b)
    margin  = get_margin_engaged(con_o)
    pnl_real = get_pnl_real(con_r)

    new_balance = capital + pnl_real
    ts_now = int(time.time())

    con_b.execute("""
        UPDATE budget_state
        SET balance=?, margin=?, pnl_real=?, ts_update=?
        WHERE id=1;
    """, (new_balance, margin, pnl_real, ts_now))
    con_b.commit()

    con_b.execute("""
        CREATE VIEW IF NOT EXISTS v_budget_overview AS
        SELECT
            ROUND(balance,4) AS balance,
            ROUND(margin,4)  AS margin,
            ROUND(pnl_real,4) AS pnl_real,
            datetime(ts_update,'unixepoch','localtime') AS ts_local
        FROM budget_state;
    """)
    con_b.commit()

    con_b.close(); con_o.close(); con_r.close()
    logging.info(f"MAJ budget ‚Üí balance={new_balance:.2f} margin={margin:.2f} pnl_real={pnl_real:.2f}")

# -----------------------------------------------------
def main(_):
    setup_logging()
    logging.info("Budget updater started ‚úì")
    try:
        update_budget()
    except Exception as e:
        logging.exception(f"Erreur mise √† jour budget: {e}")
        raise SystemExit(1)

if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))

----- FILE: /opt/scalp/project/scripts/check_atr_consistency.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
CHECK ATR CONSISTENCY

OBJECTIF :
- V√©rifier que l'ATR stock√© (gest.atr_signal) est coh√©rent
- V√©rifier que mfe/mae sont bien des PRIX (et non des ATR)
- Calculer mfe_atr / mae_atr r√©els pour comparaison humaine

AUCUNE √âCRITURE
READ-ONLY
"""

import sqlite3
from pathlib import Path

ROOT = Path("/opt/scalp/project")

DB_GEST     = ROOT / "data/gest.db"
DB_FOLLOWER = ROOT / "data/follower.db"

def conn(db):
    c = sqlite3.connect(str(db))
    c.row_factory = sqlite3.Row
    return c

g = conn(DB_GEST)
f = conn(DB_FOLLOWER)

print(
    f"{'INST':<12} "
    f"{'ATR':>8} "
    f"{'MFE_P':>8} {'MAE_P':>8} "
    f"{'MFE_ATR':>8} {'MAE_ATR':>8}"
)
print("=" * 70)

for r in f.execute("""
    SELECT
        f.uid,
        f.mfe_price,
        f.mae_price,
        g.instId,
        g.atr_signal
    FROM follower f
    JOIN gest g USING(uid)
    ORDER BY g.ts_open DESC
    LIMIT 20
"""):
    atr = float(r["atr_signal"] or 0)
    mfe_p = float(r["mfe_price"] or 0)
    mae_p = abs(float(r["mae_price"] or 0))

    mfe_atr = mfe_p / atr if atr > 0 else 0
    mae_atr = mae_p / atr if atr > 0 else 0

    print(
        f"{r['instId']:<12} "
        f"{atr:>8.4f} "
        f"{mfe_p:>8.4f} {mae_p:>8.4f} "
        f"{mfe_atr:>8.2f} {mae_atr:>8.2f}"
    )

g.close()
f.close()

----- FILE: /opt/scalp/project/scripts/closer.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3
import time
import logging
import math
from pathlib import Path
from opener_contracts import normalize_qty

ROOT = Path("/opt/scalp/project")
DB_GEST      = ROOT / "data/gest.db"
DB_EXEC      = ROOT / "data/exec.db"
DB_CLOSER    = ROOT / "data/closer.db"
DB_CONTRACTS = ROOT / "data/contracts.db"

logging.basicConfig(
    filename=str(ROOT / "logs/closer.log"),
    level=logging.INFO,
    format="%(asctime)s CLOSER %(levelname)s %(message)s"
)
log = logging.getLogger("CLOSER")

def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

def now_ms():
    return int(time.time()*1000)

def _safe(x, d=0.0):
    try:
        return float(x) if x is not None else d
    except:
        return d

# ============================================================
# AUTO PARTIAL ADAPT√â CONTRATS (ARRONDI SUP√âRIEUR)
# ============================================================

def compute_partial_qty_auto(qty_open, ratio, price, contract):
    qty_raw = qty_open * ratio

    if not contract or price <= 0:
        return qty_raw

    min_qty      = _safe(contract["minTradeNum"])
    min_notional = _safe(contract["minTradeUSDT"])
    vol_place    = int(contract["volumePlace"])
    step         = _safe(contract["sizeMultiplier"])

    # quantit√© minimale pour respecter minTradeUSDT
    qty_min_notional = min_notional / price

    qty_adj = max(qty_raw, qty_min_notional)

    # respecter minTradeNum
    if qty_adj < min_qty:
        qty_adj = min_qty

    # respecter multiple sizeMultiplier (ARRONDI SUP√âRIEUR)
    if step > 0:
        qty_adj = math.ceil(qty_adj / step) * step

    # respecter pr√©cision volumePlace (ARRONDI SUP√âRIEUR)
    factor = 10 ** vol_place
    qty_adj = math.ceil(qty_adj * factor) / factor

    # ne jamais d√©passer la position
    if qty_adj > qty_open:
        qty_adj = qty_open

    return qty_adj

def loop():
    g = conn(DB_GEST)
    e = conn(DB_EXEC)
    c = conn(DB_CLOSER)
    k = conn(DB_CONTRACTS)

    # ========================================================
    # GEST *_REQ ‚Üí CLOSER *_STDBY
    # ========================================================
    for r in g.execute("""
        SELECT uid, instId, side, status, ratio_to_close, step, reason
        FROM gest
        WHERE status IN ('partial_req','close_req')
    """):

        uid     = r["uid"]
        instId  = r["instId"]
        side    = r["side"]
        gstat   = r["status"]
        step_id = r["step"]
        reason  = r["reason"]

        exec_type = "partial" if gstat == "partial_req" else "close"

        ratio = _safe(r["ratio_to_close"], 0.0)

        if exec_type == "partial" and ratio <= 0:
            ratio = 0.25

        if exec_type == "close":
            ratio = 1.0

        pos = e.execute(
            "SELECT qty_open,last_price_exec FROM v_exec_position WHERE uid=?",
            (uid,)
        ).fetchone()

        if not pos:
            continue

        qty_open = _safe(pos["qty_open"])
        last_px  = _safe(pos["last_price_exec"])

        if qty_open <= 0:
            continue

        contract = k.execute(
            "SELECT * FROM contracts WHERE symbol=?",
            (instId.replace('/',''),)
        ).fetchone()

        # ====================================================
        # CALCUL QUANTIT√â
        # ====================================================
        if exec_type == "partial":
            qty_raw = qty_open * ratio
            qty_adj = compute_partial_qty_auto(
                qty_open=qty_open,
                ratio=ratio,
                price=last_px,
                contract=contract
            )
        else:
            # close complet
            qty_raw = qty_open
            qty_adj = qty_open

        if qty_adj <= 0:
            log.info(
                "[SKIP_TOO_SMALL] %s %s uid=%s qty_raw=%.10f",
                exec_type.upper(), instId, uid, qty_raw
            )
            continue

        # normalisation finale exchange
        qty_norm = normalize_qty(
            qty_raw=qty_adj,
            price=last_px,
            contract=contract
        ) if contract else qty_adj

        qty_norm = _safe(qty_norm)

        if qty_norm <= 0:
            log.info(
                "[SKIP_AFTER_NORMALIZE] %s %s uid=%s qty_adj=%.10f",
                exec_type.upper(), instId, uid, qty_adj
            )
            continue

        if c.execute("""
            SELECT 1 FROM closer
            WHERE uid=? AND exec_type=? AND step=?
        """,(uid,exec_type,step_id)).fetchone():
            continue

        c.execute("""
            INSERT INTO closer
            (uid, exec_type, side, qty, price_exec, fee,
             step, reason, ts_exec, status, instId,
             close_step, ratio, qty_raw, qty_norm, reject_reason)
            VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)
        """,(
            uid, exec_type, side, qty_norm, None, 0.0,
            step_id, reason, now_ms(), f"{exec_type}_stdby", instId,
            0, ratio, qty_raw, qty_norm, None
        ))

        log.info(
            "[%s_STDBY] %s qty=%.8f ratio=%.2f",
            exec_type.upper(), uid, qty_norm, ratio
        )

    # ========================================================
    # EXEC DONE ‚Üí propagate *_DONE
    # ========================================================
    for r in e.execute("""
        SELECT uid, exec_type, step
        FROM exec
        WHERE status='done'
          AND exec_type IN ('partial','close')
    """):

        uid       = r["uid"]
        exec_type = r["exec_type"]
        step_id   = r["step"]

        c.execute("""
            UPDATE closer SET status=?
            WHERE uid=? AND exec_type=? AND step=? AND status=?
        """,(
            f"{exec_type}_done",
            uid,
            exec_type,
            step_id,
            f"{exec_type}_stdby"
        ))

        g.execute("""
            UPDATE gest SET status=?
            WHERE uid=? AND step=? AND status=?
        """,(
            f"{exec_type}_done",
            uid,
            step_id,
            f"{exec_type}_req"
        ))

    c.commit()
    g.commit()
    g.close()
    e.close()
    c.close()
    k.close()

if __name__ == "__main__":
    while True:
        try:
            loop()
        except Exception:
            log.exception("ERR")
        time.sleep(0.25)

----- FILE: /opt/scalp/project/scripts/coin_classify.py -----
# -*- coding: utf-8 -*-

"""
COIN CLASSIFICATION ‚Äî D√âTERMINISTE
Aucune logique dynamique
Aucune d√©pendance march√©
FSM-safe
"""

# ------------------------------------------------------------
# Classement statique par instrument
# ------------------------------------------------------------

COIN_CLASS = {
    # CORE
    "BTC/USDT": "CORE",
    "ETH/USDT": "CORE",

    # MAJOR
    "BNB/USDT": "MAJOR",
    "SOL/USDT": "MAJOR",
    "XRP/USDT": "MAJOR",
    "ADA/USDT": "MAJOR",
    "AVAX/USDT": "MAJOR",
    "DOGE/USDT": "MAJOR",

    # STABLE / METALS
    "XAUT/USDT": "STABLE",
    "PAXG/USDT": "STABLE",
}

DEFAULT_CLASS = "ALT"


def classify_coin(instId: str) -> str:
    """
    Retourne la classe du coin.
    - d√©terministe
    - statique
    - ne change jamais pendant le trade
    """
    return COIN_CLASS.get(instId, DEFAULT_CLASS)

----- FILE: /opt/scalp/project/scripts/ctx_macro.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SCALP ‚Äî CTX MACRO (OB.DB + FEATURES)

R√îLE STRICT :
- Market OK        : market.db / v_market_latest
- Historique prix  : ob.db / ohlcv_5m
- Features         : b.db / v_feat_5m
- Output           : ctx_macro.db (sch√©ma EXISTANT)

MODES :
- --once
- --debug
"""

import sqlite3
import time
import statistics
import sys
from collections import defaultdict
from pathlib import Path

ROOT = Path("/opt/scalp/project")

DB_MARKET = ROOT / "data/market.db"
DB_OB     = ROOT / "data/ob.db"
DB_B      = ROOT / "data/b.db"
DB_CTX    = ROOT / "data/ctx_macro.db"

RET_WINDOW_MS = 15 * 60 * 1000   # 15 minutes
MIN_POINTS = 10

# ============================================================
# UTILS
# ============================================================

def now_ms():
    return int(time.time() * 1000)

def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

# ============================================================
# CORE
# ============================================================

def compute_ctx_macro(debug=False):
    ts = now_ms()

    cM = conn(DB_MARKET)
    cO = conn(DB_OB)
    cB = conn(DB_B)
    cC = conn(DB_CTX)

    # --------------------------------------------------------
    # MARKET OK
    # --------------------------------------------------------
    rows = cM.execute("""
        SELECT instId
        FROM v_market_latest
        WHERE market_ok = 1
    """).fetchall()

    insts = [r["instId"] for r in rows]

    if debug:
        print(f"[DBG] market_ok universe: {len(insts)}")

    reasons = defaultdict(int)
    examples = defaultdict(list)

    returns = []
    atrs = []

    btc_ret = None
    alt_rets = []

    # --------------------------------------------------------
    # PER COIN
    # --------------------------------------------------------
    for inst in insts:
        # latest OHLCV 5m
        r_now = cO.execute("""
            SELECT ts, c
            FROM ohlcv_5m
            WHERE instId=?
            ORDER BY ts DESC
            LIMIT 1
        """, (inst,)).fetchone()

        if not r_now:
            reasons["NO_OHLCV_LATEST"] += 1
            continue

        ts_now = r_now["ts"]
        price_now = r_now["c"]

        # past OHLCV
        r_past = cO.execute("""
            SELECT c
            FROM ohlcv_5m
            WHERE instId=?
              AND ts <= ?
            ORDER BY ts DESC
            LIMIT 1
        """, (inst, ts_now - RET_WINDOW_MS)).fetchone()

        if not r_past:
            reasons["NO_OHLCV_PAST"] += 1
            continue

        price_past = r_past["c"]

        # features 5m (ATR uniquement requis ici)
        f = cB.execute("""
            SELECT atr
            FROM v_feat_5m
            WHERE instId=?
            ORDER BY ts DESC
            LIMIT 1
        """, (inst,)).fetchone()

        if not f or not f["atr"] or f["atr"] <= 0:
            reasons["NO_ATR_FEAT"] += 1
            continue

        ret = (price_now - price_past) / price_past

        returns.append(ret)
        atrs.append(f["atr"])

        if inst.startswith("BTC"):
            btc_ret = ret
        else:
            alt_rets.append(ret)

        if debug and len(examples["PASS"]) < 5:
            examples["PASS"].append(
                f"{inst} ret={ret:+.3%} atr={f['atr']:.6f}"
            )

    # --------------------------------------------------------
    # DEBUG REPORT
    # --------------------------------------------------------
    if debug:
        print(f"[DBG] kept points: {len(returns)}")
        print("[DBG] FAIL REASONS")
        for k, v in reasons.items():
            print(f"  - {k:<18s}: {v}")
        if examples.get("PASS"):
            print("[DBG] PASS SAMPLES")
            for e in examples["PASS"]:
                print("   ", e)

    if len(returns) < MIN_POINTS:
        print(f"[CTX_MACRO] insufficient data (points={len(returns)} < {MIN_POINTS})")
        return

    # --------------------------------------------------------
    # MACRO METRICS
    # --------------------------------------------------------
    breadth = sum(1 for r in returns if abs(r) >= 0.005) / len(returns)

    if breadth >= 0.40:
        breadth_state = "STRONG"
    elif breadth >= 0.20:
        breadth_state = "WEAK"
    else:
        breadth_state = "FLAT"

    direction = statistics.mean(returns)
    if direction > 0:
        direction_state = "BULL"
    elif direction < 0:
        direction_state = "BEAR"
    else:
        direction_state = "MIXED"

    if btc_ret is not None and alt_rets:
        risk_value = statistics.median(alt_rets) - btc_ret
        risk_state = "ON" if risk_value > 0 else "OFF"
    else:
        risk_value = 0.0
        risk_state = "OFF"

    vol_value = statistics.median(atrs)

    hist = cC.execute("""
        SELECT vol_value
        FROM ctx_macro
        ORDER BY ts DESC
        LIMIT 30
    """).fetchall()

    vol_ref = statistics.mean([h["vol_value"] for h in hist]) if hist else vol_value

    if vol_value > vol_ref * 1.3:
        vol_state = "HIGH"
    elif vol_value < vol_ref * 0.7:
        vol_state = "LOW"
    else:
        vol_state = "NORMAL"

    if breadth_state == "STRONG" and direction_state == "BULL":
        regime = "TREND_BULL"
    elif breadth_state == "STRONG" and direction_state == "BEAR":
        regime = "TREND_BEAR"
    elif breadth_state == "FLAT" and vol_state == "LOW":
        regime = "DEAD"
    else:
        regime = "CHOP"

    # --------------------------------------------------------
    # WRITE (ALIGN√â SCH√âMA ctx_macro)
    # --------------------------------------------------------
    cC.execute("""
        INSERT OR REPLACE INTO ctx_macro (
            ts,
            universe_size,
            breadth_value,
            breadth_state,
            direction_value,
            direction_state,
            risk_value,
            risk_state,
            vol_value,
            vol_state,
            regime
        ) VALUES (?,?,?,?,?,?,?,?,?,?,?)
    """, (
        ts,
        len(insts),
        breadth,
        breadth_state,
        direction,
        direction_state,
        risk_value,
        risk_state,
        vol_value,
        vol_state,
        regime
    ))

    cC.commit()

    print(
        "[CTX_MACRO]",
        f"U={len(insts)}",
        f"points={len(returns)}",
        f"breadth={breadth_state}({breadth:.2f})",
        f"dir={direction_state}",
        f"risk={risk_state}",
        f"vol={vol_state}",
        f"regime={regime}"
    )

    cM.close()
    cO.close()
    cB.close()
    cC.close()

# ============================================================
# MAIN
# ============================================================

def main():
    debug = "--debug" in sys.argv
    once = "--once" in sys.argv

    if once:
        compute_ctx_macro(debug=debug)
        return

    while True:
        compute_ctx_macro(debug=debug)
        time.sleep(60)

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/dec_atr.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
DEC ‚Äî ATR LOADER + SELECTOR (CANONIQUE / SAFE)

Sources :
- b.db / v_atr_context : ATR rapides (1m / 3m / 5m)
- a.db / feat_15m, feat_30m : ATR lents
"""

import sqlite3
from pathlib import Path

ROOT = Path("/opt/scalp/project")
DB_B = ROOT / "data/b.db"
DB_A = ROOT / "data/a.db"


def conn(p):
    c = sqlite3.connect(str(p), timeout=10)
    c.row_factory = sqlite3.Row
    return c


# --------------------------------------------------
# LOAD ATR MAP (MERGE b.db + a.db)
# --------------------------------------------------
def load_atr_map():
    out = {}

    # --- ATR rapides (b.db)
    with conn(DB_B) as c:
        for r in c.execute("""
            SELECT instId, atr_1m, atr_3m, atr_5m
            FROM v_atr_context
        """):
            out[r["instId"]] = dict(r)

    # --- ATR lents 15m (a.db)
    with conn(DB_A) as c:
        for r in c.execute("""
            SELECT instId, atr AS atr_15m
            FROM feat_15m
            WHERE (instId, ts) IN (
                SELECT instId, MAX(ts)
                FROM feat_15m
                GROUP BY instId
            )
        """):
            out.setdefault(r["instId"], {})["atr_15m"] = r["atr_15m"]

    # --- ATR lents 30m (a.db)
    with conn(DB_A) as c:
        for r in c.execute("""
            SELECT instId, atr AS atr_30m
            FROM feat_30m
            WHERE (instId, ts) IN (
                SELECT instId, MAX(ts)
                FROM feat_30m
                GROUP BY instId
            )
        """):
            out.setdefault(r["instId"], {})["atr_30m"] = r["atr_30m"]

    return out


# --------------------------------------------------
# SELECT ATR PAR PATTERN
# --------------------------------------------------
def select_atr(ctx, atr):
    if not atr:
        return None, None, "UNKNOWN"

    def g(k):
        return atr.get(k)

    if ctx == "MOMENTUM":
        fast, slow = g("atr_1m"), g("atr_5m")
    elif ctx == "PREBREAK":
        fast, slow = g("atr_3m"), g("atr_5m")
    elif ctx == "DRIFT":
        fast, slow = g("atr_5m"), g("atr_15m")
    elif ctx == "CONT":
        fast, slow = g("atr_5m"), g("atr_30m")
    else:
        fast, slow = g("atr_5m"), g("atr_15m")

    if not fast or not slow or slow <= 0:
        return fast, slow, "UNKNOWN"

    ratio = fast / slow
    if ratio < 0.40:
        vol = "COMPRESS"
    elif ratio > 0.75:
        vol = "EXPAND"
    else:
        vol = "NORMAL"

    return fast, slow, vol

----- FILE: /opt/scalp/project/scripts/dec_atr_fast.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
DEC ‚Äî ATR FAST / SLOW SELECTOR (CANONIQUE)

- Source : b.db / v_atr_context (READ-ONLY)
- S√©lection ATR par pattern (ctx)
- Calcul r√©gime de volatilit√©
- AUCUN recalcul d‚Äôindicateur
- SAFE si colonnes manquantes
"""

import sqlite3
from pathlib import Path

ROOT = Path("/opt/scalp/project")
DB_B = ROOT / "data/b.db"

# ------------------------------------------------------------
# SQLITE CONN
# ------------------------------------------------------------
def conn():
    c = sqlite3.connect(str(DB_B), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

# ------------------------------------------------------------
# LOAD ATR MAP
# ------------------------------------------------------------
def load_atr_map():
    """
    Charge v_atr_context
    Retour : dict instId -> sqlite3.Row
    """
    with conn() as c:
        rows = c.execute("""
            SELECT *
            FROM v_atr_context
        """).fetchall()

    return {r["instId"]: r for r in rows}

# ------------------------------------------------------------
# SAFE ACCESS
# ------------------------------------------------------------
def _get(r, k):
    return r[k] if r and k in r.keys() else None

# ------------------------------------------------------------
# ATR SELECTION (PAR PATTERN)
# ------------------------------------------------------------
def select_atr(ctx, atr):
    """
    ctx : string (MOMENTUM / PREBREAK / DRIFT / CONT / autre)
    atr : sqlite3.Row depuis v_atr_context
    """

    if not atr:
        return None, None, "UNKNOWN"

    # ---------------------------
    # Mapping ATR fast / slow
    # ---------------------------
    if ctx == "MOMENTUM":
        fast = _get(atr, "atr_1m")
        slow = _get(atr, "atr_5m")

    elif ctx == "PREBREAK":
        fast = _get(atr, "atr_3m")
        slow = _get(atr, "atr_5m")

    elif ctx == "DRIFT":
        fast = _get(atr, "atr_5m")
        slow = _get(atr, "atr_15m")

    elif ctx == "CONT":
        fast = _get(atr, "atr_5m")
        slow = _get(atr, "atr_30m")

    else:
        fast = _get(atr, "atr_5m")
        slow = _get(atr, "atr_15m")

    # ---------------------------
    # Volatility regime
    # ---------------------------
    if not fast or not slow or slow <= 0:
        return fast, slow, "UNKNOWN"

    ratio = fast / slow

    if ratio < 0.40:
        vol = "COMPRESS"
    elif ratio > 0.75:
        vol = "EXPAND"
    else:
        vol = "NORMAL"

    return fast, slow, vol


----- FILE: /opt/scalp/project/scripts/dec_atr_map.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
DEC ‚Äî ATR MAP (FAST + SLOW MERGE)
"""

from dec_atr_fast import load_atr_fast_map
from dec_atr_slow import load_atr_slow_map

def load_atr_map():
    fast = load_atr_fast_map()
    slow = load_atr_slow_map()

    out = {}

    keys = set(fast.keys()) | set(slow.keys())
    for instId in keys:
        row = {}
        if instId in fast:
            row.update(dict(fast[instId]))
        if instId in slow:
            row.update(dict(slow[instId]))
        out[instId] = row

    return out

----- FILE: /opt/scalp/project/scripts/dec_atr_slow.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
DEC ‚Äî ATR SLOW LOADER
Source : a.db (feat_15m / feat_30m)
"""

import sqlite3
from pathlib import Path

ROOT = Path("/opt/scalp/project")
DB_A = ROOT / "data/a.db"

def conn():
    c = sqlite3.connect(str(DB_A), timeout=5)
    c.row_factory = sqlite3.Row
    return c

def load_atr_slow_map():
    with conn() as c:
        rows = c.execute("""
            SELECT instId,
                   MAX(atr) FILTER (WHERE tf='15m') AS atr_15m,
                   MAX(atr) FILTER (WHERE tf='30m') AS atr_30m
            FROM (
                SELECT instId, atr, '15m' AS tf FROM feat_15m
                UNION ALL
                SELECT instId, atr, '30m' AS tf FROM feat_30m
            )
            GROUP BY instId
        """).fetchall()

    return {r["instId"]: r for r in rows}

----- FILE: /opt/scalp/project/scripts/dec_ctx.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
DEC ‚Äî CTX MICRO READER
Source : a.db / v_ctx_signal
"""

import sqlite3
from pathlib import Path

ROOT = Path("/opt/scalp/project")
DB_A = ROOT / "data/a.db"

def conn():
    c = sqlite3.connect(str(DB_A), timeout=10)
    c.row_factory = sqlite3.Row
    return c

def load_ctx():
    with conn() as c:
        return c.execute("""
            SELECT instId, ctx, score_C, side
            FROM v_ctx_signal
            WHERE ctx_ok = 1
        """).fetchall()

----- FILE: /opt/scalp/project/scripts/dec_market.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
DEC ‚Äî MARKET VETO
Source : market.db / v_market_latest
"""

import sqlite3
from pathlib import Path

ROOT = Path("/opt/scalp/project")
DB_MARKET = ROOT / "data/market.db"

def conn():
    c = sqlite3.connect(str(DB_MARKET), timeout=10)
    c.row_factory = sqlite3.Row
    return c

def load_market_ok():
    with conn() as c:
        return {
            r["instId"]: r
            for r in c.execute("""
                SELECT instId, ticks_5s, spread_bps, staleness_ms
                FROM v_market_latest
                WHERE market_ok = 1
            """)
        }

def market_pass(m, cfg):
    return not (
        m["ticks_5s"]   < cfg["min_ticks_5s"]
        or m["spread_bps"] > cfg["max_spread_bps"]
        or m["staleness_ms"] > cfg["max_staleness_ms"]
    )

----- FILE: /opt/scalp/project/scripts/dec_ticks_mirror.py -----
#!/usr/bin/env python3
import sqlite3
import time
from pathlib import Path

ROOT = Path("/opt/scalp/project")
DB_TICKS = ROOT / "data/t.db"
DB_DEC   = ROOT / "data/dec.db"

SLEEP = 0.25

def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    return c

while True:
    with conn(DB_TICKS) as t, conn(DB_DEC) as d:
        rows = t.execute("""
            SELECT instId, lastPr, ts_ms
            FROM v_ticks_latest
        """).fetchall()

        d.executemany("""
            INSERT INTO ticks_live(instId,lastPr,ts_ms)
            VALUES(?,?,?)
            ON CONFLICT(instId) DO UPDATE SET
              lastPr=excluded.lastPr,
              ts_ms =excluded.ts_ms
        """, [(r["instId"], r["lastPr"], r["ts_ms"]) for r in rows])

    time.sleep(SLEEP)

----- FILE: /opt/scalp/project/scripts/dec_ticks_writer.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
DEC TICKS WRITER ‚Äî FINAL

- lit instId_s depuis t.db.v_ticks_latest
- copie strictement dans dec.db.snap_ticks
"""

import sqlite3
from pathlib import Path

ROOT = Path("/opt/scalp/project")
DB_TICKS = ROOT / "data/t.db"
DB_DEC   = ROOT / "data/dec.db"

def conn(p):
    c = sqlite3.connect(str(p))
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    return c

def main():
    ct = conn(DB_TICKS)
    cd = conn(DB_DEC)

    rows = ct.execute("""
        SELECT instId_s, lastPr, ts_ms
        FROM v_ticks_latest
    """).fetchall()

    cd.executemany("""
        INSERT OR REPLACE INTO snap_ticks
        (instId_s, lastPr, ts)
        VALUES (?, ?, ?)
    """, [
        (r["instId_s"], r["lastPr"], r["ts_ms"])
        for r in rows
    ])

    cd.commit()
    ct.close()
    cd.close()

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/dec_writer.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SCALP ‚Äî DEC WRITER (SPLIT / SAFE / DEBUG)

- log AVANT tout
- imports prot√©g√©s
"""

import logging
import sys
import time
import yaml
import sqlite3
from pathlib import Path

LOG_PATH = "/opt/scalp/project/logs/dec_writer.log"

logging.basicConfig(
    filename=LOG_PATH,
    level=logging.INFO,
    format="%(asctime)s DEC %(levelname)s %(message)s"
)
log = logging.getLogger("DEC")

log.info("[BOOT] dec_writer starting")

try:
    from dec_ctx import load_ctx
    from dec_atr import load_atr_map, select_atr
    from dec_market import load_market_ok, market_pass
except Exception as e:
    log.exception("[BOOT_IMPORT_ERR]")
    raise


ROOT = Path("/opt/scalp/project")
DB_DEC = ROOT / "data/dec.db"
CFG_PATH = ROOT / "conf/dec.yaml"
LOOP_SLEEP = 2.0

CFG = yaml.safe_load(open(CFG_PATH))["dec"]


def conn():
    c = sqlite3.connect(str(DB_DEC), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    return c


def now_ms():
    return int(time.time() * 1000)


def main():
    log.info("[START] dec_writer loop")

    while True:
        try:
            ts = now_ms()

            ctx_rows = load_ctx()
            atr_map  = load_atr_map()
            market   = load_market_ok()

            with conn() as c:
                c.execute("DELETE FROM snap_ctx")

                out = []
                veto = 0

                for r in ctx_rows:
                    m = market.get(r["instId"])
                    if not m or not market_pass(m, CFG["market_veto"]):
                        veto += 1
                        continue

                    atr_fast, atr_slow, vol = select_atr(
                        r["ctx"],
                        atr_map.get(r["instId"])
                    )

                    out.append((
                        r["instId"],
                        r["ctx"],
                        r["score_C"],
                        r["side"],
                        atr_fast,
                        atr_slow,
                        vol,
                        1,
                        ts
                    ))

                if out:
                    c.executemany("""
                        INSERT INTO snap_ctx (
                            instId, ctx, score_C, side,
                            atr_fast, atr_slow, vol_regime,
                            ctx_ok, ts_updated
                        ) VALUES (?,?,?,?,?,?,?,?,?)
                    """, out)

            log.info("[UPDATE] ctx=%d snap=%d veto=%d",
                     len(ctx_rows), len(out), veto)

        except Exception:
            log.exception("[RUNTIME_ERR]")

        time.sleep(LOOP_SLEEP)


if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/exec.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
EXEC ‚Äî OPENER/CLOSER ‚Üí exec.db (writer unique)

UPGRADE (non breaking / additif) :
- ACK direct upstream (opener/closer) d√©j√† pr√©sent
- ‚úÖ CANON STEP (partial + pyramide + open + close):
    Le step m√©tier avance au moment o√π EXEC confirme le done.
    => exec √©crit done_step = step+1
    => exec applique un ACK vers gest : status *_done + step=step+1 (robuste, sans d√©pendre d‚Äôun ordre exact des workers)
- Tick reader robuste : pr√©f√®re v_ticks_latest_spread si existe, sinon v_ticks_latest, fallback lastPr.
- INSERT explicite conforme au sch√©ma exec.db.
"""

import time
import logging
import sqlite3
from pathlib import Path

# ============================================================
# PATHS
# ============================================================

ROOT = Path("/opt/scalp/project")

DB_T      = ROOT / "data/t.db"
DB_EXEC   = ROOT / "data/exec.db"
DB_GEST   = ROOT / "data/gest.db"
DB_OPENER = ROOT / "data/opener.db"
DB_CLOSER = ROOT / "data/closer.db"

# ============================================================
# LOG
# ============================================================

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s"
)
log = logging.getLogger("EXEC")

# ============================================================
# DB UTILS
# ============================================================

def conn(db: Path) -> sqlite3.Connection:
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

def now_ms() -> int:
    return int(time.time() * 1000)

def table_or_view_exists(c: sqlite3.Connection, name: str) -> bool:
    r = c.execute(
        "SELECT 1 FROM sqlite_master WHERE (type='table' OR type='view') AND name=? LIMIT 1",
        (name,)
    ).fetchone()
    return bool(r)

def view_columns(c: sqlite3.Connection, view_name: str):
    try:
        rows = c.execute(f"PRAGMA table_info({view_name})").fetchall()
        return [r["name"] for r in rows]
    except Exception:
        return []

# ============================================================
# PRICING / FEES (stable non-blocking)
# ============================================================

def price_with_slippage(*, side: str, bid: float, ask: float) -> float:
    # exec au march√© : buy -> ask ; sell -> bid
    return float(ask) if side == "buy" else float(bid)

def compute_fee(*, qty: float, price_exec: float) -> float:
    # Fee simple non bloquante
    notional = float(qty) * float(price_exec)
    return 0.0004 * notional

# ============================================================
# SQL
# ============================================================

SQL_ALREADY_EXEC = """
SELECT 1
FROM exec
WHERE uid=? AND exec_type=? AND step=?
LIMIT 1
"""

SQL_GEST_SNAPSHOT = """
SELECT
    reason,
    regime,
    sl_be,
    sl_trail,
    tp_dyn,
    mfe_atr,
    mae_atr,
    golden,
    type_signal,
    dec_mode,
    step,
    status
FROM gest
WHERE uid=?
LIMIT 1
"""

SQL_GEST_STATUS_STEP = """
SELECT status, step
FROM gest
WHERE uid=?
LIMIT 1
"""

# INSERT conforme au sch√©ma exec.db
SQL_INSERT = """
INSERT OR IGNORE INTO exec (
    exec_id,
    uid,
    step,
    exec_type,
    side,
    qty,
    price_exec,
    fee,
    status,
    ts_exec,
    reason,
    regime,
    instId,
    lev,
    pnl_realized_step,
    sl_be,
    sl_trail,
    tp_dyn,
    mfe_atr,
    mae_atr,
    golden,
    type_signal,
    dec_mode,
    done_step
) VALUES (?,?,?,?,?,?,?,?, 'done', ?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)
"""

# ============================================================
# TICK READER (robuste)
# ============================================================

class TickReader:
    """
    Pr√©f√©rence:
    - v_ticks_latest_spread(instId,lastPr,bidPr,askPr,spread_bps,ts_ms) si existe
    - sinon v_ticks_latest avec colonnes existantes
    Fallback:
    - lastPr seulement
    """

    def __init__(self, tconn: sqlite3.Connection):
        self.t = tconn
        self.mode = None  # 'spread_view' | 'latest_view'
        self.cols = []

        if table_or_view_exists(self.t, "v_ticks_latest_spread"):
            self.mode = "spread_view"
            self.cols = view_columns(self.t, "v_ticks_latest_spread")
        elif table_or_view_exists(self.t, "v_ticks_latest"):
            self.mode = "latest_view"
            self.cols = view_columns(self.t, "v_ticks_latest")
        else:
            self.mode = None
            self.cols = []

        log.info("[ticks] mode=%s cols=%s", self.mode, ",".join(self.cols))

    def fetch(self, instId: str):
        if self.mode == "spread_view":
            want = ["instId", "lastPr", "bidPr", "askPr", "ts_ms"]
            sel = [c for c in want if c in self.cols]
            if "instId" not in sel:
                return None
            q = f"SELECT {','.join(sel)} FROM v_ticks_latest_spread WHERE instId=? LIMIT 1"
            return self.t.execute(q, (instId,)).fetchone()

        if self.mode == "latest_view":
            want = ["instId", "lastPr", "bidPr", "askPr", "ts_ms"]
            sel = [c for c in want if c in self.cols]
            if "instId" not in sel:
                return None
            q = f"SELECT {','.join(sel)} FROM v_ticks_latest WHERE instId=? LIMIT 1"
            return self.t.execute(q, (instId,)).fetchone()

        return None

# ============================================================
# ACK SAFETY LAYER (UPGRADE)
# ============================================================

def ack_exec_done_to_upstream(e: sqlite3.Connection, o: sqlite3.Connection, c: sqlite3.Connection) -> int:
    """
    Filet de s√©curit√© FSM:
    - exec(done) -> opener(open_done|pyramide_done)
    - exec(done) -> closer(partial_done|close_done)

    Non bloquant: retourne le nb d'updates effectu√©s.
    """
    n = 0
    rows = e.execute("""
        SELECT uid, exec_type, step
        FROM exec
        WHERE status='done'
    """).fetchall()

    for r in rows:
        uid  = r["uid"]
        et   = r["exec_type"]
        step = int(r["step"] or 0)

        if et == "open":
            cur = o.execute("""
                UPDATE opener
                SET status='open_done'
                WHERE uid=? AND step=? AND status='open_stdby'
            """, (uid, step))
            n += cur.rowcount or 0

        elif et == "pyramide":
            cur = o.execute("""
                UPDATE opener
                SET status='pyramide_done'
                WHERE uid=? AND step=? AND status='pyramide_stdby'
            """, (uid, step))
            n += cur.rowcount or 0

        elif et == "partial":
            cur = c.execute("""
                UPDATE closer
                SET status='partial_done'
                WHERE uid=? AND step=? AND status='partial_stdby'
            """, (uid, step))
            n += cur.rowcount or 0

        elif et == "close":
            cur = c.execute("""
                UPDATE closer
                SET status='close_done'
                WHERE uid=? AND step=? AND status='close_stdby'
            """, (uid, step))
            n += cur.rowcount or 0

    return n

def ack_exec_done_to_gest(g: sqlite3.Connection, e: sqlite3.Connection) -> int:
    """
    ‚úÖ Canon step (robuste):
    Sur exec(done), on fait avancer gest.step de exec.step -> exec.step+1, sans d√©pendre d‚Äôun ordre exact des workers.

    R√®gle robuste (idempotente):
    - si gest.status == *_req AND gest.step == exec.step : status=*_done, step=exec.step+1
    - si gest.status == *_done AND gest.step == exec.step : step=exec.step+1 (rattrapage)
    (On ne touche pas aux statuts non attendus, et on ne change rien si step a d√©j√† avanc√©.)
    """
    n = 0
    rows = e.execute("""
        SELECT uid, exec_type, step
        FROM exec
        WHERE status='done'
          AND exec_type IN ('open','pyramide','partial','close')
    """).fetchall()

    for r in rows:
        uid = r["uid"]
        et  = r["exec_type"]
        st  = int(r["step"] or 0)
        st_next = st + 1

        if et == "open":
            req  = "open_req"
            done = "open_done"
        elif et == "pyramide":
            req  = "pyramide_req"
            done = "pyramide_done"
        elif et == "partial":
            req  = "partial_req"
            done = "partial_done"
        else:
            req  = "close_req"
            done = "close_done"

        # 1) cas normal: *_req -> *_done + step=step+1 (match uniquement sur step)
        cur = g.execute("""
            UPDATE gest
            SET status=?,
                step=?
            WHERE uid=?
              AND step=?
              AND status=?
        """, (done, st_next, uid, st, req))
        n += cur.rowcount or 0

        # 2) rattrapage: status d√©j√† *_done mais step rest√© √† st
        cur2 = g.execute("""
            UPDATE gest
            SET step=?
            WHERE uid=?
              AND step=?
              AND status=?
        """, (st_next, uid, st, done))
        n += cur2.rowcount or 0

    return n

# ============================================================
# CORE LOOP
# ============================================================

def run_once():
    t = conn(DB_T)
    e = conn(DB_EXEC)
    g = conn(DB_GEST)
    o = conn(DB_OPENER)
    c = conn(DB_CLOSER)

    tr = TickReader(t)

    # ------------------------------------------------------------
    # OPEN / PYRAMIDE
    # ------------------------------------------------------------
    for r in o.execute("""
        SELECT uid, instId, side, qty, lev, step, status, exec_type
        FROM opener
        WHERE status IN ('open_stdby','pyramide_stdby')
    """):
        step = int(r["step"] or 0)
        exec_type = "open" if r["status"] == "open_stdby" else "pyramide"

        if e.execute(SQL_ALREADY_EXEC, (r["uid"], exec_type, step)).fetchone():
            continue

        tick = tr.fetch(r["instId"])
        if not tick:
            log.warning("[SKIP %s] %s no tick row (%s)", exec_type, r["uid"], r["instId"])
            continue

        last = tick["lastPr"] if "lastPr" in tick.keys() else None
        bid  = tick["bidPr"]  if "bidPr"  in tick.keys() else None
        ask  = tick["askPr"]  if "askPr"  in tick.keys() else None

        if bid is None or ask is None:
            if last is None:
                log.warning("[SKIP %s] %s tick missing last (and no bid/ask)", exec_type, r["uid"])
                continue
            price_exec = float(last)
        else:
            price_exec = price_with_slippage(side=r["side"], bid=float(bid), ask=float(ask))

        qty = float(r["qty"] or 0.0)
        if qty <= 0:
            log.warning("[SKIP %s] %s qty<=0", exec_type, r["uid"])
            continue

        ts = now_ms()
        fee = compute_fee(qty=qty, price_exec=price_exec)

        snap = g.execute(SQL_GEST_SNAPSHOT, (r["uid"],)).fetchone()

        exec_id = f"{r['uid']}_{exec_type}_{step}"
        done_step = step + 1  # ‚úÖ canon step (post-exec)

        e.execute(SQL_INSERT, (
            exec_id,
            r["uid"],
            step,
            exec_type,
            r["side"],
            qty,
            price_exec,
            fee,
            ts,  # ts_exec
            (snap["reason"] if snap else None),
            (snap["regime"] if snap and "regime" in snap.keys() else None),
            r["instId"],
            float(r["lev"] or 1.0),
            0.0,  # pnl_realized_step
            (snap["sl_be"] if snap else None),
            (snap["sl_trail"] if snap else None),
            (snap["tp_dyn"] if snap else None),
            (snap["mfe_atr"] if snap else None),
            (snap["mae_atr"] if snap else None),
            (snap["golden"] if snap else 0),
            (snap["type_signal"] if snap else None),
            (snap["dec_mode"] if snap else None),
            done_step
        ))

        log.info("[%s] uid=%s step=%d done_step=%d px=%.8f fee=%.8f",
                 exec_type.upper(), r["uid"], step, done_step, price_exec, fee)

    # ------------------------------------------------------------
    # PARTIAL / CLOSE (FSM SAFE) ‚Äî closer.qty_norm
    # ------------------------------------------------------------
    for r in c.execute("""
        SELECT uid, instId, side, qty_norm AS qty, step, status
        FROM closer
        WHERE status IN ('partial_stdby','close_stdby')
    """):
        step = int(r["step"] or 0)
        exec_type = "partial" if r["status"] == "partial_stdby" else "close"

        gr = g.execute(SQL_GEST_STATUS_STEP, (r["uid"],)).fetchone()
        if not gr:
            continue

        gstat = gr["status"]
        gstep = int(gr["step"] or 0)

        # garde strict
        if gstep != step:
            continue
        if gstat == "close_req" and exec_type != "close":
            continue
        if gstat == "partial_req" and exec_type != "partial":
            continue

        if e.execute(SQL_ALREADY_EXEC, (r["uid"], exec_type, step)).fetchone():
            continue

        qty = float(r["qty"] or 0.0)
        if qty <= 0:
            log.warning("[SKIP %s] %s qty_norm<=0 (closer)", exec_type, r["uid"])
            continue

        tick = tr.fetch(r["instId"])
        if not tick:
            log.warning("[SKIP %s] %s no tick row (%s)", exec_type, r["uid"], r["instId"])
            continue

        last = tick["lastPr"] if "lastPr" in tick.keys() else None
        bid  = tick["bidPr"]  if "bidPr"  in tick.keys() else None
        ask  = tick["askPr"]  if "askPr"  in tick.keys() else None

        if bid is None or ask is None:
            if last is None:
                log.warning("[SKIP %s] %s tick missing last (and no bid/ask)", exec_type, r["uid"])
                continue
            price_exec = float(last)
        else:
            price_exec = price_with_slippage(side=r["side"], bid=float(bid), ask=float(ask))

        ts = now_ms()
        fee = compute_fee(qty=qty, price_exec=price_exec)

        snap = g.execute(SQL_GEST_SNAPSHOT, (r["uid"],)).fetchone()

        exec_id = f"{r['uid']}_{exec_type}_{step}"
        done_step = step + 1  # ‚úÖ canon step (post-exec)

        e.execute(SQL_INSERT, (
            exec_id,
            r["uid"],
            step,
            exec_type,
            r["side"],
            qty,
            price_exec,
            fee,
            ts,  # ts_exec
            (snap["reason"] if snap else None),
            (snap["regime"] if snap and "regime" in snap.keys() else None),
            r["instId"],
            1.0,  # lev non critique √† la sortie
            0.0,  # pnl_realized_step
            (snap["sl_be"] if snap else None),
            (snap["sl_trail"] if snap else None),
            (snap["tp_dyn"] if snap else None),
            (snap["mfe_atr"] if snap else None),
            (snap["mae_atr"] if snap else None),
            (snap["golden"] if snap else 0),
            (snap["type_signal"] if snap else None),
            (snap["dec_mode"] if snap else None),
            done_step
        ))

        log.info("[%s] uid=%s step=%d done_step=%d px=%.8f fee=%.8f",
                 exec_type.upper(), r["uid"], step, done_step, price_exec, fee)

    # commit exec first
    e.commit()

    # ---------- UPGRADE: ACK upstream (opener/closer) ----------
    try:
        n = ack_exec_done_to_upstream(e, o, c)
        if n:
            o.commit()
            c.commit()
            log.info("[ACK] upstream updates=%d", n)
    except Exception:
        log.exception("[ACK] failed (non blocking)")

    # ---------- ‚úÖ UPGRADE: ACK gest + canon step ----------
    try:
        ng = ack_exec_done_to_gest(g, e)
        if ng:
            g.commit()
            log.info("[ACK] gest updates=%d", ng)
    except Exception:
        log.exception("[ACK] gest failed (non blocking)")

    t.close()
    e.close()
    g.close()
    o.close()
    c.close()

def main():
    while True:
        try:
            run_once()
        except Exception as ex:
            log.exception("EXEC loop error: %s", ex)
            time.sleep(0.5)
        time.sleep(0.2)

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/exec_ack_upgrade.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
UPGRADE S√âCURIT√â FSM

Si opener_from_exec plante, on garantit quand m√™me :

exec(done) ‚Üí opener(open_done / pyramide_done)
exec(done) ‚Üí closer(partial_done / close_done)

AUCUN impact si l'ancien syst√®me marche.
Simple filet de s√©curit√©.
"""

import sqlite3
from pathlib import Path

ROOT = Path("/opt/scalp/project")
DB_EXEC   = ROOT / "data/exec.db"
DB_OPENER = ROOT / "data/opener.db"
DB_CLOSER = ROOT / "data/closer.db"


def conn(db):
    c = sqlite3.connect(str(db), timeout=5)
    c.row_factory = sqlite3.Row
    return c


def run():
    e = conn(DB_EXEC)
    o = conn(DB_OPENER)
    c = conn(DB_CLOSER)

    # ---------- OPENER ACK ----------
    rows = e.execute("""
        SELECT uid, exec_type, step
        FROM exec
        WHERE status='done'
    """).fetchall()

    for r in rows:
        uid  = r["uid"]
        et   = r["exec_type"]
        step = r["step"]

        if et == "open":
            o.execute("""
                UPDATE opener
                SET status='open_done'
                WHERE uid=? AND step=? AND status='open_stdby'
            """, (uid, step))

        elif et == "pyramide":
            o.execute("""
                UPDATE opener
                SET status='pyramide_done'
                WHERE uid=? AND step=? AND status='pyramide_stdby'
            """, (uid, step))

        elif et == "partial":
            c.execute("""
                UPDATE closer
                SET status='partial_done'
                WHERE uid=? AND step=? AND status='partial_stdby'
            """, (uid, step))

        elif et == "close":
            c.execute("""
                UPDATE closer
                SET status='close_done'
                WHERE uid=? AND step=? AND status='close_stdby'
            """, (uid, step))

    o.commit()
    c.commit()
    e.close(); o.close(); c.close()


if __name__ == "__main__":
    run()

----- FILE: /opt/scalp/project/scripts/exec_market.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
EXEC ‚Äî MARKET ADAPTER
- lit v_ticks_latest_spread
- calcule prix ex√©cut√© r√©el (spread + slippage)
- calcule fees Bitget Futures
"""

import sqlite3
from pathlib import Path

from exec_price import compute_exec_price, compute_fee
from exec_slippage import compute_slippage_bps, apply_slippage

ROOT = Path("/opt/scalp/project")
DB_TICKS = ROOT / "data/t.db"

SQL_PRICE = """
SELECT lastPr, spread_bps
FROM v_ticks_latest_spread
WHERE instId=?
LIMIT 1;
"""


def conn():
    c = sqlite3.connect(str(DB_TICKS), timeout=5)
    c.row_factory = sqlite3.Row
    return c


def get_exec_price_and_fee(*, instId, side, qty):
    """
    Retourne (price_exec, fee)
    """
    with conn() as t:
        px = t.execute(SQL_PRICE, (instId,)).fetchone()

    if not px:
        return None, None

    mid = px["lastPr"]
    spread_bps = px["spread_bps"]

    if mid is None or spread_bps is None:
        return None, None

    # --- 1) spread ---
    price = compute_exec_price(
        side=side,
        mid_price=mid,
        spread_bps=spread_bps
    )

    # --- 2) slippage ---
    slip_bps = compute_slippage_bps(spread_bps=spread_bps)
    price = apply_slippage(
        side=side,
        price=price,
        slippage_bps=slip_bps
    )

    # --- 3) fees ---
    fee = compute_fee(
        qty=qty,
        price_exec=price
    )

    return price, fee

----- FILE: /opt/scalp/project/scripts/exec_market_adapter.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
EXEC ‚Äî MARKET ADAPTER
- lit v_ticks_latest_spread si dispo
- sinon fallback v_ticks_latest (lastPr uniquement)
- calcule prix ex√©cut√© (spread + slippage)
- calcule fees Bitget Futures (taker)

Note:
- Ce module ne touche AUCUNE DB en √©criture.
- Il est optionnel: exec.py peut fallback si ce module ne donne pas de prix.
"""

import sqlite3
from pathlib import Path

from exec_price import compute_exec_price, compute_fee
from exec_slippage import compute_slippage_bps, apply_slippage

ROOT = Path("/opt/scalp/project")
DB_TICKS = ROOT / "data/t.db"


def conn():
    c = sqlite3.connect(str(DB_TICKS), timeout=5)
    c.row_factory = sqlite3.Row
    return c


def _has_view(c, name: str) -> bool:
    r = c.execute(
        "SELECT 1 FROM sqlite_master WHERE (type='view' OR type='table') AND name=? LIMIT 1",
        (name,)
    ).fetchone()
    return bool(r)


def get_exec_price_and_fee(*, instId, side, qty):
    """
    Retourne (price_exec, fee) ou (None, None)
    """
    if not instId or side not in ("buy", "sell"):
        return None, None

    with conn() as t:
        if _has_view(t, "v_ticks_latest_spread"):
            row = t.execute("""
                SELECT lastPr, spread_bps
                FROM v_ticks_latest_spread
                WHERE instId=?
                LIMIT 1;
            """, (instId,)).fetchone()

            if not row:
                return None, None

            mid = row["lastPr"]
            spread_bps = row["spread_bps"]

            if mid is None:
                return None, None

            # spread: mid -> bid/ask
            price = compute_exec_price(side=side, mid_price=float(mid), spread_bps=spread_bps)

            # slippage
            slip_bps = compute_slippage_bps(spread_bps=spread_bps)
            price = apply_slippage(side=side, price=price, slippage_bps=slip_bps)

            # fees
            fee = compute_fee(qty=qty, price_exec=price)
            return float(price), float(fee)

        # fallback: v_ticks_latest lastPr
        if _has_view(t, "v_ticks_latest"):
            row = t.execute("""
                SELECT lastPr
                FROM v_ticks_latest
                WHERE instId=?
                LIMIT 1;
            """, (instId,)).fetchone()

            if not row or row["lastPr"] is None:
                return None, None

            price = float(row["lastPr"])
            fee = compute_fee(qty=qty, price_exec=price)
            return float(price), float(fee)

    return None, None

----- FILE: /opt/scalp/project/scripts/exec_price.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
EXEC ‚Äî PRICE & COST ENGINE (BITGET FUTURES)

Responsabilit√© UNIQUE :
- transformer un prix mid en prix ex√©cut√© r√©el (spread)
- calculer les fees Bitget Futures (taker)
- AUCUNE logique FSM
- AUCUNE √©criture DB
"""

BITGET_TAKER_FEE = 0.0006   # 0.06% futures taker


def compute_exec_price(*, side, mid_price, spread_bps):
    """
    side        : 'buy' | 'sell'
    mid_price  : prix mid march√©
    spread_bps : spread bid/ask en basis points (bps)
    """
    if mid_price is None:
        return None

    if spread_bps is None:
        return float(mid_price)

    spread_pct = float(spread_bps) / 10_000.0
    half = spread_pct / 2.0

    if side == "buy":
        return float(mid_price) * (1.0 + half)
    else:
        return float(mid_price) * (1.0 - half)


def compute_notional(*, qty, price_exec):
    if qty is None or price_exec is None:
        return 0.0
    return abs(float(qty) * float(price_exec))


def compute_fee(*, qty, price_exec):
    """
    Fee Bitget futures taker
    Levier d√©j√† inclus implicitement via qty
    """
    notional = compute_notional(qty=qty, price_exec=price_exec)
    return notional * BITGET_TAKER_FEE

----- FILE: /opt/scalp/project/scripts/exec_slippage.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
EXEC ‚Äî SLIPPAGE MODEL (BITGET FUTURES)

- slippage directionnel
- proportionnel au spread
- stochastique born√©
- AUCUNE DB
"""

import random

SLIPPAGE_MIN_MULT = 0.10
SLIPPAGE_MAX_MULT = 0.35


def compute_slippage_bps(*, spread_bps):
    """
    Retourne un slippage en bps (>=0)
    """
    if spread_bps is None:
        return 0.0

    try:
        sb = float(spread_bps)
    except Exception:
        return 0.0

    mult = random.uniform(SLIPPAGE_MIN_MULT, SLIPPAGE_MAX_MULT)
    return sb * mult


def apply_slippage(*, side, price, slippage_bps):
    """
    Applique le slippage directionnel
    """
    if price is None:
        return None

    try:
        p = float(price)
    except Exception:
        return None

    try:
        sb = float(slippage_bps)
    except Exception:
        sb = 0.0

    slip_pct = sb / 10_000.0

    if side == "buy":
        return p * (1.0 + slip_pct)
    else:
        return p * (1.0 - slip_pct)

----- FILE: /opt/scalp/project/scripts/feature_loader.py -----
import sqlite3, time

DB_T = "/opt/scalp/project/data/t.db"
DB_OF = "/opt/scalp/project/data/orderflow.db"
DB_CTX = "/opt/scalp/project/data/ctx.db"

def load_features():
    return {
        "price": load_price(),
        "atr": load_atr(),
        "of": load_orderflow(),
        "ctx": load_ctx()
    }

def load_price():
    c = sqlite3.connect(DB_T)
    rows = c.execute("""
        SELECT instId, ts, price
        FROM ticks
        WHERE ts > ?
    """, (int(time.time()*1000)-5000,)).fetchall()
    data = {}
    for inst, ts, px in rows:
        data.setdefault(inst, []).append((ts, px))
    return data

def load_atr():
    c = sqlite3.connect(DB_T)
    rows = c.execute("""
        SELECT instId, ts, atr
        FROM atr
        WHERE ts > ?
    """, (int(time.time()*1000)-60000,)).fetchall()
    data = {}
    for inst, ts, v in rows:
        data.setdefault(inst, []).append((ts, v))
    return data

def load_orderflow():
    c = sqlite3.connect(DB_OF)
    rows = c.execute("""
        SELECT instId, ts_ms, best_bid, best_ask, bid_size, ask_size
        FROM books1
        WHERE ts_ms > ?
    """, (int(time.time()*1000)-5000,)).fetchall()
    data = {}
    for inst, ts, bb, ba, bs, asz in rows:
        data.setdefault(inst, []).append((ts, bb, ba, bs, asz))
    return data

def load_ctx():
    c = sqlite3.connect(DB_CTX)
    rows = c.execute("""
        SELECT instId, ctx, score_final
        FROM v_ctx_latest
    """).fetchall()
    return {r[0]: {"ctx": r[1], "score_C": r[2]} for r in rows}

----- FILE: /opt/scalp/project/scripts/fetch_contracts.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import sqlite3
import time

DB = "/opt/scalp/project/data/contracts.db"

# ============================================================
# UTIL : parse float safe
# ============================================================

def parse_float(x, default=0.0):
    """
    Convertit proprement n'importe quelle valeur Bitget en float.
    - '', None  -> default
    - '123.45'  -> 123.45
    """
    if x is None:
        return default
    if isinstance(x, (int, float)):
        return float(x)
    x = str(x).strip()
    if x == "":
        return default
    try:
        return float(x)
    except:
        return default

# ============================================================
# TABLE SCHEMA
# ============================================================

schema = """
CREATE TABLE IF NOT EXISTS contracts (
    symbol TEXT PRIMARY KEY,
    baseCoin TEXT,
    quoteCoin TEXT,
    minTradeNum REAL,
    minTradeUSDT REAL,
    pricePlace INTEGER,
    volumePlace INTEGER,
    sizeMultiplier REAL,
    minLever INTEGER,
    maxLever INTEGER,
    makerFee REAL,
    takerFee REAL,
    maxOrderQty REAL,
    maxMarketOrderQty REAL,
    symbolStatus TEXT,
    last_update INTEGER
);
"""

# ============================================================
# FETCH FROM BITGET
# ============================================================

URL = "https://api.bitget.com/api/v2/mix/market/contracts?productType=usdt-futures"

def fetch():
    r = requests.get(URL, timeout=5)
    r.raise_for_status()
    data = r.json()
    return data["data"]

# ============================================================
# SAVE TO DB
# ============================================================

def save(rows):
    conn = sqlite3.connect(DB)
    conn.execute(schema)

    query = """
    INSERT OR REPLACE INTO contracts (
        symbol, baseCoin, quoteCoin,
        minTradeNum, minTradeUSDT,
        pricePlace, volumePlace, sizeMultiplier,
        minLever, maxLever,
        makerFee, takerFee,
        maxOrderQty, maxMarketOrderQty,
        symbolStatus, last_update
    )
    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?);
    """

    now = int(time.time() * 1000)

    for d in rows:
        conn.execute(query, (
            d.get("symbol"),
            d.get("baseCoin"),
            d.get("quoteCoin"),

            parse_float(d.get("minTradeNum")),
            parse_float(d.get("minTradeUSDT")),

            int(parse_float(d.get("pricePlace"))),
            int(parse_float(d.get("volumePlace"))),
            parse_float(d.get("sizeMultiplier")),

            int(parse_float(d.get("minLever"), 1)),
            int(parse_float(d.get("maxLever"), 1)),

            parse_float(d.get("makerFeeRate")),
            parse_float(d.get("takerFeeRate")),

            parse_float(d.get("maxOrderQty")),
            parse_float(d.get("maxMarketOrderQty")),

            d.get("symbolStatus", "unknown"),
            now
        ))

    conn.commit()
    conn.close()

# ============================================================
# MAIN
# ============================================================

def main():
    rows = fetch()
    save(rows)
    print(f"Saved {len(rows)} contracts into contracts.db")

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/fix_opener_db.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
FIX opener.db (IDEMPOTENT)

But :
- supprimer les vues cass√©es qui pointent sur opener_old
- migrer opener vers une table multi-lignes :
    PRIMARY KEY (uid, exec_type, step)
- pr√©server les donn√©es existantes (copie intersection colonnes)
- recr√©er une vue simple v_opener (non bloquante)

Ex√©cution :
  python3 /opt/scalp/project/scripts/fix_opener_db.py
"""

import sqlite3
import time
from pathlib import Path

ROOT = Path("/opt/scalp/project")
DB = ROOT / "data" / "opener.db"

TARGET_SCHEMA = """
CREATE TABLE opener_new (
    uid TEXT NOT NULL,
    instId TEXT NOT NULL,
    side TEXT NOT NULL,
    qty REAL NOT NULL,
    lev REAL NOT NULL,
    ts_open INTEGER,
    price_exec_open REAL,
    status TEXT NOT NULL,
    exec_type TEXT NOT NULL,
    step INTEGER NOT NULL,
    PRIMARY KEY (uid, exec_type, step)
);
"""

def table_exists(c: sqlite3.Connection, name: str) -> bool:
    r = c.execute("SELECT 1 FROM sqlite_master WHERE type='table' AND name=? LIMIT 1", (name,)).fetchone()
    return bool(r)

def view_rows(c: sqlite3.Connection):
    return c.execute("SELECT name, sql FROM sqlite_master WHERE type='view'").fetchall()

def columns(c: sqlite3.Connection, table: str):
    return [r[1] for r in c.execute(f"PRAGMA table_info({table})").fetchall()]

def main():
    if not DB.exists():
        raise SystemExit(f"DB not found: {DB}")

    c = sqlite3.connect(str(DB), timeout=30)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=30000;")
    c.execute("PRAGMA foreign_keys=OFF;")

    # 1) Drop any view referencing opener_old (and also stale v_opener)
    for r in view_rows(c):
        name = r["name"]
        sql = (r["sql"] or "").lower()
        if "opener_old" in sql or name.lower() in ("v_opener", "v_opener_monitoring"):
            c.execute(f"DROP VIEW IF EXISTS {name}")

    # 2) Clean leftovers
    c.execute("DROP TABLE IF EXISTS opener_new")

    src_table = None
    if table_exists(c, "opener_old"):
        src_table = "opener_old"
    elif table_exists(c, "opener"):
        src_table = "opener"
    else:
        # DB empty: create target table and view then exit
        c.execute(TARGET_SCHEMA)
        c.execute("ALTER TABLE opener_new RENAME TO opener")
        c.execute("CREATE VIEW IF NOT EXISTS v_opener AS SELECT * FROM opener;")
        c.commit()
        c.close()
        return

    src_cols = set(columns(c, src_table))

    # 3) Create new table
    c.execute(TARGET_SCHEMA)

    # 4) Build safe insert using available columns (defaults otherwise)
    def col(name: str, default_sql: str):
        return name if name in src_cols else default_sql

    uid   = col("uid", "NULL")
    inst  = col("instId", "''")
    side  = col("side", "''")
    qty   = col("qty", "0.0")
    lev   = col("lev", "1.0")
    tsop  = col("ts_open", "NULL")
    pxop  = col("price_exec_open", "NULL")
    stat  = col("status", "''")

    # exec_type / step : si absents, fallback propre
    etype = col("exec_type", "'open'")
    step  = col("step", "0")

    # 5) Copy rows (dedupe by composite key)
    c.execute(f"""
        INSERT OR IGNORE INTO opener_new
        (uid, instId, side, qty, lev, ts_open, price_exec_open, status, exec_type, step)
        SELECT
            {uid}   AS uid,
            {inst}  AS instId,
            {side}  AS side,
            CAST({qty} AS REAL) AS qty,
            CAST({lev} AS REAL) AS lev,
            {tsop}  AS ts_open,
            {pxop}  AS price_exec_open,
            {stat}  AS status,
            {etype} AS exec_type,
            CAST({step} AS INTEGER) AS step
        FROM {src_table}
        WHERE {uid} IS NOT NULL AND TRIM({uid}) <> ''
    """)

    # 6) Backup old opener table (if exists) and swap
    ts = int(time.time())
    if table_exists(c, "opener"):
        c.execute(f"ALTER TABLE opener RENAME TO opener_backup_{ts}")

    c.execute("ALTER TABLE opener_new RENAME TO opener")

    # 7) Minimal view recreated
    c.execute("CREATE VIEW IF NOT EXISTS v_opener AS SELECT * FROM opener;")

    c.execute("PRAGMA foreign_keys=ON;")
    c.commit()
    c.close()

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/follower.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import time
import logging
import sqlite3
import yaml
from pathlib import Path

from follower_ingest import ingest_open_done
from follower_sync_mfemae import sync_mfemae
from follower_fsm_sync import sync_fsm_status
from follower_timeout import apply_timeouts
from follower_decide import decide_core
from follower_purge_closed import purge_closed

ROOT = Path("/opt/scalp/project")

DB_FOLLOWER = ROOT / "data/follower.db"
DB_GEST     = ROOT / "data/gest.db"
DB_EXEC     = ROOT / "data/exec.db"
DB_MFEMAE   = ROOT / "data/mfe_mae.db"   # ‚úÖ CORRECTION NOM FICHIER
DB_TICKS    = ROOT / "data/ticks.db"

CFG = yaml.safe_load(
    open(ROOT / "conf/follower.yaml", "r")
)["follower"]

log = logging.getLogger("FOLLOWER")
logging.basicConfig(level=logging.INFO)

def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

def now_ms():
    return int(time.time() * 1000)

def main():
    log.info("[START] follower orchestrator")

    while True:
        now = now_ms()

        f = conn(DB_FOLLOWER)
        g = conn(DB_GEST)
        e = conn(DB_EXEC)
        m = conn(DB_MFEMAE)
        t = conn(DB_TICKS)

        try:
            ingest_open_done(g, f, now)
            sync_mfemae(f, m)
            sync_fsm_status(g, f, now)

            rows_exec = e.execute("""
                SELECT uid,
                       qty_open,
                       avg_price_open,
                       last_exec_type,
                       last_step,
                       last_price_exec,
                       last_ts_exec
                FROM v_exec_position
            """).fetchall()

            for r_exec in rows_exec:
                f.execute("""
                    UPDATE follower
                    SET qty_open=?,
                        avg_price_open=?,
                        last_exec_type=?,
                        last_step=?,
                        last_price_exec=?,
                        last_ts_exec=?
                    WHERE uid=?
                """, (
                    r_exec["qty_open"],
                    r_exec["avg_price_open"],
                    r_exec["last_exec_type"],
                    r_exec["last_step"],
                    r_exec["last_price_exec"],
                    r_exec["last_ts_exec"],
                    r_exec["uid"]
                ))

            rows = f.execute("""
                SELECT *
                FROM v_follower_state
                WHERE status='follow'
            """).fetchall()

            for r in rows:
                apply_timeouts(
                    f=f,
                    fr=r,
                    qty_open=r["qty_ratio"] or 1.0,
                    age_s=r["age_s"],
                    CFG=CFG,
                    now=now
                )

            decide_core(f=f, CFG=CFG, now=now)
            purge_closed(g, f, now)

            f.commit()

        except Exception:
            log.exception("[ERR] follower loop")

        finally:
            f.close()
            g.close()
            e.close()
            m.close()
            t.close()

        time.sleep(0.5)

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/follower_advanced.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
FOLLOWER ‚Äî ACTIONS AVANC√âES
PARTIAL / PYRAMIDE
"""

def advanced_actions(f, e, CFG, now):

    for fr in f.execute("""
        SELECT *
        FROM follower
        WHERE status='follow'
    """):
        uid = fr["uid"]

        pos = e.execute("""
            SELECT qty_open
            FROM v_exec_position
            WHERE uid=?
        """, (uid,)).fetchone()

        if not pos or float(pos["qty_open"] or 0) <= 0:
            continue

        qty_open = float(pos["qty_open"])

        mfe_atr = fr["mfe_atr"]
        mae_atr = fr["mae_atr"]

        # ====================================================
        # TP PARTIAL (SAFE)
        # ====================================================
        if (
            fr["nb_partial"] == 0
            and mfe_atr is not None
            and mfe_atr >= CFG["partial_atr_trigger"]
        ):
            qty = qty_open * CFG["partial_qty_ratio"]

            f.execute("""
                UPDATE follower
                SET status='partial_req',
                    step=step+1,
                    qty_to_close=?,
                    nb_partial=1,
                    last_decision_ts=?,
                    reason='TP_PARTIAL'
                WHERE uid=?
            """, (qty, now, uid))
            continue

        # ====================================================
        # PYRAMIDE (SAFE)
        # ====================================================
        if (
            fr["nb_partial"] >= 1
            and fr["nb_pyramide"] < CFG["max_pyramide_post_partial"]
            and mfe_atr is not None
            and mfe_atr >= CFG["pyramide_atr_trigger"]
            and (
                fr["cooldown_pyramide_ts"] is None
                or now - fr["cooldown_pyramide_ts"] >= CFG["pyramide_cooldown_s"] * 1000
            )
            and (mae_atr is None or mae_atr < CFG["min_mae_forbid_pyramide"])
        ):
            qty = qty_open * CFG["pyramide_qty_ratio"]

            f.execute("""
                UPDATE follower
                SET status='pyramide_req',
                    step=step+1,
                    qty_to_close=?,
                    nb_pyramide=nb_pyramide+1,
                    cooldown_pyramide_ts=?,
                    last_decision_ts=?,
                    reason='PYRAMIDE'
                WHERE uid=?
            """, (qty, now, now, uid))
            continue

----- FILE: /opt/scalp/project/scripts/follower_arm_levels.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
FOLLOWER ‚Äî ARMEMENT DES NIVEAUX
SL_BE / SL_TRAIL / TP_DYN
AUCUNE ACTION
"""

def arm_levels(f, g, CFG):
    for r in g.execute("""
        SELECT uid, side, entry
        FROM gest
        WHERE status='follow'
    """):
        fr = f.execute("SELECT * FROM follower WHERE uid=?", (r["uid"],)).fetchone()
        if not fr:
            continue

        mfe_atr = fr["mfe_atr"]
        if mfe_atr is None:
            continue

        sl_be    = fr["sl_be"]
        sl_trail = fr["sl_trail"]
        tp_dyn   = fr["tp_dyn"]

        if sl_be is None and mfe_atr >= CFG["sl_be_atr_trigger"]:
            sl_be = r["entry"]

        if sl_trail is None and mfe_atr >= CFG["sl_trail_atr_trigger"]:
            off = CFG["sl_trail_offset_atr"] * fr["atr_signal"]
            sl_trail = r["entry"] - off if r["side"] == "sell" else r["entry"] + off

        if tp_dyn is None and mfe_atr >= CFG["tp_dyn_atr_trigger"]:
            mul = CFG["tp_dyn_atr_mult"] * fr["atr_signal"]
            tp_dyn = r["entry"] - mul if r["side"] == "sell" else r["entry"] + mul

        f.execute("""
            UPDATE follower
            SET sl_be=?, sl_trail=?, tp_dyn=?
            WHERE uid=?
        """, (sl_be, sl_trail, tp_dyn, r["uid"]))

----- FILE: /opt/scalp/project/scripts/follower_decide.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from follower_decide_guard import is_valid_position

def decide_core(f, CFG, now):

    rows = f.execute("""
        SELECT *
        FROM v_follower_state
        WHERE status='follow'
    """).fetchall()

    for fr in rows:

        if not is_valid_position(fr):
            continue

        uid = fr["uid"]

        # ==========================================================
        # PARTIAL ‚Äî FILTRE TRADABILIT√â
        # ==========================================================
        if fr["mfe_atr"] >= CFG["partial_mfe_atr"] and fr["nb_partial"] == 0:

            ratio_cfg = CFG["partial_close_ratio"]

            # üî• qty_open d√©sormais mat√©rialis√© dans follower
            qty_open = float(fr["qty_open"] or 0.0)

            if qty_open <= 0:
                continue

            min_qty = CFG.get("min_partial_qty", 0.0)
            ratio_min_exec = (min_qty / qty_open) if qty_open > 0 else 999.0

            # ------------------------------------------------------
            # üö´ PARTIAL IMPOSSIBLE
            # ------------------------------------------------------
            if ratio_min_exec > ratio_cfg:
                f.execute("""
                    UPDATE follower
                    SET nb_partial = nb_partial + 1,
                        cooldown_partial_ts=?,
                        ts_decision=?
                    WHERE uid=?
                """, (now, now, uid))
                continue

            # ------------------------------------------------------
            # ‚úÖ PARTIAL VALIDE
            # ------------------------------------------------------
            f.execute("""
                UPDATE follower
                SET status='partial_req',
                    qty_to_close_ratio=?,
                    ratio_to_close=?,
                    req_step=req_step+1,
                    ts_decision=?,
                    nb_partial=1
                WHERE uid=?
            """, (ratio_cfg, ratio_cfg, now, uid))

            continue

----- FILE: /opt/scalp/project/scripts/follower_decide_guard.py -----
def is_valid_position(fr):
    """
    Autorise une d√©cision uniquement si la position est r√©ellement ouverte
    et suivie dans la FSM centrale.

    Conditions :
    - qty_ratio > 0  ‚Üí exposition r√©elle
    - done_step == 0 ‚Üí pas d√©j√† cl√¥tur√©e
    """
    return (
        fr["qty_ratio"] is not None
        and fr["qty_ratio"] > 0
        and fr["done_step"] == 0
    )

----- FILE: /opt/scalp/project/scripts/follower_from_exec.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
FOLLOWER ‚Äî ne doit JAMAIS produire *_stdby
R√¥le : transformer les √©v√©nements exec en intentions FSM pour GEST.

R√®gle syst√®me :
- *_stdby est STRICTEMENT r√©serv√© √† opener / closer.
- follower ne produit que : follow | partial_req | close_req | pyramide_req
"""

import sqlite3
import time
import logging
from pathlib import Path

ROOT = Path("/opt/scalp/project")

DB_EXEC     = ROOT / "data/exec.db"
DB_FOLLOWER = ROOT / "data/follower.db"
DB_GEST     = ROOT / "data/gest.db"

logging.basicConfig(level=logging.INFO,
    format="%(asctime)s FOLLOWER %(levelname)s %(message)s")
log = logging.getLogger("FOLLOWER")

def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

def now_ms(): return int(time.time()*1000)

# ============================================================
# SANITIZE HARD RULE
# ============================================================

def sanitize_forbidden_states(f):
    f.execute("""
        UPDATE follower
        SET status='follow'
        WHERE status LIKE '%_stdby'
    """)

# ============================================================
# EXEC ‚Üí FOLLOWER
# ============================================================

def process_exec():
    e = conn(DB_EXEC)
    f = conn(DB_FOLLOWER)
    g = conn(DB_GEST)

    sanitize_forbidden_states(f)

    for ex in e.execute("""
        SELECT uid, exec_type, step
        FROM exec
        WHERE status='done'
    """):

        uid  = ex["uid"]
        etyp = ex["exec_type"]
        step = int(ex["step"] or 0)

        fr = f.execute("SELECT status, step FROM follower WHERE uid=?", (uid,)).fetchone()
        if not fr:
            continue

        # =====================================================
        # OPEN termin√© ‚Üí follower passe follow
        # =====================================================
        if etyp in ("open","pyramide"):
            f.execute("""
                UPDATE follower
                SET status='follow',
                    step=?,
                    ts_updated=?
                WHERE uid=?
            """,(step, now_ms(), uid))

        # =====================================================
        # PARTIAL ex√©cut√© ‚Üí demander prochaine √©tape √† GEST
        # =====================================================
        elif etyp == "partial":
            f.execute("""
                UPDATE follower
                SET status='follow',
                    step=?,
                    ts_updated=?
                WHERE uid=?
            """,(step, now_ms(), uid))

        # =====================================================
        # CLOSE ex√©cut√© ‚Üí fin de vie
        # =====================================================
        elif etyp == "close":
            f.execute("""
                UPDATE follower
                SET status='follow',
                    step=?,
                    ts_updated=?
                WHERE uid=?
            """,(step, now_ms(), uid))

    f.commit()
    e.close(); f.close(); g.close()

# ============================================================

def main():
    while True:
        try:
            process_exec()
        except Exception as e:
            log.exception(e)
        time.sleep(0.25)

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/follower_fsm_guard.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

def fsm_ready(fr):
    """
    FOLLOWER invariant :
    - autorise action uniquement si req_step == done_step
    """
    return int(fr["req_step"] or 0) == int(fr["done_step"] or 0)

----- FILE: /opt/scalp/project/scripts/follower_fsm_status.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
FOLLOWER FSM STATUS SYNC
- Pas de *_stdby c√¥t√© follower
- Reset follow UNIQUEMENT apr√®s gest.*_done
- Purge follower sur gest.close_done
"""

def sync_fsm_status(g, f, now):
    """
    g : connexion gest.db
    f : connexion follower.db
    """

    for fr in f.execute("SELECT uid, status, step FROM follower"):
        uid      = fr["uid"]
        f_status = fr["status"]
        f_step   = fr["step"]

        gr = g.execute(
            "SELECT status, step FROM gest WHERE uid=?",
            (uid,)
        ).fetchone()

        # --------------------------------------------
        # UID orphelin ‚Üí purge (NO_GEST)
        # --------------------------------------------
        if not gr:
            f.execute("DELETE FROM follower WHERE uid=?", (uid,))
            continue

        g_status = gr["status"]
        g_step   = gr["step"]

        # --------------------------------------------
        # CLOSE_DONE = √âTAT TERMINAL ‚Üí PURGE FOLLOWER
        # --------------------------------------------
        if g_status == "close_done":
            f.execute("DELETE FROM follower WHERE uid=?", (uid,))
            continue

        # --------------------------------------------
        # RESET FOLLOWER APR√àS *_DONE (ACK FINAL)
        # --------------------------------------------
        if (
            g_status.endswith("_done")
            and f_step == g_step
            and f_status != "follow"
        ):
            f.execute("""
                UPDATE follower
                SET
                    status='follow',
                    reason='DONE_RESET',
                    last_action_ts=?
                WHERE uid=?
            """, (now, uid))
            continue

        # --------------------------------------------
        # AUCUN *_stdby AUTORIS√â C√îT√â FOLLOWER
        # --------------------------------------------
        if f_status.endswith("_stdby"):
            f.execute("""
                UPDATE follower
                SET
                    status='follow',
                    reason='FORCED_NO_STDBY',
                    last_action_ts=?
                WHERE uid=?
            """, (now, uid))
            continue

----- FILE: /opt/scalp/project/scripts/follower_fsm_sync.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
FOLLOWER ‚Äî FSM SYNC STRICT CANONIQUE

R√àGLES :

1) close_done  ‚Üí purge follower
2) *_req ACK   ‚Üí *_stdby (m√™me step)
3) *_done      ‚Üí retour follow + step = g_step
   CONDITION STRICTE :
       g_step == f_step + 1

INVARIANTS :
- follower.step ne bouge QUE sur *_done
- aucune transition permissive
- aucune r√©gression de step possible
"""

def sync_fsm_status(g, f, now):

    # --------------------------------------------------
    # 1) PURGE CLOSE_DONE
    # --------------------------------------------------
    for r in g.execute("SELECT uid FROM gest WHERE status='close_done'"):
        f.execute("DELETE FROM follower WHERE uid=?", (r["uid"],))


    # --------------------------------------------------
    # 2) SYNC FSM
    # --------------------------------------------------
    rows = f.execute("""
        SELECT uid, status, step
        FROM follower
    """).fetchall()

    for fr in rows:

        uid       = fr["uid"]
        f_status  = fr["status"]
        f_step    = fr["step"] or 0

        gr = g.execute("""
            SELECT status, step
            FROM gest
            WHERE uid=?
        """, (uid,)).fetchone()

        if not gr:
            continue

        g_status = gr["status"]
        g_step   = gr["step"] or 0


        # --------------------------------------------------
        # 2.A) ACK *_req ‚Üí *_stdby (m√™me step)
        # --------------------------------------------------
        if (
            f_status.endswith("_req")
            and g_status == f_status
            and g_step == f_step
        ):
            f.execute("""
                UPDATE follower
                SET status=?,
                    ts_decision=?
                WHERE uid=?
            """, (f_status.replace("_req", "_stdby"), now, uid))
            continue


        # --------------------------------------------------
        # 2.B) DONE ‚Üí retour follow + incr√©ment step
        # CONDITION CANONIQUE :
        # g_step == f_step + 1
        # --------------------------------------------------
        if (
            g_status.endswith("_done")
            and g_step == f_step + 1
        ):
            f.execute("""
                UPDATE follower
                SET status='follow',
                    step=?,
                    done_step=?,
                    ts_decision=?
                WHERE uid=?
            """, (g_step, g_step, now, uid))
            continue


----- FILE: /opt/scalp/project/scripts/follower_ingest.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
FOLLOWER ‚Äî INGEST OPEN_DONE
SOURCE UNIQUE : gest.db
R√îLE :
- cr√©er la ligne follower √† open_done
- NE JAMAIS updater une ligne inexistante
"""

def ingest_open_done(g, f, now):
    """
    g : sqlite gest (READ)
    f : sqlite follower (WRITE)
    now : timestamp ms
    """

    rows = g.execute("""
        SELECT
            uid,
            instId,
            side,
            step,
            ts_open,
            entry,
            qty,
            lev
        FROM gest
        WHERE status='open_done'
    """).fetchall()

    if not rows:
        return

    for r in rows:
        uid = r["uid"]

        # üîí Verrou absolu : follower d√©j√† cr√©√© ?
        exists = f.execute("""
            SELECT 1 FROM follower WHERE uid=?
        """, (uid,)).fetchone()

        if exists:
            continue

        f.execute("""
            INSERT INTO follower (
                uid,
                instId,
                side,
                step,
                status,
                ts_follow,
                last_action_ts,
                qty_ratio,
                nb_partial,
                nb_pyramide
            ) VALUES (
                ?,?,?,?,?,?,?,?,?,?
            )
        """, (
            uid,
            r["instId"],
            r["side"],
            r["step"] or 0,
            "follow",
            now,
            now,
            1.0,
            0,
            0
        ))

----- FILE: /opt/scalp/project/scripts/follower_live_view.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SCALP - FOLLOWER LIVE VIEW (READ ONLY)

OBJECTIF :
- Afficher TOUT follower.db (aucun filtrage)
- Distinguer clairement :
  * ouverture en cours (OPEN_PENDING)
  * vrais zombies UID
  * incoh√©rences FSM
- AUCUNE √©criture
"""

import sqlite3
import time
from pathlib import Path

ROOT = Path("/opt/scalp/project")

DB_FOLLOWER = ROOT / "data/follower.db"
DB_GEST     = ROOT / "data/gest.db"
DB_EXEC     = ROOT / "data/exec.db"
DB_TICKS    = ROOT / "data/t.db"

REFRESH_S = 1.0

# ============================================================
# SQLITE
# ============================================================

def conn(db):
    c = sqlite3.connect(str(db), timeout=5)
    c.row_factory = sqlite3.Row
    return c

# ============================================================
# LOADERS
# ============================================================

def load_follower():
    c = conn(DB_FOLLOWER)
    rows = c.execute("SELECT * FROM follower").fetchall()
    c.close()
    return {r["uid"]: dict(r) for r in rows}

def load_gest():
    c = conn(DB_GEST)
    rows = c.execute("""
        SELECT uid, instId, side, entry, ts_open, status, atr_signal
        FROM gest
    """).fetchall()
    c.close()
    return {r["uid"]: dict(r) for r in rows}

def load_exec_pos():
    c = conn(DB_EXEC)
    rows = c.execute("""
        SELECT uid, qty_open
        FROM v_exec_position
    """).fetchall()
    c.close()
    return {r["uid"]: dict(r) for r in rows}

def load_ticks():
    c = conn(DB_TICKS)
    rows = c.execute("""
        SELECT instId, lastPr, ts_ms
        FROM ticks
    """).fetchall()
    c.close()
    return {r["instId"]: dict(r) for r in rows}

# ============================================================
# DISPLAY
# ============================================================

def clear():
    print("\033[2J\033[H", end="")

def header():
    print(
        f"{'FLAG':<13} "
        f"{'INST':<12} {'SIDE':<5} "
        f"{'ENTRY':>10} {'NOW':>10} "
        f"{'POS_QTY':>12} {'REQ_QTY':>12} "
        f"{'PNL':>8} {'%PNL':>7} "
        f"{'AGE':>6} "
        f"{'ATR':>10} "
        f"{'MFE_ATR':>8} {'MAE_ATR':>8} "
        f"{'F_STATUS':<14} {'G_STATUS':<14} "
        f"{'STEP':>4}"
    )
    print("=" * 172)

def fmt_price(x, digits=4):
    try:
        return f"{float(x):.{digits}f}"
    except Exception:
        return "0.0000"

def fmt_qty(x):
    try:
        return f"{float(x):.4f}"
    except Exception:
        return "0.0000"

def fmt_atr(x):
    try:
        v = float(x)
        if v == 0:
            return "0"
        if abs(v) < 0.001:
            return f"{v:.2e}"
        return f"{v:.4f}"
    except Exception:
        return "0"

def row(flag, inst, side, entry, now, pos_qty, req_qty,
        pnl, pnl_pct, age, atr, mfe_atr, mae_atr,
        f_status, g_status, step):

    print(
        f"{flag:<13} "
        f"{inst:<12} {side:<5} "
        f"{entry:>10} {now:>10} "
        f"{pos_qty:>12} {req_qty:>12} "
        f"{pnl:>8.2f} {pnl_pct:>7.2f}% "
        f"{age:>6.0f}s "
        f"{atr:>10} "
        f"{mfe_atr:>8.2f} {mae_atr:>8.2f} "
        f"{f_status:<14} {g_status:<14} "
        f"{step:>4}"
    )

# ============================================================
# FLAGGING
# ============================================================

def compute_flag(f_status, g_status, pos_qty, req_qty):
    if g_status in ("open_req", "open_done") and pos_qty <= 0:
        return "OPEN_PENDING"

    if f_status == "follow" and g_status == "NO_GEST" and pos_qty <= 0:
        return "ZOMBIE_UID"

    if f_status.endswith("_req") and g_status != f_status:
        return "REQ_NACK"

    if f_status.endswith("_stdby"):
        expected = f_status.replace("_stdby", "_req")
        if g_status != expected:
            return "STDBY_MIS"

    if g_status == "close_done":
        return "GEST_CDONE"

    if f_status in ("partial_req", "pyramide_req", "close_req") and req_qty <= 0:
        return "REQ_Q0"

    return "OK"

# ============================================================
# MAIN
# ============================================================

def main():
    while True:
        clear()

        follower = load_follower()
        gest     = load_gest()
        execpos  = load_exec_pos()
        ticks    = load_ticks()

        header()

        now_ts = int(time.time() * 1000)
        enriched = []

        for uid, f in follower.items():
            g = gest.get(uid)
            e = execpos.get(uid)

            inst = g["instId"] if g else uid[:12]
            side = g["side"] if g else "?"
            entry_val = g["entry"] if g and g["entry"] else 0.0

            t = ticks.get(inst)
            now_val = t["lastPr"] if t else entry_val

            pos_qty = float(e["qty_open"]) if e and e["qty_open"] else 0.0
            req_qty = float(f.get("qty_to_close") or 0.0)

            pnl = pnl_pct = 0.0
            if pos_qty > 0 and entry_val > 0:
                diff = (now_val - entry_val) if side == "buy" else (entry_val - now_val)
                pnl = diff * pos_qty
                pnl_pct = (diff / entry_val) * 100.0

            age = (now_ts - g["ts_open"]) / 1000.0 if g and g.get("ts_open") else 0.0

            # ATR SAFE
            if g and g.get("atr_signal") is not None:
                atr = float(g["atr_signal"])
            else:
                atr = float(f.get("atr_signal") or 0.0)

            mfe_atr = float(f.get("mfe_atr") or 0.0)
            mae_atr = float(f.get("mae_atr") or 0.0)

            f_status = f.get("status") or "?"
            g_status = g.get("status") if g else "NO_GEST"
            step = int(f.get("step") or 0)

            flag = compute_flag(f_status, g_status, pos_qty, req_qty)
            prio = 0 if flag == "OK" else 1

            enriched.append((prio, -age, flag, inst, side,
                             entry_val, now_val, pos_qty, req_qty,
                             pnl, pnl_pct, age, atr, mfe_atr, mae_atr,
                             f_status, g_status, step))

        enriched.sort()

        for _, _, flag, inst, side, entry, now, pos, req, pnl, pct, age, atr, mfe, mae, fs, gs, step in enriched:
            row(flag, inst, side,
                fmt_price(entry), fmt_price(now),
                fmt_qty(pos), fmt_qty(req),
                pnl, pct, age,
                fmt_atr(atr), mfe, mae,
                fs, gs, step)

        time.sleep(REFRESH_S)

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/follower_purge_closed.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
FOLLOWER ‚Äî PURGE CLOSED
R√®gle canonique :
- quand gest.status == close_done
- alors suppression d√©finitive de follower
"""

def purge_closed(g, f, now):
    """
    g : sqlite3 connection gest.db (read-only)
    f : sqlite3 connection follower.db (writer)
    now : timestamp ms (unused, mais homog√®ne)
    """

    for r in g.execute("""
        SELECT uid
        FROM gest
        WHERE status='close_done'
    """):
        uid = r["uid"]
        f.execute("DELETE FROM follower WHERE uid=?", (uid,))

----- FILE: /opt/scalp/project/scripts/follower_pyramide_guard.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
FOLLOWER ‚Äî PYRAMIDE FSM GUARD
R√¥le :
- emp√™cher les blocages pyramide_req
- synchroniser follower <-> gest
- üîí garde-fou pyramide avanc√©e (BTC / ETH uniquement)
"""

# ------------------------------------------------------------
# Instruments autoris√©s pour pyramide >= 3 (step >= 4)
# ------------------------------------------------------------
ALLOWED_DEEP_PYRAMIDE = {
    "BTC/USDT",
    "ETH/USDT",
}


def guard_pyramide_fsm(*, g, f, now):
    """
    API CANONIQUE ‚Äî NE JAMAIS MODIFIER LA SIGNATURE

    g   : sqlite gest (READ)
    f   : sqlite follower (WRITE)
    now : timestamp ms
    """

    # Tous les followers bloqu√©s en pyramide_req
    rows = f.execute("""
        SELECT uid, step, instId
        FROM follower
        WHERE status='pyramide_req'
    """).fetchall()

    for fr in rows:
        uid    = fr["uid"]
        step   = fr["step"]
        instId = fr["instId"]

        # --------------------------------------------------------
        # üîí GARDE-FOU PYRAMIDE AVANC√âE
        # step:
        # 2 = pyramide 1
        # 3 = pyramide 2
        # 4 = pyramide 3  ‚ùå sauf BTC / ETH
        # --------------------------------------------------------
        if step >= 4 and instId not in ALLOWED_DEEP_PYRAMIDE:
            # Refus silencieux, FSM safe
            f.execute("""
                UPDATE follower
                SET status='follow',
                    last_action_ts=?
                WHERE uid=? AND status='pyramide_req'
            """, (now, uid))
            continue

        # --------------------------------------------------------
        # SYNCHRO AVEC GEST
        # --------------------------------------------------------
        gr = g.execute("""
            SELECT status, step
            FROM gest
            WHERE uid=?
        """, (uid,)).fetchone()

        if not gr:
            continue

        g_status = gr["status"]
        g_step   = gr["step"]

        # --- PYRAMIDE ACCEPT√âE ---
        if g_status == "pyramide_done" and g_step == step:
            f.execute("""
                UPDATE follower
                SET status='follow',
                    nb_pyramide = nb_pyramide + 1,
                    last_action_ts=?
                WHERE uid=? AND status='pyramide_req'
            """, (now, uid))

        # --- PYRAMIDE REFUS√âE / D√âSYNCHRO ---
        elif g_status not in ("pyramide_req", "pyramide_done"):
            f.execute("""
                UPDATE follower
                SET status='follow',
                    last_action_ts=?
                WHERE uid=? AND status='pyramide_req'
            """, (now, uid))

----- FILE: /opt/scalp/project/scripts/follower_sync_mfemae.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
FOLLOWER ‚Äî SYNC MFE / MAE (CANONIQUE)

Responsabilit√© UNIQUE :
- lire mfe_mae.db
- projeter mfe_atr / mae_atr dans follower.db
- AUCUNE logique de d√©cision
- AUCUNE √©criture ailleurs que follower.db
"""

import sqlite3
import time
from pathlib import Path

# ============================================================
# PATHS
# ============================================================

ROOT = Path("/opt/scalp/project")

DB_FOLLOWER = ROOT / "data/follower.db"
DB_MFEMAE   = ROOT / "data/mfe_mae.db"

# ============================================================
# UTILS
# ============================================================

def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

# ============================================================
# API CANONIQUE (IMPORT√âE PAR follower.py)
# ============================================================

def sync_mfemae(f, m):
    """
    Synchronise mfe_atr / mae_atr dans follower
    Matching STRICT par uid (design actuel)
    """

    rows = m.execute("""
        SELECT
            uid,
            mfe,
            mae,
            atr
        FROM mfe_mae
        WHERE atr IS NOT NULL
          AND atr > 0
    """).fetchall()

    if not rows:
        return

    now = int(time.time() * 1000)

    for r in rows:
        mfe_atr = (r["mfe"] or 0.0) / r["atr"]
        mae_atr = abs(r["mae"] or 0.0) / r["atr"]

        f.execute("""
            UPDATE follower
            SET
                mfe_atr = ?,
                mae_atr = ?,
                ts_updated = ?
            WHERE uid = ?
        """, (
            mfe_atr,
            mae_atr,
            now,
            r["uid"]
        ))

# ============================================================
# MODE STANDALONE (DEBUG UNIQUEMENT)
# ============================================================

if __name__ == "__main__":
    f = conn(DB_FOLLOWER)
    m = conn(DB_MFEMAE)

    sync_mfemae(f, m)

    f.commit()
    f.close()
    m.close()

----- FILE: /opt/scalp/project/scripts/follower_sync_steps.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
FOLLOWER ‚Äî SYNC done_step FROM exec.db

- done_step √©crit uniquement ici c√¥t√© follower (lecture exec)
- exec est source de v√©rit√© : max(done_step) par uid
- ne modifie pas req_step
"""

import sqlite3
from pathlib import Path

ROOT = Path("/opt/scalp/project")
DB_EXEC = ROOT / "data/exec.db"
DB_FOLLOWER = ROOT / "data/follower.db"

def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA busy_timeout=10000;")
    return c

def sync_done_steps(*, f):
    """
    f : sqlite connection follower.db (writer loop)
    """
    e = conn(DB_EXEC)

    rows = e.execute("""
        SELECT uid, MAX(COALESCE(done_step, step)) AS done_step
        FROM exec
        WHERE status='done'
        GROUP BY uid
    """).fetchall()

    for r in rows:
        f.execute("""
            UPDATE follower
            SET done_step=?
            WHERE uid=?
        """, (int(r["done_step"] or 0), r["uid"]))

    e.close()

----- FILE: /opt/scalp/project/scripts/follower_timeout.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
FOLLOWER ‚Äî TIMEOUT LOGIC
API FIG√âE ‚Äî NE JAMAIS MODIFIER LA SIGNATURE
"""

def apply_timeouts(*, f, fr, qty_open, age_s, CFG, now):
    """
    f        : sqlite cursor follower
    fr       : row follower
    qty_open : taille r√©elle ouverte (SOURCE exec.db)
    age_s    : √¢ge en secondes
    CFG      : config follower
    now      : timestamp ms
    """

    uid  = fr["uid"]
    step = int(fr["step"] or 0)

    # --------------------------------------------------
    # HARD TIMEOUT GLOBAL
    # --------------------------------------------------
    if age_s >= CFG["max_trade_age_s"]:
        f.execute("""
            UPDATE follower
            SET status='close_req',
                reason='TIMEOUT_MAX_AGE',
                qty_to_close=?,
                close_step=?,
                last_action_ts=?
            WHERE uid=? AND status='follow'
        """, (qty_open, step, now, uid))
        return

    # --------------------------------------------------
    # NO-MFE TIMEOUT
    # --------------------------------------------------
    if (
        fr["mfe_atr"] < CFG["min_mfe_keep_atr"]
        and age_s >= CFG["max_no_mfe_age_s"]
    ):
        f.execute("""
            UPDATE follower
            SET status='close_req',
                reason='TIMEOUT_NO_MFE',
                qty_to_close=?,
                close_step=?,
                last_action_ts=?
            WHERE uid=? AND status='follow'
        """, (qty_open, step, now, uid))
        return

----- FILE: /opt/scalp/project/scripts/gen_schema_ref.sh -----
#!/usr/bin/env bash
set -euo pipefail

# -------- CONFIG --------
DATA_DIR="/opt/scalp/project/data"
OUT="${DATA_DIR}/schema_ref.sql"

# -------- INIT --------
{
  echo "-- === SCHEMA GLOBAL SCALP ==="
  echo "-- G√©n√©r√© le $(date '+%Y-%m-%d %H:%M:%S')"
  echo
} > "$OUT"

# -------- EXTRACTION COMPL√àTE --------
for DB in oa.db a.db ob.db b.db budget.db gest.db h.db t.db u.db  triggers.db signals.db opener.db follower.db closer.db recorder.db; do
  DB_PATH="${DATA_DIR}/${DB}"
  echo "-- --- $DB ---" >> "$OUT"
  if [[ -f "$DB_PATH" ]]; then
    # Sortie compl√®te des tables et vues
    sqlite3 "$DB_PATH" "SELECT sql FROM sqlite_master WHERE type IN ('table','view') AND sql NOT NULL ORDER BY name;" \
      >> "$OUT" 2>/dev/null || true
    echo >> "$OUT"
  else
    echo "-- (absent) $DB" >> "$OUT"
    echo >> "$OUT"
  fi
done

echo "-- === FIN ===" >> "$OUT"
echo "‚úÖ Sch√©ma complet sauvegard√© dans $OUT"

----- FILE: /opt/scalp/project/scripts/gest.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3
import time
from pathlib import Path

ROOT = Path("/opt/scalp/project")

DB_GEST     = ROOT / "data/gest.db"
DB_TRIGGERS = ROOT / "data/triggers.db"
DB_FOLLOWER = ROOT / "data/follower.db"
DB_OPENER   = ROOT / "data/opener.db"
DB_CLOSER   = ROOT / "data/closer.db"

LOOP_SLEEP = 0.2


def conn(path):
    c = sqlite3.connect(str(path), timeout=10, isolation_level=None)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA synchronous=NORMAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c


# -------------------------------------------------
# TRIGGERS ‚Üí open_req (create trade)
# -------------------------------------------------
def ingest_triggers():
    t = conn(DB_TRIGGERS)
    g = conn(DB_GEST)

    try:
        rows = t.execute("""
            SELECT uid, instId, side, price, ts, ts_fire, atr
            FROM triggers
            WHERE status='fired'
        """).fetchall()

        for r in rows:
            uid = r["uid"]
            if g.execute("SELECT 1 FROM gest WHERE uid=?", (uid,)).fetchone():
                continue

            g.execute("""
                INSERT INTO gest
                (uid, instId, side, entry, price_signal,
                 atr_signal, ts_signal, ts_open, status)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, 'open_req')
            """, (
                uid,
                r["instId"],
                r["side"],
                r["price"],
                r["price"],
                r["atr"],
                r["ts"],
                r["ts_fire"]
            ))
    finally:
        t.close()
        g.close()


# -------------------------------------------------
# OPENER ACK ‚Üí *_done
# -------------------------------------------------
def ingest_opener_done():
    o = conn(DB_OPENER)
    g = conn(DB_GEST)

    try:
        rows = o.execute("""
            SELECT uid, status
            FROM opener
            WHERE status IN ('open_done','pyramide_done')
        """).fetchall()

        for r in rows:
            uid = r["uid"]
            st  = r["status"]

            if st == "open_done":
                g.execute("""
                    UPDATE gest
                    SET status='open_done',
                        ts_status_update=strftime('%s','now')*1000
                    WHERE uid=?
                      AND status='open_req'
                """, (uid,))
            elif st == "pyramide_done":
                g.execute("""
                    UPDATE gest
                    SET status='pyramide_done',
                        ts_status_update=strftime('%s','now')*1000
                    WHERE uid=?
                      AND status='pyramide_req'
                """, (uid,))
    finally:
        o.close()
        g.close()


# -------------------------------------------------
# CLOSER ACK ‚Üí *_done
# -------------------------------------------------
def ingest_closer_done():
    c = conn(DB_CLOSER)
    g = conn(DB_GEST)

    try:
        rows = c.execute("""
            SELECT uid, status
            FROM closer
            WHERE status IN ('close_done','partial_done')
        """).fetchall()

        for r in rows:
            uid = r["uid"]
            st  = r["status"]

            if st == "partial_done":
                g.execute("""
                    UPDATE gest
                    SET status='partial_done',
                        ts_status_update=strftime('%s','now')*1000
                    WHERE uid=?
                      AND status='partial_req'
                """, (uid,))
            elif st == "close_done":
                g.execute("""
                    UPDATE gest
                    SET status='close_done',
                        ts_status_update=strftime('%s','now')*1000
                    WHERE uid=?
                      AND status='close_req'
                """, (uid,))
    finally:
        c.close()
        g.close()


# -------------------------------------------------
# FOLLOWER MIRROR ‚Üí follow
# -------------------------------------------------
def mirror_follower_follow():
    f = conn(DB_FOLLOWER)
    g = conn(DB_GEST)

    try:
        rows = f.execute("""
            SELECT uid
            FROM follower
            WHERE status='follow'
        """).fetchall()

        for r in rows:
            uid = r["uid"]
            g.execute("""
                UPDATE gest
                SET status='follow',
                    ts_status_update=strftime('%s','now')*1000
                WHERE uid=?
                  AND status LIKE '%_done'
            """, (uid,))
    finally:
        f.close()
        g.close()


# -------------------------------------------------
# FOLLOWER REQUESTS ‚Üí *_req  (RATIO SYNC FIX + STEP FIX)
# -------------------------------------------------
def ingest_follower_requests():
    f = conn(DB_FOLLOWER)
    g = conn(DB_GEST)

    try:
        rows = f.execute("""
            SELECT uid, status,
                   ratio_to_close,
                   ratio_to_add
            FROM follower
            WHERE status IN ('pyramide_req','partial_req','close_req')
        """).fetchall()

        for r in rows:
            uid = r["uid"]
            st  = r["status"]

            if st == "pyramide_req":
                # üî• CRITIQUE: incr√©menter step pour que opener puisse ins√©rer (uid, exec_type, step) sans collision
                # open initial = step 0, pyramide #1 = step 1, etc.
                g.execute("""
                    UPDATE gest
                    SET status='pyramide_req',
                        ratio_to_add=?,
                        step=COALESCE(step,0)+1,
                        ts_status_update=strftime('%s','now')*1000
                    WHERE uid=?
                      AND status='follow'
                """, (r["ratio_to_add"], uid))

            elif st == "partial_req":
                g.execute("""
                    UPDATE gest
                    SET status='partial_req',
                        ratio_to_close=?,
                        ts_status_update=strftime('%s','now')*1000
                    WHERE uid=?
                      AND status='follow'
                """, (r["ratio_to_close"], uid))

            elif st == "close_req":
                g.execute("""
                    UPDATE gest
                    SET status='close_req',
                        ratio_to_close=1.0,
                        ts_status_update=strftime('%s','now')*1000
                    WHERE uid=?
                      AND status='follow'
                """, (uid,))
    finally:
        f.close()
        g.close()


def main():
    while True:
        try:
            ingest_triggers()
            ingest_opener_done()
            ingest_closer_done()
            mirror_follower_follow()
            ingest_follower_requests()
        except Exception as e:
            print("[GEST ERROR]", e)

        time.sleep(LOOP_SLEEP)


if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/gest_from_closer.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3
import time
import logging
from pathlib import Path

ROOT = Path("/opt/scalp/project")
DB_GEST   = ROOT / "data/gest.db"
DB_CLOSER = ROOT / "data/closer.db"

log = logging.getLogger("GEST")

def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

def now_ms():
    return int(time.time() * 1000)

def copy_closer():
    g = conn(DB_GEST)
    c = conn(DB_CLOSER)
    now = now_ms()

    for r in c.execute("""
        SELECT uid, status, ts_exec
        FROM closer
        WHERE status IN ('partial_done','close_done')
    """):
        if r["status"] == "partial_done":
            g.execute("""
                UPDATE gest
                SET status='partial_done',
                    ts_close=?,
                    ts_updated=?
                WHERE uid=? AND status='partial_req'
            """, (r["ts_exec"], now, r["uid"]))

        elif r["status"] == "close_done":
            g.execute("""
                UPDATE gest
                SET status='close_done',
                    ts_close=?,
                    ts_updated=?
                WHERE uid=? AND status='close_req'
            """, (r["ts_exec"], now, r["uid"]))

    g.commit()
    g.close()
    c.close()

----- FILE: /opt/scalp/project/scripts/gest_from_follower.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3, time
from pathlib import Path

ROOT = Path("/opt/scalp/project")
DB_GEST = ROOT / "data/gest.db"
DB_FOLLOWER = ROOT / "data/follower.db"

def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    return c

def now_ms(): return int(time.time()*1000)

def loop():
    f = conn(DB_FOLLOWER)
    g = conn(DB_GEST)
    now = now_ms()

    for fr in f.execute("SELECT * FROM follower"):

        g.execute("""
        INSERT INTO gest (uid, instId, side, status, step,
                          ratio_to_close, ratio_to_add, ts_updated)
        VALUES (?,?,?,?,?,?,?,?)
        ON CONFLICT(uid) DO UPDATE SET
            status=excluded.status,
            step=excluded.step,
            ratio_to_close=excluded.ratio_to_close,
            ratio_to_add=excluded.ratio_to_add,
            ts_updated=excluded.ts_updated
        """, (
            fr["uid"],
            fr["instId"],
            fr["side"],
            fr["status"],
            fr["req_step"],
            fr["qty_to_close_ratio"],   -- ‚úÖ LE BON CHAMP
            fr["qty_to_add_ratio"],
            now
        ))

    g.commit()
    f.close(); g.close()

if __name__ == "__main__":
    while True:
        loop()
        time.sleep(0.25)

----- FILE: /opt/scalp/project/scripts/gest_from_follower_follow.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3
import time
import logging
from pathlib import Path

ROOT = Path("/opt/scalp/project")
DB_GEST   = ROOT / "data/gest.db"
DB_FOLLOW = ROOT / "data/follower.db"

log = logging.getLogger("GEST")

def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

def now_ms():
    return int(time.time() * 1000)

def sync_follow_state():
    g = conn(DB_GEST)
    f = conn(DB_FOLLOW)
    now = now_ms()

    rows = g.execute("""
        SELECT uid, status
        FROM gest
        WHERE status IN ('open_done','partial_done','pyramide_done')
    """).fetchall()

    for r in rows:
        uid = r["uid"]

        fr = f.execute("""
            SELECT status FROM follower WHERE uid=?
        """, (uid,)).fetchone()

        if not fr:
            continue

        if fr["status"] == "follow":
            g.execute("""
                UPDATE gest
                SET status='follow',
                    ts_updated=?
                WHERE uid=? AND status=?
            """, (now, uid, r["status"]))

            log.info("[GEST FOLLOW] %s %s -> follow", uid, r["status"])

    g.commit()
    g.close()
    f.close()

----- FILE: /opt/scalp/project/scripts/gest_from_opener.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3
import time
import logging
from pathlib import Path

ROOT = Path("/opt/scalp/project")
DB_GEST   = ROOT / "data/gest.db"
DB_OPENER = ROOT / "data/opener.db"

log = logging.getLogger("GEST")

def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

def now_ms():
    return int(time.time() * 1000)

def copy_opener():
    g = conn(DB_GEST)
    o = conn(DB_OPENER)
    now = now_ms()

    for r in o.execute("""
        SELECT uid, status, price_exec_open, ts_open
        FROM opener
        WHERE status IN ('open_done','pyramide_done')
    """):
        if r["status"] == "open_done":
            g.execute("""
                UPDATE gest
                SET status='open_done',
                    entry=?,
                    ts_open=?,
                    ts_updated=?
                WHERE uid=? AND status='open_req'
            """, (r["price_exec_open"], r["ts_open"], now, r["uid"]))

        elif r["status"] == "pyramide_done":
            g.execute("""
                UPDATE gest
                SET status='pyramide_done',
                    ts_updated=?
                WHERE uid=? AND status='pyramide_req'
            """, (now, r["uid"]))

    g.commit()
    g.close()
    o.close()

----- FILE: /opt/scalp/project/scripts/gest_from_triggers.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
GEST ‚Äî TRIGGERS ‚Üí OPEN_REQ
Ajoute les nouveaux trades dans GEST
Ne touche PAS aux transitions FSM
"""

import sqlite3
from pathlib import Path

ROOT = Path("/opt/scalp/project")
DB_TRIG = ROOT / "data/triggers.db"
DB_GEST = ROOT / "data/gest.db"

def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

def ingest():
    t = conn(DB_TRIG)
    g = conn(DB_GEST)

    rows = t.execute("""
        SELECT uid, instId, side, price, score_C
        FROM triggers
        WHERE status='fired'
    """).fetchall()

    for r in rows:
        if g.execute("SELECT 1 FROM gest WHERE uid=?", (r["uid"],)).fetchone():
            continue

        g.execute("""
            INSERT INTO gest (uid, instId, side, entry, price_signal, score_C, status)
            VALUES (?, ?, ?, ?, ?, ?, 'open_req')
        """, (
            r["uid"],
            r["instId"],
            r["side"],
            r["price"],
            r["price"],
            r["score_C"]
        ))

    g.commit()
    t.close()
    g.close()

if __name__ == "__main__":
    ingest()

----- FILE: /opt/scalp/project/scripts/gest_ingest_triggers.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
GEST ‚Äî INGEST TRIGGERS ‚Üí OPEN_REQ

R√àGLES :
- lecture STRICTE du sch√©ma triggers
- aucun champ fant√¥me
- aucun calcul
"""

import sqlite3
import logging
from pathlib import Path

ROOT = Path("/opt/scalp/project")

DB_TRIG = ROOT / "data/triggers.db"
DB_GEST = ROOT / "data/gest.db"

LOG = ROOT / "logs/gest.log"
log = logging.getLogger("GEST")

# ============================================================
# UTILS
# ============================================================

def now_ms():
    import time
    return int(time.time() * 1000)

def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

def rget(row, k, d=None):
    try:
        return row[k]
    except Exception:
        return d

# ============================================================
# INGEST
# ============================================================

def ingest_triggers():
    t = conn(DB_TRIG)
    g = conn(DB_GEST)
    now = now_ms()

    rows = list(t.execute("""
        SELECT *
        FROM triggers
        WHERE status='fired'
    """))

    if rows:
        log.info("[INGEST] %d triggers fired", len(rows))

    for r in rows:
        uid = rget(r, "uid")
        if not uid:
            continue

        # d√©j√† ing√©r√©
        if g.execute("SELECT 1 FROM gest WHERE uid=?", (uid,)).fetchone():
            continue

        g.execute("""
            INSERT INTO gest (
                uid, instId, side,

                ts_signal,
                price_signal,
                atr_signal,

                reason,
                entry_reason,
                type_signal,

                score_of,
                score_mo,
                score_br,
                score_force,

                dec_mode,
                dec_score_C,
                dec_ctx,

                status,
                step,
                ts_created,
                ts_updated
            ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)
        """, (
            uid,
            rget(r,"instId"),
            rget(r,"side"),

            rget(r,"ts"),
            rget(r,"price"),
            rget(r,"atr"),

            rget(r,"fire_reason"),
            rget(r,"entry_reason"),
            rget(r,"trigger_type"),

            rget(r,"score_of"),
            rget(r,"score_mo"),
            rget(r,"score_br"),
            rget(r,"score_force"),

            rget(r,"dec_mode"),
            rget(r,"dec_score_C"),
            rget(r,"ctx"),

            "open_req",
            0,
            now,
            now
        ))

        log.info("[OPEN_REQ] %s (%s)", uid, rget(r,"instId"))

    g.commit()
    t.close()
    g.close()


----- FILE: /opt/scalp/project/scripts/gest_purge.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
GEST ‚Äî PURGE FINALE
Recorder = source de v√©rit√©
"""

import sqlite3
import logging
from pathlib import Path

ROOT = Path("/opt/scalp/project")

DB_GEST     = ROOT / "data/gest.db"
DB_RECORDER = ROOT / "data/recorder.db"

log = logging.getLogger("GEST")

def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

def purge_recorded():
    g = conn(DB_GEST)
    r = conn(DB_RECORDER)

    for x in r.execute("SELECT DISTINCT uid FROM recorder"):
        if g.execute("DELETE FROM gest WHERE uid=?", (x["uid"],)).rowcount:
            log.info("[PURGE] %s", x["uid"])

    g.commit()
    g.close()
    r.close()

----- FILE: /opt/scalp/project/scripts/ingest_triggers_to_gest.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SCALP ‚Äî INGEST TRIGGERS ‚Üí GEST (FINAL / SNAPSHOT SAFE)

R√îLE :
- lit triggers.db (read-only)
- √©crit gest.db (SEUL writer)
- snapshot COMPLET du signal
- cr√©e open_req avec entry NON NULL
"""

import sqlite3
import time
import logging
from pathlib import Path

# =============================================================================
# PATHS
# =============================================================================

ROOT = Path("/opt/scalp/project")

DB_TRIG = ROOT / "data/triggers.db"
DB_GEST = ROOT / "data/gest.db"

LOG = ROOT / "logs/ingest_triggers.log"
LOOP_SLEEP = 0.3

# =============================================================================
# LOG
# =============================================================================

logging.basicConfig(
    filename=str(LOG),
    level=logging.INFO,
    format="%(asctime)s INGEST %(levelname)s %(message)s"
)
log = logging.getLogger("INGEST")

# =============================================================================
# UTILS
# =============================================================================

def now_ms():
    return int(time.time() * 1000)

def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

# =============================================================================
# CORE
# =============================================================================

def ingest():
    cT = conn(DB_TRIG)
    cG = conn(DB_GEST)

    rows = cT.execute("""
        SELECT
            uid,
            instId,
            side,
            price,
            atr,
            entry_reason,
            score_of
        FROM triggers
        WHERE status='fired'
    """).fetchall()

    if not rows:
        cT.close()
        cG.close()
        return

    now = now_ms()

    for t in rows:
        # idempotence
        if cG.execute(
            "SELECT 1 FROM gest WHERE uid=?",
            (t["uid"],)
        ).fetchone():
            continue

        if t["price"] is None or t["atr"] is None:
            log.warning("[SKIP] uid=%s price/atr NULL", t["uid"])
            continue

        cG.execute("""
            INSERT INTO gest (
                uid,
                instId,
                side,
                ts_open,
                entry,
                atr_signal,
                entry_reason,
                score_of,
                status
            ) VALUES (?,?,?,?,?,?,?,?,?)
        """, (
            t["uid"],
            t["instId"],
            t["side"],
            now,
            float(t["price"]),       -- üîë SNAPSHOT ENTRY
            float(t["atr"]),         -- üîë SNAPSHOT ATR
            t["entry_reason"],
            t["score_of"],
            "open_req"
        ))

        log.info(
            "[OPEN_REQ] uid=%s %s %s entry=%.5f atr=%.5f",
            t["uid"],
            t["instId"],
            t["side"],
            t["price"],
            t["atr"]
        )

    cG.commit()
    cT.close()
    cG.close()

# =============================================================================
# MAIN
# =============================================================================

def main():
    log.info("[START] ingest triggers ‚Üí gest")
    while True:
        try:
            ingest()
        except Exception as e:
            log.exception("[ERR]")
        time.sleep(LOOP_SLEEP)

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/list_opened_coins.sh -----
#!/usr/bin/env bash
set -euo pipefail

sqlite3 /opt/scalp/project/data/gest.db <<'SQL'
.headers on
.mode column
SELECT DISTINCT
    instId,
    REPLACE(instId,'/','') AS inst_norm
FROM gest
WHERE status='opened'
ORDER BY instId;
SQL

----- FILE: /opt/scalp/project/scripts/maemfe.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SCALP ‚Äî MAE / MFE ENGINE (DEDICATED WRITER)

R√îLE STRICT :
- lit gest.db (trades ouverts)
- lit t.db (ticks)
- calcule MFE / MAE
- √©crit UNIQUEMENT dans mfe_mae.db
- aucune d√©cision, aucun blocage
"""

import sqlite3
import time
import logging
from pathlib import Path

# =====================
# PATHS
# =====================
ROOT = Path("/opt/scalp/project")

DB_GEST = ROOT / "data/gest.db"
DB_TICK = ROOT / "data/t.db"
DB_MFE  = ROOT / "data/mfe_mae.db"

LOG = ROOT / "logs/maemfe.log"
LOOP_SLEEP = 0.2

# =====================
# LOG
# =====================
logging.basicConfig(
    filename=str(LOG),
    level=logging.INFO,
    format="%(asctime)s MAEMFE %(levelname)s %(message)s"
)
log = logging.getLogger("MAEMFE")

# =====================
# UTILS
# =====================
def now_ms():
    return int(time.time() * 1000)

def conn(p):
    c = sqlite3.connect(str(p), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

# =====================
# LOADERS
# =====================
def load_active_trades():
    """
    Trades r√©ellement vivants (post-open)
    """
    with conn(DB_GEST) as c:
        return c.execute("""
            SELECT
                uid,
                instId,
                side,
                avg_entry_price AS entry_price,
                ts_open
            FROM gest
            WHERE status IN (
                'open_done',
                'follow',
                'partial_done'
            )
              AND avg_entry_price IS NOT NULL
        """).fetchall()

def load_ticks():
    with conn(DB_TICK) as c:
        rows = c.execute("""
            SELECT instId_s AS instId, lastPr, ts_ms
            FROM v_ticks_latest
        """).fetchall()
        return {r["instId"]: r for r in rows}

# =====================
# CORE LOOP
# =====================
def process():
    ticks = load_ticks()
    trades = load_active_trades()

    with conn(DB_MFE) as c:
        for t in trades:
            tick = ticks.get(t["instId"])
            if not tick:
                continue

            uid   = t["uid"]
            side  = t["side"]
            entry = t["entry_price"]
            price = tick["lastPr"]
            ts    = tick["ts_ms"]

            move = (entry - price) if side == "sell" else (price - entry)

            row = c.execute(
                "SELECT mfe, mae FROM mfe_mae WHERE uid=?",
                (uid,)
            ).fetchone()

            if row is None:
                # INSERT initial
                mfe = move
                mae = move

                c.execute("""
                    INSERT INTO mfe_mae (
                        uid, instId, side,
                        entry_price, ts_open,
                        mfe, mfe_ts,
                        mae, mae_ts,
                        last_price, last_ts,
                        ts_updated
                    ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?)
                """, (
                    uid,
                    t["instId"],
                    side,
                    entry,
                    t["ts_open"],
                    mfe,
                    ts,
                    mae,
                    ts,
                    price,
                    ts,
                    now_ms()
                ))

                log.info("[INIT] %s mfe=%.5f mae=%.5f", uid, mfe, mae)

            else:
                mfe = max(row["mfe"], move)
                mae = min(row["mae"], move)

                c.execute("""
                    UPDATE mfe_mae
                    SET
                        mfe=?,
                        mfe_ts=CASE WHEN ?>mfe THEN ? ELSE mfe_ts END,
                        mae=?,
                        mae_ts=CASE WHEN ?<mae THEN ? ELSE mae_ts END,
                        last_price=?,
                        last_ts=?,
                        ts_updated=?
                    WHERE uid=?
                """, (
                    mfe,
                    move, ts,
                    mae,
                    move, ts,
                    price,
                    ts,
                    now_ms(),
                    uid
                ))

# =====================
# MAIN
# =====================
def main():
    log.info("[START] maemfe engine running")
    while True:
        try:
            process()
        except Exception as e:
            log.exception("[ERROR] maemfe loop")
        time.sleep(LOOP_SLEEP)

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/market_collector.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SCALP ‚Äî MARKET COLLECTOR (AUTHORITATIVE)

R√îLE :
- lire universe.db (v_universe_tradable)
- lire ticks (t.db)
- lire ohlcv (ob.db)
- snapshot REST ccxt
- calculer ticks_5s / spread / staleness
- √âCRIRE market_latest (SEUL writer)
"""

import sqlite3
import time
import logging
import ccxt
from pathlib import Path
from collections import deque, defaultdict

# ============================================================
# PATHS
# ============================================================

ROOT = Path("/opt/scalp/project")

DB_U = ROOT / "data/universe.db"
DB_T = ROOT / "data/t.db"
DB_O = ROOT / "data/ob.db"
DB_M = ROOT / "data/market.db"

# ============================================================
# PARAMS
# ============================================================

LOOP_SLEEP   = 1.0
SNAPSHOT_TTL = 30.0
BATCH_SIZE   = 5

# ============================================================
# LOG
# ============================================================

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s MARKET %(levelname)s %(message)s"
)
log = logging.getLogger("MARKET")

# ============================================================
# DB
# ============================================================

def conn(db):
    c = sqlite3.connect(str(db), timeout=10, isolation_level=None)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA synchronous=NORMAL;")
    c.execute("PRAGMA busy_timeout=5000;")
    return c

# ============================================================
# UNIVERSE
# ============================================================

def load_universe():
    cu = conn(DB_U)
    xs = [r[0] for r in cu.execute(
        "SELECT instId FROM v_universe_tradable"
    ).fetchall()]
    cu.close()
    log.info("Universe loaded: %d symbols", len(xs))
    return xs

# ============================================================
# CCXT SNAPSHOT
# ============================================================

EX = ccxt.bitget({"options": {"defaultType": "swap"}})

snapshot_cache = {}
snapshot_ts = 0.0

def refresh_snapshots(insts):
    global snapshot_cache, snapshot_ts

    now = time.time()
    if now - snapshot_ts < SNAPSHOT_TTL:
        return

    snapshot_cache.clear()
    log.info("Refreshing snapshots (%d symbols)", len(insts))

    for i in range(0, len(insts), BATCH_SIZE):
        batch = insts[i:i + BATCH_SIZE]
        syms = [x.replace("/", "") for x in batch]

        try:
            res = EX.fetch_tickers(syms)
        except Exception as e:
            log.error("Snapshot batch FAIL: %s", e)
            continue

        for k, t in res.items():
            if not t:
                continue

            inst = k.split(":")[0]
            if inst not in insts:
                continue

            snapshot_cache[inst] = {
                "last": float(t.get("last") or 0.0),
                "bid":  float(t.get("bid") or 0.0),
                "ask":  float(t.get("ask") or 0.0),
                "volume_24h": float(t.get("quoteVolume") or 0.0),
            }

    snapshot_ts = now
    log.info("Snapshot refresh done (%d cached)", len(snapshot_cache))

# ============================================================
# ATR 1m
# ============================================================

def atr_1m(inst, period=14):
    co = conn(DB_O)
    rows = co.execute("""
        SELECT h,l,c
        FROM ohlcv_1m
        WHERE instId=?
        ORDER BY ts DESC
        LIMIT ?
    """, (inst, period + 1)).fetchall()
    co.close()

    if len(rows) < period + 1:
        return None

    trs = []
    for i in range(1, period + 1):
        h, l, c = rows[i]
        pc = rows[i - 1][2]
        trs.append(max(h - l, abs(h - pc), abs(l - pc)))

    return sum(trs) / period

# ============================================================
# TICKS BUFFER
# ============================================================

tick_buf = defaultdict(lambda: deque(maxlen=500))

def update_ticks():
    ct = conn(DB_T)
    rows = ct.execute("""
        SELECT instId, lastPr, ts_ms
        FROM ticks
        WHERE ts_ms > ?
    """, (int(time.time() * 1000) - 5000,)).fetchall()
    ct.close()

    for r in rows:
        tick_buf[r["instId"]].append((r["ts_ms"], r["lastPr"]))

# ============================================================
# MAIN LOOP
# ============================================================

def main():
    log.info("MARKET START")

    universe = load_universe()
    cm = conn(DB_M)

    while True:
        try:
            now_ms = int(time.time() * 1000)

            update_ticks()
            refresh_snapshots(universe)

            for inst in universe:
                buf  = tick_buf.get(inst)
                snap = snapshot_cache.get(inst)

                if not buf or not snap or snap["last"] <= 0:
                    continue

                ticks_5s = sum(1 for ts, _ in buf if ts > now_ms - 5000)
                last_ts, _ = buf[-1]
                staleness = now_ms - last_ts

                spread = snap["ask"] - snap["bid"]
                spread_bps = (spread / snap["last"] * 10000) if snap["last"] else 0.0

                # ===============================
                # üîë AUTHORITATIVE WRITE
                # ===============================
                cm.execute("""
                    INSERT INTO market_latest (
                        instId,
                        ticks_5s,
                        spread_bps,
                        staleness_ms,
                        ts_update
                    ) VALUES (?,?,?,?,?)
                    ON CONFLICT(instId) DO UPDATE SET
                        ticks_5s     = excluded.ticks_5s,
                        spread_bps   = excluded.spread_bps,
                        staleness_ms = excluded.staleness_ms,
                        ts_update    = excluded.ts_update
                """, (
                    inst,
                    ticks_5s,
                    spread_bps,
                    staleness,
                    now_ms
                ))

            time.sleep(LOOP_SLEEP)

        except Exception:
            log.exception("MARKET LOOP ERROR")
            time.sleep(2)

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/mfe_mae.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SCALP ‚Äî MFE / MAE ENGINE (FINAL / STRICT)

R√îLE :
- lit gest.db (read-only)
- lit ticks_hist (read-only)
- √©crit UNIQUEMENT mfe_mae.db
- calcule MFE / MAE par UID
- AUCUNE logique m√©tier
"""

import sqlite3
import time
import logging
from pathlib import Path

###############################################################################
# PATHS
###############################################################################

ROOT = Path("/opt/scalp/project")

DB_GEST = ROOT / "data/gest.db"
DB_TICK = ROOT / "data/t.db"
DB_MFE  = ROOT / "data/mfe_mae.db"

LOG = ROOT / "logs/mfe_mae.log"
LOOP_SLEEP = 0.5

###############################################################################
# LOG
###############################################################################

logging.basicConfig(
    filename=str(LOG),
    level=logging.INFO,
    format="%(asctime)s MFE_MAE %(levelname)s %(message)s"
)
log = logging.getLogger("MFE_MAE")

###############################################################################
# UTILS
###############################################################################

def now_ms():
    return int(time.time() * 1000)

def conn(p):
    c = sqlite3.connect(str(p), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

###############################################################################
# CORE
###############################################################################

def loop():
    g = conn(DB_GEST)
    t = conn(DB_TICK)
    m = conn(DB_MFE)

    now = now_ms()

    # ============================================================
    # 1) GEST SNAPSHOT (UID actifs)
    # ============================================================
    gest_rows = g.execute("""
        SELECT
            uid,
            instId,
            side,
            entry,
            ts_open,
            atr_signal
        FROM gest
        WHERE status IN ('open_done','follow','partial_done','pyramide_done')
          AND ts_open IS NOT NULL
    """).fetchall()

    gest_map = {r["uid"]: r for r in gest_rows}

    # ============================================================
    # 2) PURGE UID ABSENTS DE GEST
    # ============================================================
    db_uids = {
        r["uid"]
        for r in m.execute("SELECT uid FROM mfe_mae")
    }

    for uid in db_uids - set(gest_map.keys()):
        m.execute("DELETE FROM mfe_mae WHERE uid=?", (uid,))
        log.info("[PURGE] uid=%s", uid)

    # ============================================================
    # 3) INGEST NOUVEAUX UID
    # ============================================================
    for uid, r in gest_map.items():
        if m.execute(
            "SELECT 1 FROM mfe_mae WHERE uid=?",
            (uid,)
        ).fetchone():
            continue

        m.execute("""
            INSERT INTO mfe_mae (
                uid, instId, side,
                entry_price, ts_open,
                mfe, mfe_ts,
                mae, mae_ts,
                last_price, last_ts,
                atr,
                ts_updated
            ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?)
        """, (
            uid,
            r["instId"],
            r["side"],
            r["entry"],
            r["ts_open"],
            0.0, r["ts_open"],
            0.0, r["ts_open"],
            r["entry"],
            r["ts_open"],
            r["atr_signal"],
            now
        ))

        log.info("[INGEST] uid=%s inst=%s", uid, r["instId"])

    # ============================================================
    # 4) UPDATE MFE / MAE (ticks_hist, fen√™tre correcte)
    # ============================================================
    for r in m.execute("SELECT * FROM mfe_mae"):
        ticks = t.execute("""
            SELECT lastPr, ts_ms
            FROM ticks_hist
            WHERE instId=?
              AND ts_ms>=?
            ORDER BY ts_ms
        """, (r["instId"], r["ts_open"])).fetchall()

        if not ticks:
            continue

        mfe = r["mfe"]
        mae = r["mae"]
        mfe_ts = r["mfe_ts"]
        mae_ts = r["mae_ts"]

        for tk in ticks:
            move = (
                tk["lastPr"] - r["entry_price"]
                if r["side"] == "buy"
                else r["entry_price"] - tk["lastPr"]
            )

            if move > mfe:
                mfe = move
                mfe_ts = tk["ts_ms"]

            if move < mae:
                mae = move
                mae_ts = tk["ts_ms"]

        last_price = ticks[-1]["lastPr"]
        last_ts    = ticks[-1]["ts_ms"]

        m.execute("""
            UPDATE mfe_mae
            SET
                mfe=?,
                mfe_ts=?,
                mae=?,
                mae_ts=?,
                last_price=?,
                last_ts=?,
                ts_updated=?
            WHERE uid=?
        """, (
            mfe,
            mfe_ts,
            mae,
            mae_ts,
            last_price,
            last_ts,
            now,
            r["uid"]
        ))

    m.commit()
    g.close()
    t.close()
    m.close()

###############################################################################
# MAIN
###############################################################################

def main():
    log.info("[START] mfe_mae engine running (FINAL)")
    while True:
        try:
            loop()
        except Exception:
            log.exception("[ERR] mfe_mae loop")
        time.sleep(LOOP_SLEEP)

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/monitor_snapshot.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SCALP ‚Äî MONITOR SNAPSHOT (READ ONLY)

- aucune √©criture
- aucune attach
- visibilit√© compl√®te du pipeline
"""

import sqlite3
from pathlib import Path

ROOT = Path("/opt/scalp/project")

DB_UNIVERSE = ROOT / "data/universe.db"
DB_MARKET   = ROOT / "data/market.db"
DB_CTX      = ROOT / "data/a.db"
DB_DEC      = ROOT / "data/dec.db"

# ------------------------------------------------------------
def conn(p):
    c = sqlite3.connect(str(p), timeout=5)
    c.row_factory = sqlite3.Row
    return c

# ------------------------------------------------------------
def universe_snapshot():
    with conn(DB_UNIVERSE) as c:
        r = c.execute("""
            SELECT
              (SELECT COUNT(*) FROM universe_seed)      AS seed,
              (SELECT COUNT(*) FROM v_universe_enabled) AS enabled,
              (SELECT COUNT(*) FROM universe_tradable)  AS tradable
        """).fetchone()
    return r

# ------------------------------------------------------------
def market_snapshot():
    with conn(DB_MARKET) as c:
        r = c.execute("""
            SELECT
              COUNT(*)                                   AS seen,
              SUM(staleness_ms <= 1000)                 AS fresh,
              SUM(ticks_5s >= 5)                        AS flow_ok,
              SUM(spread_bps <= 5.0)                    AS spread_ok,
              SUM(market_ok = 1)                        AS market_ok
            FROM v_market_latest
        """).fetchone()
    return r

# ------------------------------------------------------------
def ctx_snapshot():
    with conn(DB_CTX) as c:
        total = c.execute("SELECT COUNT(*) FROM v_ctx_signal").fetchone()[0]
        ok    = c.execute("SELECT COUNT(*) FROM v_ctx_signal WHERE ctx_ok=1").fetchone()[0]

        by_ctx = {
            r["ctx"]: r["n"]
            for r in c.execute("""
                SELECT ctx, COUNT(*) AS n
                FROM v_ctx_signal
                WHERE ctx_ok=1
                GROUP BY ctx
            """)
        }
    return total, ok, by_ctx

# ------------------------------------------------------------
def ctx_on_market_snapshot():
    with conn(DB_CTX) as c_ctx, conn(DB_MARKET) as c_m:
        market_ok = {
            r["instId"]
            for r in c_m.execute("SELECT instId FROM v_market_latest WHERE market_ok=1")
        }

        rows = c_ctx.execute("""
            SELECT instId, ctx
            FROM v_ctx_signal
            WHERE ctx_ok=1
        """).fetchall()

        total = 0
        by_ctx = {"bullish": 0, "bearish": 0, "flat": 0}

        for r in rows:
            if r["instId"] in market_ok:
                total += 1
                by_ctx[r["ctx"]] += 1

    return total, by_ctx

# ------------------------------------------------------------
def dec_explain_snapshot():
    with conn(DB_DEC) as c:
        base = c.execute("""
            SELECT
              COUNT(*)                                 AS ctx_ok,
              SUM(high_20 IS NOT NULL)                 AS has_range,
              SUM(atr IS NOT NULL)                     AS has_atr,
              SUM(compression_ok = 1)                  AS compression_ok
            FROM v_dec_candidates
        """).fetchone()

        modes = {
            r["dec_mode"]: r["n"]
            for r in c.execute("""
                SELECT dec_mode, COUNT(*) AS n
                FROM v_dec_explain
                GROUP BY dec_mode
            """)
        }

    return base, modes

# ------------------------------------------------------------
def main():
    print("\nPIPELINE SNAPSHOT")
    print("=" * 62)

    # ---------------- UNIVERSE ----------------
    u = universe_snapshot()
    print("\nUNIVERSE")
    print(f"Seed              : {u['seed']}")
    print(f"Enabled (allowed) : {u['enabled']} / {u['seed']}  ({u['enabled']-u['seed']:+d})")
    print(f"Tradable          : {u['tradable']} / {u['enabled']}  ({u['tradable']-u['enabled']:+d})")

    # ---------------- MARKET ----------------
    m = market_snapshot()
    print("\nMARKET FILTERS")
    print(f"Seen by market    : {m['seen']} / {u['tradable']}  ({m['seen']-u['tradable']:+d})")
    print(f"Fresh prices     : {m['fresh']} / {m['seen']}  ({m['fresh']-m['seen']:+d})")
    print(f"Sufficient flow  : {m['flow_ok']} / {m['seen']}  ({m['flow_ok']-m['seen']:+d})")
    print(f"Acceptable spread: {m['spread_ok']} / {m['flow_ok']}  ({m['spread_ok']-m['flow_ok']:+d})")
    print(f"Market OK        : {m['market_ok']} / {m['spread_ok']}  ({m['market_ok']-m['spread_ok']:+d})")

    # ---------------- CTX ----------------
    ctx_total, ctx_ok, by_ctx = ctx_snapshot()
    print("\nCONTEXT (micro)")
    print(f"Directional ctx   : {ctx_ok} / {ctx_total}  ({ctx_ok-ctx_total:+d})")
    for k in ("bullish", "bearish", "flat"):
        print(f"  {k:<14}: {by_ctx.get(k,0)}")

    # ---------------- CTX ‚à© MARKET ----------------
    ctx_mkt, by_ctx_mkt = ctx_on_market_snapshot()
    print("\nCTX ON MARKET OK")
    print(f"CTX OK on market  : {ctx_mkt}")
    for k in ("bullish", "bearish", "flat"):
        print(f"  {k:<14}: {by_ctx_mkt.get(k,0)}")

    # ---------------- DEC ----------------
    base, modes = dec_explain_snapshot()
    print("\nDEC (dry-run / explain)")
    print(f"CTX candidates    : {base['ctx_ok']}")
    print(f"  with range      : {base['has_range']} / {base['ctx_ok']}")
    print(f"  with ATR        : {base['has_atr']} / {base['ctx_ok']}")
    print(f"  compression OK  : {base['compression_ok']} / {base['ctx_ok']}")

    for mode in ("PREBREAK","PULLBACK","MOMENTUM","NO_ENTRY"):
        print(f"  {mode:<14}: {modes.get(mode,0)}")

    print("\n" + "=" * 62)

# ------------------------------------------------------------
if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/monitor_snapshot_5m.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SCALP ‚Äî PIPELINE MONITOR SNAPSHOT (Œî 5 MIN)

- ex√©cution √† la demande
- aucune t√¢che persistante
- 1 writer : monitor.db
- snapshots horodat√©s
- affichage delta vs T-5min
"""

import sqlite3
import time
from pathlib import Path

ROOT = Path("/opt/scalp/project")

DB_MARKET  = ROOT / "data/market.db"
DB_DEC     = ROOT / "data/dec.db"
DB_TRIG    = ROOT / "data/triggers.db"
DB_MON     = ROOT / "data/monitor.db"

NOW_MS = int(time.time() * 1000)
DELTA_MS = 5 * 60 * 1000


# -------------------------------------------------------------------
# DB UTILS
# -------------------------------------------------------------------

def conn(p):
    c = sqlite3.connect(str(p), timeout=10)
    c.row_factory = sqlite3.Row
    return c

def scalar(db, sql):
    c = conn(db)
    r = c.execute(sql).fetchone()
    c.close()
    return int(list(r)[0]) if r and list(r)[0] is not None else 0


# -------------------------------------------------------------------
# SNAPSHOT COUNTS
# -------------------------------------------------------------------

def collect_counts():
    return {
        "universe": scalar(DB_MARKET, "SELECT COUNT(*) FROM v_market_latest"),
        "market_ok": scalar(
            DB_MARKET,
            "SELECT COUNT(*) FROM v_market_latest WHERE spread_ok=1 AND liquidity_ok=1"
        ),
        "ctx_ok": scalar(
            DB_DEC,
            "SELECT COUNT(*) FROM snap_ctx WHERE ctx_ok=1"
        ),
        "dec_tradable": scalar(
            DB_DEC,
            "SELECT COUNT(*) FROM snap_ctx WHERE ctx_ok=1 AND side IS NOT NULL"
        ),
        "armed": scalar(
            DB_TRIG,
            "SELECT COUNT(*) FROM triggers WHERE status='armed'"
        ),
        "fired": scalar(
            DB_TRIG,
            "SELECT COUNT(*) FROM triggers WHERE status='fired'"
        ),
    }


# -------------------------------------------------------------------
# MAIN
# -------------------------------------------------------------------

def main():
    c = conn(DB_MON)

    # table snapshot
    c.execute("""
        CREATE TABLE IF NOT EXISTS pipeline_snapshot (
            ts_ms INTEGER PRIMARY KEY,
            universe INTEGER,
            market_ok INTEGER,
            ctx_ok INTEGER,
            dec_tradable INTEGER,
            armed INTEGER,
            fired INTEGER
        )
    """)

    counts = collect_counts()

    # insert snapshot
    c.execute("""
        INSERT INTO pipeline_snapshot
        (ts_ms, universe, market_ok, ctx_ok, dec_tradable, armed, fired)
        VALUES (?,?,?,?,?,?,?)
    """, (
        NOW_MS,
        counts["universe"],
        counts["market_ok"],
        counts["ctx_ok"],
        counts["dec_tradable"],
        counts["armed"],
        counts["fired"]
    ))
    c.commit()

    # fetch T-5min snapshot
    prev = c.execute("""
        SELECT *
        FROM pipeline_snapshot
        WHERE ts_ms <= ?
        ORDER BY ts_ms DESC
        LIMIT 1
    """, (NOW_MS - DELTA_MS,)).fetchone()

    c.close()

    def delta(k):
        if not prev:
            return " N/A"
        d = counts[k] - prev[k]
        return f"{d:+4d}"

    # -------------------------------------------------------------------
    # DISPLAY
    # -------------------------------------------------------------------

    print("\nPIPELINE SNAPSHOT (Œî 5 MIN)")
    print("=" * 42)
    print(f"Universe (market) : {counts['universe']:4d}")
    print(f"Market OK         : {counts['market_ok']:4d} ({delta('market_ok')})")
    print(f"CTX OK            : {counts['ctx_ok']:4d} ({delta('ctx_ok')})")
    print(f"DEC tradable      : {counts['dec_tradable']:4d} ({delta('dec_tradable')})")
    print(f"ARMED             : {counts['armed']:4d} ({delta('armed')})")
    print(f"FIRED             : {counts['fired']:4d} ({delta('fired')})")
    print("=" * 42)


if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/opener.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SCALP ‚Äî OPENER DAEMON
Responsabilit√© :
- ACK exec ‚Üí opener (*_done)
- ingest open_req
- ingest pyramide_req

UPGRADE (non-breaking):
- try/except par √©tape : un crash dans ingest_open_req ne bloque plus ingest_pyramide_req
  (et inversement). Sinon tu peux rester bloqu√© en pyramide_req √† vie.
"""

import time
import logging

from opener_from_exec import ingest_exec_done
from opener_ingest_open import ingest_open_req
from opener_pyramide import ingest_pyramide_req

LOG = "/opt/scalp/project/logs/opener.log"
LOOP_SLEEP = 0.3

logging.basicConfig(
    filename=LOG,
    level=logging.INFO,
    format="%(asctime)s OPENER %(levelname)s %(message)s"
)

log = logging.getLogger("OPENER")


def main():
    log.info("[START] opener daemon")
    while True:
        # üîë ORDRE CRITIQUE
        try:
            ingest_exec_done()      # exec ‚Üí opener
        except Exception:
            log.exception("[ERR] ingest_exec_done")

        try:
            ingest_open_req()       # gest ‚Üí opener (open)
        except Exception:
            log.exception("[ERR] ingest_open_req")

        try:
            ingest_pyramide_req()   # gest ‚Üí opener (pyramide)
        except Exception:
            log.exception("[ERR] ingest_pyramide_req")

        time.sleep(LOOP_SLEEP)


if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/opener_adapt.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
OPENER ‚Äî ADAPTIVE ADMISSION
- ajuste UNIQUEMENT le ticket d'entr√©e (STEP 0)
- AUCUNE limite sur les pyramides
"""

import sqlite3
from pathlib import Path

DB_REC = Path("/opt/scalp/project/data/recorder.db")

def conn():
    c = sqlite3.connect(str(DB_REC), timeout=3)
    c.row_factory = sqlite3.Row
    return c


def adaptive_ticket_ratio(instId):
    """
    Retourne ticket_ratio ‚àà [0.05 ; 0.10]
    """

    c = conn()
    r = c.execute("""
        SELECT exp, pf
        FROM v_edge_coin
        WHERE instId=?
        LIMIT 1
    """, (instId,)).fetchone()
    c.close()

    # Fallback s√©curit√©
    if not r:
        return 0.05

    exp = r["exp"] or 0.0
    pf  = r["pf"] or 0.0

    # Coin toxique ‚Üí ticket minimal
    if exp < 0 or pf < 1.0:
        return 0.05

    # Edge faible
    if exp < 0.1 or pf < 1.5:
        return 0.06

    # Edge correct
    if exp < 0.5 or pf < 2.5:
        return 0.08

    # Edge fort
    return 0.10

----- FILE: /opt/scalp/project/scripts/opener_contracts.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import math

def normalize_qty(*, qty_raw, price, contract):
    """
    contract : row contracts.db
    """

    if qty_raw <= 0:
        return None

    min_qty = contract["minTradeNum"]
    step    = contract["sizeMultiplier"]
    vol_dec = contract["volumePlace"]
    min_usd = contract["minTradeUSDT"]
    max_qty = contract["maxOrderQty"]

    # arrondi step
    qty = math.floor(qty_raw / step) * step
    qty = round(qty, vol_dec)

    if qty < min_qty:
        return None

    if qty * price < min_usd:
        return None

    if max_qty and qty > max_qty:
        qty = max_qty

    return qty

----- FILE: /opt/scalp/project/scripts/opener_from_exec.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3
from pathlib import Path
import logging
import time

ROOT = Path("/opt/scalp/project")
DB_OPENER = ROOT / "data/opener.db"
DB_EXEC   = ROOT / "data/exec.db"

log = logging.getLogger("OPENER")


def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c


def now_ms():
    return int(time.time() * 1000)


def ingest_exec_done():
    o = conn(DB_OPENER)
    e = conn(DB_EXEC)

    try:
        rows = o.execute("""
            SELECT *
            FROM opener
            WHERE status='open_stdby'
              AND exec_type='open'
        """).fetchall()

        for r in rows:
            uid   = r["uid"]
            inst  = r["instId"]
            side  = r["side"]
            qty   = float(r["qty"] or 0.0)
            step  = int(r["step"] or 0)

            exec_id = f"{uid}_open_{step}"

            # d√©j√† ex√©cut√© ?
            if e.execute("SELECT 1 FROM exec WHERE exec_id=?", (exec_id,)).fetchone():
                continue

            # ‚¨áÔ∏è SCHEMA EXEC R√âEL COMPATIBLE (AUCUN BREAK)
            e.execute("""
                INSERT INTO exec (
                    exec_id, uid, step, exec_type, side,
                    qty, price_exec, fee,
                    status, ts_exec,
                    ts_ack, ts_done,
                    instId, ratio,
                    pnl, pnl_pct,
                    slippage, latency,
                    flags, comment,
                    retry, err_code,
                    reserved1, reserved2
                )
                VALUES (?,?,?,?,?,
                        ?,?,?,
                        'done',?,
                        NULL,NULL,
                        ?,1.0,
                        0.0,0.0,
                        0.0,0.0,
                        0,'',
                        0,0,
                        0,0)
            """, (
                exec_id, uid, step, 'open', side,
                qty, 0.0, 0.0,
                now_ms(),
                inst
            ))

            o.execute("""
                UPDATE opener
                SET status='open_done',
                    price_exec_open=0.0
                WHERE uid=? AND step=? AND exec_type='open'
            """, (uid, step))

            log.info("[EXEC_OPEN] uid=%s step=%d qty=%f", uid, step, qty)

        e.commit()
        o.commit()

    finally:
        o.close()
        e.close()

----- FILE: /opt/scalp/project/scripts/opener_ingest_open.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3
import time
import logging
from pathlib import Path

from opener_sizing import compute_ticket_qty, apply_contract_constraints

ROOT = Path("/opt/scalp/project")

DB_GEST      = ROOT / "data/gest.db"
DB_OPENER    = ROOT / "data/opener.db"
DB_CONTRACTS = ROOT / "data/contracts.db"
DB_BUDGET    = ROOT / "data/budget.db"

log = logging.getLogger("OPENER")


def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c


def now_ms():
    return int(time.time() * 1000)


def _f(x, d=0.0):
    try:
        if x is None:
            return d
        return float(x)
    except Exception:
        return d


def _get_budget_usdt(b):
    row = b.execute("SELECT balance_usdt FROM balance WHERE id=1").fetchone()
    if not row:
        return None
    return _f(row["balance_usdt"], None)


def _get_contract(k, instId):
    sym = (instId or "").replace("/", "")
    if not sym:
        return None
    return k.execute("SELECT * FROM contracts WHERE symbol=? LIMIT 1", (sym,)).fetchone()


def ingest_open_req():
    g = conn(DB_GEST)
    o = conn(DB_OPENER)
    k = conn(DB_CONTRACTS)
    b = conn(DB_BUDGET)

    try:
        rows = g.execute("""
            SELECT uid, instId, side, price_signal, score_C, score_S, score_H, step
            FROM gest
            WHERE status='open_req'
        """).fetchall()

        if not rows:
            return

        budget_usdt = _get_budget_usdt(b)
        if budget_usdt is None:
            log.error("[OPEN] budget.db missing row id=1 (balance.balance_usdt)")
            return

        market_risk = 1.0

        for r in rows:
            uid    = r["uid"]
            instId = r["instId"]
            side   = r["side"]
            step   = int(r["step"] or 0)

            price   = _f(r["price_signal"], 0.0)
            score_C = _f(r["score_C"], 0.0)
            score_S = _f(r["score_S"], 0.0)
            score_H = _f(r["score_H"], 0.0)

            if not instId or side not in ("buy", "sell") or price <= 0:
                continue

            contract = _get_contract(k, instId)
            if not contract:
                g.execute("""
                    UPDATE gest
                    SET skipped_reason='no_contract',
                        ts_status_update=?
                    WHERE uid=? AND status='open_req'
                """, (now_ms(), uid))
                log.info("[OPEN_SKIP] uid=%s inst=%s reason=no_contract", uid, instId)
                continue

            qty_ticket, lev, _ = compute_ticket_qty(
                balance_usdt=budget_usdt,
                price=price,
                score_C=score_C,
                score_S=score_S,
                score_H=score_H,
                market_risk=market_risk,
                ticket_ratio=1.0
            )

            # ================================
            # FLOOR MIN NOTIONAL (USDT)
            # ================================
            min_usdt = _f(contract["minTradeUSDT"], 0.0)
            if min_usdt > 0:
                floor_qty_usdt = min_usdt / price
                if qty_ticket < floor_qty_usdt:
                    qty_ticket = floor_qty_usdt

            # ================================
            # FLOOR MIN QTY COIN (CRITICAL FIX)
            # ================================
            min_qty = _f(contract["minTradeNum"], 0.0)
            if min_qty > 0 and qty_ticket < min_qty:
                qty_ticket = min_qty

            qty_norm = apply_contract_constraints(qty_ticket, price, contract)
            qty_norm = _f(qty_norm, 0.0)

            if qty_norm <= 0:
                g.execute("""
                    UPDATE gest
                    SET skipped_reason='min_trade_filter',
                        ts_status_update=?
                    WHERE uid=? AND status='open_req'
                """, (now_ms(), uid))
                log.info("[OPEN_SKIP] uid=%s inst=%s qty_ticket=%.10f price=%.10f",
                         uid, instId, _f(qty_ticket, 0.0), price)
                continue

            if o.execute("""
                SELECT 1 FROM opener
                WHERE uid=? AND exec_type='open' AND step=?
                LIMIT 1
            """, (uid, step)).fetchone():
                continue

            ts_open = now_ms()
            ratio = 1.0

            o.execute("""
                INSERT INTO opener
                (uid, instId, side, qty, lev,
                 ts_open, price_exec_open, status,
                 exec_type, step, ratio, qty_raw, qty_norm, reject_reason)
                VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?)
            """, (
                uid, instId, side, qty_norm, float(lev),
                ts_open, None, "open_stdby",
                "open", step, ratio, _f(qty_ticket, 0.0), qty_norm, None
            ))

            g.execute("""
                UPDATE gest
                SET qty=?,
                    lev=?,
                    entry=?,
                    ts_open=?,
                    ts_status_update=?
                WHERE uid=? AND status='open_req'
            """, (qty_norm, float(lev), price, ts_open, ts_open, uid))

            log.info("[OPEN_STDBY] uid=%s inst=%s side=%s qty=%.10f lev=%s step=%d budget=%.2f",
                     uid, instId, side, qty_norm, lev, step, budget_usdt)

        o.commit()
        g.commit()

    finally:
        g.close()
        o.close()
        k.close()
        b.close()

----- FILE: /opt/scalp/project/scripts/opener_pyramide.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3
import time
import math
import logging
from pathlib import Path

from opener_sizing import apply_contract_constraints

ROOT = Path("/opt/scalp/project")

DB_GEST      = ROOT / "data/gest.db"
DB_OPENER    = ROOT / "data/opener.db"
DB_CONTRACTS = ROOT / "data/contracts.db"
DB_EXEC      = ROOT / "data/exec.db"

log = logging.getLogger("OPENER")

def _conn(p: Path):
    c = sqlite3.connect(str(p), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

def now_ms():
    return int(time.time() * 1000)

def _f(x, d=0.0):
    try:
        if x is None:
            return d
        return float(x)
    except Exception:
        return d

def _next_pyramide_step(edb, uid: str) -> int:
    # step pyramide monotone par uid pour √©viter collision + permettre plusieurs ajouts
    r = edb.execute("""
        SELECT COALESCE(MAX(step), -1) AS mx
        FROM exec
        WHERE uid=? AND exec_type='pyramide'
    """, (uid,)).fetchone()
    mx = int(r["mx"] if r and r["mx"] is not None else -1)
    return mx + 1

def ingest_pyramide_req():
    g   = _conn(DB_GEST)
    o   = _conn(DB_OPENER)
    cdb = _conn(DB_CONTRACTS)
    edb = _conn(DB_EXEC)

    try:
        rows = g.execute("""
            SELECT uid, instId, side, ratio_to_add
            FROM gest
            WHERE status='pyramide_req'
        """).fetchall()

        if not rows:
            return

        for r in rows:
            uid    = r["uid"]
            instId = r["instId"]
            side   = r["side"]
            ratio  = _f(r["ratio_to_add"], 0.0)

            if not uid or not instId or side not in ("buy", "sell") or ratio <= 0:
                continue

            # position r√©elle + dernier prix exec (via v_exec_position)
            pos = edb.execute("""
                SELECT qty_open, last_price_exec
                FROM v_exec_position
                WHERE uid=?
                LIMIT 1
            """, (uid,)).fetchone()

            qty_pos = _f(pos["qty_open"], 0.0) if pos else 0.0
            price   = _f(pos["last_price_exec"], 0.0) if pos else 0.0

            if qty_pos <= 0 or price <= 0:
                continue

            # contrat
            sym = instId.replace("/", "")
            contract = cdb.execute("""
                SELECT * FROM contracts WHERE symbol=? LIMIT 1
            """, (sym,)).fetchone()

            if not contract:
                log.info("[PYR_SKIP] uid=%s inst=%s reason=no_contract", uid, instId)
                continue

            min_usdt  = _f(contract["minTradeUSDT"], 0.0)
            min_qty   = _f(contract["minTradeNum"], 0.0)
            step_size = _f(contract["sizeMultiplier"], 1.0)
            if step_size <= 0:
                step_size = 1.0

            # sizing pyramide (ratio)
            qty_raw = qty_pos * ratio

            # --- scale up AU-DESSUS du min notional + step ---
            notional = qty_raw * price
            if min_usdt > 0 and notional < min_usdt:
                qty_min = (min_usdt / price)
                steps = math.ceil(qty_min / step_size)
                qty_raw = steps * step_size

            # respect min_qty (au-dessus)
            if min_qty > 0 and qty_raw < min_qty:
                steps = math.ceil(min_qty / step_size)
                qty_raw = steps * step_size

            qty_norm = apply_contract_constraints(qty_raw, price, contract)
            qty_norm = _f(qty_norm, 0.0)

            if qty_norm <= 0:
                log.info("[PYR_SKIP] uid=%s inst=%s reason=contract_filter qty_raw=%.10f price=%.10f min_usdt=%.4f",
                         uid, instId, _f(qty_raw, 0.0), price, min_usdt)
                continue

            step = _next_pyramide_step(edb, uid)

            # anti-dup opener PK (uid, exec_type, step)
            if o.execute("""
                SELECT 1 FROM opener
                WHERE uid=? AND exec_type='pyramide' AND step=?
                LIMIT 1
            """, (uid, step)).fetchone():
                continue

            ts = now_ms()

            # IMPORTANT: status = 'pyramide_stdby' (sinon exec.py traite comme open)
            o.execute("""
                INSERT OR REPLACE INTO opener
                (uid, instId, side, qty, lev, ts_open, price_exec_open,
                 status, exec_type, step, ratio, qty_raw, qty_norm, reject_reason)
                VALUES (?, ?, ?, ?, 1, ?, ?, 'pyramide_stdby', 'pyramide', ?,
                        ?, ?, ?, NULL)
            """, (uid, instId, side, qty_norm, ts, price, step,
                  ratio, _f(qty_raw, 0.0), qty_norm))

            log.info("[PYR_STDBY] uid=%s inst=%s side=%s step=%d ratio=%.4f qty_pos=%.10f qty=%.10f price=%.10f",
                     uid, instId, side, step, ratio, qty_pos, qty_norm, price)

        o.commit()

    finally:
        g.close()
        o.close()
        cdb.close()
        edb.close()

if __name__ == "__main__":
    ingest_pyramide_req()

----- FILE: /opt/scalp/project/scripts/opener_pyramide_ingest.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
OPENER ‚Äî PYRAMIDE INGEST (FSM SAFE)
Consomme UNIQUEMENT gest.status = pyramide_req
Index√© STRICTEMENT sur gest.step
"""

import sqlite3
import logging
from pathlib import Path

ROOT = Path("/opt/scalp/project")

DB_GEST   = ROOT / "data/gest.db"
DB_OPENER = ROOT / "data/opener.db"

log = logging.getLogger("OPENER")

def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

def ingest_pyramide():
    g = conn(DB_GEST)
    o = conn(DB_OPENER)

    for r in g.execute("""
        SELECT uid, instId, side, qty_to_close, step
        FROM gest
        WHERE status='pyramide_req'
    """):
        uid  = r["uid"]
        qty  = float(r["qty_to_close"] or 0.0)
        step = int(r["step"])

        if qty <= 0:
            continue

        # üîí VERROU FSM STRICT
        if o.execute("""
            SELECT 1 FROM opener
            WHERE uid=? AND exec_type='pyramide' AND step=?
        """, (uid, step)).fetchone():
            continue

        o.execute("""
            INSERT INTO opener
            (uid, instId, side, qty, lev, status, exec_type, step)
            VALUES (?,?,?,?,1,'open_stdby','pyramide',?)
        """, (
            uid,
            r["instId"],
            r["side"],
            qty,
            step
        ))

        log.info("[PYRAMIDE_STDBY] %s step=%d qty=%.6f", uid, step, qty)

    o.commit()
    g.close()
    o.close()

----- FILE: /opt/scalp/project/scripts/opener_sizing.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

def clamp(v, lo, hi):
    return max(lo, min(hi, v))


def compute_ticket_qty(*, balance_usdt, price, score_C, score_S, score_H,
                       market_risk, ticket_ratio):
    """
    Mod√®le de sizing (inchang√©)
    """
    score = clamp(
        ((abs(score_C) + score_S) / 2.0) * (0.5 + score_H),
        0.0,
        1.0
    )

    margin_pct  = 0.01 + score * 0.09
    margin_usdt = balance_usdt * margin_pct
    lev         = int(round(1 + score * 19))

    risk = clamp(market_risk, 0.3, 1.0)
    lev  = max(1, int(lev * risk))

    qty_nominal = (margin_usdt * lev * risk) / price
    qty_ticket  = qty_nominal * ticket_ratio

    return qty_ticket, lev, score


# ============================================================
# üî• EXCHANGE FLOOR + CONTRACT VALIDATION (UPGRADE SAFE)
# ============================================================

def apply_contract_constraints(qty, price, contract):
    """
    Respect strict contraintes exchange.
    Retourne qty_final ou 0 si non tradable.
    """
    if not contract:
        return qty

    min_qty   = float(contract["minTradeNum"])
    step_size = float(contract["sizeMultiplier"])
    min_usdt  = float(contract["minTradeUSDT"])

    # --- FLOOR NOTIONAL (nouveau comportement critique) ---
    qty_floor = min_usdt / price
    if qty < qty_floor:
        qty = qty_floor

    # --- ARRONDI STEP ---
    qty = (qty // step_size) * step_size

    # --- MIN QTY ---
    if qty < min_qty:
        return 0.0

    # --- NOTIONAL CHECK FINAL ---
    if qty * price < min_usdt:
        return 0.0

    return qty

----- FILE: /opt/scalp/project/scripts/orderflow.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3, json, time, threading, logging, traceback
import websocket

ROOT = "/opt/scalp/project"
DB_G = f"{ROOT}/data/gest.db"
DB_OF = f"{ROOT}/data/orderflow.db"

LOG = f"{ROOT}/logs/orderflow.log"
logging.basicConfig(
    filename=LOG,
    level=logging.DEBUG,
    format="%(asctime)s ORDERFLOW %(levelname)s %(message)s"
)
log = logging.getLogger("ORDERFLOW")


# ============================================================
# DB UTILS
# ============================================================
def conn(path):
    c = sqlite3.connect(path, timeout=3, isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=3000;")
    return c


# ============================================================
# READ ACTIVE COINS FROM gest
# ============================================================
def load_active_coins():
    try:
        c = conn(DB_G)
        rows = c.execute("SELECT instId FROM v_active_coins;").fetchall()
        coins = set()

        for (instId,) in rows:
            if instId:
                inst = instId.replace("/", "")  # normalize
                coins.add(inst)

        log.info(f"[ACTIVE] {coins}")
        return coins
    except Exception as e:
        log.error(f"[ERR] load_active_coins {e}")
        return set()


# ============================================================
# ORDERFLOW CLIENT
# ============================================================
BITGET_WS = "wss://ws.bitget.com/v2/ws/public"


class OrderFlowClient:
    def __init__(self):
        self.ws = None
        self.active = load_active_coins()
        self.last_refresh = time.time()
        self.subscribed = False

    # -----------------------------------------
    # WS CALLBACK : open
    # -----------------------------------------
    def on_open(self, ws):
        log.info("WS OPEN")

        # subscribe immediately
        self.subscribe_all()
        self.subscribed = True

    # -----------------------------------------
    # WS CALLBACK : message
    # -----------------------------------------
    def on_message(self, ws, msg):
        try:
            data = json.loads(msg)

            # ignore subscription confirmations
            if "event" in data:
                return

            if "data" not in data:
                return

            arg = data.get("arg", {})
            instId = arg.get("instId")
            if not instId:
                return

            inst = instId.replace("/", "")
            snapshot = data["data"][0]

            best_bid = None
            best_ask = None
            bid_size = None
            ask_size = None

            bids = snapshot.get("bids", [])
            asks = snapshot.get("asks", [])

            if bids:
                best_bid = float(bids[0][0])
                bid_size = float(bids[0][1])

            if asks:
                best_ask = float(asks[0][0])
                ask_size = float(asks[0][1])

            ts = int(snapshot["ts"])

            # save into DB
            c = conn(DB_OF)
            c.execute("""
                REPLACE INTO books1(instId, ts_ms, best_bid, best_ask, bid_size, ask_size)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (inst, ts, best_bid, best_ask, bid_size, ask_size))
            c.commit()

        except Exception as e:
            log.error(f"[ERR] on_message {e} {traceback.format_exc()}")

    # -----------------------------------------
    # WS CALLBACK : error
    # -----------------------------------------
    def on_error(self, ws, err):
        log.error(f"WS ERROR {err}")

    # -----------------------------------------
    # WS CALLBACK : close
    # -----------------------------------------
    def on_close(self, ws, *args):
        log.warning("WS CLOSED")

    # -----------------------------------------
    # SUBSCRIBE ALL ACTIVE COINS
    # -----------------------------------------
    def subscribe_all(self):
        if not self.active:
            log.warning("[SUB] No active coins to subscribe")
            return

        for inst in self.active:
            req = {
                "op": "subscribe",
                "args": [{
                    "instType": "USDT-FUTURES",
                    "channel": "books1",
                    "instId": inst,
                    "debounce": "true"
                }]
            }

            try:
                self.ws.send(json.dumps(req))
                log.info(f"[SUB] {inst}")
            except Exception as e:
                log.error(f"[ERR] subscribe {inst} {e}")

    # -----------------------------------------
    # MAIN LOOP
    # -----------------------------------------
    def run(self):
        while True:
            try:
                self.ws = websocket.WebSocketApp(
                    BITGET_WS,
                    on_open=self.on_open,
                    on_message=self.on_message,
                    on_error=self.on_error,
                    on_close=self.on_close
                )

                log.info(f"Connecting to {BITGET_WS}")

                # blocking call
                self.ws.run_forever(ping_interval=20, ping_timeout=10)

            except Exception as e:
                log.error(f"[ERR] run loop {e}")

            time.sleep(2)  # reconnect delay


# ============================================================
# MAIN
# ============================================================
def main():
    client = OrderFlowClient()
    client.run()


if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/prove_ohlcv_20_vs_next.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import time
import sqlite3
import ccxt

DB = "/opt/scalp/project/data/universe.db"

def conn(path: str):
    c = sqlite3.connect(path, timeout=30, isolation_level=None)
    c.execute("PRAGMA busy_timeout=5000;")
    return c

def get_next_seed(db, inst: str):
    row = db.execute(
        "SELECT instId FROM universe_seed WHERE instId > ? ORDER BY instId LIMIT 1",
        (inst,)
    ).fetchone()
    return row[0] if row else None

def fetch_probe(ex, inst: str, tf="1m", limit=50):
    now_ms = int(time.time() * 1000)
    try:
        candles = ex.fetch_ohlcv(inst, timeframe=tf, since=None, limit=limit)
        n = len(candles) if candles else 0
        last_ts = candles[-1][0] if n > 0 else None
        stale = int((now_ms - last_ts) / 1000) if last_ts else None
        return {
            "inst": inst,
            "ok_call": True,
            "n": n,
            "last_ts": last_ts,
            "staleness_sec": stale,
            "error": None,
        }
    except Exception as e:
        return {
            "inst": inst,
            "ok_call": False,
            "n": 0,
            "last_ts": None,
            "staleness_sec": None,
            "error": str(e),
        }

def fmt_ts(ts_ms):
    if ts_ms is None:
        return "NULL"
    return time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(ts_ms / 1000))

def main():
    db = conn(DB)

    inst_ok = "XTZ/USDT"
    inst_next = get_next_seed(db, inst_ok)

    if not inst_next:
        print("[ERR] No next seed found after XTZ/USDT")
        return

    print(f"[INFO] inst_ok   = {inst_ok}")
    print(f"[INFO] inst_next = {inst_next}")
    print()

    # same exchange settings as your OA stack
    ex = ccxt.bitget({"options": {"defaultType": "swap"}})

    r1 = fetch_probe(ex, inst_ok, tf="1m", limit=50)
    r2 = fetch_probe(ex, inst_next, tf="1m", limit=50)

    for r in (r1, r2):
        print(f"== {r['inst']} ==")
        print(f"ok_call        : {r['ok_call']}")
        print(f"candle_count   : {r['n']}")
        print(f"last_ts_ms     : {r['last_ts']}")
        print(f"last_ts_human  : {fmt_ts(r['last_ts'])}")
        print(f"staleness_sec  : {r['staleness_sec']}")
        print(f"error          : {r['error']}")
        print()

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/recorder.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SCALP ‚Äî RECORDER (FINAL / SCHEMA-SAFE + STEPS)

R√àGLES :
- SEUL writer de recorder.db
- AUCUN calcul m√©tier
- AUCUNE logique d√©cisionnelle
- gest = snapshot FSM final
- exec = source de v√©rit√© (ledger)
- recorder = 1 ligne / trade
- recorder_steps = N lignes / trade (1 par step exec)
"""

import sqlite3
import time
import logging
import traceback
from pathlib import Path

# ============================================================
# PATHS
# ============================================================

ROOT = Path("/opt/scalp/project")

DB_GEST = ROOT / "data/gest.db"
DB_EXEC = ROOT / "data/exec.db"
DB_REC  = ROOT / "data/recorder.db"

LOG = ROOT / "logs/recorder.log"
SLEEP = 0.5

logging.basicConfig(
    filename=str(LOG),
    level=logging.INFO,
    format="%(asctime)s RECORDER %(levelname)s %(message)s"
)
log = logging.getLogger("RECORDER")

# ============================================================
# UTILS
# ============================================================

def now_ms():
    return int(time.time() * 1000)

def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c

def rget(row, key, default=None):
    try:
        return row[key]
    except Exception:
        return default

def table_columns(c, table_name):
    return [r["name"] for r in c.execute(f"PRAGMA table_info({table_name})")]

# ============================================================
# INIT recorder_steps (IDEMPOTENT)
# ============================================================

def ensure_recorder_steps():
    c = conn(DB_REC)
    c.execute("""
        CREATE TABLE IF NOT EXISTS recorder_steps (
            uid        TEXT NOT NULL,
            step       INTEGER NOT NULL,

            exec_type  TEXT,
            reason     TEXT,

            price_exec REAL,
            qty_exec   REAL,
            ts_exec    INTEGER,

            sl_be      REAL,
            sl_trail   REAL,
            tp_dyn     REAL,

            mfe_atr    REAL,
            mae_atr    REAL,
            golden     INTEGER,

            PRIMARY KEY (uid, step)
        );
    """)
    c.commit()
    c.close()

# ============================================================
# LOAD PNL (SOURCE DE V√âRIT√â)
# ============================================================

def load_pnl(uid):
    c = conn(DB_EXEC)
    r = c.execute("""
        SELECT pnl_realized
        FROM v_exec_pnl_uid
        WHERE uid=?
    """, (uid,)).fetchone()
    c.close()
    return float(r["pnl_realized"]) if r and r["pnl_realized"] is not None else 0.0

# ============================================================
# FETCH FINAL TRADES FROM GEST
# ============================================================

def fetch_close_done():
    c = conn(DB_GEST)
    rows = c.execute("""
        SELECT *
        FROM gest
        WHERE status='close_done'
    """).fetchall()
    c.close()
    return rows

# ============================================================
# VALUE MAPPING (GEST -> RECORDER)
# ============================================================

def build_value_for_column(col, g, pnl_realized, ts_rec):
    if col in ("pnl_realized", "pnl", "pnl_net"):
        return pnl_realized
    if col == "ts_recorded":
        return ts_rec
    if col == "close_steps":
        return rget(g, "close_steps", rget(g, "close_step"))
    if col == "price_exec_close":
        return rget(g, "price_exec_close", rget(g, "avg_exit_price"))
    return rget(g, col)

def normalize_required(col, v):
    if col in ("price_signal",) and v is None:
        return 0.0
    return v

# ============================================================
# RECORD STEPS (EXEC -> recorder_steps)
# ============================================================

def record_steps(uid):
    e = conn(DB_EXEC)
    r = conn(DB_REC)

    rows = e.execute("""
        SELECT
            uid,
            step,
            exec_type,
            reason,
            price_exec,
            qty,
            ts_exec,
            sl_be,
            sl_trail,
            tp_dyn,
            mfe_atr,
            mae_atr,
            golden
        FROM exec
        WHERE uid=?
        ORDER BY step
    """, (uid,)).fetchall()

    for x in rows:
        r.execute("""
            INSERT OR IGNORE INTO recorder_steps (
                uid, step,
                exec_type, reason,
                price_exec, qty_exec, ts_exec,
                sl_be, sl_trail, tp_dyn,
                mfe_atr, mae_atr, golden
            ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?)
        """, (
            x["uid"],
            x["step"],
            x["exec_type"],
            x["reason"],
            x["price_exec"],
            x["qty"],
            x["ts_exec"],
            x["sl_be"],
            x["sl_trail"],
            x["tp_dyn"],
            x["mfe_atr"],
            x["mae_atr"],
            x["golden"]
        ))

    r.commit()
    e.close()
    r.close()

# ============================================================
# RECORD TRADE (GEST -> recorder)
# ============================================================

def record_trade(g):
    uid = rget(g, "uid")
    if not uid:
        return

    c = conn(DB_REC)
    if c.execute("SELECT 1 FROM recorder WHERE uid=?", (uid,)).fetchone():
        c.close()
        return

    rec_cols = table_columns(c, "recorder")
    c.close()

    pnl_realized = load_pnl(uid)
    ts_rec = now_ms()

    values = []
    for col in rec_cols:
        v = build_value_for_column(col, g, pnl_realized, ts_rec)
        v = normalize_required(col, v)
        values.append(v)

    placeholders = ",".join(["?"] * len(rec_cols))
    col_list = ",".join(rec_cols)

    c = conn(DB_REC)
    c.execute(f"INSERT INTO recorder ({col_list}) VALUES ({placeholders})", values)
    c.commit()
    c.close()

    record_steps(uid)

    log.info("[RECORDED] %s pnl=%+.6f (steps copied)", uid, pnl_realized)

# ============================================================
# MAIN
# ============================================================

def main():
    log.info("[START] recorder FINAL (with steps)")
    ensure_recorder_steps()

    while True:
        try:
            for g in fetch_close_done():
                record_trade(g)
        except Exception:
            log.error("[ERR]\n%s", traceback.format_exc())
        time.sleep(SLEEP)

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/recorder_analyse.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
RECORDER ‚Äî ANALYSE GLOBALE AVANC√âE

Inclut :
- performance globale
- admission (step final)
- sorties FSM
- edge par coin
- üî• analyse par TYPE D‚ÄôENTR√âE (dec_mode / entry_reason / ctx)
- best / worst trades enrichis
"""

import sqlite3
from statistics import mean
from pathlib import Path
from collections import defaultdict

DB = Path("/opt/scalp/project/data/recorder.db")

# ============================================================
# UTILS
# ============================================================

def conn():
    c = sqlite3.connect(str(DB))
    c.row_factory = sqlite3.Row
    return c

def safe(xs):
    return [x for x in xs if x is not None]

def avg(xs):
    xs = safe(xs)
    return mean(xs) if xs else 0.0

def pf(pnls):
    wins = sum(p for p in pnls if p > 0)
    loss = -sum(p for p in pnls if p < 0)
    return wins / loss if loss > 0 else 0.0

def fmt(v, n=4):
    return f"{v:+.{n}f}"

# ============================================================
# LOAD DATA
# ============================================================

with conn() as c:
    rows = c.execute("""
        SELECT
            uid,
            instId,
            side,
            dec_mode,
            entry_reason,
            ctx_close,
            pnl_net,
            pnl,
            fee_total,
            nb_partial,
            nb_pyramide,
            close_steps
        FROM recorder
        WHERE pnl_net IS NOT NULL
    """).fetchall()

trades = []
for r in rows:
    trades.append({
        "uid": r["uid"],
        "inst": r["instId"],
        "side": r["side"],
        "mode": r["dec_mode"] or "UNKNOWN",
        "entry": (r["entry_reason"] or "UNKNOWN").split(":")[0],
        "ctx": r["ctx_close"] or "UNKNOWN",
        "pnl": float(r["pnl"] or 0.0),
        "pnl_net": float(r["pnl_net"] or 0.0),
        "fees": float(r["fee_total"] or 0.0),
        "partial": int(r["nb_partial"] or 0),
        "pyramide": int(r["nb_pyramide"] or 0),
        "step": int(r["close_steps"] or 1),
    })

# ============================================================
# GLOBAL
# ============================================================

print("\nR√âSUM√â GLOBAL")
print("=" * 70)

pnls = [t["pnl_net"] for t in trades]

print(f"Trades        : {len(trades)}")
print(f"PNL net total : {sum(pnls):+.4f}")
print(f"PNL net moyen : {fmt(avg(pnls))}")
print(f"Profit factor: {pf(pnls):.2f}")

# ============================================================
# R√âPARTITION PAR TYPE D‚ÄôENTR√âE
# ============================================================

print("\nR√âPARTITION ‚Äî TYPE D‚ÄôENTR√âE (dec_mode)")
print("=" * 70)

by_mode = defaultdict(list)
for t in trades:
    by_mode[t["mode"]].append(t["pnl_net"])

for mode, xs in sorted(by_mode.items(), key=lambda x: avg(x[1]), reverse=True):
    print(f"{mode:12s} | n={len(xs):3d} | exp={fmt(avg(xs))} | pf={pf(xs):.2f}")

# ============================================================
# TYPE D‚ÄôENTR√âE √ó STEP FINAL
# ============================================================

print("\nTYPE D‚ÄôENTR√âE √ó STEP FINAL")
print("=" * 70)

grid = defaultdict(list)
for t in trades:
    key = (t["mode"], t["step"])
    grid[key].append(t["pnl_net"])

for (mode, step), xs in sorted(grid.items()):
    if len(xs) >= 3:
        print(
            f"{mode:12s} | step={step:<2d} "
            f"| n={len(xs):3d} "
            f"| exp={fmt(avg(xs))} "
            f"| pf={pf(xs):.2f}"
        )

# ============================================================
# EDGE NET ‚Äî PAR COIN
# ============================================================

print("\nEDGE NET ‚Äî PAR COIN")
print("=" * 70)

by_inst = defaultdict(list)
for t in trades:
    by_inst[t["inst"]].append(t["pnl_net"])

for inst, xs in sorted(by_inst.items(), key=lambda x: avg(x[1]), reverse=True):
    if len(xs) >= 3:
        print(
            f"{inst:12s} | n={len(xs):3d} "
            f"| exp={fmt(avg(xs))} "
            f"| pf={pf(xs):.2f}"
        )

# ============================================================
# BEST / WORST TRADES
# ============================================================

print("\nBEST 2 TRADES (PNL NET)")
print("=" * 70)

for t in sorted(trades, key=lambda x: x["pnl_net"], reverse=True)[:2]:
    print(
        f"{t['uid']} {t['inst']} {t['side']} "
        f"| net={fmt(t['pnl_net'])} brut={fmt(t['pnl'])} "
        f"fees={fmt(-t['fees'])} "
        f"| step={t['step']} pyr={t['pyramide']} part={t['partial']} "
        f"| entry={t['mode']}"
    )

print("\nWORST 2 TRADES (PNL NET)")
print("=" * 70)

for t in sorted(trades, key=lambda x: x["pnl_net"])[:2]:
    print(
        f"{t['uid']} {t['inst']} {t['side']} "
        f"| net={fmt(t['pnl_net'])} brut={fmt(t['pnl'])} "
        f"fees={fmt(-t['fees'])} "
        f"| step={t['step']} pyr={t['pyramide']} part={t['partial']} "
        f"| entry={t['mode']}"
    )


----- FILE: /opt/scalp/project/scripts/recorder_analyse_capture.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
RECORDER ‚Äî ANALYSE DE CAPTURE R√âELLE (FSM / STEP AWARE)

But :
- mesurer ce que SL / BE / TRAIL / TP_dyn CAPTURENT r√©ellement
- comparer PNL vs MFE par step
- identifier gestion utile vs cosm√©tique
"""

import sqlite3
from statistics import mean
from pathlib import Path

DB = Path("/opt/scalp/project/data/recorder.db")

# ============================================================
# UTILS
# ============================================================

def conn():
    c = sqlite3.connect(str(DB))
    c.row_factory = sqlite3.Row
    return c

def avg(xs):
    xs = [x for x in xs if x is not None]
    return mean(xs) if xs else None

def fmt(v, n=4):
    return f"{v:+.{n}f}" if v is not None else "NA"

# ============================================================
# LOAD
# ============================================================

with conn() as c:
    steps = c.execute("""
        SELECT
            uid,
            step,
            exec_type,
            mfe_atr,
            mae_atr,
            reason
        FROM recorder_steps
        WHERE exec_type IN ('partial','close')
        ORDER BY uid, step
    """).fetchall()

    trades = {
        r["uid"]: r
        for r in c.execute("""
            SELECT
                uid,
                pnl_realized,
                mfe_atr,
                mae_atr,
                reason_close
            FROM recorder
        """)
    }

# ============================================================
# ANALYSE
# ============================================================

by_reason = {}
by_step = {}

for s in steps:
    uid = s["uid"]
    r = trades.get(uid)
    if not r:
        continue

    mfe = s["mfe_atr"]
    pnl = r["pnl_realized"]

    capture = pnl / mfe if mfe and mfe > 0 else None

    key_r = s["reason"] or "UNKNOWN"
    key_s = s["step"]

    by_reason.setdefault(key_r, []).append(capture)
    by_step.setdefault(key_s, []).append(capture)

# ============================================================
# OUTPUT
# ============================================================

print("\nCAPTURE R√âELLE PAR TYPE DE SORTIE")
print("=" * 60)

for k, xs in sorted(by_reason.items(), key=lambda x: avg(x[1]) or -999, reverse=True):
    print(
        f"{k:18s} | n={len(xs):3d} "
        f"| cap={fmt(avg(xs))}"
    )

print("\nCAPTURE R√âELLE PAR STEP")
print("=" * 60)

for s in sorted(by_step):
    xs = by_step[s]
    print(
        f"STEP {s:<2d} | n={len(xs):3d} "
        f"| cap={fmt(avg(xs))}"
    )


----- FILE: /opt/scalp/project/scripts/recorder_analyse_exit_failure.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
RECORDER ‚Äî EXIT FAILURE ANALYSER (DESK-GRADE / TIMED / FSM-AWARE)

UPGRADE :
- distinction claire STEP 1 vs STEP >=2
- DRIFT / early trades analys√©s comme ADMISSION failures
- lock-in failure r√©serv√© aux trades exploit√©s
"""

import argparse
import sqlite3
from statistics import mean
from pathlib import Path

DB = Path("/opt/scalp/project/data/recorder.db")

# ============================================================
# UTILS
# ============================================================

def conn():
    c = sqlite3.connect(str(DB))
    c.row_factory = sqlite3.Row
    return c

def avg(xs):
    xs = [x for x in xs if x is not None]
    return mean(xs) if xs else None

def fmt(v, n=4):
    if v is None:
        return "NA"
    if isinstance(v, float):
        return f"{v:+.{n}f}"
    return str(v)

def fmt_s(v):
    if v is None:
        return "NA"
    return f"{v:.1f}s"

def exit_family(reason):
    r = (reason or "").upper()
    if "TIME" in r:
        return "TIME"
    if "TP" in r:
        return "TP"
    if "SL" in r:
        return "SL"
    return "OTHER"

# ============================================================
# LOAD
# ============================================================

def load_trades(c):
    return c.execute("""
        SELECT
            uid, instId, side,
            pnl_realized,
            mfe_atr, mae_atr,
            nb_partial, nb_pyramide,
            reason_close,
            type_signal, dec_mode,
            ts_open, ts_close
        FROM recorder
        ORDER BY ts_open
    """).fetchall()

def load_steps(c):
    rows = c.execute("""
        SELECT uid, step, exec_type, reason,
               mfe_atr, mae_atr, ts_exec
        FROM recorder_steps
        ORDER BY uid, ts_exec
    """).fetchall()
    out = {}
    for r in rows:
        out.setdefault(r["uid"], []).append(r)
    return out

# ============================================================
# CORE
# ============================================================

def compute_peak(steps):
    peak = None
    ts_peak = None
    step_peak = None
    for s in steps:
        if s["mfe_atr"] is None:
            continue
        if peak is None or s["mfe_atr"] > peak:
            peak = float(s["mfe_atr"])
            ts_peak = s["ts_exec"]
            step_peak = s["step"]
    return peak, ts_peak, step_peak

def classify(trade, steps, admit_mfe, lock_mfe):
    pnl = trade["pnl_realized"]
    mfe_peak, ts_peak, step_peak = compute_peak(steps)
    step_final = max((s["step"] for s in steps), default=0)

    tags = []

    # ---------------- STEP 1 ONLY ----------------
    if step_final <= 1:
        if mfe_peak is None or mfe_peak < admit_mfe:
            tags.append("ADMISSION_FAIL_EARLY")
        else:
            tags.append("ADMISSION_FAIL_TIMEOUT")
        return tags, mfe_peak, ts_peak, step_peak

    # ---------------- EXPLOITATION ----------------
    tags.append("ADMITTED")

    if mfe_peak is not None and mfe_peak >= lock_mfe and pnl < 0:
        tags.append("LOCKIN_FAILURE")

    if trade["nb_pyramide"] >= 2 and pnl < 0:
        tags.append("PYR_RISK")

    return tags, mfe_peak, ts_peak, step_peak

# ============================================================
# REPORT
# ============================================================

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--uid", help="UID √† d√©tailler")
    ap.add_argument("--admit-mfe", type=float, default=0.30)
    ap.add_argument("--lock-mfe", type=float, default=1.00)
    args = ap.parse_args()

    with conn() as c:
        trades = load_trades(c)
        steps = load_steps(c)

    rows = []

    for t in trades:
        uid = t["uid"]
        st = steps.get(uid, [])
        tags, mfe_peak, ts_peak, step_peak = classify(t, st, args.admit_mfe, args.lock_mfe)

        rows.append({
            "uid": uid,
            "inst": t["instId"],
            "side": t["side"],
            "pnl": t["pnl_realized"],
            "mfe_peak": mfe_peak,
            "tags": tags,
            "nb_pyr": t["nb_pyramide"],
            "nb_part": t["nb_partial"],
            "entry": t["dec_mode"]
        })

    # ========================================================
    # WORST STEP 1
    # ========================================================

    print("\nWORST STEP 1 ‚Äî ADMISSION FAILURES")
    print("=" * 60)

    bad = [r for r in rows if "ADMISSION_FAIL" in ",".join(r["tags"])]
    bad = sorted(bad, key=lambda x: x["pnl"])

    for r in bad[:10]:
        print(
            f"{r['uid']:<28s} "
            f"{r['inst']:<8s} "
            f"pnl={r['pnl']:+.2f} "
            f"mfe_peak={fmt(r['mfe_peak'],2):>6s} "
            f"tags={','.join(r['tags'])} "
            f"entry={r['entry']}"
        )

    # ========================================================
    # DETAIL UID
    # ========================================================

    if args.uid:
        hit = next((r for r in rows if r["uid"] == args.uid), None)
        if not hit:
            print("UID introuvable")
            return

        print("\nDETAIL TRADE")
        print("=" * 60)
        for k, v in hit.items():
            print(f"{k:12s}: {v}")

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/recorder_analyse_extremes.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
RECORDER ‚Äî ANALYSE DES EXTREMES (BEST / WORST TRADE)

- Lecture seule recorder.db
- Reconstruction FSM compl√®te
- Focus MFE / MAE / sorties
"""

import sqlite3
from pathlib import Path

DB = Path("/opt/scalp/project/data/recorder.db")

# ============================================================
# UTILS
# ============================================================

def conn():
    c = sqlite3.connect(str(DB))
    c.row_factory = sqlite3.Row
    return c

def print_block(title):
    print("\n" + title)
    print("=" * len(title))

def fmt(v, n=4):
    return f"{v:+.{n}f}" if v is not None else "NA"

# ============================================================
# LOAD
# ============================================================

with conn() as c:
    trades = c.execute("""
        SELECT
            uid,
            instId,
            side,
            pnl_realized,
            mfe_atr,
            mae_atr,
            nb_partial,
            nb_pyramide,
            reason_close,
            ts_open,
            ts_close,
            type_signal,
            dec_mode
        FROM recorder
    """).fetchall()

if not trades:
    print("Aucun trade.")
    exit(0)

best = max(trades, key=lambda r: r["pnl_realized"])
worst = min(trades, key=lambda r: r["pnl_realized"])

# ============================================================
# CORE PRINT
# ============================================================

def analyse_trade(label, r):
    print_block(f"{label} TRADE ‚Äî {r['uid']}")

    dur = (
        (r["ts_close"] - r["ts_open"]) / 1000
        if r["ts_open"] and r["ts_close"] else None
    )

    capture = (
        r["pnl_realized"] / r["mfe_atr"]
        if r["mfe_atr"] and r["mfe_atr"] > 0 else None
    )

    print(f"Instrument     : {r['instId']} ({r['side']})")
    print(f"Type / Mode    : {r['type_signal']} / {r['dec_mode']}")
    print(f"PNL            : {fmt(r['pnl_realized'],6)}")
    print(f"Dur√©e          : {dur:.1f}s" if dur else "Dur√©e          : NA")
    print(f"MFE (ATR)      : {fmt(r['mfe_atr'])}")
    print(f"MAE (ATR)      : {fmt(r['mae_atr'])}")
    print(f"Capture        : {fmt(capture)}")
    print(f"Nb partial     : {r['nb_partial']}")
    print(f"Nb pyramide    : {r['nb_pyramide']}")
    print(f"Sortie finale  : {r['reason_close']}")

    # --------------------------------------------------------
    # FSM DETAIL
    # --------------------------------------------------------

    with conn() as c:
        steps = c.execute("""
            SELECT
                step,
                exec_type,
                reason,
                mfe_atr,
                mae_atr,
                golden,
                ts_exec
            FROM recorder_steps
            WHERE uid=?
            ORDER BY ts_exec
        """, (r["uid"],)).fetchall()

    print("\nFSM ‚Äî D√âROUL√â CHRONOLOGIQUE")
    print("-" * 60)

    for s in steps:
        print(
            f"step={s['step']:>2d} | "
            f"{s['exec_type']:<8s} | "
            f"mfe={fmt(s['mfe_atr'])} | "
            f"mae={fmt(s['mae_atr'])} | "
            f"golden={s['golden']} | "
            f"{s['reason']}"
        )

# ============================================================
# RUN
# ============================================================

analyse_trade("BEST", best)
analyse_trade("WORST", worst)


----- FILE: /opt/scalp/project/scripts/recorder_analyse_steps.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
RECORDER ‚Äî ANALYSE STEP 1 (ADMISSION ONLY)
"""

import sqlite3
from pathlib import Path

DB = Path("/opt/scalp/project/data/recorder.db")

def conn():
    c = sqlite3.connect(str(DB))
    c.row_factory = sqlite3.Row
    return c

def fmt(v):
    return f"{v:+.4f}" if v is not None else "N/A"

with conn() as c:
    rows = c.execute("""
        SELECT
            r.uid,
            r.pnl_realized AS pnl,
            rs.mfe_atr,
            rs.mae_atr
        FROM recorder r
        JOIN recorder_steps rs USING(uid)
        WHERE rs.step = 1
          AND rs.exec_type = 'close'
    """).fetchall()

tox = [r for r in rows if r["mfe_atr"] is not None and r["mfe_atr"] < 0.3]
ok = [r for r in rows if r not in tox]

print("\nSTEP 1 ‚Äî ADMISSION STRICTE")
print("=" * 60)
print(f"Trades STEP 1 : {len(rows)}")
print(f"Toxiques      : {len(tox)}")
print(f"Sains         : {len(ok)}")

print("\nD√âTAIL")
print("-" * 60)
print(f"Toxiques | exp={fmt(sum(r['pnl'] for r in tox)/len(tox) if tox else None)}")
print(f"Sains    | exp={fmt(sum(r['pnl'] for r in ok)/len(ok) if ok else None)}")

----- FILE: /opt/scalp/project/scripts/recorder_analyse_uid.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
RECORDER ‚Äî ANALYSE UNITAIRE PAR UID (DESK-GRADE)

- lecture seule recorder.db
- aucune logique m√©tier
- analyse FSM compl√®te d'un trade
"""

import sqlite3
from pathlib import Path

DB = Path("/opt/scalp/project/data/recorder.db")

UID = "BTC-sell-173146-eb55"   # <<< UID √Ä ANALYSER ICI

# ============================================================
# UTILS
# ============================================================

def conn():
    c = sqlite3.connect(str(DB))
    c.row_factory = sqlite3.Row
    return c

def fmt(v, n=4):
    if v is None:
        return "NA"
    if isinstance(v, float):
        return f"{v:+.{n}f}"
    return str(v)

def print_block(title):
    print("\n" + title)
    print("=" * len(title))

# ============================================================
# LOAD
# ============================================================

c = conn()

trade = c.execute("""
    SELECT *
    FROM recorder
    WHERE uid=?
""", (UID,)).fetchone()

if not trade:
    print(f"UID introuvable : {UID}")
    exit(1)

steps = c.execute("""
    SELECT *
    FROM recorder_steps
    WHERE uid=?
    ORDER BY step, ts_exec
""", (UID,)).fetchall()

# ============================================================
# R√âSUM√â GLOBAL
# ============================================================

print_block(f"TRADE ‚Äî {UID}")

dur = (
    (trade["ts_close"] - trade["ts_open"]) / 1000.0
    if trade["ts_open"] and trade["ts_close"] else None
)

mfe = trade["mfe_atr"]
mae = trade["mae_atr"]
admitted = mfe is not None and mfe >= 0.30

print(f"Instrument     : {trade['instId']} ({trade['side']})")
print(f"Type / Mode    : {trade['type_signal']} / {trade['dec_mode']}")
print(f"PNL net        : {fmt(trade['pnl_realized'])}")
print(f"Dur√©e          : {fmt(dur,1)}s")
print(f"MFE (ATR)      : {fmt(mfe)}")
print(f"MAE (ATR)      : {fmt(mae)}")
print(f"Admission      : {'ADMISE' if admitted else 'REJET√âE'}")
print(f"Nb partial     : {trade['nb_partial']}")
print(f"Nb pyramide    : {trade['nb_pyramide']}")

# ============================================================
# FSM ‚Äî TIMELINE
# ============================================================

print_block("FSM ‚Äî D√âROUL√â CHRONOLOGIQUE")

if not steps:
    print("Aucune √©tape enregistr√©e.")
else:
    for s in steps:
        print(
            f"step={s['step']:>2} | "
            f"{s['exec_type']:<8} | "
            f"mfe={fmt(s['mfe_atr'])} | "
            f"mae={fmt(s['mae_atr'])} | "
            f"golden={s['golden']} | "
            f"{s['reason']}"
        )

# ============================================================
# DIAGNOSTIC DESK
# ============================================================

print_block("DIAGNOSTIC DESK")

if not admitted:
    print("‚ùå Trade REJET√â (jamais admis)")
    print("‚Üí Toute exploitation est structurellement n√©gative.")
else:
    print("‚úÖ Trade ADMIS (edge th√©orique valid√©)")

if trade["nb_partial"] > 0:
    print("‚Ä¢ Partial ex√©cut√© : r√©duction du risque ‚úî")
else:
    print("‚Ä¢ Aucun partial : exposition pleine jusqu'√† la fin")

if trade["nb_pyramide"] > 0:
    print("‚Ä¢ Pyramide ex√©cut√©e : allocation progressive")
else:
    print("‚Ä¢ Aucune pyramide")

if trade["pnl_realized"] < 0:
    print("‚ö†Ô∏è Trade perdant")
    if admitted:
        print("‚Üí perte malgr√© admission : probl√®me d'exploitation / timing sortie")
    else:
        print("‚Üí perte normale (trade rejet√©)")
else:
    print("üí∞ Trade gagnant")

c.close()

----- FILE: /opt/scalp/project/scripts/recorder_detect_golden.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SCALP ‚Äî GOLDEN TRADE DETECTOR (DESK-GRADE)

D√©tecte les trades √† tr√®s forte qualit√© :
- momentum r√©el
- drawdown ma√Ætris√©
- scaling (partial + pyramide)
"""

import sqlite3
from pathlib import Path
from statistics import mean

ROOT = Path("/opt/scalp/project")
DB = ROOT / "data/recorder.db"

# ============================================================
# PARAM√àTRES GOLDEN
# ============================================================

CFG = {
    "min_mfe_atr": 2.0,
    "max_mae_atr": 0.5,
    "min_partial": 1,
    "min_pyramide": 1,
}

# ============================================================
# SQLITE
# ============================================================

def conn():
    c = sqlite3.connect(str(DB))
    c.row_factory = sqlite3.Row
    return c

# ============================================================
# LOAD
# ============================================================

with conn() as c:
    rows = c.execute("""
        SELECT
            uid,
            instId,
            pnl,
            mfe_atr,
            mae_atr,
            nb_partial,
            nb_pyramide
        FROM recorder
        WHERE ts_close IS NOT NULL
    """).fetchall()

trades = [dict(r) for r in rows]
if not trades:
    print("Aucun trade.")
    exit(0)

# ============================================================
# GOLDEN FILTER
# ============================================================

def is_golden(t):
    return (
        t["pnl"] is not None and t["pnl"] > 0
        and t["mfe_atr"] is not None and t["mfe_atr"] >= CFG["min_mfe_atr"]
        and t["mae_atr"] is not None and t["mae_atr"] <= CFG["max_mae_atr"]
        and (t["nb_partial"] or 0) >= CFG["min_partial"]
        and (t["nb_pyramide"] or 0) >= CFG["min_pyramide"]
    )

golden = [t for t in trades if is_golden(t)]
non_golden = [t for t in trades if not is_golden(t)]

# ============================================================
# STATS
# ============================================================

def stats(ts):
    if not ts:
        return None
    pnls = [t["pnl"] for t in ts]
    return {
        "n": len(ts),
        "pnl_total": sum(pnls),
        "pnl_mean": mean(pnls),
        "winrate": sum(1 for p in pnls if p > 0) / len(pnls) * 100,
    }

s_all = stats(trades)
s_g   = stats(golden)
s_ng  = stats(non_golden)

# ============================================================
# OUTPUT
# ============================================================

print("\nGOLDEN TRADE DETECTOR")
print("=" * 60)

print("\nR√àGLES")
for k, v in CFG.items():
    print(f"- {k}: {v}")

print("\nR√âPARTITION")
print(f"Total trades : {s_all['n']}")
print(f"Golden       : {s_g['n'] if s_g else 0} ({100*(s_g['n']/s_all['n']):.2f}%)")

print("\nPERFORMANCE")
print("-" * 60)

print("ALL")
print(f"  PNL total : {s_all['pnl_total']:+.4f}")
print(f"  PNL mean  : {s_all['pnl_mean']:+.4f}")
print(f"  Winrate   : {s_all['winrate']:.2f}%")

if s_g:
    print("\nGOLDEN")
    print(f"  PNL total : {s_g['pnl_total']:+.4f}")
    print(f"  PNL mean  : {s_g['pnl_mean']:+.4f}")
    print(f"  Winrate   : {s_g['winrate']:.2f}%")

if s_ng:
    print("\nNON-GOLDEN")
    print(f"  PNL total : {s_ng['pnl_total']:+.4f}")
    print(f"  PNL mean  : {s_ng['pnl_mean']:+.4f}")
    print(f"  Winrate   : {s_ng['winrate']:.2f}%")

# ============================================================
# D√âTAILS
# ============================================================

print("\nLISTE GOLDEN TRADES")
print("=" * 60)
for t in sorted(golden, key=lambda x: x["pnl"], reverse=True):
    print(
        f"{t['instId']:10s} | pnl={t['pnl']:+.4f} | "
        f"mfe_atr={t['mfe_atr']:.2f} | mae_atr={t['mae_atr']:.2f} | "
        f"partial={t['nb_partial']} | pyramide={t['nb_pyramide']}"
    )

----- FILE: /opt/scalp/project/scripts/snap_gest_writer.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# SNAPSHOT GEST ‚Üí MFE/MAE DB
# single-writer, read-only pour les autres

import sqlite3
import time
from pathlib import Path

ROOT = Path("/opt/scalp/project")
DB_GEST = ROOT / "data/gest.db"
DB_MFE  = ROOT / "data/mfe_mae.db"

SLEEP = 0.5

def conn(p):
    c = sqlite3.connect(str(p))
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    return c

def main():
    while True:
        g = conn(DB_GEST)
        m = conn(DB_MFE)

        rows = g.execute("""
            SELECT
                uid,
                instId,
                side,
                entry,
                qty,
                atr_signal AS atr,
                status,
                close_step,
                ts_updated
            FROM gest
            WHERE status NOT IN ('close_done','expired')
        """).fetchall()

        for r in rows:
            m.execute("""
                INSERT INTO snap_gest (
                    uid, instId, side,
                    entry, qty, atr,
                    status, close_step, ts_updated
                ) VALUES (?,?,?,?,?,?,?,?,?)
                ON CONFLICT(uid) DO UPDATE SET
                    instId=excluded.instId,
                    side=excluded.side,
                    entry=excluded.entry,
                    qty=excluded.qty,
                    atr=excluded.atr,
                    status=excluded.status,
                    close_step=excluded.close_step,
                    ts_updated=excluded.ts_updated
            """, (
                r["uid"], r["instId"], r["side"],
                r["entry"], r["qty"], r["atr"],
                r["status"], r["close_step"],
                r["ts_updated"]
            ))

        m.commit()
        g.close()
        m.close()
        time.sleep(SLEEP)

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/ticks.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SCALP ‚Äî TICKS COLLECTOR v2 (LAST + BID/ASK + SPREAD)

- instId canon = BASE/USDT
- WS Bitget : ticker USDT-FUTURES
- lastPr, bidPr, askPr stock√©s
- spread_bps calcul√© LIVE
- UN SEUL WRITER
- WAL SAFE
- AUCUN calcul m√©tier (ledger only)
"""

import asyncio
import websockets
import json
import sqlite3
import threading
import time
from queue import Queue

ROOT = "/opt/scalp/project"
DB_T = f"{ROOT}/data/t.db"
DB_A = f"{ROOT}/data/a.db"

WS_URL = "wss://ws.bitget.com/v2/ws/public"

QUEUE_MAX = 8000
FLUSH_DELAY = 0.25
ROLLING_LIMIT = 200
CHECKPOINT_EVERY = 5.0

q = Queue(maxsize=QUEUE_MAX)
stop_event = threading.Event()

# =========================================================
# DB
# =========================================================
def conn_t():
    c = sqlite3.connect(
        DB_T,
        timeout=5,
        check_same_thread=False,
        isolation_level=None
    )
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA synchronous=NORMAL;")
    c.execute("PRAGMA busy_timeout=5000;")
    c.execute("PRAGMA wal_autocheckpoint=0;")
    return c

# =========================================================
# instId helpers
# =========================================================
def ws_to_canon(ws_id: str) -> str:
    s = ws_id.upper().replace("/", "")
    if not s.endswith("USDT"):
        return None
    return f"{s[:-4]}/USDT"

def canon_to_ws(instId: str) -> str:
    return instId.replace("/", "")

# =========================================================
# Symbols
# =========================================================
def load_symbols():
    c = sqlite3.connect(DB_A)
    rows = c.execute("SELECT instId FROM v_ctx_latest").fetchall()
    c.close()
    return [canon_to_ws(r[0]) for r in rows]

# =========================================================
# Writer
# =========================================================
def writer():
    conn = conn_t()
    cur = conn.cursor()

    buf = []
    last_flush = time.time()
    last_checkpoint = time.time()

    print("[ticks] Writer started (LAST + BID/ASK + SPREAD).")

    while not stop_event.is_set():
        try:
            row = q.get(timeout=FLUSH_DELAY)
            buf.append(row)
        except:
            pass

        now = time.time()

        # -------- FLUSH --------
        if buf and (now - last_flush) >= FLUSH_DELAY:
            try:
                cur.executemany("""
                    INSERT INTO ticks(instId,lastPr,bidPr,askPr,spread_bps,ts_ms)
                    VALUES (?,?,?,?,?,?)
                    ON CONFLICT(instId) DO UPDATE SET
                        lastPr=excluded.lastPr,
                        bidPr=excluded.bidPr,
                        askPr=excluded.askPr,
                        spread_bps=excluded.spread_bps,
                        ts_ms=excluded.ts_ms;
                """, buf)

                cur.executemany("""
                    INSERT INTO ticks_hist(instId,lastPr,bidPr,askPr,spread_bps,ts_ms)
                    VALUES (?,?,?,?,?,?);
                """, buf)

                for instId, *_ in buf:
                    cur.execute("""
                        DELETE FROM ticks_hist
                        WHERE instId=?
                          AND id NOT IN (
                            SELECT id FROM ticks_hist
                            WHERE instId=?
                            ORDER BY ts_ms DESC
                            LIMIT ?
                          );
                    """, (instId, instId, ROLLING_LIMIT))

                conn.commit()

            except Exception as e:
                print("[ticks] DB error:", e)
                conn.rollback()

            buf.clear()
            last_flush = now

        # -------- CHECKPOINT --------
        if (now - last_checkpoint) >= CHECKPOINT_EVERY:
            try:
                cur.execute("PRAGMA wal_checkpoint(PASSIVE);")
            except:
                pass
            last_checkpoint = now

    conn.close()
    print("[ticks] Writer stopped.")

# =========================================================
# Websocket
# =========================================================
async def ws_one(ws_inst):
    canon = ws_to_canon(ws_inst)
    if not canon:
        return

    sub = {
        "op": "subscribe",
        "args": [{
            "instType": "USDT-FUTURES",
            "channel": "ticker",
            "instId": ws_inst
        }]
    }

    msg = json.dumps(sub)

    while not stop_event.is_set():
        try:
            async with websockets.connect(
                WS_URL,
                ping_interval=15,
                ping_timeout=15,
                max_size=2**20
            ) as ws:

                await ws.send(msg)
                print(f"[ticks] {canon} subscribed")

                async for raw in ws:
                    data = json.loads(raw)
                    if "data" not in data:
                        continue

                    d = data["data"][0]

                    try:
                        lastPr = float(d["lastPr"])
                        bidPr  = float(d.get("bidPr") or 0)
                        askPr  = float(d.get("askPr") or 0)
                        ts_ms  = int(d["ts"])
                    except:
                        continue

                    spread_bps = None
                    if bidPr > 0 and askPr > 0 and askPr > bidPr:
                        mid = (bidPr + askPr) / 2
                        spread_bps = (askPr - bidPr) / mid * 10_000

                    if not q.full():
                        q.put((canon, lastPr, bidPr, askPr, spread_bps, ts_ms))

        except Exception as e:
            print(f"[ticks] {canon} WS error:", e)
            await asyncio.sleep(1.0)

# =========================================================
# MAIN
# =========================================================
def main():
    syms = load_symbols()
    print(f"[ticks] Starting {len(syms)} instruments")

    wt = threading.Thread(target=writer, daemon=True)
    wt.start()

    try:
        asyncio.run(run_all(syms))
    except KeyboardInterrupt:
        pass
    finally:
        stop_event.set()
        wt.join()

async def run_all(symbols):
    tasks = [asyncio.create_task(ws_one(s)) for s in symbols]
    await asyncio.gather(*tasks)

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/trade_check.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SCALP ‚Äî TRADE CHECK (POST-MORTEM)

But:
- afficher un check COMPLET d'un UID : qty entr√©e, levier, margin, prix, pnl, fees, steps.
- read-only (aucune √©criture DB)
- compatible avec sch√©mas actuels (recorder.db + recorder_steps + exec.db + gest/opener/closer si dispo)
"""

import sys
import sqlite3
from pathlib import Path
from typing import Optional

ROOT = Path("/opt/scalp/project")

DB_REC  = ROOT / "data/recorder.db"
DB_EXEC = ROOT / "data/exec.db"
DB_GEST = ROOT / "data/gest.db"
DB_OPN  = ROOT / "data/opener.db"
DB_CLS  = ROOT / "data/closer.db"


def conn(p: Path) -> sqlite3.Connection:
    c = sqlite3.connect(str(p), timeout=5)
    c.row_factory = sqlite3.Row
    return c


def q1(c: sqlite3.Connection, sql: str, params=()) -> Optional[sqlite3.Row]:
    return c.execute(sql, params).fetchone()


def qall(c: sqlite3.Connection, sql: str, params=()):
    return c.execute(sql, params).fetchall()


def fmt(v):
    if v is None:
        return ""
    if isinstance(v, float):
        return f"{v:.10g}"
    return str(v)


def print_kv(title: str, row: sqlite3.Row, keys):
    print(title)
    print("-" * len(title))
    for k in keys:
        if k in row.keys():
            print(f"{k:18s} : {fmt(row[k])}")
    print()


def try_open(path: Path) -> Optional[sqlite3.Connection]:
    try:
        if not path.exists():
            return None
        return conn(path)
    except Exception:
        return None


def main():
    if len(sys.argv) < 2:
        print("Usage: trade_check.py <UID> [UID2 ...]")
        sys.exit(2)

    uids = sys.argv[1:]

    c_rec  = try_open(DB_REC)
    c_exec = try_open(DB_EXEC)
    c_gest = try_open(DB_GEST)
    c_opn  = try_open(DB_OPN)
    c_cls  = try_open(DB_CLS)

    for uid in uids:
        print("=" * 86)
        print(f"UID: {uid}")
        print("=" * 86)

        # ---------------- RECORDER (trade-level) ----------------
        if c_rec:
            r = q1(c_rec, "SELECT * FROM recorder WHERE uid=? LIMIT 1", (uid,))
            if r:
                keys = [
                    "instId", "side",
                    "ts_signal", "price_signal", "entry_reason", "type_signal",
                    "score_C", "score_S", "score_H", "score_M",
                    "ts_open", "entry", "qty", "lev", "margin",
                    "ts_close", "price_close", "price_exec_close", "reason_close",
                    "pnl", "pnl_pct", "pnl_net",
                    "fee", "fee_total", "pnl_realized",
                    "close_steps", "nb_partial", "nb_pyramide",
                    "atr_signal",
                    "mfe_price", "mfe_ts", "mae_price", "mae_ts",
                    "mfe_atr", "mae_atr",
                    "golden", "golden_ts",
                    "trigger_type", "dec_mode", "dec_ctx", "dec_score_C",
                    "momentum_ok", "prebreak_ok", "pullback_ok", "compression_ok",
                    "ts_recorded",
                ]
                print_kv("RECORDER", r, keys)
            else:
                print("RECORDER\n--------\n(no row)\n")

            # --------------- RECORDER_STEPS (structure) ---------------
            rs = qall(c_rec, """
                SELECT uid, step, exec_type, reason, price_exec, qty_exec, ts_exec,
                       sl_be, sl_trail, tp_dyn, mfe_atr, mae_atr, golden
                FROM recorder_steps
                WHERE uid=?
                ORDER BY step ASC
            """, (uid,))
            print("RECORDER_STEPS")
            print("--------------")
            if not rs:
                print("(none)\n")
            else:
                hdr = ["step","exec_type","reason","price_exec","qty_exec","ts_exec","sl_be","sl_trail","tp_dyn","mfe_atr","mae_atr","golden"]
                print(" | ".join(f"{h:>10s}" for h in hdr))
                print("-" * (13 * len(hdr)))
                for row in rs:
                    vals = [
                        row["step"], row["exec_type"], row["reason"],
                        row["price_exec"], row["qty_exec"], row["ts_exec"],
                        row["sl_be"], row["sl_trail"], row["tp_dyn"],
                        row["mfe_atr"], row["mae_atr"], row["golden"],
                    ]
                    print(" | ".join(f"{fmt(v):>10s}" for v in vals))
                print()

        # ---------------- EXEC (ledger facts) ----------------
        if c_exec:
            ex = qall(c_exec, """
                SELECT exec_id, uid, step, exec_type, side, qty, price_exec, fee, status, ts_exec,
                       instId, lev, pnl_realized_step, reason
                FROM exec
                WHERE uid=?
                ORDER BY ts_exec ASC, step ASC
            """, (uid,))
            print("EXEC (exec.db)")
            print("------------")
            if not ex:
                print("(none)\n")
            else:
                hdr = ["ts_exec","step","exec_type","side","qty","price_exec","fee","pnl_realized_step","lev","status","reason"]
                print(" | ".join(f"{h:>14s}" for h in hdr))
                print("-" * (18 * len(hdr)))
                for row in ex:
                    vals = [
                        row["ts_exec"], row["step"], row["exec_type"], row["side"],
                        row["qty"], row["price_exec"], row["fee"],
                        row["pnl_realized_step"], row["lev"], row["status"], row["reason"],
                    ]
                    print(" | ".join(f"{fmt(v):>14s}" for v in vals))
                print()

        # ---------------- GEST (state) ----------------
        if c_gest:
            g = q1(c_gest, "SELECT * FROM gest WHERE uid=? LIMIT 1", (uid,))
            print("GEST (gest.db)")
            print("-------------")
            if not g:
                print("(none)\n")
            else:
                # affiche un sous-ensemble s√ªr (colonnes existent souvent)
                wanted = [
                    "instId","side","status","step","qty","qty_to_close",
                    "entry","price_signal","ts_signal",
                    "sl_be","sl_trail","tp_dyn",
                    "mfe_atr","mae_atr","golden","type_signal","dec_mode","reason",
                    "last_action_ts",
                ]
                for k in wanted:
                    if k in g.keys():
                        print(f"{k:18s} : {fmt(g[k])}")
                print()

        # ---------------- OPENER / CLOSER (queues) ----------------
        if c_opn:
            o = qall(c_opn, """
                SELECT uid, instId, side, qty, lev, status, exec_type, step, price_exec_open, ts_open
                FROM opener
                WHERE uid=?
                ORDER BY step ASC
            """, (uid,))
            print("OPENER (opener.db)")
            print("-----------------")
            if not o:
                print("(none)\n")
            else:
                hdr = ["step","exec_type","status","qty","lev","price_exec_open","ts_open"]
                print(" | ".join(f"{h:>14s}" for h in hdr))
                print("-" * (18 * len(hdr)))
                for row in o:
                    vals = [
                        row["step"], row["exec_type"], row["status"],
                        row["qty"], row["lev"], row["price_exec_open"], row["ts_open"],
                    ]
                    print(" | ".join(f"{fmt(v):>14s}" for v in vals))
                print()

        if c_cls:
            cl = qall(c_cls, """
                SELECT uid, instId, side, qty, status, step
                FROM closer
                WHERE uid=?
                ORDER BY step ASC
            """, (uid,))
            print("CLOSER (closer.db)")
            print("-----------------")
            if not cl:
                print("(none)\n")
            else:
                hdr = ["step","status","qty","side"]
                print(" | ".join(f"{h:>12s}" for h in hdr))
                print("-" * (16 * len(hdr)))
                for row in cl:
                    vals = [row["step"], row["status"], row["qty"], row["side"]]
                    print(" | ".join(f"{fmt(v):>12s}" for v in vals))
                print()

    for c in (c_rec, c_exec, c_gest, c_opn, c_cls):
        try:
            if c:
                c.close()
        except Exception:
            pass


if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/trade_check_worst2.sh -----
#!/usr/bin/env bash
set -euo pipefail

# Remplace si besoin par tes UIDs exacts (les 2 pires)
UID1="${1:-BTC-sell-153204-e5ab}"
UID2="${2:-BTC-buy-183702-364a}"

exec /opt/scalp/project/venv/bin/python3 /opt/scalp/project/scripts/trade_check.py "$UID1" "$UID2"

----- FILE: /opt/scalp/project/scripts/triggers.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3
import time
import uuid
import yaml
import logging
from pathlib import Path
from datetime import datetime

ROOT = Path("/opt/scalp/project")

DB_DEC      = ROOT / "data/dec.db"
DB_TRIG     = ROOT / "data/triggers.db"
DB_GEST     = ROOT / "data/gest.db"
DB_RECORDER = ROOT / "data/recorder.db"
DB_TICKS    = ROOT / "data/t.db"

CONF_YAML = ROOT / "conf/triggers.yaml"
LOG = ROOT / "logs/triggers.log"

CFG = yaml.safe_load(open(CONF_YAML)).get("triggers", {})
ENGINE_SLEEP = float(CFG.get("engine_sleep", 0.5))
ARM_TTL_MS   = int(CFG.get("arm_ttl_ms", 120000))

logging.basicConfig(filename=str(LOG),
    level=logging.INFO,
    format="%(asctime)s TRIG %(levelname)s %(message)s")
log = logging.getLogger("TRIG")


def now_ms():
    return int(time.time() * 1000)

def conn(db):
    c = sqlite3.connect(str(db), timeout=10)
    c.row_factory = sqlite3.Row
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=10000;")
    return c


# üî• PRIX LIVE DIRECT (sans vue)
def live_price(instId):
    with conn(DB_TICKS) as c:
        r = c.execute("""
            SELECT lastPr
            FROM ticks_hist
            WHERE instId=?
            ORDER BY ts_ms DESC
            LIMIT 1
        """, (instId,)).fetchone()
        return float(r["lastPr"]) if r else None


def uid_exists_anywhere(uid):
    with conn(DB_GEST) as g:
        if g.execute("SELECT 1 FROM gest WHERE uid=? LIMIT 1", (uid,)).fetchone():
            return True
    with conn(DB_RECORDER) as r:
        if r.execute("SELECT 1 FROM recorder WHERE uid=? LIMIT 1", (uid,)).fetchone():
            return True
    return False


def instid_active(instId):
    with conn(DB_GEST) as g:
        return g.execute("""
            SELECT 1 FROM gest
            WHERE instId=?
              AND status NOT IN ('close_done','expired')
            LIMIT 1
        """, (instId,)).fetchone() is not None


def trigger_active(instId):
    with conn(DB_TRIG) as t:
        return t.execute("""
            SELECT 1 FROM triggers
            WHERE instId=?
              AND status='fired'
            LIMIT 1
        """, (instId,)).fetchone() is not None


def purge_expired_triggers(t, now):
    rows = t.execute("""
        SELECT uid, ts FROM triggers WHERE status='fired'
    """).fetchall()

    for r in rows:
        if now - int(r["ts"]) > ARM_TTL_MS:
            t.execute("UPDATE triggers SET status='expired' WHERE uid=?", (r["uid"],))
            log.info("[TTL_EXPIRE] %s", r["uid"])


def build_uid(instId, side):
    base = instId.split("/")[0]
    hhmmss = datetime.utcnow().strftime("%H%M%S")
    u4 = uuid.uuid4().hex[:4]
    return f"{base}-{side}-{hhmmss}-{u4}"


def load_dec_fires():
    with conn(DB_DEC) as c:
        return c.execute("""
            SELECT instId, side, atr, dec_mode, score_C, ctx
            FROM v_dec_fire
            WHERE fire = 1
        """).fetchall()


def write_triggers():
    now = now_ms()
    rows = load_dec_fires()
    if not rows:
        return

    with conn(DB_TRIG) as t:
        purge_expired_triggers(t, now)

        for r in rows:
            instId = r["instId"]
            side   = r["side"]
            atr    = r["atr"]
            mode   = r["dec_mode"] or "DEC"
            scoreC = float(r["score_C"] or 0.0)
            ctx    = r["ctx"]

            price = live_price(instId)  # üî• prix r√©el

            if not instId or side not in ("buy", "sell"):
                continue
            if price is None or atr is None or atr <= 0:
                continue
            if instid_active(instId) or trigger_active(instId):
                continue

            uid = build_uid(instId, side)
            if uid_exists_anywhere(uid):
                continue

            sc = abs(scoreC)
            score_of = sc
            score_mo = sc
            score_br = 0.45 if mode == "MOMENTUM" else 0.30
            score_force = min(1.0, 0.5 + sc)

            t.execute("""
                INSERT INTO triggers (
                    uid, instId, side, entry_reason,
                    score_of, score_mo, score_br, score_force,
                    price, atr, ts, status, ts_fire,
                    phase, fire_reason, ctx,
                    score_ctx, dec_score_C, dec_mode, ts_created
                ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)
            """, (
                uid, instId, side,
                f"DEC:{mode}",
                score_of, score_mo, score_br, score_force,
                price, atr,
                now, "fired",
                now, "fire",
                f"DEC:{mode}",
                ctx,
                scoreC, scoreC, mode, now
            ))

            log.info("[FIRED] %s %s uid=%s price=%.6f", instId, side, uid, price)


def main():
    log.info("[START] triggers engine (DEC ‚Üí TRIGGERS)")
    while True:
        try:
            write_triggers()
        except Exception:
            log.exception("[ERR]")
        time.sleep(ENGINE_SLEEP)


if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/universe_audit_ccxt.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import ccxt
import sqlite3
import time
import yaml
import logging

ROOT = "/opt/scalp/project"
CONF = f"{ROOT}/conf/universe.conf.yaml"
DB_UNIVERSE = f"{ROOT}/data/universe.db"
DB_U = f"{ROOT}/data/u.db"

LOG = f"{ROOT}/logs/universe_audit.log"
logging.basicConfig(
    filename=LOG,
    level=logging.INFO,
    format="%(asctime)s UNIVERSE_AUDIT %(levelname)s %(message)s"
)
log = logging.getLogger("UNIVERSE_AUDIT")

# --------------------------------------------------
def conn(path):
    c = sqlite3.connect(path, timeout=30, isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA synchronous=NORMAL;")
    c.execute("PRAGMA busy_timeout=5000;")
    return c

def load_cfg():
    with open(CONF, "r") as f:
        return yaml.safe_load(f)

def canon_inst_usdt(instId):
    s = instId.upper().replace("_", "").replace("-", "").replace("/", "")
    if not s.endswith("USDT"):
        return None
    return f"{s[:-4]}/USDT"

# --------------------------------------------------
def main():
    cfg = load_cfg()
    p = cfg["universe_probes"]["ohlcv"]

    # --- candidates universe (structurels)
    cu = conn(DB_U)
    raw = [r[0] for r in cu.execute("SELECT instId FROM v_universe_tradable;").fetchall()]
    cu.close()

    # --- exchange ccxt (read-only)
    ex = getattr(ccxt, cfg["exchange"]["ccxt_id"])({
        "options": cfg["exchange"]["options"]
    })

    db = conn(DB_UNIVERSE)
    now = int(time.time() * 1000)

    for r in raw:
        inst = canon_inst_usdt(r)
        if not inst:
            continue

        try:
            candles = ex.fetch_ohlcv(
                inst,
                timeframe=p["timeframe"],
                limit=p["max_lookback_bars"]
            )

            n = len(candles)
            if n == 0:
                raise Exception("no_candles")

            last_ts = candles[-1][0]
            staleness = int((now - last_ts) / 1000)

            ok = (
                n >= p["min_candles"]
                and staleness <= p["max_staleness_seconds"]
            )

            err = None if ok else "ohlcv_invalid"

        except Exception as e:
            ok = 0
            n = 0
            last_ts = None
            staleness = None
            err = str(e)

        db.execute("""
            INSERT INTO universe_probe_audit (
                instId,
                ohlcv_ok,
                candle_count,
                last_ts,
                staleness_sec,
                error,
                ts_update
            )
            VALUES (?, ?, ?, ?, ?, ?, ?)
            ON CONFLICT(instId) DO UPDATE SET
                ohlcv_ok       = excluded.ohlcv_ok,
                candle_count  = excluded.candle_count,
                last_ts       = excluded.last_ts,
                staleness_sec = excluded.staleness_sec,
                error         = excluded.error,
                ts_update     = excluded.ts_update
        """, (
            inst,
            1 if ok else 0,
            n,
            last_ts,
            staleness,
            err,
            now
        ))

        log.info(f"{inst} ok={ok} n={n} stale={staleness} err={err}")

    db.close()
    log.info("UNIVERSE AUDIT DONE")

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/universe_collector.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import time
import sqlite3
import yaml
import os

CONF_PATH = os.environ.get(
    "UNIVERSE_CONF",
    "/opt/scalp/project/conf/universe.conf.yaml"
)

# -------------------------------------------------
# utils
# -------------------------------------------------

def load_yaml(path):
    with open(path, "r") as f:
        return yaml.safe_load(f)

def conn(path, ro=False):
    if ro:
        uri = f"file:{path}?mode=ro"
        return sqlite3.connect(uri, uri=True, timeout=5, isolation_level=None)
    return sqlite3.connect(path, timeout=5, isolation_level=None)

# -------------------------------------------------
# collectors
# -------------------------------------------------

def collect_volume_24h(ob_db):
    since = (int(time.time()) - 86400) * 1000
    db = conn(ob_db, ro=True)

    rows = db.execute("""
        SELECT instId, SUM(v)
        FROM ohlcv_1m
        WHERE ts >= ?
        GROUP BY instId
    """, (since,)).fetchall()

    db.close()
    return {inst: float(v or 0.0) for inst, v in rows}

def collect_ticks_24h(t_db):
    since = (int(time.time()) - 86400) * 1000
    db = conn(t_db, ro=True)

    rows = db.execute("""
        SELECT instId, COUNT(*)
        FROM ticks
        WHERE ts_ms >= ?
        GROUP BY instId
    """, (since,)).fetchall()

    db.close()
    return {inst: int(n or 0) for inst, n in rows}

# -------------------------------------------------
# upsert
# -------------------------------------------------

def upsert_universe(universe_db, volumes, ticks):
    db = conn(universe_db)
    db.execute("PRAGMA journal_mode=WAL;")
    db.execute("PRAGMA busy_timeout=5000;")

    now = int(time.time() * 1000)
    insts = set(volumes) | set(ticks)

    for instId in insts:
        db.execute("""
            INSERT INTO universe_coin (
                instId,
                status,
                enabled,

                volume_24h,
                ticks_24h,

                spread_avg,
                spread_p95,

                data_ok,
                status_exchange,

                ts_update
            )
            VALUES (
                ?, 'enabled', 0,
                ?, ?,
                NULL, NULL,
                1, 'listed',
                ?
            )
            ON CONFLICT(instId) DO UPDATE SET
                volume_24h = excluded.volume_24h,
                ticks_24h  = excluded.ticks_24h,
                ts_update  = excluded.ts_update
        """, (
            instId,
            volumes.get(instId, 0.0),
            ticks.get(instId, 0),
            now
        ))

    db.close()

# -------------------------------------------------
# main
# -------------------------------------------------

def main():
    cfg = load_yaml(CONF_PATH)

    vol = collect_volume_24h(cfg["sources"]["ob_db"])
    t24 = collect_ticks_24h(cfg["sources"]["t_db"])

    upsert_universe(cfg["paths"]["universe_db"], vol, t24)

    print(f"[OK] universe collected ‚Äî {len(vol)} coins")

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/universe_probe_bitget.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import time
import yaml
import sqlite3
import requests
import os
import sys

CONF_PATH = os.environ.get(
    "UNIVERSE_CONF",
    "/opt/scalp/project/conf/universe.conf.yaml"
)

# ------------------------------------------------------------
# utils
# ------------------------------------------------------------

def load_yaml(path):
    with open(path, "r") as f:
        return yaml.safe_load(f)

def db_connect(path):
    db = sqlite3.connect(path, timeout=5, isolation_level=None)
    db.execute("PRAGMA journal_mode=WAL;")
    db.execute("PRAGMA busy_timeout=5000;")
    return db

def http_get(url, params, timeout, retries):
    for _ in range(retries + 1):
        try:
            r = requests.get(url, params=params, timeout=timeout)
            if r.status_code == 200:
                return r.json()
        except Exception:
            pass
        time.sleep(0.2)
    return None

# ------------------------------------------------------------
# probes
# ------------------------------------------------------------

def probe_meta(cfg):
    url = cfg["exchange"]["rest_base_url"] + cfg["probes"]["meta"]["endpoint"]
    js = http_get(
        url,
        params={},
        timeout=cfg["exchange"]["timeouts"]["read_seconds"],
        retries=cfg["exchange"]["timeouts"]["max_retries"],
    )
    if not js or "data" not in js:
        return {}

    out = {}
    for row in js["data"]:
        inst = row.get("symbol")
        if not inst:
            continue

        ok = (
            row.get("status") == cfg["probes"]["meta"]["require_status"]
            and row.get("tradeEnable", True)
        )

        out[inst] = {
            "status_exchange": row.get("status"),
            "meta_ok": 1 if ok else 0,
        }
    return out

def probe_ohlcv(cfg, instId):
    p = cfg["probes"]["ohlcv"]
    url = cfg["exchange"]["rest_base_url"] + p["endpoint"]

    params = {
        "symbol": instId,
        "granularity": p["granularity"],
        "limit": p["min_candles"],
    }

    js = http_get(
        url,
        params=params,
        timeout=cfg["exchange"]["timeouts"]["read_seconds"],
        retries=cfg["exchange"]["timeouts"]["max_retries"],
    )

    if not js or "data" not in js or len(js["data"]) < p["min_candles"]:
        return 0

    ts = [int(c[0]) for c in js["data"]]
    ts.sort()

    if ts[-1] < int(time.time() * 1000) - p["max_staleness_ms"]:
        return 0

    for i in range(1, len(ts)):
        if ts[i] - ts[i - 1] > p["max_gap_ms"]:
            return 0

    return 1

def probe_trades(cfg, instId):
    p = cfg["probes"]["trades"]
    url = cfg["exchange"]["rest_base_url"] + p["endpoint"]

    params = {
        "symbol": instId,
        "limit": p["min_trades"],
    }

    js = http_get(
        url,
        params=params,
        timeout=cfg["exchange"]["timeouts"]["read_seconds"],
        retries=cfg["exchange"]["timeouts"]["max_retries"],
    )

    if not js or "data" not in js:
        return 0

    now_ms = int(time.time() * 1000)
    trades = js["data"]

    if len(trades) < p["min_trades"]:
        return 0

    notional = 0.0
    recent = 0

    for t in trades:
        ts = int(t.get("ts", 0))
        if ts >= now_ms - p["lookback_seconds"] * 1000:
            recent += 1
            notional += float(t.get("quoteVol", 0.0))

    if recent < p["min_trades"]:
        return 0
    if notional < p["min_notional"]:
        return 0

    return 1

# ------------------------------------------------------------
# main
# ------------------------------------------------------------

def main():
    cfg = load_yaml(CONF_PATH)

    universe_db = cfg["paths"]["universe_db"]
    probes_cfg  = cfg["probes"]

    db = db_connect(universe_db)

    meta = probe_meta(cfg)
    now = int(time.time() * 1000)

    for instId, m in meta.items():
        ohlcv_ok = 1
        trades_ok = 1

        if probes_cfg["ohlcv"]["enabled"]:
            ohlcv_ok = probe_ohlcv(cfg, instId)

        if probes_cfg["trades"]["enabled"]:
            trades_ok = probe_trades(cfg, instId)

        data_ok = 1 if (m["meta_ok"] and ohlcv_ok and trades_ok) else 0

        db.execute("""
            INSERT INTO universe_coin (
                instId,
                status,
                enabled,
                data_ok,
                status_exchange,
                ts_update
            )
            VALUES (?, 'enabled', 0, ?, ?, ?)
            ON CONFLICT(instId) DO UPDATE SET
                data_ok = excluded.data_ok,
                status_exchange = excluded.status_exchange,
                ts_update = excluded.ts_update
        """, (
            instId,
            data_ok,
            m["status_exchange"],
            now
        ))

    db.close()

    print(f"[OK] universe probes applied ({len(meta)} symbols)")

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/universe_probe_ccxt.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import ccxt
import sqlite3
import time
import yaml
import logging

ROOT = "/opt/scalp/project"
CONF = f"{ROOT}/conf/universe.conf.yaml"
DB_UNIVERSE = f"{ROOT}/data/universe.db"

LOG = f"{ROOT}/logs/universe_probe.log"
logging.basicConfig(
    filename=LOG,
    level=logging.INFO,
    format="%(asctime)s UNIVERSE_PROBE %(levelname)s %(message)s"
)
log = logging.getLogger("UNIVERSE_PROBE")

# ------------------------------------------------------
# DB
# ------------------------------------------------------
def conn(path):
    c = sqlite3.connect(path, timeout=30, isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA synchronous=NORMAL;")
    c.execute("PRAGMA busy_timeout=5000;")
    return c

# ------------------------------------------------------
# CONFIG
# ------------------------------------------------------
def load_cfg():
    with open(CONF, "r") as f:
        return yaml.safe_load(f)

# ------------------------------------------------------
# CANONICAL instId : BASE/USDT
# ------------------------------------------------------
def canon_inst_usdt(symbol: str):
    if not symbol:
        return None
    s = symbol.upper().replace("_", "").replace("-", "").replace("/", "")
    if not s.endswith("USDT"):
        return None
    base = s[:-4]
    if not base:
        return None
    return f"{base}/USDT"

# ------------------------------------------------------
# PROBE OHLCV ‚Äî MARKET EXISTENCE (GLOBAL)
# ------------------------------------------------------
def probe_ohlcv(exchange, instId, cfg):
    p = cfg["universe_probes"]["ohlcv"]
    tf = p["timeframe"]

    try:
        candles = exchange.fetch_ohlcv(
            instId,
            timeframe=tf,
            since=None,
            limit=p["max_lookback_bars"]
        )
    except Exception as e:
        log.debug(f"{instId} fetch error: {e}")
        return (0, 0, None, None)

    if not candles:
        return (0, 0, None, None)

    n = len(candles)
    last_ts = candles[-1][0]
    now_ms = int(time.time() * 1000)
    staleness = int((now_ms - last_ts) / 1000)

    ok = (
        n >= p["min_candles"]
        and staleness <= p["max_staleness_seconds"]
    )

    return (1 if ok else 0, n, last_ts, staleness)

# ------------------------------------------------------
# MAIN
# ------------------------------------------------------
def main():
    cfg = load_cfg()
    if not cfg.get("universe_probes", {}).get("enabled", False):
        log.info("Universe probes disabled")
        return

    # -------- source UNIVERSE : universe_seed (EXHAUSTIF)
    db = conn(DB_UNIVERSE)
    seeds = [r[0] for r in db.execute(
        "SELECT instId FROM universe_seed ORDER BY instId"
    ).fetchall()]

    # -------- exchange (ccxt, read-only)
    ex = getattr(ccxt, cfg["exchange"]["ccxt_id"])({
        "options": cfg["exchange"]["options"]
    })

    now = int(time.time() * 1000)

    ok_cnt = 0

    for seed in seeds:
        inst = canon_inst_usdt(seed)
        if not inst:
            continue

        ohlcv_ok, candle_count, last_ts, staleness = probe_ohlcv(ex, inst, cfg)

        db.execute("""
            INSERT INTO universe_coin (
                instId,
                status,
                enabled,
                data_ok,
                status_exchange,
                ts_update
            )
            VALUES (?, 'enabled', 0, ?, 'listed', ?)
            ON CONFLICT(instId) DO UPDATE SET
                data_ok   = excluded.data_ok,
                ts_update = excluded.ts_update
        """, (inst, ohlcv_ok, now))

        db.execute("""
            INSERT INTO universe_probe_audit (
                instId,
                ohlcv_ok,
                candle_count,
                last_ts,
                staleness_sec,
                error,
                ts_update
            )
            VALUES (?, ?, ?, ?, ?, NULL, ?)
            ON CONFLICT(instId) DO UPDATE SET
                ohlcv_ok       = excluded.ohlcv_ok,
                candle_count  = excluded.candle_count,
                last_ts       = excluded.last_ts,
                staleness_sec = excluded.staleness_sec,
                ts_update     = excluded.ts_update
        """, (
            inst,
            ohlcv_ok,
            candle_count,
            last_ts,
            staleness,
            now
        ))

        if ohlcv_ok:
            ok_cnt += 1

    db.close()
    print(f"[OK] universe_probe_ccxt done ‚Äî data_ok={ok_cnt}/{len(seeds)}")

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/universe_runner.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import time
import sqlite3

try:
    import yaml
except Exception:
    print("[ERR] Missing dependency: PyYAML (pip install pyyaml)", file=sys.stderr)
    sys.exit(1)

CONF_PATH = os.environ.get("UNIVERSE_CONF", "/opt/scalp/project/conf/universe.conf.yaml")

def load_yaml(path: str) -> dict:
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)

def load_sql(path: str) -> str:
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

def connect(db_path: str) -> sqlite3.Connection:
    con = sqlite3.connect(db_path, timeout=5, isolation_level=None)
    con.execute("PRAGMA journal_mode=WAL;")
    con.execute("PRAGMA synchronous=NORMAL;")
    con.execute("PRAGMA busy_timeout=5000;")
    return con

def main() -> int:
    if not os.path.exists(CONF_PATH):
        print(f"[ERR] Missing config: {CONF_PATH}", file=sys.stderr)
        return 1

    cfg = load_yaml(CONF_PATH)

    universe_db = cfg["paths"]["universe_db"]
    sql_dir     = cfg["paths"]["sql_dir"]

    sql_schema = os.path.join(sql_dir, "universe_schema.sql")
    sql_views  = os.path.join(sql_dir, "universe_views.sql")
    sql_update = os.path.join(sql_dir, "universe_update.sql")

    for p in (sql_schema, sql_views, sql_update):
        if not os.path.exists(p):
            print(f"[ERR] Missing SQL file: {p}", file=sys.stderr)
            return 1

    params = {
        "V_MIN":     float(cfg["liquidity"]["volume_24h_min"]),
        "T_MIN":     int(cfg["liquidity"]["ticks_24h_min"]),
        "S_AVG_MAX": float(cfg["spread"]["avg_max"]),
        "S_P95_MAX": float(cfg["spread"]["p95_max"]),
    }

    con = connect(universe_db)

    # bootstrap schema/views (idempotent)
    con.executescript(load_sql(sql_schema))
    con.executescript(load_sql(sql_views))

    # apply rules
    con.execute(load_sql(sql_update), params)

    con.close()

    print(f"[OK] universe rules applied @ {int(time.time())}")
    return 0

if __name__ == "__main__":
    raise SystemExit(main())

----- FILE: /opt/scalp/project/scripts/universe_seed_ccxt.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import ccxt
import sqlite3
import time
import logging

ROOT = "/opt/scalp/project"
DB_UNIVERSE = f"{ROOT}/data/universe.db"

LOG = f"{ROOT}/logs/universe_seed.log"
logging.basicConfig(
    filename=LOG,
    level=logging.INFO,
    format="%(asctime)s UNIVERSE_SEED %(levelname)s %(message)s"
)
log = logging.getLogger("UNIVERSE_SEED")

# ------------------------------------------------------
# DB
# ------------------------------------------------------
def conn(path):
    c = sqlite3.connect(path, timeout=30, isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA synchronous=NORMAL;")
    c.execute("PRAGMA busy_timeout=5000;")
    return c

# ------------------------------------------------------
# MAIN
# ------------------------------------------------------
def main():
    log.info("START universe_seed_ccxt")

    ex = ccxt.bitget({
        "options": {"defaultType": "swap"}
    })

    markets = ex.load_markets()
    now = int(time.time() * 1000)

    db = conn(DB_UNIVERSE)

    n_total = 0
    n_kept = 0

    for m in markets.values():
        n_total += 1

        # --- STRUCTURAL FILTERS ONLY
        if not m.get("swap"):
            continue
        if m.get("quote") != "USDT":
            continue
        if not m.get("active", True):
            continue

        base = m.get("base")
        if not base:
            continue

        inst = f"{base}/USDT"

        db.execute("""
            INSERT INTO universe_seed (
                instId,
                source,
                ts_update
            )
            VALUES (?, 'ccxt', ?)
            ON CONFLICT(instId) DO UPDATE SET
                ts_update = excluded.ts_update
        """, (inst, now))

        n_kept += 1

    db.close()

    log.info(f"END universe_seed_ccxt total={n_total} kept={n_kept}")
    print(f"[OK] universe_seed_ccxt ‚Üí {n_kept} swap USDT markets")

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/universe_tradable_runner.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import ccxt
import sqlite3
import time
import yaml
import logging
import sys

ROOT = "/opt/scalp/project"
CONF = f"{ROOT}/conf/universe.conf.yaml"
DB_UNIVERSE = f"{ROOT}/data/universe.db"

LOG = f"{ROOT}/logs/universe_tradable.log"
logging.basicConfig(
    filename=LOG,
    level=logging.INFO,
    format="%(asctime)s UNIVERSE_TRADABLE %(levelname)s %(message)s"
)
log = logging.getLogger("UNIVERSE_TRADABLE")

# ------------------------------------------------------
# DB
# ------------------------------------------------------
def conn(path):
    c = sqlite3.connect(path, timeout=30, isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA synchronous=NORMAL;")
    c.execute("PRAGMA busy_timeout=5000;")
    return c

# ------------------------------------------------------
# CONFIG
# ------------------------------------------------------
def load_cfg():
    with open(CONF, "r") as f:
        return yaml.safe_load(f)

# ------------------------------------------------------
def chunks(lst, n):
    for i in range(0, len(lst), n):
        yield lst[i:i + n]

# ------------------------------------------------------
# MAIN
# ------------------------------------------------------
def main():
    cfg = load_cfg()

    trad_cfg = cfg.get("tradable", {})
    VOL_MIN = float(trad_cfg.get("volume_24h_min", 0))
    BATCH   = int(trad_cfg.get("batch_size", 5))

    act_cfg = trad_cfg.get("activity_recent", {})
    ACT_ENABLED = bool(act_cfg.get("enabled", False))
    ACT_MAX_AGE = int(act_cfg.get("max_age_seconds", 120))

    ex = ccxt.bitget({
        "enableRateLimit": True,
        "timeout": 10000,
        "options": {"defaultType": "swap"}
    })

    db = conn(DB_UNIVERSE)

    insts = [r[0] for r in db.execute(
        "SELECT instId FROM v_universe_enabled"
    ).fetchall()]

    total = len(insts)
    if total == 0:
        print("[WARN] no universe input")
        return

    now = int(time.time() * 1000)
    kept = 0
    done = 0

    print(f"[INFO] universe_tradable_runner snapshot ({total} symbols)")
    sys.stdout.flush()

    for batch in chunks(insts, BATCH):
        try:
            tickers = ex.fetch_tickers(batch)
        except Exception as e:
            log.warning(f"batch fetch error: {e}")
            continue

        for inst in batch:
            t = tickers.get(inst)
            reason = None
            tradable = 0
            vol = 0.0

            if not t:
                reason = "no_ticker"
            else:
                vol = float(
                    t.get("quoteVolume")
                    or t.get("baseVolume", 0.0)
                    or 0.0
                )

                if vol < VOL_MIN:
                    reason = "low_volume"
                else:
                    tradable = 1

                # --------------------------------------
                # ACTIVITY RECENT (OPTIONAL GUARDFENCE)
                # --------------------------------------
                if tradable and ACT_ENABLED:
                    ts = t.get("timestamp")
                    if not ts:
                        tradable = 0
                        reason = "no_timestamp"
                    else:
                        age = int((now - ts) / 1000)
                        if age > ACT_MAX_AGE:
                            tradable = 0
                            reason = "inactive_recent"

            if tradable:
                kept += 1

            db.execute("""
                INSERT INTO universe_tradable
                    (instId, volume_24h, tradable, reason, ts_update)
                VALUES (?, ?, ?, ?, ?)
                ON CONFLICT(instId) DO UPDATE SET
                    volume_24h = excluded.volume_24h,
                    tradable   = excluded.tradable,
                    reason     = excluded.reason,
                    ts_update  = excluded.ts_update
            """, (inst, vol, tradable, reason, now))

            done += 1

        print(f"[PROGRESS] {done}/{total} tradable={kept}")
        sys.stdout.flush()

    db.close()
    print(f"[OK] universe_tradable_runner done ‚Üí tradable={kept}/{total}")

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/upgrade_views_analysis_steps.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SCALP ‚Äî UPGRADE ANALYSIS VIEWS (STEP / EXIT / PERFORMANCE)

R√àGLES :
- AUCUNE modification de donn√©es
- AUCUN recalcul m√©tier
- uniquement des VUES SQL
- source : exec.db + recorder.db
"""

import sqlite3
from pathlib import Path

ROOT = Path("/opt/scalp/project")

DB_EXEC = ROOT / "data/exec.db"
DB_REC  = ROOT / "data/recorder.db"

def conn(db):
    c = sqlite3.connect(str(db))
    c.execute("PRAGMA journal_mode=WAL;")
    return c

# ============================================================
# EXEC.DB ‚Äî ANALYSE PAR STEP / TYPE
# ============================================================

def upgrade_exec_views():
    c = conn(DB_EXEC)

    # --------------------------------------------------------
    # STEP PERFORMANCE
    # --------------------------------------------------------
    c.execute("""
    CREATE VIEW IF NOT EXISTS v_exec_perf_by_step AS
    SELECT
        step,
        COUNT(*)                       AS n,
        AVG(pnl_realized_step)         AS exp,
        SUM(CASE WHEN pnl_realized_step > 0 THEN pnl_realized_step ELSE 0 END)
        / ABS(SUM(CASE WHEN pnl_realized_step < 0 THEN pnl_realized_step ELSE 0 END)) AS pf
    FROM exec
    WHERE exec_type IN ('close','partial')
    GROUP BY step;
    """)

    # --------------------------------------------------------
    # EXIT TYPE PERFORMANCE
    # --------------------------------------------------------
    c.execute("""
    CREATE VIEW IF NOT EXISTS v_exec_perf_by_exit AS
    SELECT
        reason,
        COUNT(*)                       AS n,
        AVG(pnl_realized_step)         AS exp,
        SUM(CASE WHEN pnl_realized_step > 0 THEN pnl_realized_step ELSE 0 END)
        / ABS(SUM(CASE WHEN pnl_realized_step < 0 THEN pnl_realized_step ELSE 0 END)) AS pf
    FROM exec
    WHERE exec_type IN ('close','partial')
    GROUP BY reason;
    """)

    # --------------------------------------------------------
    # STEP √ó EXIT
    # --------------------------------------------------------
    c.execute("""
    CREATE VIEW IF NOT EXISTS v_exec_perf_step_exit AS
    SELECT
        step,
        reason,
        COUNT(*)                       AS n,
        AVG(pnl_realized_step)         AS exp
    FROM exec
    WHERE exec_type IN ('close','partial')
    GROUP BY step, reason;
    """)

    c.commit()
    c.close()

# ============================================================
# RECORDER.DB ‚Äî CONTEXTE ASSOCI√â
# ============================================================

def upgrade_recorder_views():
    c = conn(DB_REC)

    # --------------------------------------------------------
    # PERFORMANCE STEP AVEC CONTEXTE
    # --------------------------------------------------------
    c.execute("""
    CREATE VIEW IF NOT EXISTS v_rec_perf_step_context AS
    SELECT
        r.close_steps          AS step,
        COUNT(*)               AS n,
        AVG(r.pnl_realized)    AS exp,
        AVG(r.mfe_atr)         AS mfe,
        AVG(r.mae_atr)         AS mae,
        SUM(r.golden)          AS golden
    FROM recorder r
    GROUP BY r.close_steps;
    """)

    # --------------------------------------------------------
    # EXIT TYPE AVEC CONTEXTE
    # --------------------------------------------------------
    c.execute("""
    CREATE VIEW IF NOT EXISTS v_rec_perf_exit_context AS
    SELECT
        r.reason_close         AS exit_type,
        COUNT(*)               AS n,
        AVG(r.pnl_realized)    AS exp,
        AVG(r.mfe_atr)         AS mfe,
        AVG(r.mae_atr)         AS mae,
        SUM(r.golden)          AS golden
    FROM recorder r
    GROUP BY r.reason_close;
    """)

    c.commit()
    c.close()

# ============================================================
# MAIN
# ============================================================

def main():
    upgrade_exec_views()
    upgrade_recorder_views()
    print("‚úÖ Analysis views upgraded (STEP / EXIT / PERFORMANCE)")

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/w_ticks.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3, time, logging, traceback

ROOT = "/opt/scalp/project"
DB_T = f"{ROOT}/data/t.db"
DB_TR = f"{ROOT}/data/trigger.db"
DB_WT = f"{ROOT}/data/wticks.db"

LOG = f"{ROOT}/logs/wticks.log"

logging.basicConfig(
    filename=LOG,
    level=logging.INFO,
    format="%(asctime)s W-TICKS %(levelname)s %(message)s"
)
log = logging.getLogger("WTICKS")

# ----------------------------------------------------------------------
def conn(path):
    c = sqlite3.connect(path, timeout=3, isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA busy_timeout=3000;")
    return c

# ----------------------------------------------------------------------
def fetch_pending_tasks():
    c = conn(DB_TR)
    rows = c.execute("""
        SELECT uid, instId
        FROM v_wticks_tasks
        WHERE done=0;
    """).fetchall()
    c.close()
    return rows

# ----------------------------------------------------------------------
def get_ts_signal(uid):
    c = conn(DB_TR)
    row = c.execute("""
        SELECT ts_signal
        FROM trigger_signals
        WHERE uid=?;
    """, (uid,)).fetchone()
    c.close()
    return row[0] if row else None

# ----------------------------------------------------------------------
def extract_ticks(instId, ts_signal):
    ts_before = ts_signal - 10_000
    ts_after  = ts_signal + 30_000

    c = conn(DB_T)
    rows = c.execute("""
        SELECT ts_ms, bid, ask, lastPr, vol
        FROM ticks
        WHERE instId=?
          AND ts_ms BETWEEN ? AND ?
        ORDER BY ts_ms ASC;
    """, (instId.replace("/", ""), ts_before, ts_after)).fetchall()
    c.close()

    return rows, ts_before, ts_after

# ----------------------------------------------------------------------
def store_ticks(uid, instId, rows, ts_signal):
    c = conn(DB_WT)

    for (ts, bid, ask, last, vol) in rows:
        window_pos = "before" if ts < ts_signal else "after"
        c.execute("""
            INSERT OR REPLACE INTO wticks
            (uid, instId, ts_ms, bid, ask, last, volume, window_pos)
            VALUES (?,?,?,?,?,?,?,?);
        """, (uid, instId, ts, bid, ask, last, vol, window_pos))

    c.close()

# ----------------------------------------------------------------------
def mark_done(uid):
    c = conn(DB_TR)
    c.execute("UPDATE wticks_tasks SET done=1 WHERE uid=?;", (uid,))
    c.close()

# ----------------------------------------------------------------------
def main():
    while True:
        try:
            tasks = fetch_pending_tasks()
            if not tasks:
                time.sleep(0.2)
                continue

            for uid, instId in tasks:
                log.info(f"[TASK] Processing {uid} {instId}")

                ts_signal = get_ts_signal(uid)
                if not ts_signal:
                    log.error(f"[ERR] No ts_signal for UID {uid}")
                    mark_done(uid)
                    continue

                rows, ts_before, ts_after = extract_ticks(instId, ts_signal)
                log.info(f"[TICKS] {uid} ‚Üí {len(rows)} ticks found")

                store_ticks(uid, instId, rows, ts_signal)
                mark_done(uid)

        except Exception as e:
            log.error(f"[ERR] main loop {e}\n{traceback.format_exc()}")
            time.sleep(0.5)

if __name__ == "__main__":
    main()


----- FILE: /opt/scalp/project/scripts/wticks.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3, time, logging, traceback
import statistics

ROOT="/opt/scalp/project"
DB_T=f"{ROOT}/data/t.db"
DB_TR=f"{ROOT}/data/trigger.db"
DB_W=f"{ROOT}/data/wticks.db"

LOG=f"{ROOT}/logs/wticks.log"
logging.basicConfig(
    filename=LOG,
    level=logging.INFO,
    format="%(asctime)s WTICKS %(levelname)s %(message)s"
)
log=logging.getLogger("WTICKS")

def conn(path):
    c=sqlite3.connect(path,timeout=3,isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    return c

def fetch_tasks():
    c=conn(DB_TR)
    rows=c.execute("""
        SELECT uid, instId_raw, ts_signal, price_signal
        FROM v_wticks_tasks
        WHERE status='pending'
    """).fetchall()
    return rows

def fetch_ticks(instId_raw, ts_signal):
    c=conn(DB_T)
    t_min = ts_signal - 10_000
    t_max = ts_signal + 30_000
    rows=c.execute("""
        SELECT ts, price, bid, ask, q_buy, q_sell
        FROM ticks
        WHERE instId=? AND ts BETWEEN ? AND ?
        ORDER BY ts ASC
    """,(instId_raw, t_min, t_max)).fetchall()
    return rows

def compute_metrics(rows, price_signal, ts_signal):
    if not rows:
        return None

    prices=[r[1] for r in rows]
    ts=[r[0] for r in rows]
    minp=min(prices)
    maxp=max(prices)
    meanp=sum(prices)/len(prices)
    varp=statistics.pvariance(prices) if len(prices)>1 else 0.0

    # pic : max prix
    peak_price=maxp
    peak_ts = rows[prices.index(maxp)][0]
    delta_t = peak_ts - ts_signal
    delta_pct = (peak_price - price_signal)/price_signal if price_signal>0 else 0.0

    # pression OF simple = somme(q_buy - q_sell)
    pressure=sum([r[4]-r[5] for r in rows])

    return (peak_ts, peak_price, delta_t, delta_pct,
            minp, maxp, meanp, varp, pressure)

def save(uid, instId_raw, ts_signal, metrics):
    (peak_ts, peak_price, delta_t, delta_pct,
     minp, maxp, meanp, varp, pressure)=metrics

    ts_now=int(time.time()*1000)
    c=conn(DB_W)

    c.execute("""
        INSERT OR REPLACE INTO wticks_extended (
            uid, instId_raw, ts_signal,
            peak_ts, peak_price,
            delta_t_ms, delta_price_pct,
            window_min_price, window_max_price,
            window_mean_price, window_var_price,
            pressure_bias,
            ts_created, ts_updated
        )
        VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?)
    """,(uid,instId_raw,ts_signal,
         peak_ts,peak_price,
         delta_t,delta_pct,
         minp,maxp,meanp,varp,
         pressure,
         ts_now,ts_now))

def mark_done(uid):
    ts=int(time.time()*1000)
    c=conn(DB_TR)
    c.execute("""
        UPDATE wticks_tasks
        SET status='done', ts_updated=?
        WHERE uid=?
    """,(ts,uid))

def main():
    while True:
        try:
            tasks=fetch_tasks()
            for uid,instId_raw,ts_signal,price_signal in tasks:
                ticks = fetch_ticks(instId_raw, ts_signal)
                metrics=compute_metrics(ticks, price_signal, ts_signal)
                if metrics:
                    save(uid,instId_raw,ts_signal,metrics)
                mark_done(uid)
                log.info(f"[DONE] WTICKS {uid}")
        except Exception as e:
            log.error(f"[ERR] {e}\n{traceback.format_exc()}")

        time.sleep(0.5)

if __name__=="__main__":
    main()

----- FILE: /opt/scalp/project/upgrade_add_qty_snapshot.sql -----
ALTER TABLE follower ADD COLUMN qty_open_snapshot REAL DEFAULT 0.0;

========== DATABASE STRUCTURE ==========

----- DATABASE: /opt/scalp/project/data/a.db -----
-- TABLES --
ctx_A                   ohlcv_5m                v_ctx_latest          
feat_15m                v_atr_context           v_ctx_market_stats    
feat_30m                v_atr_context_test      v_ctx_overview        
feat_5m                 v_atr_latest_15m        v_ctx_signal          
ohlcv_15m               v_atr_latest_30m        v_ctx_signal_market_ok
ohlcv_30m               v_atr_latest_5m         v_ohlcv_freshness     

[TABLE: ctx_A]
0|instId|TEXT|0||1
1|ts_updated|INTEGER|0||0
2|trend_5m|TEXT|0||0
3|trend_15m|TEXT|0||0
4|trend_30m|TEXT|0||0
5|score_5m|REAL|0||0
6|score_15m|REAL|0||0
7|score_30m|REAL|0||0
8|score_final|REAL|0||0
9|p_buy|REAL|0||0
10|p_sell|REAL|0||0
11|p_hold|REAL|0||0
12|ctx|TEXT|0||0
13|score_A|REAL|0|0.5|0

[TABLE: ohlcv_5m]
0|instId|TEXT|0||1
1|ts|INTEGER|0||2
2|o|REAL|0||0
3|h|REAL|0||0
4|l|REAL|0||0
5|c|REAL|0||0
6|v|REAL|0||0

[TABLE: v_ctx_latest]
0|instId|TEXT|0||0
1|ctx|TEXT|0||0
2|score_C|REAL|0||0
3|ts_updated||0||0

[TABLE: feat_15m]
0|instId|TEXT|0||1
1|ts|INTEGER|0||2
2|o|REAL|0||0
3|h|REAL|0||0
4|l|REAL|0||0
5|c|REAL|0||0
6|v|REAL|0||0
7|ema9|REAL|0||0
8|ema21|REAL|0||0
9|ema50|REAL|0||0
10|macd|REAL|0||0
11|macdsignal|REAL|0||0
12|macdhist|REAL|0||0
13|rsi|REAL|0||0
14|atr|REAL|0||0

[TABLE: v_atr_context]
0|instId|TEXT|0||0
1|atr_5m|REAL|0||0
2|atr_15m|REAL|0||0
3|atr_30m|REAL|0||0
4|ratio_5m_15m||0||0
5|ratio_5m_30m||0||0
6|age_ms||0||0

[TABLE: v_ctx_market_stats]

[TABLE: feat_30m]
0|instId|TEXT|0||1
1|ts|INTEGER|0||2
2|o|REAL|0||0
3|h|REAL|0||0
4|l|REAL|0||0
5|c|REAL|0||0
6|v|REAL|0||0
7|ema9|REAL|0||0
8|ema21|REAL|0||0
9|ema50|REAL|0||0
10|macd|REAL|0||0
11|macdsignal|REAL|0||0
12|macdhist|REAL|0||0
13|rsi|REAL|0||0
14|atr|REAL|0||0

[TABLE: v_atr_context_test]
0|instId|TEXT|0||0
1|atr_5m|REAL|0||0
2|atr_15m|REAL|0||0
3|atr_30m|REAL|0||0
4|ratio_5m_15m||0||0
5|ratio_5m_30m||0||0
6|age_ms||0||0

[TABLE: v_ctx_overview]
0|instId|TEXT|0||0
1|ts||0||0
2|score_5m|REAL|0||0
3|score_15m|REAL|0||0
4|score_30m|REAL|0||0
5|score_final|REAL|0||0
6|p_buy||0||0
7|p_sell||0||0
8|p_hold||0||0
9|ctx|TEXT|0||0

[TABLE: feat_5m]
0|instId|TEXT|0||1
1|ts|INTEGER|0||2
2|o|REAL|0||0
3|h|REAL|0||0
4|l|REAL|0||0
5|c|REAL|0||0
6|v|REAL|0||0
7|ema9|REAL|0||0
8|ema21|REAL|0||0
9|ema50|REAL|0||0
10|macd|REAL|0||0
11|macdsignal|REAL|0||0
12|macdhist|REAL|0||0
13|rsi|REAL|0||0
14|atr|REAL|0||0

[TABLE: v_atr_latest_15m]
0|instId|TEXT|0||0
1|atr_15m|REAL|0||0
2|ts_15m|INTEGER|0||0
3|age_15m_ms||0||0

[TABLE: v_ctx_signal]
0|instId|TEXT|0||0
1|ctx|TEXT|0||0
2|score_C|REAL|0||0
3|ts_updated||0||0
4|side||0||0
5|ctx_ok||0||0
6|atr_5m|REAL|0||0
7|atr_15m|REAL|0||0
8|atr_30m|REAL|0||0
9|ratio_5m_15m||0||0
10|ratio_5m_30m||0||0
11|vol_regime||0||0
12|ctx_ok_final||0||0
13|age_ms||0||0

[TABLE: ohlcv_15m]
0|instId|TEXT|0||1
1|ts|INTEGER|0||2
2|o|REAL|0||0
3|h|REAL|0||0
4|l|REAL|0||0
5|c|REAL|0||0
6|v|REAL|0||0

[TABLE: v_atr_latest_30m]
0|instId|TEXT|0||0
1|atr_30m|REAL|0||0
2|ts_30m|INTEGER|0||0
3|age_30m_ms||0||0

[TABLE: v_ctx_signal_market_ok]

[TABLE: ohlcv_30m]
0|instId|TEXT|0||1
1|ts|INTEGER|0||2
2|o|REAL|0||0
3|h|REAL|0||0
4|l|REAL|0||0
5|c|REAL|0||0
6|v|REAL|0||0

[TABLE: v_atr_latest_5m]
0|instId|TEXT|0||0
1|atr_5m|REAL|0||0
2|ts_5m|INTEGER|0||0
3|age_5m_ms||0||0

[TABLE: v_ohlcv_freshness]
0|instId|TEXT|0||0
1|ts||0||0
2|age_ms||0||0

-- VIEWS --
v_atr_context|CREATE VIEW v_atr_context AS
WITH
-- ------------------------------------------------------------
-- DERNIER ATR 5m
-- ------------------------------------------------------------
a5 AS (
    SELECT
        f.instId,
        f.atr       AS atr_5m,
        f.ts        AS ts_5m
    FROM feat_5m f
    JOIN (
        SELECT instId, MAX(ts) AS ts
        FROM feat_5m
        GROUP BY instId
    ) m
      ON f.instId = m.instId
     AND f.ts     = m.ts
),

-- ------------------------------------------------------------
-- DERNIER ATR 15m
-- ------------------------------------------------------------
a15 AS (
    SELECT
        f.instId,
        f.atr       AS atr_15m,
        f.ts        AS ts_15m
    FROM feat_15m f
    JOIN (
        SELECT instId, MAX(ts) AS ts
        FROM feat_15m
        GROUP BY instId
    ) m
      ON f.instId = m.instId
     AND f.ts     = m.ts
),

-- ------------------------------------------------------------
-- DERNIER ATR 30m
-- ------------------------------------------------------------
a30 AS (
    SELECT
        f.instId,
        f.atr       AS atr_30m,
        f.ts        AS ts_30m
    FROM feat_30m f
    JOIN (
        SELECT instId, MAX(ts) AS ts
        FROM feat_30m
        GROUP BY instId
    ) m
      ON f.instId = m.instId
     AND f.ts     = m.ts
)

-- ------------------------------------------------------------
-- CONTEXTE FINAL
-- ------------------------------------------------------------
SELECT
    a5.instId,

    a5.atr_5m,
    a15.atr_15m,
    a30.atr_30m,

    CASE
        WHEN a15.atr_15m > 0 THEN a5.atr_5m / a15.atr_15m
        ELSE NULL
    END AS ratio_5m_15m,

    CASE
        WHEN a30.atr_30m > 0 THEN a5.atr_5m / a30.atr_30m
        ELSE NULL
    END AS ratio_5m_30m,

    (strftime('%s','now')*1000 - a5.ts_5m) AS age_ms

FROM a5
LEFT JOIN a15 ON a5.instId = a15.instId
LEFT JOIN a30 ON a5.instId = a30.instId
v_atr_context_test|CREATE VIEW v_atr_context_test AS
WITH
atr_5m AS (
    SELECT instId, atr, ts
    FROM feat_5m
),
atr_15m AS (
    SELECT instId, atr, ts
    FROM feat_15m
),
atr_30m AS (
    SELECT instId, atr, ts
    FROM feat_30m
),
joined AS (
    SELECT
        a5.instId,
        a5.atr  AS atr_5m,
        a15.atr AS atr_15m,
        a30.atr AS atr_30m,
        a5.ts   AS ts_5m
    FROM atr_5m a5
    LEFT JOIN atr_15m a15
        ON a15.instId = a5.instId
       AND a15.ts = (
            SELECT MAX(ts)
            FROM feat_15m
            WHERE instId = a5.instId
        )
    LEFT JOIN atr_30m a30
        ON a30.instId = a5.instId
       AND a30.ts = (
            SELECT MAX(ts)
            FROM feat_30m
            WHERE instId = a5.instId
        )
)
SELECT
    instId,
    atr_5m,
    atr_15m,
    atr_30m,
    CASE
        WHEN atr_15m > 0 THEN atr_5m / atr_15m
        ELSE NULL
    END AS ratio_5m_15m,
    CASE
        WHEN atr_30m > 0 THEN atr_5m / atr_30m
        ELSE NULL
    END AS ratio_5m_30m,
    (strftime('%s','now') * 1000 - ts_5m) AS age_ms
FROM joined
v_atr_latest_15m|CREATE VIEW v_atr_latest_15m AS
SELECT
    f.instId,
    f.atr      AS atr_15m,
    f.ts       AS ts_15m,
    (strftime('%s','now')*1000 - f.ts) AS age_15m_ms
FROM feat_15m f
JOIN (
    SELECT instId, MAX(ts) AS ts
    FROM feat_15m
    GROUP BY instId
) last
ON f.instId = last.instId
AND f.ts = last.ts
v_atr_latest_30m|CREATE VIEW v_atr_latest_30m AS
SELECT
    f.instId,
    f.atr      AS atr_30m,
    f.ts       AS ts_30m,
    (strftime('%s','now')*1000 - f.ts) AS age_30m_ms
FROM feat_30m f
JOIN (
    SELECT instId, MAX(ts) AS ts
    FROM feat_30m
    GROUP BY instId
) last
ON f.instId = last.instId
AND f.ts = last.ts
v_atr_latest_5m|CREATE VIEW v_atr_latest_5m AS
SELECT
    f.instId,
    f.atr      AS atr_5m,
    f.ts       AS ts_5m,
    (strftime('%s','now')*1000 - f.ts) AS age_5m_ms
FROM feat_5m f
JOIN (
    SELECT instId, MAX(ts) AS ts
    FROM feat_5m
    GROUP BY instId
) last
ON f.instId = last.instId
AND f.ts = last.ts
v_ctx_latest|CREATE VIEW v_ctx_latest AS
SELECT
    o.instId                         AS instId,
    o.ctx                            AS ctx,
    o.score_final                    AS score_C,
    o.ts                             AS ts_updated
FROM v_ctx_overview o
v_ctx_market_stats|CREATE VIEW v_ctx_market_stats AS
SELECT
    COUNT(*)                                AS ctx_tested,
    SUM(ctx_ok)                             AS ctx_ok,

    SUM(ctx = 'bullish')                    AS bull_total,
    SUM(ctx = 'bullish' AND ctx_ok = 1)     AS bull_ok,

    SUM(ctx = 'bearish')                    AS bear_total,
    SUM(ctx = 'bearish' AND ctx_ok = 1)     AS bear_ok,

    SUM(ctx NOT IN ('bullish','bearish'))   AS flat_total,
    SUM(ctx NOT IN ('bullish','bearish') AND ctx_ok = 1) AS flat_ok
FROM v_ctx_signal_market_ok
v_ctx_overview|CREATE VIEW v_ctx_overview AS
SELECT
    instId,
    DATETIME(ts_updated/1000,'unixepoch','localtime') AS ts,
    score_5m,
    score_15m,
    score_30m,
    score_final,
    CASE
        WHEN score_final IS NOT NULL THEN
            ROUND( exp(score_final/0.35)
                / (exp(score_final/0.35) + 1 + exp(-score_final/0.35)), 6 )
    END AS p_buy,
    CASE
        WHEN score_final IS NOT NULL THEN
            ROUND( exp(-score_final/0.35)
                / (exp(score_final/0.35) + 1 + exp(-score_final/0.35)), 6 )
    END AS p_sell,
    CASE
        WHEN score_final IS NOT NULL THEN
            ROUND( 1
                - (exp(score_final/0.35)
                   / (exp(score_final/0.35) + 1 + exp(-score_final/0.35)))
                - (exp(-score_final/0.35)
                   / (exp(score_final/0.35) + 1 + exp(-score_final/0.35))), 6 )
    END AS p_hold,
    ctx
FROM ctx_A
ORDER BY instId
v_ctx_signal|CREATE VIEW v_ctx_signal AS
WITH base AS (
    SELECT
        c.instId,
        c.ctx,                -- bullish / bearish / flat
        c.score_C,
        c.ts_updated,
        a.atr_5m,
        a.atr_15m,
        a.atr_30m,
        a.ratio_5m_15m,
        a.ratio_5m_30m,
        a.age_ms
    FROM v_ctx_latest c
    LEFT JOIN v_atr_context a
        ON a.instId = c.instId
),
vol AS (
    SELECT *,
        CASE
            WHEN ratio_5m_15m IS NULL THEN 'UNKNOWN'
            WHEN ratio_5m_15m < 0.55 THEN 'COMPRESS'
            WHEN ratio_5m_15m > 1.30 THEN 'EXPAND'
            ELSE 'NORMAL'
        END AS vol_regime
    FROM base
)
SELECT
    instId,
    ctx,
    score_C,
    ts_updated,

    CASE
        WHEN ctx='bullish' AND score_C >  0.30 THEN 'buy'
        WHEN ctx='bearish' AND score_C < -0.30 THEN 'sell'
        ELSE NULL
    END AS side,

    CASE
        WHEN ctx IN ('bullish','bearish') AND ABS(score_C) >= 0.30 THEN 1
        ELSE 0
    END AS ctx_ok,

    atr_5m,
    atr_15m,
    atr_30m,
    ratio_5m_15m,
    ratio_5m_30m,
    vol_regime,

    CASE
        WHEN ctx IN ('bullish','bearish')
         AND ABS(score_C) >= 0.30
         AND vol_regime != 'UNKNOWN'
        THEN 1
        ELSE 0
    END AS ctx_ok_final,

    age_ms
FROM vol
v_ctx_signal_market_ok|CREATE VIEW v_ctx_signal_market_ok AS
SELECT
    c.instId,
    c.ctx,
    c.score_C,
    c.side,
    c.ctx_ok,
    c.ts_updated
FROM snap_ctx c
WHERE c.instId IN (
    SELECT instId
    FROM market_latest
    WHERE
        -- flags stricts market
        staleness_ms <= 1000
        AND ticks_5s >= 5
        AND spread_bps <= 5.0
)
v_ohlcv_freshness|CREATE VIEW v_ohlcv_freshness AS
SELECT
    instId,
    MAX(ts) AS ts,
    (strftime('%s','now') * 1000 - MAX(ts)) AS age_ms
FROM ohlcv_5m
GROUP BY instId

-- INDEXES --
idx_ohlcv15_inst_ts|CREATE INDEX idx_ohlcv15_inst_ts ON ohlcv_15m(instId, ts)
idx_ohlcv30_inst_ts|CREATE INDEX idx_ohlcv30_inst_ts ON ohlcv_30m(instId, ts)
idx_ohlcv5_inst_ts|CREATE INDEX idx_ohlcv5_inst_ts ON ohlcv_5m(instId, ts)
sqlite_autoindex_ctx_A_1|
sqlite_autoindex_feat_15m_1|
sqlite_autoindex_feat_30m_1|
sqlite_autoindex_feat_5m_1|
sqlite_autoindex_ohlcv_15m_1|
sqlite_autoindex_ohlcv_30m_1|
sqlite_autoindex_ohlcv_5m_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/analytics.db -----
-- TABLES --
exposure_scores       v_atr_bucket          v_score_H           
factor_stats          v_ctx_bucket          v_scores_for_opener 
historical_scores     v_ctx_latest          v_signal_bucket     
historical_scores_v2  v_historical          v_signal_timing     
signal_timing         v_orderflow_bucket    v_timing            

[TABLE: exposure_scores]
0|instId|TEXT|0||1
1|side|TEXT|0||2
2|ctx|TEXT|0||3
3|scoreB_bucket|INTEGER|0||4
4|hour_bucket|INTEGER|0||5
5|n_trades|INTEGER|0||0
6|winrate|REAL|0||0
7|pnl_net_avg|REAL|0||0
8|score|REAL|0||0
9|last_update|INTEGER|0||0

[TABLE: v_atr_bucket]

[TABLE: v_score_H]
0|instId|TEXT|0||0
1|side|TEXT|0||0
2|reason|TEXT|0||0
3|ctx_dir|TEXT|0||0
4|ctx_strength|TEXT|0||0
5|signal_strength|TEXT|0||0
6|day_bucket|TEXT|0||0
7|hour_bucket|INTEGER|0||0
8|vol_bucket|TEXT|0||0
9|of_bucket|TEXT|0||0
10|total_trades|INTEGER|0||0
11|win_rate|REAL|0||0
12|avg_pnl|REAL|0||0
13|median_pnl|REAL|0||0
14|score_H|REAL|0||0
15|last_update|INTEGER|0||0

[TABLE: factor_stats]
0|instId|TEXT|0||1
1|side|TEXT|0||2
2|reason|TEXT|0||3
3|scoreA_bucket|INTEGER|0||4
4|scoreB_bucket|INTEGER|0||5
5|hour_bucket|INTEGER|0||6
6|n_trades|INTEGER|0||0
7|wins|INTEGER|0||0
8|pnl_net_sum|REAL|0||0
9|pnl_net_avg|REAL|0||0
10|wr_local|REAL|0||0
11|granularity|INTEGER|0||0

[TABLE: v_ctx_bucket]

[TABLE: v_scores_for_opener]
0|instId|TEXT|0||0
1|side|TEXT|0||0
2|ctx|TEXT|0||0
3|scoreB_bucket|INTEGER|0||0
4|hour_bucket|INTEGER|0||0
5|score|REAL|0||0

[TABLE: historical_scores]
0|instId|TEXT|1||1
1|side|TEXT|1||2
2|type_signal|TEXT|1||3
3|ctx|TEXT|1||4
4|score_C|REAL|1||5
5|score_S|REAL|1||6
6|score_OF|REAL|0||0
7|atr_bucket|TEXT|0||0
8|win_rate|REAL|0||0
9|pnl_avg|REAL|0||0
10|score_H|REAL|1||0
11|ts_updated|INTEGER|1||0

[TABLE: v_ctx_latest]

[TABLE: v_signal_bucket]

[TABLE: historical_scores_v2]
0|instId|TEXT|1||1
1|side|TEXT|1||2
2|reason|TEXT|1||3
3|ctx_dir|TEXT|1||4
4|ctx_strength|TEXT|1||5
5|signal_strength|TEXT|1||6
6|day_bucket|TEXT|1||7
7|hour_bucket|INTEGER|1||8
8|vol_bucket|TEXT|1||9
9|of_bucket|TEXT|1||10
10|total_trades|INTEGER|1||0
11|win_rate|REAL|1||0
12|avg_pnl|REAL|1||0
13|median_pnl|REAL|1||0
14|score_H|REAL|1||0
15|last_update|INTEGER|1||0

[TABLE: v_historical]
0|instId|TEXT|0||0
1|side|TEXT|0||0
2|type_signal|TEXT|0||0
3|ctx|TEXT|0||0
4|score_C|REAL|0||0
5|score_S|REAL|0||0
6|score_OF|REAL|0||0
7|atr_bucket|TEXT|0||0
8|win_rate|REAL|0||0
9|pnl_avg|REAL|0||0
10|score_H|REAL|0||0
11|score_H_final|REAL|0||0
12|ts_updated|INTEGER|0||0

[TABLE: v_signal_timing]

[TABLE: signal_timing]
0|uid|TEXT|0||1
1|instId|TEXT|1||0
2|side|TEXT|1||0
3|type_signal|TEXT|1||0
4|ts_signal|INTEGER|1||0
5|price_signal|REAL|1||0
6|peak_ts|INTEGER|0||0
7|peak_price|REAL|0||0
8|delta_t_ms|INTEGER|0||0
9|delta_price|REAL|0||0
10|delta_price_pct|REAL|0||0
11|score_T|REAL|0||0
12|ts_updated|INTEGER|1||0

[TABLE: v_orderflow_bucket]

[TABLE: v_timing]
0|uid|TEXT|0||0
1|instId|TEXT|0||0
2|side|TEXT|0||0
3|type_signal|TEXT|0||0
4|ts_signal|INTEGER|0||0
5|price_signal|REAL|0||0
6|peak_ts|INTEGER|0||0
7|peak_price|REAL|0||0
8|delta_t_ms|INTEGER|0||0
9|delta_price|REAL|0||0
10|delta_price_pct|REAL|0||0
11|score_T|REAL|0||0
12|ts_updated|INTEGER|0||0

-- VIEWS --
v_atr_bucket|CREATE VIEW v_atr_bucket AS
SELECT
    instId,
    CASE
        WHEN atr_signal <= 0.5 THEN 'low'
        WHEN atr_signal <= 1.5 THEN 'mid'
        ELSE 'high'
    END AS atr_bucket
FROM trades_recorded
v_ctx_bucket|CREATE VIEW v_ctx_bucket AS
SELECT
    instId,
    ctx AS ctx_dir,
    CASE
        WHEN score_A >= 0.70 THEN 'strong'
        WHEN score_A <= 0.30 THEN 'weak'
        ELSE 'mid'
    END AS score_C_bucket
FROM ctx_A
v_ctx_latest|CREATE VIEW v_ctx_latest AS
SELECT
    instId,
    ctx,
    score_A AS score_C,
    ts_updated
FROM ctx_A
WHERE ts_updated = (
    SELECT MAX(ts_updated) FROM ctx_A c2 WHERE c2.instId = ctx_A.instId
)
v_historical|CREATE VIEW v_historical AS
SELECT
    instId,
    side,
    type_signal,
    ctx,
    score_C,
    score_S,
    score_OF,
    atr_bucket,
    win_rate,
    pnl_avg,
    score_H,
    score_H AS score_H_final,
    ts_updated
FROM historical_scores
ORDER BY ts_updated DESC
v_orderflow_bucket|CREATE VIEW v_orderflow_bucket AS
SELECT
    instId,
    CASE
        WHEN imbalance >= 0.20 THEN 'strong_buy'
        WHEN imbalance <= -0.20 THEN 'strong_sell'
        ELSE 'neutral'
    END AS of_bucket
FROM v_orderflow_features
v_score_H|CREATE VIEW v_score_H AS
SELECT
    instId,
    side,
    reason,
    ctx_dir,
    ctx_strength,
    signal_strength,
    day_bucket,
    hour_bucket,
    vol_bucket,
    of_bucket,
    total_trades,
    win_rate,
    avg_pnl,
    median_pnl,
    score_H,
    last_update
FROM historical_scores_v2
ORDER BY last_update DESC
v_scores_for_opener|CREATE VIEW v_scores_for_opener AS
SELECT
    instId,
    side,
    ctx,
    scoreB_bucket,
    hour_bucket,
    score
FROM exposure_scores
v_signal_bucket|CREATE VIEW v_signal_bucket AS
SELECT
    uid,
    instId,
    side,
    reason,
    score_B,
    CASE
        WHEN score_B >= 0.70 THEN 'strong'
        WHEN score_B <= 0.30 THEN 'weak'
        ELSE 'mid'
    END AS score_S_bucket
FROM signals_B
v_signal_timing|CREATE VIEW v_signal_timing AS
SELECT
    uid,
    instId,
    side,
    reason,
    ts_signal,
    price_signal,
    peak_ts,
    peak_price,
    delta_t_ms,
    delta_price,
    delta_price_pct,
    score_T,
    ts_updated
FROM signal_timing
ORDER BY ts_updated DESC
v_timing|CREATE VIEW v_timing AS
SELECT *
FROM signal_timing
ORDER BY ts_signal DESC

-- INDEXES --
sqlite_autoindex_exposure_scores_1|
sqlite_autoindex_factor_stats_1|
sqlite_autoindex_historical_scores_1|
sqlite_autoindex_historical_scores_v2_1|
sqlite_autoindex_signal_timing_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/audit_triggers.db -----
-- TABLES --
audit_triggers        v_trigger_audit_full
trigger_audit         v_trigger_perf      

[TABLE: audit_triggers]
0|uid|TEXT|0||1
1|instId|TEXT|1||0
2|side|TEXT|1||0
3|trigger_status|TEXT|1||0
4|price_entry|REAL|1||0
5|atr|REAL|1||0
6|mfe|REAL|1||0
7|mae|REAL|1||0
8|outcome|TEXT|1||0
9|entry_price|REAL|0||0
10|mfe_atr|REAL|0||0
11|mae_atr|REAL|0||0
12|ts_trigger|INTEGER|0||0
13|window_ms|INTEGER|0||0
14|validated|INTEGER|0||0
15|mfe_early|REAL|0||0
16|mae_early|REAL|0||0
17|ttl_ms|INTEGER|0||0
18|life_ms|INTEGER|0||0
19|outcome_early|TEXT|0||0
20|ctx|TEXT|0||0
21|score_ctx|REAL|0||0

[TABLE: v_trigger_audit_full]

[TABLE: trigger_audit]
0|uid|TEXT|0||1
1|instId|TEXT|1||0
2|regime|TEXT|1||0
3|ts_fire|INTEGER|1||0
4|price_fire|REAL|1||0
5|side|TEXT|1||0
6|atr|REAL|1||0
7|mfe|REAL|0||0
8|mae|REAL|0||0
9|mfe_atr|REAL|0||0
10|mae_atr|REAL|0||0
11|t_mfe_ms|INTEGER|0||0
12|t_mae_ms|INTEGER|0||0
13|valid|INTEGER|0||0
14|ts_audit|INTEGER|1||0

[TABLE: v_trigger_perf]
0|instId|TEXT|0||0
1|side|TEXT|0||0
2|mfe_atr|REAL|0||0
3|mae_atr|REAL|0||0
4|outcome|TEXT|0||0
5|life_s||0||0

-- VIEWS --
v_trigger_audit_full|CREATE VIEW v_trigger_audit_full AS
SELECT
    a.uid,
    a.instId,
    a.side,
    a.mfe_atr,
    a.mae_atr,
    a.outcome,
    a.window_ms/1000.0 AS life_s,

    s.reason,
    s.score_B,

    t.score_T,
    t.delta_t_ms,

    h.score_H
FROM audit_triggers a
LEFT JOIN signals_B      s ON s.uid = a.uid
LEFT JOIN signal_timing  t ON t.uid = a.uid
LEFT JOIN historical_scores_v2 h
       ON h.instId = a.instId
      AND h.side   = a.side
v_trigger_perf|CREATE VIEW v_trigger_perf AS
SELECT
    instId,
    side,
    mfe_atr,
    mae_atr,
    outcome,
    window_ms/1000.0 AS life_s
FROM audit_triggers

-- INDEXES --
idx_audit_instId|CREATE INDEX idx_audit_instId ON trigger_audit(instId)
idx_audit_regime|CREATE INDEX idx_audit_regime ON trigger_audit(regime)
idx_audit_ts|CREATE INDEX idx_audit_ts     ON trigger_audit(ts_fire)
idx_audit_uid|CREATE INDEX idx_audit_uid ON audit_triggers(uid)
sqlite_autoindex_audit_triggers_1|
sqlite_autoindex_trigger_audit_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/b.db -----
-- TABLES --
feat_1m        feat_5m        v_feat_1m      v_feat_5m    
feat_3m        v_atr_context  v_feat_3m      v_range_1m   

[TABLE: feat_1m]
0|instId|TEXT|0||1
1|ts|INTEGER|0||2
2|o|REAL|0||0
3|h|REAL|0||0
4|l|REAL|0||0
5|c|REAL|0||0
6|v|REAL|0||0
7|ema9|REAL|0||0
8|ema12|REAL|0||0
9|ema21|REAL|0||0
10|ema26|REAL|0||0
11|ema50|REAL|0||0
12|macd|REAL|0||0
13|macdsignal|REAL|0||0
14|macdhist|REAL|0||0
15|rsi|REAL|0||0
16|atr|REAL|0||0
17|bb_mid|REAL|0||0
18|bb_std|REAL|0||0
19|bb_up|REAL|0||0
20|bb_low|REAL|0||0
21|bb_width|REAL|0||0
22|mom|REAL|0||0
23|roc|REAL|0||0
24|slope|REAL|0||0
25|ctx|TEXT|0||0
26|plus_di|REAL|0||0
27|minus_di|REAL|0||0
28|adx|REAL|0||0

[TABLE: feat_5m]
0|instId|TEXT|0||0
1|ts|INT|0||0
2|o|REAL|0||0
3|h|REAL|0||0
4|l|REAL|0||0
5|c|REAL|0||0
6|v|REAL|0||0
7|ema9|REAL|0||0
8|ema12|REAL|0||0
9|ema21|REAL|0||0
10|ema26|REAL|0||0
11|ema50|REAL|0||0
12|macd|REAL|0||0
13|macdsignal|REAL|0||0
14|macdhist|REAL|0||0
15|rsi|REAL|0||0
16|atr|REAL|0||0
17|bb_mid|REAL|0||0
18|bb_std|REAL|0||0
19|bb_up|REAL|0||0
20|bb_low|REAL|0||0
21|bb_width|REAL|0||0
22|mom|REAL|0||0
23|roc|REAL|0||0
24|slope|REAL|0||0
25|ctx|TEXT|0||0
26|plus_di|REAL|0||0
27|minus_di|REAL|0||0
28|adx|REAL|0||0

[TABLE: v_feat_1m]
0|instId|TEXT|0||0
1|ts|INTEGER|0||0
2|o|REAL|0||0
3|h|REAL|0||0
4|l|REAL|0||0
5|c|REAL|0||0
6|v|REAL|0||0
7|ema9|REAL|0||0
8|ema12|REAL|0||0
9|ema21|REAL|0||0
10|ema26|REAL|0||0
11|ema50|REAL|0||0
12|macd|REAL|0||0
13|macdsignal|REAL|0||0
14|macdhist|REAL|0||0
15|rsi|REAL|0||0
16|atr|REAL|0||0
17|bb_mid|REAL|0||0
18|bb_std|REAL|0||0
19|bb_up|REAL|0||0
20|bb_low|REAL|0||0
21|bb_width|REAL|0||0
22|mom|REAL|0||0
23|roc|REAL|0||0
24|slope|REAL|0||0
25|ctx|TEXT|0||0
26|plus_di|REAL|0||0
27|minus_di|REAL|0||0
28|adx|REAL|0||0
29|age_ms||0||0

[TABLE: v_feat_5m]
0|instId|TEXT|0||0
1|ts|INT|0||0
2|o|REAL|0||0
3|h|REAL|0||0
4|l|REAL|0||0
5|c|REAL|0||0
6|v|REAL|0||0
7|ema9|REAL|0||0
8|ema12|REAL|0||0
9|ema21|REAL|0||0
10|ema26|REAL|0||0
11|ema50|REAL|0||0
12|macd|REAL|0||0
13|macdsignal|REAL|0||0
14|macdhist|REAL|0||0
15|rsi|REAL|0||0
16|atr|REAL|0||0
17|bb_mid|REAL|0||0
18|bb_std|REAL|0||0
19|bb_up|REAL|0||0
20|bb_low|REAL|0||0
21|bb_width|REAL|0||0
22|mom|REAL|0||0
23|roc|REAL|0||0
24|slope|REAL|0||0
25|ctx|TEXT|0||0
26|plus_di|REAL|0||0
27|minus_di|REAL|0||0
28|adx|REAL|0||0
29|age_ms||0||0

[TABLE: feat_3m]
0|instId|TEXT|0||0
1|ts|INT|0||0
2|o|REAL|0||0
3|h|REAL|0||0
4|l|REAL|0||0
5|c|REAL|0||0
6|v|REAL|0||0
7|ema9|REAL|0||0
8|ema12|REAL|0||0
9|ema21|REAL|0||0
10|ema26|REAL|0||0
11|ema50|REAL|0||0
12|macd|REAL|0||0
13|macdsignal|REAL|0||0
14|macdhist|REAL|0||0
15|rsi|REAL|0||0
16|atr|REAL|0||0
17|bb_mid|REAL|0||0
18|bb_std|REAL|0||0
19|bb_up|REAL|0||0
20|bb_low|REAL|0||0
21|bb_width|REAL|0||0
22|mom|REAL|0||0
23|roc|REAL|0||0
24|slope|REAL|0||0
25|ctx|TEXT|0||0
26|plus_di|REAL|0||0
27|minus_di|REAL|0||0
28|adx|REAL|0||0

[TABLE: v_atr_context]
0|instId|TEXT|0||0
1|atr_1m|REAL|0||0
2|atr_3m|REAL|0||0
3|atr_5m|REAL|0||0
4|ratio_1m_3m||0||0
5|ratio_1m_5m||0||0
6|ratio_3m_5m||0||0
7|compression_ok||0||0
8|age_ms||0||0

[TABLE: v_feat_3m]
0|instId|TEXT|0||0
1|ts|INT|0||0
2|o|REAL|0||0
3|h|REAL|0||0
4|l|REAL|0||0
5|c|REAL|0||0
6|v|REAL|0||0
7|ema9|REAL|0||0
8|ema12|REAL|0||0
9|ema21|REAL|0||0
10|ema26|REAL|0||0
11|ema50|REAL|0||0
12|macd|REAL|0||0
13|macdsignal|REAL|0||0
14|macdhist|REAL|0||0
15|rsi|REAL|0||0
16|atr|REAL|0||0
17|bb_mid|REAL|0||0
18|bb_std|REAL|0||0
19|bb_up|REAL|0||0
20|bb_low|REAL|0||0
21|bb_width|REAL|0||0
22|mom|REAL|0||0
23|roc|REAL|0||0
24|slope|REAL|0||0
25|ctx|TEXT|0||0
26|plus_di|REAL|0||0
27|minus_di|REAL|0||0
28|adx|REAL|0||0
29|age_ms||0||0

[TABLE: v_range_1m]
0|instId|TEXT|0||0
1|ts|INTEGER|0||0
2|high_20||0||0
3|low_20||0||0
4|atr|REAL|0||0
5|bb_width|REAL|0||0
6|compression_ok||0||0

-- VIEWS --
v_atr_context|CREATE VIEW v_atr_context AS
WITH
atr1 AS (
    SELECT instId, atr AS atr_1m, age_ms
    FROM v_feat_1m
),
atr3 AS (
    SELECT instId, atr AS atr_3m
    FROM v_feat_3m
),
atr5 AS (
    SELECT instId, atr AS atr_5m
    FROM v_feat_5m
),
rng AS (
    SELECT instId, compression_ok
    FROM v_range_1m
)
SELECT
    a1.instId,

    -- ATR par horizon
    a1.atr_1m,
    a3.atr_3m,
    a5.atr_5m,

    -- Ratios ATR (guards division)
    CASE
        WHEN a3.atr_3m > 0 THEN a1.atr_1m / a3.atr_3m
        ELSE NULL
    END AS ratio_1m_3m,

    CASE
        WHEN a5.atr_5m > 0 THEN a1.atr_1m / a5.atr_5m
        ELSE NULL
    END AS ratio_1m_5m,

    CASE
        WHEN a5.atr_5m > 0 THEN a3.atr_3m / a5.atr_5m
        ELSE NULL
    END AS ratio_3m_5m,

    -- Compression / contexte
    r.compression_ok,

    -- Fra√Æcheur
    a1.age_ms

FROM atr1 a1
LEFT JOIN atr3 a3 ON a1.instId = a3.instId
LEFT JOIN atr5 a5 ON a1.instId = a5.instId
LEFT JOIN rng  r  ON a1.instId = r.instId
v_feat_1m|CREATE VIEW v_feat_1m AS
SELECT
  f.instId,
  f.ts,
  f.o,
  f.h,
  f.l,
  f.c,
  f.v,
  f.ema9,
  f.ema12,
  f.ema21,
  f.ema26,
  f.ema50,
  f.macd,
  f.macdsignal,
  f.macdhist,
  f.rsi,
  f.atr,
  f.bb_mid,
  f.bb_std,
  f.bb_up,
  f.bb_low,
  f.bb_width,
  f.mom,
  f.roc,
  f.slope,
  f.ctx,
  f.plus_di,
  f.minus_di,
  f.adx,
  (strftime('%s','now')*1000 - f.ts) AS age_ms
FROM feat_1m f
JOIN (
  SELECT instId, MAX(ts) AS ts
  FROM feat_1m
  GROUP BY instId
) last
ON f.instId = last.instId
AND f.ts = last.ts
v_feat_3m|CREATE VIEW v_feat_3m AS
SELECT *,
       (strftime('%s','now')*1000 - ts) AS age_ms
FROM feat_3m
v_feat_5m|CREATE VIEW v_feat_5m AS
SELECT *,
       (strftime('%s','now')*1000 - ts) AS age_ms
FROM feat_5m
v_range_1m|CREATE VIEW v_range_1m AS
WITH w AS (
  SELECT
    instId,
    ts,
    MAX(h) OVER win AS high_20,
    MIN(l) OVER win AS low_20,
    atr,
    bb_width,
    AVG(bb_width) OVER win AS bb_width_avg,
    ROW_NUMBER() OVER (PARTITION BY instId ORDER BY ts DESC) AS rn
  FROM feat_1m
  WINDOW win AS (
    PARTITION BY instId
    ORDER BY ts
    ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
  )
)
SELECT
  instId,
  ts,
  high_20,
  low_20,
  atr,
  bb_width,
  CASE
    WHEN bb_width_avg IS NOT NULL
     AND bb_width < bb_width_avg * 0.85
    THEN 1
    ELSE 0
  END AS compression_ok
FROM w
WHERE rn = 1

-- INDEXES --
idx_feat1|CREATE INDEX idx_feat1 ON feat_1m(instId, ts DESC)
idx_feat3|CREATE INDEX idx_feat3 ON feat_3m(instId, ts DESC)
idx_feat5|CREATE INDEX idx_feat5 ON feat_5m(instId, ts DESC)
sqlite_autoindex_feat_1m_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/budget.db -----
-- TABLES --
balance            budget_state       v_budget_overview
budget_exposure    v_balance          v_exposure       

[TABLE: balance]
0|id|INTEGER|0||1
1|balance_usdt|REAL|1||0

[TABLE: budget_state]
0|id|INTEGER|0||1
1|equity|REAL|1||0
2|margin_used|REAL|1||0
3|free_balance|REAL|1||0
4|exposure|REAL|1||0
5|ts_ms|INTEGER|1||0

[TABLE: v_budget_overview]

[TABLE: budget_exposure]
0|uid|TEXT|0||1
1|notional_engaged|REAL|1||0
2|ts_update|INTEGER|1||0

[TABLE: v_balance]
0|balance_usdt|REAL|0||0

[TABLE: v_exposure]

-- VIEWS --
v_balance|CREATE VIEW v_balance AS
SELECT balance_usdt
FROM balance
WHERE id = 1
v_budget_overview|CREATE VIEW v_budget_overview AS
SELECT
  ROUND(balance,6) AS balance,
  ROUND(margin,6)  AS margin,
  ROUND(pnl_real,6) AS pnl_real,
  datetime(ts_update,'unixepoch','localtime') AS last_update
FROM budget_state
v_exposure|CREATE VIEW v_exposure AS
SELECT
    instId,
    ROUND(SUM(CASE WHEN type='margin' THEN amount ELSE 0 END),6) AS margin,
    ROUND(SUM(CASE WHEN type='pnl_real' THEN amount ELSE 0 END),6) AS pnl_real
FROM ledger
GROUP BY instId
ORDER BY ABS(margin) DESC

-- INDEXES --
sqlite_autoindex_budget_exposure_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/closer.db -----
-- TABLES --
closer             trades_close       v_closer           v_closer_for_gest

[TABLE: closer]
0|uid|TEXT|1||1
1|exec_type|TEXT|1||2
2|side|TEXT|1||0
3|qty|REAL|1||0
4|price_exec|REAL|0||0
5|fee|REAL|0|0.0|0
6|step|INTEGER|0|0|3
7|reason|TEXT|0||0
8|ts_exec|INTEGER|1||0
9|status|TEXT|1||0
10|instId|TEXT|0||0
11|close_step|INTEGER|0|0|0
12|ratio|REAL|0||0
13|qty_raw|REAL|0||0
14|qty_norm|REAL|0||0
15|reject_reason|TEXT|0||0

[TABLE: trades_close]
0|uid|TEXT|0||1
1|instId|TEXT|1||0
2|price_exec|REAL|1||0
3|ts_exec|INTEGER|1||0

[TABLE: v_closer]
0|uid|TEXT|0||0
1|instId|TEXT|0||0
2|exec_type|TEXT|0||0
3|side|TEXT|0||0
4|qty|REAL|0||0
5|price_exec|REAL|0||0
6|fee|REAL|0||0
7|step|INTEGER|0||0
8|close_step|INTEGER|0||0
9|status|TEXT|0||0
10|ts_exec|INTEGER|0||0

[TABLE: v_closer_for_gest]
0|uid|TEXT|0||0
1|ts_close|INTEGER|0||0
2|price_close|REAL|0||0
3|pnl_usdt||0||0
4|pnl_pct||0||0
5|status||0||0
6|reason_close||0||0

-- VIEWS --
v_closer|CREATE VIEW v_closer AS
SELECT
    uid,
    instId,
    exec_type,
    side,
    qty,
    price_exec,
    fee,
    step,
    close_step,
    status,
    ts_exec
FROM closer
v_closer_for_gest|CREATE VIEW v_closer_for_gest AS
SELECT
    uid,
    ts_exec      AS ts_close,
    price_exec   AS price_close,
    NULL         AS pnl_usdt,
    NULL         AS pnl_pct,
    'closed'     AS status,
    NULL         AS reason_close
FROM trades_close
ORDER BY ts_exec ASC

-- INDEXES --
sqlite_autoindex_closer_1|
sqlite_autoindex_trades_close_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/contracts.db -----
-- TABLES --
contracts    v_contracts

[TABLE: contracts]
0|symbol|TEXT|0||1
1|baseCoin|TEXT|0||0
2|quoteCoin|TEXT|0||0
3|minTradeNum|REAL|0||0
4|minTradeUSDT|REAL|0||0
5|pricePlace|INTEGER|0||0
6|volumePlace|INTEGER|0||0
7|sizeMultiplier|REAL|0||0
8|minLever|INTEGER|0||0
9|maxLever|INTEGER|0||0
10|makerFee|REAL|0||0
11|takerFee|REAL|0||0
12|maxOrderQty|REAL|0||0
13|maxMarketOrderQty|REAL|0||0
14|symbolStatus|TEXT|0||0
15|last_update|INTEGER|0||0

[TABLE: v_contracts]
0|symbol|TEXT|0||0
1|minTradeUSDT|REAL|0||0
2|minTradeNum|REAL|0||0
3|minLever|INTEGER|0||0
4|maxLever|INTEGER|0||0
5|pricePlace|INTEGER|0||0
6|volumePlace|INTEGER|0||0
7|makerFee|REAL|0||0
8|takerFee|REAL|0||0
9|sizeMultiplier|REAL|0||0
10|symbolStatus|TEXT|0||0

-- VIEWS --
v_contracts|CREATE VIEW v_contracts AS
SELECT
    symbol,
    minTradeUSDT,
    minTradeNum,
    minLever,
    maxLever,
    pricePlace,
    volumePlace,
    makerFee    AS makerFee,
    takerFee    AS takerFee,
    sizeMultiplier,
    symbolStatus
FROM contracts

-- INDEXES --
sqlite_autoindex_contracts_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/ctx_macro.db -----
-- TABLES --
ctx_macro         ctx_macro_detail

[TABLE: ctx_macro]
0|ts|INTEGER|0||1
1|universe_size|INTEGER|1||0
2|breadth_value|REAL|1||0
3|breadth_state|TEXT|1||0
4|direction_value|REAL|0||0
5|direction_disp|REAL|0||0
6|direction_state|TEXT|0||0
7|risk_value|REAL|0||0
8|risk_state|TEXT|0||0
9|vol_value|REAL|0||0
10|vol_ref|REAL|0||0
11|vol_state|TEXT|0||0
12|regime|TEXT|0||0

[TABLE: ctx_macro_detail]
0|ts|INTEGER|1||1
1|instId|TEXT|1||2
2|ret_value|REAL|0||0
3|atr_value|REAL|0||0
4|active|INTEGER|0||0

-- VIEWS --

-- INDEXES --
ix_ctx_macro_detail_ts|CREATE INDEX ix_ctx_macro_detail_ts
ON ctx_macro_detail(ts)
ix_ctx_macro_ts|CREATE INDEX ix_ctx_macro_ts
ON ctx_macro(ts)
sqlite_autoindex_ctx_macro_detail_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/dec.db -----
-- TABLES --
dec_breakout          v_dec_cont            v_dec_pb            
dec_fire_log          v_dec_debug_ctx       v_dec_prebreak      
snap_atr              v_dec_drift           v_dec_pullback      
snap_ctx              v_dec_drift_simple    v_dec_pyramide_ok   
snap_range            v_dec_explain         v_dec_rejected      
snap_ticks            v_dec_fbo             v_dec_score_s       
ticks_live            v_dec_fire            v_snap_range_valid  
v_dec_armed           v_dec_fire_debug      v_snap_ticks_latest 
v_dec_bo              v_dec_flags           v_triggers_norm     
v_dec_breakout_ready  v_dec_market_ok     
v_dec_candidates      v_dec_momentum      

[TABLE: dec_breakout]
0|instId|TEXT|0||1
1|ts|INTEGER|0||0
2|side|TEXT|0||0
3|price|REAL|0||0
4|range_high|REAL|0||0
5|range_low|REAL|0||0
6|atr|REAL|0||0
7|score_ctx|REAL|0||0
8|regime|TEXT|0||0
9|compression_ok|INTEGER|0||0
10|breakout_now|INTEGER|0||0
11|ctx|TEXT|0||0
12|score_C|REAL|0||0
13|ts_updated|INTEGER|0||0
14|high_20|REAL|0||0
15|low_20|REAL|0||0
16|bb_width|REAL|0||0

[TABLE: v_dec_cont]
0|instId|TEXT|0||0
1|ctx|TEXT|0||0
2|score_C|REAL|0||0
3|side|TEXT|0||0
4|ctx_ok|INTEGER|0||0
5|high_20|REAL|0||0
6|low_20|REAL|0||0
7|atr|REAL|0||0
8|bb_width|REAL|0||0
9|compression_ok|INTEGER|0||0
10|lastPr|REAL|0||0
11|fire_cont||0||0

[TABLE: v_dec_pb]
0|instId|TEXT|0||0
1|ctx|TEXT|0||0
2|score_C|REAL|0||0
3|side|TEXT|0||0
4|ctx_ok|INTEGER|0||0
5|high_20|REAL|0||0
6|low_20|REAL|0||0
7|atr|REAL|0||0
8|bb_width|REAL|0||0
9|compression_ok|INTEGER|0||0
10|lastPr|REAL|0||0
11|armed_pb||0||0

[TABLE: dec_fire_log]
0|ts|INTEGER|1||1
1|instId|TEXT|1||2
2|ctx|TEXT|0||0
3|score_dec|REAL|0||0
4|regime|TEXT|0||0
5|reason|TEXT|0||0

[TABLE: v_dec_debug_ctx]
0|instId|TEXT|0||0
1|ctx|TEXT|0||0
2|side|TEXT|0||0
3|score_C|REAL|0||0
4|atr_fast|REAL|0||0
5|atr_slow|REAL|0||0
6|vol_regime|TEXT|0||0
7|vol_flag||0||0
8|age_ms||0||0

[TABLE: v_dec_prebreak]
0|instId|TEXT|0||0
1|ctx|TEXT|0||0
2|score_C|REAL|0||0
3|side|TEXT|0||0
4|ctx_ok|INTEGER|0||0
5|high_20|REAL|0||0
6|low_20|REAL|0||0
7|atr|REAL|0||0
8|bb_width|REAL|0||0
9|compression_ok|INTEGER|0||0
10|lastPr|REAL|0||0
11|prebreak_ok||0||0

[TABLE: snap_atr]
0|instId|TEXT|0||1
1|atr_1m|REAL|0||0
2|atr_3m|REAL|0||0
3|atr_5m|REAL|0||0
4|atr_15m|REAL|0||0
5|atr_30m|REAL|0||0
6|ratio_1m_5m|REAL|0||0
7|ratio_5m_15m|REAL|0||0
8|ratio_5m_30m|REAL|0||0
9|vol_regime|TEXT|0||0
10|ts_updated|INTEGER|0||0

[TABLE: v_dec_drift]
0|instId|TEXT|0||0
1|ctx|TEXT|0||0
2|score_C|REAL|0||0
3|side|TEXT|0||0
4|ctx_ok|INTEGER|0||0
5|high_20|REAL|0||0
6|low_20|REAL|0||0
7|atr|REAL|0||0
8|bb_width|REAL|0||0
9|compression_ok|INTEGER|0||0
10|lastPr|REAL|0||0
11|drift_ok||0||0

[TABLE: v_dec_pullback]
0|instId|TEXT|0||0
1|ctx|TEXT|0||0
2|score_C|REAL|0||0
3|side|TEXT|0||0
4|ctx_ok|INTEGER|0||0
5|high_20|REAL|0||0
6|low_20|REAL|0||0
7|atr|REAL|0||0
8|bb_width|REAL|0||0
9|compression_ok|INTEGER|0||0
10|lastPr|REAL|0||0
11|pullback_ok||0||0

[TABLE: snap_ctx]
0|instId|TEXT|0||1
1|ctx|TEXT|0||0
2|score_C|REAL|0||0
3|side|TEXT|0||0
4|ctx_ok|INTEGER|0||0
5|ts_updated|INTEGER|0||0
6|atr_fast|REAL|0||0
7|atr_slow|REAL|0||0
8|vol_regime|TEXT|0||0

[TABLE: v_dec_drift_simple]
0|instId|TEXT|0||0
1|ctx|TEXT|0||0
2|score_C|REAL|0||0
3|side|TEXT|0||0
4|ctx_ok|INTEGER|0||0
5|high_20|REAL|0||0
6|low_20|REAL|0||0
7|atr|REAL|0||0
8|bb_width|REAL|0||0
9|compression_ok|INTEGER|0||0
10|lastPr|REAL|0||0
11|drift_ok||0||0

[TABLE: v_dec_pyramide_ok]

[TABLE: snap_range]
0|instId|TEXT|0||1
1|high_20|REAL|0||0
2|low_20|REAL|0||0
3|atr|REAL|0||0
4|bb_width|REAL|0||0
5|compression_ok|INTEGER|0||0
6|ts|INTEGER|0||0

[TABLE: v_dec_explain]
0|instId|TEXT|0||0
1|side|TEXT|0||0
2|ctx|TEXT|0||0
3|score_C|REAL|0||0
4|lastPr|REAL|0||0
5|high_20|REAL|0||0
6|low_20|REAL|0||0
7|atr|REAL|0||0
8|compression_ok|INTEGER|0||0
9|prebreak_ok||0||0
10|pullback_ok||0||0
11|momentum_ok||0||0
12|dec_mode||0||0

[TABLE: v_dec_rejected]
0|instId|TEXT|0||0
1|ctx|TEXT|0||0
2|score_C|REAL|0||0
3|atr|REAL|0||0
4|bb_width|REAL|0||0
5|compression_ok|INTEGER|0||0

[TABLE: snap_ticks]
0|instId|TEXT|0||1
1|lastPr|REAL|1||0
2|ts|INTEGER|1||0

[TABLE: v_dec_fbo]
0|instId|TEXT|0||0
1|ctx|TEXT|0||0
2|score_C|REAL|0||0
3|side|TEXT|0||0
4|ctx_ok|INTEGER|0||0
5|high_20|REAL|0||0
6|low_20|REAL|0||0
7|atr|REAL|0||0
8|bb_width|REAL|0||0
9|compression_ok|INTEGER|0||0
10|lastPr|REAL|0||0
11|fire_fbo||0||0

[TABLE: v_dec_score_s]

[TABLE: ticks_live]
0|instId|TEXT|0||1
1|lastPr|REAL|1||0
2|ts_ms|INTEGER|1||0

[TABLE: v_dec_fire]
0|instId|TEXT|0||0
1|side|TEXT|0||0
2|lastPr|REAL|0||0
3|atr|REAL|0||0
4|dec_mode||0||0
5|score_C|REAL|0||0
6|ctx|TEXT|0||0
7|fire||0||0

[TABLE: v_snap_range_valid]
0|instId|TEXT|0||0
1|high_20|REAL|0||0
2|low_20|REAL|0||0
3|atr|REAL|0||0
4|bb_width|REAL|0||0
5|compression_ok|INTEGER|0||0
6|ts|INTEGER|0||0

[TABLE: v_dec_armed]
0|instId|TEXT|0||0
1|side|TEXT|0||0
2|ctx|TEXT|0||0
3|score_C|REAL|0||0
4|lastPr|REAL|0||0
5|high_20|REAL|0||0
6|low_20|REAL|0||0
7|atr|REAL|0||0
8|compression_ok|INTEGER|0||0
9|prebreak_ok||0||0
10|pullback_ok||0||0
11|momentum_ok||0||0
12|dec_mode||0||0
13|armed||0||0

[TABLE: v_dec_fire_debug]
0|instId|TEXT|0||0
1|side|TEXT|0||0
2|lastPr||0||0
3|atr|REAL|0||0
4|dec_mode|TEXT|0||0
5|score_C|REAL|0||0
6|ctx|TEXT|0||0
7|fire||0||0

[TABLE: v_snap_ticks_latest]

[TABLE: v_dec_bo]
0|instId|TEXT|0||0
1|ctx|TEXT|0||0
2|score_C|REAL|0||0
3|side|TEXT|0||0
4|ctx_ok|INTEGER|0||0
5|high_20|REAL|0||0
6|low_20|REAL|0||0
7|atr|REAL|0||0
8|bb_width|REAL|0||0
9|compression_ok|INTEGER|0||0
10|lastPr|REAL|0||0
11|fire_bo||0||0

[TABLE: v_dec_flags]

[TABLE: v_triggers_norm]

[TABLE: v_dec_breakout_ready]
0|instId|TEXT|0||0
1|ts|INTEGER|0||0
2|side|TEXT|0||0
3|price|REAL|0||0
4|range_high|REAL|0||0
5|range_low|REAL|0||0
6|atr|REAL|0||0
7|score_ctx|REAL|0||0
8|regime|TEXT|0||0
9|compression_ok|INTEGER|0||0
10|breakout_now|INTEGER|0||0
11|ctx|TEXT|0||0
12|score_C|REAL|0||0
13|ts_updated|INTEGER|0||0
14|high_20|REAL|0||0
15|low_20|REAL|0||0
16|bb_width|REAL|0||0

[TABLE: v_dec_market_ok]

[TABLE: v_dec_candidates]
0|instId|TEXT|0||0
1|ctx|TEXT|0||0
2|score_C|REAL|0||0
3|side|TEXT|0||0
4|ctx_ok|INTEGER|0||0
5|high_20|REAL|0||0
6|low_20|REAL|0||0
7|atr|REAL|0||0
8|bb_width|REAL|0||0
9|compression_ok|INTEGER|0||0
10|lastPr|REAL|0||0

[TABLE: v_dec_momentum]
0|instId|TEXT|0||0
1|ctx|TEXT|0||0
2|score_C|REAL|0||0
3|side|TEXT|0||0
4|ctx_ok|INTEGER|0||0
5|high_20|REAL|0||0
6|low_20|REAL|0||0
7|atr|REAL|0||0
8|bb_width|REAL|0||0
9|compression_ok|INTEGER|0||0
10|lastPr|REAL|0||0
11|momentum_ok||0||0

-- VIEWS --
v_dec_armed|CREATE VIEW v_dec_armed AS
SELECT
  e.*,
  CASE
    WHEN e.dec_mode IN ('PREBREAK','MOMENTUM')
    THEN 1
    ELSE 0
  END AS armed
FROM v_dec_explain e
v_dec_bo|CREATE VIEW v_dec_bo AS
SELECT *,
  CASE
    WHEN ctx_ok=1
     AND compression_ok=1
     AND (
       (side='buy'  AND lastPr > high_20) OR
       (side='sell' AND lastPr < low_20)
     )
    THEN 1 ELSE 0
  END AS fire_bo
FROM v_dec_candidates
v_dec_breakout_ready|CREATE VIEW v_dec_breakout_ready AS
SELECT *
FROM dec_breakout
WHERE breakout_now = 1
v_dec_candidates|CREATE VIEW v_dec_candidates AS
SELECT
  c.instId,
  c.ctx,
  c.score_C,
  c.side,
  c.ctx_ok,

  r.high_20,
  r.low_20,
  r.atr,
  r.bb_width,
  r.compression_ok,

  t.lastPr
FROM snap_ctx c
LEFT JOIN snap_range r
  ON r.instId = c.instId
LEFT JOIN snap_ticks t
  ON t.instId = c.instId
WHERE c.ctx_ok = 1
  AND c.side IS NOT NULL
  AND t.lastPr IS NOT NULL
v_dec_cont|CREATE VIEW v_dec_cont AS
SELECT *,
  CASE
    WHEN ctx_ok=1
     AND (
       (side='buy'  AND lastPr > high_20 + atr*0.5) OR
       (side='sell' AND lastPr < low_20  - atr*0.5)
     )
    THEN 1 ELSE 0
  END AS fire_cont
FROM v_dec_candidates
v_dec_debug_ctx|CREATE VIEW v_dec_debug_ctx AS
SELECT
    instId,
    ctx,
    side,
    score_C,
    atr_fast,
    atr_slow,
    vol_regime,
    CASE
        WHEN vol_regime = 'COMPRESS' THEN 'COMPRESS'
        WHEN vol_regime = 'EXPAND'  THEN 'EXPAND'
        ELSE 'NORMAL'
    END AS vol_flag,
    (strftime('%s','now')*1000 - ts_updated) AS age_ms
FROM snap_ctx
v_dec_drift|CREATE VIEW v_dec_drift AS
SELECT
  d.*,

  CASE
    WHEN
      d.ctx_ok = 1
      AND d.atr IS NOT NULL
      AND d.high_20 IS NOT NULL
      AND d.low_20  IS NOT NULL
      AND (
        (d.side = 'buy'
          AND d.lastPr >
              d.low_20 + (d.high_20 - d.low_20) * 0.55
        )
        OR
        (d.side = 'sell'
          AND d.lastPr <
              d.high_20 - (d.high_20 - d.low_20) * 0.55
        )
      )
    THEN 1 ELSE 0
  END AS drift_ok

FROM v_dec_candidates d
v_dec_drift_simple|CREATE VIEW v_dec_drift_simple AS
SELECT
  d.*,
  CASE
    WHEN d.ctx_ok = 1
     AND d.atr IS NOT NULL
     AND d.lastPr IS NOT NULL
     AND d.high_20 IS NOT NULL
     AND d.low_20  IS NOT NULL
     AND d.lastPr >= d.low_20
     AND d.lastPr <= d.high_20
    THEN 1 ELSE 0
  END AS drift_ok
FROM v_dec_candidates d
v_dec_explain|CREATE VIEW v_dec_explain AS
SELECT
  c.instId,
  c.side,
  c.ctx,
  c.score_C,

  c.lastPr,
  c.high_20,
  c.low_20,
  c.atr,

  r.compression_ok,
  pb.prebreak_ok,
  pl.pullback_ok,
  mo.momentum_ok,

  CASE
    WHEN pb.prebreak_ok = 1 THEN 'PREBREAK'
    WHEN mo.momentum_ok = 1 THEN 'MOMENTUM'
    WHEN pl.pullback_ok = 1 THEN 'PULLBACK'
    ELSE 'NO_ENTRY'
  END AS dec_mode

FROM v_dec_candidates c
LEFT JOIN snap_range r USING(instId)
LEFT JOIN v_dec_prebreak pb USING(instId)
LEFT JOIN v_dec_pullback pl USING(instId)
LEFT JOIN v_dec_momentum mo USING(instId)
v_dec_fbo|CREATE VIEW v_dec_fbo AS
SELECT *,
  CASE
    WHEN ctx_ok=1
     AND (
       (side='buy'
         AND lastPr < high_20
         AND lastPr > low_20
       )
       OR
       (side='sell'
         AND lastPr > low_20
         AND lastPr < high_20
       )
     )
    THEN 1 ELSE 0
  END AS fire_fbo
FROM v_dec_candidates
WHERE compression_ok=1
v_dec_fire|CREATE VIEW v_dec_fire AS
WITH base AS (
    SELECT
        s.instId,
        s.side,
        s.ctx,
        s.score_C,
        s.atr_fast,
        s.atr_slow,
        s.vol_regime,
        t.lastPr,
        s.ts_updated
    FROM snap_ctx s
    JOIN ticks_live t   -- ‚úÖ PRIX MARCH√â R√âEL LOCAL
      ON t.instId = s.instId
    WHERE s.ctx_ok = 1
),
patterned AS (
    SELECT *,
        CASE
            WHEN ctx='bullish' AND vol_regime='EXPAND'  THEN 'MOMENTUM'
            WHEN ctx='bullish' AND vol_regime='NORMAL'  THEN 'CONT'
            WHEN ctx='bearish' AND vol_regime='NORMAL'  THEN 'DRIFT'
            WHEN ctx='bearish' AND vol_regime='COMPRESS' THEN 'PREBREAK'
            ELSE 'IGNORE'
        END AS dec_mode
    FROM base
),
admission AS (
    SELECT *,
        CASE
            WHEN dec_mode='MOMENTUM' AND ABS(score_C)>=0.45 THEN 1
            WHEN dec_mode='PREBREAK' THEN 1
            WHEN dec_mode='DRIFT' AND ABS(score_C)>=0.30 THEN 1
            WHEN dec_mode='CONT'  AND ABS(score_C)>=0.30 THEN 1
            ELSE 0
        END AS fire
    FROM patterned
)
SELECT
    instId, side, lastPr, atr_fast AS atr,
    dec_mode, score_C, ctx, fire
FROM admission
WHERE fire=1
v_dec_fire_debug|CREATE VIEW v_dec_fire_debug AS
SELECT
  instId,
  side,
  0.0      AS lastPr,
  atr_fast AS atr,
  ctx      AS dec_mode,
  score_C,
  ctx,
  1        AS fire
FROM snap_ctx
WHERE ctx_ok = 1
v_dec_flags|CREATE VIEW v_dec_flags AS
WITH latest_ticks AS (
  SELECT
    instId_s,
    lastPr,
    ts
  FROM snap_ticks t1
  WHERE ts = (
    SELECT MAX(ts)
    FROM snap_ticks t2
    WHERE t2.instId_s = t1.instId_s
  )
)
SELECT
  c.instId,
  c.side,
  c.score_C,
  c.ctx_ok,

  t.lastPr,
  t.ts AS tick_ts,

  r.high_20,
  r.low_20,
  r.atr,
  r.bb_width,
  r.compression_ok,

  CASE
    WHEN r.atr IS NOT NULL
     AND r.high_20 IS NOT NULL
     AND r.low_20 IS NOT NULL
     AND (
       (c.side='buy'  AND t.lastPr > r.high_20 + r.atr*0.60) OR
       (c.side='sell' AND t.lastPr < r.low_20  - r.atr*0.60)
     )
    THEN 1 ELSE 0
  END AS cont_ok,

  CASE
    WHEN r.atr IS NOT NULL
     AND r.high_20 IS NOT NULL
     AND r.low_20 IS NOT NULL
     AND (
       (c.side='sell' AND t.lastPr <= r.low_20  + r.atr*0.20) OR
       (c.side='buy'  AND t.lastPr >= r.high_20 - r.atr*0.20)
     )
    THEN 1 ELSE 0
  END AS trend_ok,

  CASE
    WHEN c.ctx_ok = 1
     AND (
       (c.side='sell' AND c.score_C <= -0.30) OR
       (c.side='buy'  AND c.score_C >=  0.30)
     )
    THEN 1 ELSE 0
  END AS drift_ok

FROM snap_ctx c
LEFT JOIN snap_range r
  ON r.instId = c.instId
LEFT JOIN latest_ticks t
  ON t.instId_s = c.instId

WHERE c.ctx_ok = 1
  AND c.side IS NOT NULL
  AND t.lastPr IS NOT NULL
v_dec_market_ok|CREATE VIEW v_dec_market_ok AS
SELECT *
FROM v_dec_candidates
WHERE instId IN (
    SELECT instId
    FROM market_latest
    WHERE market_ok = 1
)
v_dec_momentum|CREATE VIEW v_dec_momentum AS
SELECT
  d.*,
  CASE
    WHEN d.atr IS NOT NULL
     AND d.compression_ok = 0
     AND (
       (d.side='buy'
        AND d.lastPr > d.low_20 + (d.high_20-d.low_20)*0.65)
       OR
       (d.side='sell'
        AND d.lastPr < d.high_20 - (d.high_20-d.low_20)*0.65)
     )
    THEN 1 ELSE 0
  END AS momentum_ok
FROM v_dec_candidates d
v_dec_pb|CREATE VIEW v_dec_pb AS
SELECT *,
  CASE
    WHEN ctx_ok=1
     AND compression_ok=0
     AND (
       (side='buy'
         AND lastPr < high_20
         AND lastPr > (high_20 - (high_20-low_20)*0.62)
       )
       OR
       (side='sell'
         AND lastPr > low_20
         AND lastPr < (low_20 + (high_20-low_20)*0.62)
       )
     )
    THEN 1 ELSE 0
  END AS armed_pb
FROM v_dec_candidates
v_dec_prebreak|CREATE VIEW v_dec_prebreak AS
SELECT
  d.*,
  CASE
    WHEN d.compression_ok = 1
     AND d.atr IS NOT NULL
     AND (
       (d.side='buy'  AND d.lastPr >= d.high_20 - d.atr * 0.25) OR
       (d.side='sell' AND d.lastPr <= d.low_20  + d.atr * 0.25)
     )
    THEN 1 ELSE 0
  END AS prebreak_ok
FROM v_dec_candidates d
v_dec_pullback|CREATE VIEW v_dec_pullback AS
SELECT
  d.*,
  CASE
    WHEN d.atr IS NOT NULL
     AND (
       (d.side='buy'
        AND d.lastPr < d.high_20
        AND d.lastPr > d.high_20 - d.atr * 0.6)
       OR
       (d.side='sell'
        AND d.lastPr > d.low_20
        AND d.lastPr < d.low_20 + d.atr * 0.6)
     )
    THEN 1 ELSE 0
  END AS pullback_ok
FROM v_dec_candidates d
v_dec_pyramide_ok|CREATE VIEW v_dec_pyramide_ok AS
SELECT
    instId,
    cont_ok,
    drift_ok,
    score_C
FROM v_dec_flags
WHERE cont_ok = 1
v_dec_rejected|CREATE VIEW v_dec_rejected AS
SELECT
  instId,
  ctx,
  score_C,
  atr,
  bb_width,
  compression_ok
FROM snap_ctx
LEFT JOIN snap_range USING(instId)
WHERE ctx_ok = 0
v_dec_score_s|CREATE VIEW v_dec_score_s AS
SELECT
    d.*,

    /* ================= STRUCTURE ================= */
    CASE
        WHEN d.cont_ok  = 1 THEN 1.00
        WHEN d.drift_ok = 1 THEN 0.70
        ELSE 0.0
    END AS s_struct,

    /* ================= TIMING COMBIN√â (ATR + RANGE) ================= */
    MIN(
        1.0,
        MAX(
            0.0,

            /* ATR adouci (K = 3) */
            0.5 * COALESCE(
                EXP(
                    -1.0 * (
                        ABS(
                            d.lastPr -
                            CASE
                                WHEN d.side='buy'  THEN d.high_20
                                WHEN d.side='sell' THEN d.low_20
                                ELSE d.lastPr
                            END
                        ) / NULLIF(d.atr * 3.0, 0)
                    )
                ),
                0.30
            )

            +

            /* Range timing */
            0.5 * COALESCE(
                CASE
                    WHEN d.high_20 IS NULL
                      OR d.low_20  IS NULL
                      OR d.high_20 <= d.low_20
                    THEN 0.30
                    ELSE
                        MAX(
                            0.0,
                            MIN(
                                1.0,
                                1.0 -
                                (
                                    ABS(
                                        d.lastPr -
                                        CASE
                                            WHEN d.side='buy'  THEN d.high_20
                                            WHEN d.side='sell' THEN d.low_20
                                            ELSE d.lastPr
                                        END
                                    ) /
                                    (d.high_20 - d.low_20)
                                )
                            )
                        )
                END,
                0.30
            )
        )
    ) AS s_timing,

    /* ================= QUALIT√â (range ^0.65 * timing) ================= */
    MAX(
        0.25,   -- PLANCHER DE QUALIT√â (CRITIQUE)
        MIN(
            1.0,
            POWER(
                CASE
                    WHEN d.high_20 IS NULL
                      OR d.low_20  IS NULL
                      OR d.high_20 <= d.low_20
                    THEN 0.30

                    WHEN d.side='buy' THEN
                        MAX(
                            0.0,
                            MIN(
                                1.0,
                                (d.high_20 - d.lastPr) /
                                (d.high_20 - d.low_20)
                            )
                        )

                    WHEN d.side='sell' THEN
                        MAX(
                            0.0,
                            MIN(
                                1.0,
                                (d.lastPr - d.low_20) /
                                (d.high_20 - d.low_20)
                            )
                        )

                    ELSE 0.30
                END,
                0.65
            )
            *
            MIN(
                1.0,
                MAX(
                    0.0,

                    0.5 * COALESCE(
                        EXP(
                            -1.0 * (
                                ABS(
                                    d.lastPr -
                                    CASE
                                        WHEN d.side='buy'  THEN d.high_20
                                        WHEN d.side='sell' THEN d.low_20
                                        ELSE d.lastPr
                                    END
                                ) / NULLIF(d.atr * 3.0, 0)
                            )
                        ),
                        0.30
                    )

                    +

                    0.5 * COALESCE(
                        CASE
                            WHEN d.high_20 IS NULL
                              OR d.low_20  IS NULL
                              OR d.high_20 <= d.low_20
                            THEN 0.30
                            ELSE
                                MAX(
                                    0.0,
                                    MIN(
                                        1.0,
                                        1.0 -
                                        (
                                            ABS(
                                                d.lastPr -
                                                CASE
                                                    WHEN d.side='buy'  THEN d.high_20
                                                    WHEN d.side='sell' THEN d.low_20
                                                    ELSE d.lastPr
                                                END
                                            ) /
                                            (d.high_20 - d.low_20)
                                        )
                                    )
                                )
                        END,
                        0.30
                    )
                )
            )
        )
    ) AS s_quality,

    /* ================= VOLATILIT√â ================= */
    CASE
        WHEN d.compression_ok = 1 THEN 1.00
        ELSE 0.70
    END AS s_vol,

    /* ================= CONFIRMATION ================= */
    (CASE WHEN d.cont_ok  = 1 THEN 0.20 ELSE 0.0 END) +
    (CASE WHEN d.drift_ok = 1 THEN 0.10 ELSE 0.0 END)
    AS s_confirm,

    /* ================= SCORE S FINAL ================= */
    MIN(
        1.0,
        MAX(
            0.0,
            0.40 * (
                CASE
                    WHEN d.cont_ok  = 1 THEN 1.00
                    WHEN d.drift_ok = 1 THEN 0.70
                    ELSE 0.0
                END
            )
            +
            0.30 * (
                MAX(
                    0.25,
                    MIN(
                        1.0,
                        POWER(
                            CASE
                                WHEN d.high_20 IS NULL
                                  OR d.low_20  IS NULL
                                  OR d.high_20 <= d.low_20
                                THEN 0.30

                                WHEN d.side='buy' THEN
                                    MAX(
                                        0.0,
                                        MIN(
                                            1.0,
                                            (d.high_20 - d.lastPr) /
                                            (d.high_20 - d.low_20)
                                        )
                                    )

                                WHEN d.side='sell' THEN
                                    MAX(
                                        0.0,
                                        MIN(
                                            1.0,
                                            (d.lastPr - d.low_20) /
                                            (d.high_20 - d.low_20)
                                        )
                                    )

                                ELSE 0.30
                            END,
                            0.65
                        )
                        *
                        MIN(
                            1.0,
                            MAX(
                                0.0,

                                0.5 * COALESCE(
                                    EXP(
                                        -1.0 * (
                                            ABS(
                                                d.lastPr -
                                                CASE
                                                    WHEN d.side='buy'  THEN d.high_20
                                                    WHEN d.side='sell' THEN d.low_20
                                                    ELSE d.lastPr
                                                END
                                            ) / NULLIF(d.atr * 3.0, 0)
                                        )
                                    ),
                                    0.30
                                )

                                +

                                0.5 * COALESCE(
                                    CASE
                                        WHEN d.high_20 IS NULL
                                          OR d.low_20  IS NULL
                                          OR d.high_20 <= d.low_20
                                        THEN 0.30
                                        ELSE
                                            MAX(
                                                0.0,
                                                MIN(
                                                    1.0,
                                                    1.0 -
                                                    (
                                                        ABS(
                                                            d.lastPr -
                                                            CASE
                                                                WHEN d.side='buy'  THEN d.high_20
                                                                WHEN d.side='sell' THEN d.low_20
                                                                ELSE d.lastPr
                                                            END
                                                        ) /
                                                        (d.high_20 - d.low_20)
                                                    )
                                                )
                                            )
                                    END,
                                    0.30
                                )
                            )
                        )
                    )
                )
            )
            +
            0.20 * (
                CASE
                    WHEN d.compression_ok = 1 THEN 1.00
                    ELSE 0.70
                END
            )
            +
            0.10 * (
                (CASE WHEN d.cont_ok  = 1 THEN 0.20 ELSE 0.0 END) +
                (CASE WHEN d.drift_ok = 1 THEN 0.10 ELSE 0.0 END)
            )
        )
    ) AS score_S

FROM v_dec_flags d
v_snap_range_valid|CREATE VIEW v_snap_range_valid AS
SELECT *
FROM snap_range
WHERE high_20 IS NOT NULL
  AND low_20  IS NOT NULL
  AND high_20 > low_20
  AND atr IS NOT NULL
  AND atr > 0
v_snap_ticks_latest|CREATE VIEW v_snap_ticks_latest AS
WITH latest AS (
  SELECT
    instId_s AS instId,
    lastPr,
    ts,
    ROW_NUMBER() OVER (PARTITION BY instId_s ORDER BY ts DESC) AS rn
  FROM snap_ticks
  WHERE instId_s IS NOT NULL
    AND instId_s <> ''
    AND lastPr IS NOT NULL
)
SELECT instId, lastPr, ts
FROM latest
WHERE rn = 1
v_triggers_norm|CREATE VIEW v_triggers_norm AS
SELECT
    instId,
    side,
    ctx,

    -- d√©clencheur principal
    dec_mode            AS trigger_type,

    -- m√©triques
    score_C,
    atr,

    -- √©tat
    fire                AS fired,

    -- flags analytiques
    momentum_ok,
    prebreak_ok,
    pullback_ok,
    compression_ok

FROM v_dec_fire
WHERE armed = 1

-- INDEXES --
idx_dec_fire_log_inst|CREATE INDEX idx_dec_fire_log_inst
    ON dec_fire_log(instId)
idx_dec_fire_log_ts|CREATE INDEX idx_dec_fire_log_ts
    ON dec_fire_log(ts)
idx_snap_atr_ts|CREATE INDEX idx_snap_atr_ts
ON snap_atr(ts_updated)
idx_snap_ticks_ts|CREATE INDEX idx_snap_ticks_ts
ON snap_ticks(ts DESC)
idx_ticks_live_ts|CREATE INDEX idx_ticks_live_ts ON ticks_live(ts_ms)
sqlite_autoindex_dec_breakout_1|
sqlite_autoindex_dec_fire_log_1|
sqlite_autoindex_snap_atr_1|
sqlite_autoindex_snap_ctx_1|
sqlite_autoindex_snap_range_1|
sqlite_autoindex_snap_ticks_1|
sqlite_autoindex_ticks_live_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/exec.db -----
-- TABLES --
exec                   v_exec_perf_by_step    v_exec_step_exit_perf
v_exec_ledger          v_exec_perf_step_exit  v_follower_monitoring
v_exec_monitoring      v_exec_pnl_uid         v_gest_monitoring    
v_exec_perf_by_exit    v_exec_position        v_ticks_monitoring   

[TABLE: exec]
0|exec_id|TEXT|0||1
1|uid|TEXT|1||0
2|step|INTEGER|1||0
3|exec_type|TEXT|1||0
4|side|TEXT|1||0
5|qty|REAL|1||0
6|price_exec|REAL|1||0
7|fee|REAL|0|0.0|0
8|status|TEXT|1||0
9|ts_exec|INTEGER|1||0
10|reason|TEXT|0||0
11|regime|TEXT|0||0
12|instId|TEXT|0||0
13|lev|REAL|1|1.0|0
14|pnl_realized_step|REAL|1|0.0|0
15|sl_be|REAL|0||0
16|sl_trail|REAL|0||0
17|tp_dyn|REAL|0||0
18|mfe_atr|REAL|0||0
19|mae_atr|REAL|0||0
20|golden|INTEGER|0||0
21|type_signal|TEXT|0||0
22|dec_mode|TEXT|0||0
23|done_step|INTEGER|0|0|0

[TABLE: v_exec_perf_by_step]
0|step|INTEGER|0||0
1|n||0||0
2|exp||0||0
3|pf||0||0

[TABLE: v_exec_step_exit_perf]
0|step|INTEGER|0||0
1|exec_type|TEXT|0||0
2|reason|TEXT|0||0
3|n||0||0
4|exp||0||0
5|pf||0||0
6|mfe_atr||0||0
7|mae_atr||0||0
8|golden_n||0||0

[TABLE: v_exec_ledger]
0|exec_id|TEXT|0||0
1|uid|TEXT|0||0
2|step|INTEGER|0||0
3|exec_type|TEXT|0||0
4|side|TEXT|0||0
5|qty|REAL|0||0
6|price_exec|REAL|0||0
7|fee|REAL|0||0
8|status|TEXT|0||0
9|ts_exec|INTEGER|0||0

[TABLE: v_exec_perf_step_exit]
0|step|INTEGER|0||0
1|reason|TEXT|0||0
2|n||0||0
3|exp||0||0

[TABLE: v_follower_monitoring]

[TABLE: v_exec_monitoring]
0|uid|TEXT|0||0
1|side||0||0
2|qty_open||0||0
3|avg_price_open||0||0
4|last_exec_type|TEXT|0||0
5|last_step|INTEGER|0||0
6|last_price_exec|REAL|0||0
7|last_ts_exec|INTEGER|0||0

[TABLE: v_exec_pnl_uid]
0|uid|TEXT|0||0
1|pnl_realized||0||0

[TABLE: v_gest_monitoring]

[TABLE: v_exec_perf_by_exit]
0|reason|TEXT|0||0
1|n||0||0
2|exp||0||0
3|pf||0||0

[TABLE: v_exec_position]
0|uid|TEXT|0||0
1|side||0||0
2|qty_open||0||0
3|avg_price_open||0||0
4|fee_total||0||0
5|last_exec_type|TEXT|0||0
6|last_step|INTEGER|0||0
7|last_price_exec|REAL|0||0
8|last_ts_exec|INTEGER|0||0

[TABLE: v_ticks_monitoring]

-- VIEWS --
v_exec_ledger|CREATE VIEW v_exec_ledger AS
SELECT
  exec_id,
  uid,
  step,
  exec_type,
  side,
  qty,
  price_exec,
  fee,
  status,
  ts_exec
FROM exec
WHERE status='done'
/* v_exec_ledger(exec_id,uid,step,exec_type,side,qty,price_exec,fee,status,ts_exec) */
v_exec_monitoring|CREATE VIEW v_exec_monitoring AS
SELECT
    uid,
    side,
    qty_open,
    avg_price_open,
    last_exec_type,
    last_step,
    last_price_exec,
    last_ts_exec
FROM v_exec_position
v_exec_perf_by_exit|CREATE VIEW v_exec_perf_by_exit AS
    SELECT
        reason,
        COUNT(*)                       AS n,
        AVG(pnl_realized_step)         AS exp,
        SUM(CASE WHEN pnl_realized_step > 0 THEN pnl_realized_step ELSE 0 END)
        / ABS(SUM(CASE WHEN pnl_realized_step < 0 THEN pnl_realized_step ELSE 0 END)) AS pf
    FROM exec
    WHERE exec_type IN ('close','partial')
    GROUP BY reason
v_exec_perf_by_step|CREATE VIEW v_exec_perf_by_step AS
    SELECT
        step,
        COUNT(*)                       AS n,
        AVG(pnl_realized_step)         AS exp,
        SUM(CASE WHEN pnl_realized_step > 0 THEN pnl_realized_step ELSE 0 END)
        / ABS(SUM(CASE WHEN pnl_realized_step < 0 THEN pnl_realized_step ELSE 0 END)) AS pf
    FROM exec
    WHERE exec_type IN ('close','partial')
    GROUP BY step
v_exec_perf_step_exit|CREATE VIEW v_exec_perf_step_exit AS
    SELECT
        step,
        reason,
        COUNT(*)                       AS n,
        AVG(pnl_realized_step)         AS exp
    FROM exec
    WHERE exec_type IN ('close','partial')
    GROUP BY step, reason
v_exec_pnl_uid|CREATE VIEW v_exec_pnl_uid AS
WITH p AS (
  SELECT
    uid,
    side,
    avg_price_open,
    fee_total
  FROM v_exec_position
),
out_exec AS (
  SELECT
    e.uid,
    e.side,
    e.exec_type,
    e.qty,
    e.price_exec
  FROM v_exec_ledger e
  WHERE e.exec_type IN ('partial','close')
),
pnl_core AS (
  SELECT
    o.uid,
    SUM(
      CASE
        WHEN o.side='buy'  THEN o.qty * (o.price_exec - p.avg_price_open)
        WHEN o.side='sell' THEN o.qty * (p.avg_price_open - o.price_exec)
        ELSE 0.0
      END
    ) AS pnl_gross
  FROM out_exec o
  JOIN p ON p.uid=o.uid
  GROUP BY o.uid
)
SELECT
  p.uid,
  COALESCE(pc.pnl_gross,0.0) - COALESCE(p.fee_total,0.0) AS pnl_realized
FROM p
LEFT JOIN pnl_core pc USING(uid)
/* v_exec_pnl_uid(uid,pnl_realized) */
v_exec_position|CREATE VIEW v_exec_position AS
WITH x AS (
  SELECT
    uid,
    side,
    exec_type,
    step,
    qty,
    price_exec,
    fee,
    ts_exec,
    CASE
      WHEN exec_type IN ('open','pyramide') THEN qty
      WHEN exec_type IN ('partial','close') THEN -qty
      ELSE 0
    END AS signed_qty,
    CASE
      WHEN exec_type IN ('open','pyramide') THEN qty
      ELSE 0
    END AS qty_in,
    CASE
      WHEN exec_type IN ('open','pyramide') THEN qty * price_exec
      ELSE 0
    END AS notional_in
  FROM v_exec_ledger
),
agg AS (
  SELECT
    uid,
    MAX(side) AS side,
    SUM(signed_qty) AS qty_open,
    SUM(qty_in) AS qty_in_total,
    SUM(notional_in) AS notional_in_total,
    SUM(COALESCE(fee,0.0)) AS fee_total,
    MAX(ts_exec) AS last_ts_exec
  FROM x
  GROUP BY uid
),
last_row AS (
  SELECT
    uid,
    exec_type AS last_exec_type,
    step AS last_step,
    price_exec AS last_price_exec,
    ts_exec AS last_ts_exec
  FROM (
    SELECT
      uid, exec_type, step, price_exec, ts_exec,
      ROW_NUMBER() OVER (PARTITION BY uid ORDER BY ts_exec DESC, step DESC) AS rn
    FROM v_exec_ledger
  )
  WHERE rn = 1
)
SELECT
  a.uid,
  a.side,
  a.qty_open,
  CASE
    WHEN a.qty_in_total > 0
    THEN a.notional_in_total / a.qty_in_total
    ELSE 0.0
  END AS avg_price_open,
  a.fee_total,
  l.last_exec_type,
  l.last_step,
  l.last_price_exec,
  l.last_ts_exec
FROM agg a
LEFT JOIN last_row l USING(uid)
v_exec_step_exit_perf|CREATE VIEW v_exec_step_exit_perf AS
SELECT
  step,
  exec_type,
  reason,
  COUNT(*) AS n,
  AVG(pnl_realized_step) AS exp,
  SUM(CASE WHEN pnl_realized_step > 0 THEN pnl_realized_step ELSE 0 END)
   / NULLIF(ABS(SUM(CASE WHEN pnl_realized_step < 0 THEN pnl_realized_step ELSE 0 END)),0) AS pf,
  AVG(mfe_atr) AS mfe_atr,
  AVG(mae_atr) AS mae_atr,
  SUM(golden) AS golden_n
FROM exec
WHERE exec_type IN ('partial','close')
GROUP BY step, exec_type, reason
v_follower_monitoring|CREATE VIEW v_follower_monitoring AS
SELECT
    uid,
    mfe_price,
    mae_price,
    sl_trail,
    tp_dyn,
    atr_signal
FROM follower
WHERE status = 'follow'
v_gest_monitoring|CREATE VIEW v_gest_monitoring AS
SELECT
    uid,
    instId,
    side,
    entry,
    qty,
    status,
    ts_open
FROM gest
WHERE status IN (
    'open_req',
    'open_done',
    'follow',
    'partial_req',
    'partial_done',
    'pyramide_req',
    'pyramide_done',
    'close_req'
)
v_ticks_monitoring|CREATE VIEW v_ticks_monitoring AS
SELECT
    instId,
    lastPr
FROM v_ticks_latest

-- INDEXES --
idx_exec_status|CREATE INDEX idx_exec_status ON exec(status)
idx_exec_type|CREATE INDEX idx_exec_type
    ON exec(exec_type)
idx_exec_uid|CREATE INDEX idx_exec_uid ON exec(uid)
ix_exec_status|CREATE INDEX ix_exec_status
ON exec(status)
ix_exec_uid_step|CREATE INDEX ix_exec_uid_step
ON exec(uid, step)
sqlite_autoindex_exec_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/follower.db -----
-- TABLES --
follower               v_follower_monitoring  v_ticks_monitoring   
trades_follow          v_follower_state     
v_follower             v_gest_monitoring    

[TABLE: follower]
0|uid|TEXT|0||1
1|ts_follow|INTEGER|0|0|0
2|sl_be|REAL|0|0|0
3|sl_trail|REAL|0|0|0
4|tp_dyn|REAL|0|0|0
5|atr_signal|REAL|0|0|0
6|status|TEXT|1|'follow'|0
7|reason_close|TEXT|0||0
8|price_to_close|REAL|0||0
9|qty_to_close|REAL|0||0
10|close_step|INTEGER|0|0|0
11|mfe_price|REAL|0||0
12|mfe_ts|INTEGER|0||0
13|mae_price|REAL|0||0
14|mae_ts|INTEGER|0||0
15|reason|TEXT|0||0
16|ts_decision|INTEGER|0||0
17|nb_partial|INTEGER|0|0|0
18|nb_pyramide|INTEGER|0|0|0
19|nb_pyramide_post_partial|INTEGER|0|0|0
20|last_partial_price|REAL|0||0
21|last_partial_ts|INTEGER|0||0
22|last_pyramide_price|REAL|0||0
23|last_pyramide_ts|INTEGER|0||0
24|mfe_local|REAL|0||0
25|mae_local|REAL|0||0
26|vwap_local|REAL|0||0
27|cooldown_partial_ts|INTEGER|0||0
28|cooldown_pyramide_ts|INTEGER|0||0
29|regime|TEXT|0|'scalp'|0
30|qty_ratio|REAL|0||0
31|step|INTEGER|0|0|0
32|ensure_step_column|INTEGER|0|0|0
33|mfe_atr|REAL|0|0.0|0
34|mae_atr|REAL|0|0.0|0
35|last_pyramide_mfe_atr|REAL|0|0.0|0
36|last_partial_mfe_atr|REAL|0|0.0|0
37|last_action_ts|INTEGER|0|0|0
38|golden|INTEGER|1|0|0
39|golden_ts|INTEGER|0||0
40|sl_be_price|REAL|0||0
41|sl_be_atr|REAL|0||0
42|sl_be_ts|INTEGER|0||0
43|sl_trail_active|INTEGER|0|0|0
44|sl_trail_start_atr|REAL|0||0
45|sl_trail_ts|INTEGER|0||0
46|tp_dyn_atr|REAL|0||0
47|tp_dyn_ts|INTEGER|0||0
48|first_partial_ts|INTEGER|0||0
49|first_partial_mfe_atr|REAL|0||0
50|first_pyramide_ts|INTEGER|0||0
51|last_decision_ts||0||0
52|instId|TEXT|0||0
53|side|TEXT|0||0
54|ratio_opened|REAL|0|0.0|0
55|ratio_to_open|REAL|0||0
56|ratio_to_close|REAL|0||0
57|ratio_closed|REAL|0|0|0
58|ratio_exposed|REAL|0|0|0
59|trade_free|INTEGER|0|0|0
60|req_step|INTEGER|0|0|0
61|done_step|INTEGER|0|0|0
62|qty_to_close_ratio|REAL|0|0.0|0
63|qty_to_add_ratio|REAL|0|0.0|0
64|ts_updated|INTEGER|0||0
65|ratio_to_add|REAL|0|NULL|0
66|qty_open_snapshot|REAL|0|0.0|0
67|qty_open|REAL|0|0.0|0
68|avg_price_open|REAL|0||0
69|last_exec_type|TEXT|0||0
70|last_step|INTEGER|0||0
71|last_price_exec|REAL|0||0
72|last_ts_exec|INTEGER|0||0

[TABLE: v_follower_monitoring]
0|uid|TEXT|0||0
1|mfe_price|REAL|0||0
2|mae_price|REAL|0||0
3|sl_trail|REAL|0||0
4|tp_dyn|REAL|0||0
5|atr_signal|REAL|0||0

[TABLE: v_ticks_monitoring]

[TABLE: trades_follow]
0|uid|TEXT|0||0
1|instId|TEXT|0||0
2|side|TEXT|0||0
3|status|TEXT|0||0
4|mfe|REAL|0||0
5|atr|REAL|0||0
6|nb_pyramide|INTEGER|0||0
7|last_pyramide_price|REAL|0||0
8|last_pyramide_ts|INTEGER|0||0
9|cooldown_pyramide_ts|INTEGER|0||0
10|pyramide_inflight_step|INTEGER|0||0
11|ts_update|INTEGER|0||0

[TABLE: v_follower_state]
0|uid|TEXT|0||0
1|instId|TEXT|0||0
2|side|TEXT|0||0
3|status|TEXT|0||0
4|step|INTEGER|0||0
5|qty_ratio|REAL|0||0
6|qty_to_close_ratio|REAL|0||0
7|qty_to_add_ratio|REAL|0||0
8|req_step|INTEGER|0||0
9|done_step|INTEGER|0||0
10|age_s||0||0
11|mfe_atr|REAL|0||0
12|mae_atr|REAL|0||0
13|nb_partial|INTEGER|0||0
14|nb_pyramide|INTEGER|0||0
15|qty_open|REAL|0||0
16|avg_price_open|REAL|0||0
17|last_exec_type|TEXT|0||0
18|last_step|INTEGER|0||0
19|last_price_exec|REAL|0||0
20|last_ts_exec|INTEGER|0||0

[TABLE: v_follower]
0|uid|TEXT|0||0
1|ts_follow|INTEGER|0||0
2|sl_be|REAL|0||0
3|sl_trail|REAL|0||0
4|tp_dyn|REAL|0||0
5|status|TEXT|0||0

[TABLE: v_gest_monitoring]

-- VIEWS --
trades_follow|CREATE VIEW trades_follow AS
SELECT
    uid,
    instId,
    side,
    status,
    mfe_atr     AS mfe,
    atr_signal  AS atr,
    nb_pyramide,
    last_pyramide_price,
    last_pyramide_ts,
    cooldown_pyramide_ts,
    step        AS pyramide_inflight_step,
    last_action_ts AS ts_update
FROM follower
v_follower|CREATE VIEW v_follower AS
SELECT
    uid,
    ts_follow,
    sl_be,
    sl_trail,
    tp_dyn,
    status
FROM follower
v_follower_monitoring|CREATE VIEW v_follower_monitoring AS
SELECT
    uid,
    mfe_price,
    mae_price,
    sl_trail,
    tp_dyn,
    atr_signal
FROM follower
WHERE status = 'follow'
v_follower_state|CREATE VIEW v_follower_state AS
SELECT
    uid,
    instId,
    side,
    status,
    step,

    -- ratios
    qty_ratio,
    qty_to_close_ratio,
    qty_to_add_ratio,

    -- FSM
    req_step,
    done_step,

    -- AGE
    (strftime('%s','now') - ts_follow / 1000) AS age_s,

    -- MFE / MAE
    mfe_atr,
    mae_atr,

    -- COUNTERS
    nb_partial,
    nb_pyramide,

    -- ‚úÖ EXEC MATERIALIS√â
    qty_open,
    avg_price_open,
    last_exec_type,
    last_step,
    last_price_exec,
    last_ts_exec

FROM follower
v_gest_monitoring|CREATE VIEW v_gest_monitoring AS
SELECT
    uid,
    instId,
    side,
    entry,
    qty,
    status,
    ts_open
FROM gest
WHERE status IN (
    'open_req',
    'open_done',
    'follow',
    'partial_req',
    'partial_done',
    'pyramide_req',
    'pyramide_done',
    'close_req'
)
v_ticks_monitoring|CREATE VIEW v_ticks_monitoring AS
SELECT
    instId,
    lastPr
FROM v_ticks_latest

-- INDEXES --
idx_follower_status|CREATE INDEX idx_follower_status
    ON follower(status)
idx_follower_uid|CREATE INDEX idx_follower_uid
    ON follower(uid)
ix_follower_status|CREATE INDEX ix_follower_status
ON follower(status)
sqlite_autoindex_follower_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/gest.db -----
-- TABLES --
exec_snapshot          v_exec_monitoring      v_gest_open_inst     
gest                   v_follower_monitoring  v_gest_status_count  
v_active_coins         v_gest                 v_position           
v_exec_agg             v_gest_fsm             v_status             
v_exec_close_agg       v_gest_monitoring      v_ticks_monitoring   

[TABLE: exec_snapshot]
0|uid|TEXT|1||1
1|exec_type|TEXT|1||2
2|side|TEXT|1||0
3|qty|REAL|1||0
4|price_exec|REAL|1||0
5|ts_exec|INTEGER|1||0
6|step|INTEGER|1||3

[TABLE: v_exec_monitoring]

[TABLE: v_gest_open_inst]
0|instId|TEXT|0||0

[TABLE: gest]
0|uid|TEXT|0||1
1|instId|TEXT|1||0
2|side|TEXT|1||0
3|ts_signal|INTEGER|1||0
4|price_signal|REAL|0|0|0
5|atr_signal|REAL|0|0|0
6|reason|TEXT|0||0
7|entry_reason|TEXT|0||0
8|type_signal|TEXT|0||0
9|score_C|REAL|0||0
10|score_S|REAL|0||0
11|score_H|REAL|0||0
12|entry|REAL|0||0
13|qty|REAL|0||0
14|lev|REAL|0||0
15|margin|REAL|0||0
16|ts_open|INTEGER|0||0
17|sl_init|REAL|0||0
18|tp_init|REAL|0||0
19|ts_follow|INTEGER|0||0
20|sl_be|REAL|0||0
21|sl_trail|REAL|0||0
22|tp_dyn|REAL|0||0
23|price_to_close|REAL|0||0
24|ts_close|INTEGER|0||0
25|price_close|REAL|0||0
26|reason_close|TEXT|0||0
27|ctx_close|TEXT|0||0
28|price_exec_close|REAL|0||0
29|pnl|REAL|0||0
30|pnl_pct|REAL|0||0
31|fee|REAL|0||0
32|fee_total|REAL|0||0
33|pnl_net|REAL|0||0
34|wt_delta_t_ms|INTEGER|0||0
35|wt_delta_price_pct|REAL|0||0
36|wt_peak_ts|INTEGER|0||0
37|wt_peak_price|REAL|0||0
38|status|TEXT|1||0
39|ts_status_update|INTEGER|0||0
40|instId_raw|TEXT|0||0
41|strength|REAL|0||0
42|ctx|TEXT|0||0
43|atr|REAL|0||0
44|of_imbalance|REAL|0||0
45|confluence|REAL|0||0
46|ts_created|INTEGER|0||0
47|ts_updated|INTEGER|0||0
48|skipped_reason|TEXT|0||0
49|fire|INTEGER|0|0|0
50|score_of|REAL|0||0
51|score_mo|REAL|0||0
52|score_br|REAL|0||0
53|score_force|REAL|0||0
54|qty_open|REAL|0||0
55|pnl_realized|REAL|0||0
56|qty_to_close|REAL|0||0
57|close_step|INTEGER|0|0|0
58|mfe_price|REAL|0||0
59|mfe_ts|INTEGER|0||0
60|mae_price|REAL|0||0
61|mae_ts|INTEGER|0||0
62|qty_in_exec|REAL|0|0|0
63|qty_out_exec|REAL|0|0|0
64|qty_open_exec|REAL|0|0|0
65|avg_entry_price|REAL|0||0
66|avg_exit_price|REAL|0||0
67|fee_total_exec|REAL|0|0|0
68|last_exec_step|INTEGER|0|0|0
69|fsm_state|TEXT|0||0
70|qty_in|REAL|0|0|0
71|qty_out|REAL|0|0|0
72|fee_exec_total|REAL|0|0|0
73|ts_first_open|INTEGER|0||0
74|ts_last_close|INTEGER|0||0
75|step|INTEGER|1|0|0
76|nb_partial|INTEGER|0|0|0
77|nb_pyramide|INTEGER|0|0|0
78|nb_pyramide_post_partial|INTEGER|0|0|0
79|last_partial_price|REAL|0||0
80|last_partial_ts|INTEGER|0||0
81|last_pyramide_price|REAL|0||0
82|last_pyramide_ts|INTEGER|0||0
83|mfe_local|REAL|0||0
84|mae_local|REAL|0||0
85|vwap_local|REAL|0||0
86|cooldown_partial_ts|INTEGER|0||0
87|cooldown_pyramide_ts|INTEGER|0||0
88|regime|TEXT|0||0
89|score_M|REAL|0||0
90|mfe_atr|REAL|0||0
91|mae_atr|REAL|0||0
92|mfe_atr_partial|REAL|0||0
93|mfe_atr_pyramide|REAL|0||0
94|golden|INTEGER|0|0|0
95|golden_ts|INTEGER|0||0
96|first_partial_ts|INTEGER|0||0
97|first_partial_mfe_atr|REAL|0||0
98|first_pyramide_ts|INTEGER|0||0
99|last_pyramide_mfe_atr|REAL|0||0
100|last_action_ts|INTEGER|0||0
101|last_emit_status||0||0
102|last_emit_ts||0||0
103|trigger_type|TEXT|0||0
104|dec_mode|TEXT|0||0
105|momentum_ok|INTEGER|0|0|0
106|prebreak_ok|INTEGER|0|0|0
107|pullback_ok|INTEGER|0|0|0
108|compression_ok|INTEGER|0|0|0
109|dec_ctx|TEXT|0||0
110|dec_score_C|REAL|0||0
111|ratio_to_open|REAL|0||0
112|ratio_to_add|REAL|0||0
113|ratio_to_close|REAL|0||0

[TABLE: v_follower_monitoring]

[TABLE: v_gest_status_count]
0|status|TEXT|0||0
1|cnt||0||0

[TABLE: v_active_coins]
0|instId|TEXT|0||0

[TABLE: v_gest]
0|uid|TEXT|0||0
1|instId|TEXT|0||0
2|side|TEXT|0||0
3|ts_signal|INTEGER|0||0
4|price_signal|REAL|0||0
5|atr_signal|REAL|0||0
6|reason|TEXT|0||0
7|entry_reason|TEXT|0||0
8|type_signal|TEXT|0||0
9|score_C|REAL|0||0
10|score_S|REAL|0||0
11|score_H|REAL|0||0
12|entry|REAL|0||0
13|qty|REAL|0||0
14|lev|REAL|0||0
15|margin|REAL|0||0
16|ts_open|INTEGER|0||0
17|sl_init|REAL|0||0
18|tp_init|REAL|0||0
19|ts_follow|INTEGER|0||0
20|sl_be|REAL|0||0
21|sl_trail|REAL|0||0
22|tp_dyn|REAL|0||0
23|price_to_close|REAL|0||0
24|ts_close|INTEGER|0||0
25|price_close|REAL|0||0
26|reason_close|TEXT|0||0
27|ctx_close|TEXT|0||0
28|price_exec_close|REAL|0||0
29|pnl|REAL|0||0
30|pnl_pct|REAL|0||0
31|fee|REAL|0||0
32|fee_total|REAL|0||0
33|pnl_net|REAL|0||0
34|wt_delta_t_ms|INTEGER|0||0
35|wt_delta_price_pct|REAL|0||0
36|wt_peak_ts|INTEGER|0||0
37|wt_peak_price|REAL|0||0
38|status|TEXT|0||0
39|ts_status_update|INTEGER|0||0
40|instId_raw|TEXT|0||0
41|strength|REAL|0||0
42|ctx|TEXT|0||0
43|atr|REAL|0||0
44|of_imbalance|REAL|0||0
45|confluence|REAL|0||0
46|ts_created|INTEGER|0||0
47|ts_updated|INTEGER|0||0
48|skipped_reason|TEXT|0||0
49|fire|INTEGER|0||0
50|score_of|REAL|0||0
51|score_mo|REAL|0||0
52|score_br|REAL|0||0
53|score_force|REAL|0||0
54|qty_open|REAL|0||0
55|pnl_realized|REAL|0||0
56|qty_to_close|REAL|0||0
57|close_step|INTEGER|0||0
58|mfe_price|REAL|0||0
59|mfe_ts|INTEGER|0||0
60|mae_price|REAL|0||0
61|mae_ts|INTEGER|0||0
62|qty_in_exec|REAL|0||0
63|qty_out_exec|REAL|0||0
64|qty_open_exec|REAL|0||0
65|avg_entry_price|REAL|0||0
66|avg_exit_price|REAL|0||0
67|fee_total_exec|REAL|0||0
68|last_exec_step|INTEGER|0||0
69|fsm_state|TEXT|0||0
70|qty_in|REAL|0||0
71|qty_out|REAL|0||0
72|fee_exec_total|REAL|0||0
73|ts_first_open|INTEGER|0||0
74|ts_last_close|INTEGER|0||0
75|step|INTEGER|0||0
76|nb_partial|INTEGER|0||0
77|nb_pyramide|INTEGER|0||0
78|nb_pyramide_post_partial|INTEGER|0||0
79|last_partial_price|REAL|0||0
80|last_partial_ts|INTEGER|0||0
81|last_pyramide_price|REAL|0||0
82|last_pyramide_ts|INTEGER|0||0
83|mfe_local|REAL|0||0
84|mae_local|REAL|0||0
85|vwap_local|REAL|0||0
86|cooldown_partial_ts|INTEGER|0||0
87|cooldown_pyramide_ts|INTEGER|0||0
88|regime|TEXT|0||0
89|score_M|REAL|0||0
90|mfe_atr|REAL|0||0
91|mae_atr|REAL|0||0
92|mfe_atr_partial|REAL|0||0
93|mfe_atr_pyramide|REAL|0||0
94|golden|INTEGER|0||0
95|golden_ts|INTEGER|0||0
96|first_partial_ts|INTEGER|0||0
97|first_partial_mfe_atr|REAL|0||0
98|first_pyramide_ts|INTEGER|0||0
99|last_pyramide_mfe_atr|REAL|0||0
100|last_action_ts|INTEGER|0||0
101|last_emit_status||0||0
102|last_emit_ts||0||0
103|trigger_type|TEXT|0||0
104|dec_mode|TEXT|0||0
105|momentum_ok|INTEGER|0||0
106|prebreak_ok|INTEGER|0||0
107|pullback_ok|INTEGER|0||0
108|compression_ok|INTEGER|0||0
109|dec_ctx|TEXT|0||0
110|dec_score_C|REAL|0||0
111|ratio_to_open|REAL|0||0
112|ratio_to_add|REAL|0||0
113|ratio_to_close|REAL|0||0

[TABLE: v_position]

[TABLE: v_exec_agg]

[TABLE: v_gest_fsm]

[TABLE: v_status]

[TABLE: v_exec_close_agg]
0|uid|TEXT|0||0
1|qty_out_exec||0||0
2|cash_out_exec||0||0
3|avg_exit_price||0||0
4|ts_last_exec||0||0
5|has_close||0||0

[TABLE: v_gest_monitoring]
0|uid|TEXT|0||0
1|instId|TEXT|0||0
2|side|TEXT|0||0
3|entry|REAL|0||0
4|qty|REAL|0||0
5|status|TEXT|0||0
6|ts_open|INTEGER|0||0

[TABLE: v_ticks_monitoring]

-- VIEWS --
v_active_coins|CREATE VIEW v_active_coins AS
SELECT DISTINCT
    instId
FROM gest
WHERE status IN (
    'armed',
    'fire',
    'opened',
    'follow',
    'to_close'
)
AND instId IS NOT NULL
v_exec_agg|CREATE VIEW v_exec_agg AS
SELECT
    uid,

    SUM(CASE
        WHEN exec_type IN ('open','pyramide')
        THEN qty ELSE 0 END) AS qty_in,

    SUM(CASE
        WHEN exec_type IN ('partial','close')
        THEN qty ELSE 0 END) AS qty_out,

    SUM(CASE
        WHEN exec_type IN ('open','pyramide')
        THEN qty * price_exec ELSE 0 END)
      / NULLIF(
          SUM(CASE
              WHEN exec_type IN ('open','pyramide')
              THEN qty ELSE 0 END),
          0
        ) AS avg_entry_price,

    SUM(CASE
        WHEN exec_type IN ('partial','close')
        THEN qty * price_exec ELSE 0 END)
      / NULLIF(
          SUM(CASE
              WHEN exec_type IN ('partial','close')
              THEN qty ELSE 0 END),
          0
        ) AS avg_exit_price,

    SUM(fee) AS fee_total,

    MIN(ts_exec) AS ts_first_exec,
    MAX(ts_exec) AS ts_last_exec,

    MAX(step) AS last_step

FROM exec
GROUP BY uid
v_exec_close_agg|CREATE VIEW v_exec_close_agg AS
SELECT
    uid,
    SUM(qty)                          AS qty_out_exec,
    SUM(qty * price_exec)             AS cash_out_exec,
    CASE
        WHEN SUM(qty) > 0
        THEN SUM(qty * price_exec) / SUM(qty)
        ELSE NULL
    END                               AS avg_exit_price,
    MAX(ts_exec)                      AS ts_last_exec,
    MAX(CASE WHEN exec_type='close' THEN 1 ELSE 0 END) AS has_close
FROM exec_snapshot
WHERE exec_type IN ('partial','close')
GROUP BY uid
v_exec_monitoring|CREATE VIEW v_exec_monitoring AS
SELECT
    uid,
    side,
    qty_open,
    avg_price_open,
    last_exec_type,
    last_step,
    last_price_exec,
    last_ts_exec
FROM v_exec_position
v_follower_monitoring|CREATE VIEW v_follower_monitoring AS
SELECT
    uid,
    mfe_price,
    mae_price,
    sl_trail,
    tp_dyn,
    atr_signal
FROM follower
WHERE status = 'follow'
v_gest|CREATE VIEW v_gest AS
SELECT *
FROM gest
ORDER BY ts_signal DESC
v_gest_fsm|CREATE VIEW v_gest_fsm AS
SELECT
    g.*,

    p.qty_open,
    p.avg_entry_price,
    p.avg_exit_price,
    p.fee_total,

    CASE
        WHEN g.status IN ('partial_done','pyramid_done') THEN 'follow'
        ELSE g.status
    END AS fsm_state

FROM gest g
LEFT JOIN v_position p ON p.uid = g.uid
v_gest_monitoring|CREATE VIEW v_gest_monitoring AS
SELECT
    uid,
    instId,
    side,
    entry,
    qty,
    status,
    ts_open
FROM gest
WHERE status IN (
    'open_req',
    'open_done',
    'follow',
    'partial_req',
    'partial_done',
    'pyramide_req',
    'pyramide_done',
    'close_req'
)
v_gest_open_inst|CREATE VIEW v_gest_open_inst AS
SELECT DISTINCT instId
FROM gest
WHERE status IN (
  'open_req',
  'open_done',
  'follow',
  'partial_done',
  'pyramide_done'
)
v_gest_status_count|CREATE VIEW v_gest_status_count AS
SELECT
    status,
    COUNT(*) AS cnt
FROM gest
GROUP BY status
v_position|CREATE VIEW v_position AS
SELECT
    g.uid,
    g.instId,
    g.side,

    e.qty_in,
    e.qty_out,
    (e.qty_in - e.qty_out) AS qty_open,

    e.avg_entry_price,
    e.avg_exit_price,
    e.fee_total,

    e.ts_first_exec AS ts_first_open,
    e.ts_last_exec  AS ts_last_close,

    CASE
        WHEN (e.qty_in - e.qty_out) <= 1e-8
        THEN 'closed'
        ELSE 'open'
    END AS position_state,

    g.status AS fsm_state,
    g.ts_status_update

FROM gest g
LEFT JOIN v_exec_agg e USING(uid)
v_status|CREATE VIEW v_status AS
SELECT uid, fsm_state AS status
FROM v_gest_fsm
v_ticks_monitoring|CREATE VIEW v_ticks_monitoring AS
SELECT
    instId,
    lastPr
FROM v_ticks_latest

-- INDEXES --
idx_exec_snapshot_uid|CREATE INDEX idx_exec_snapshot_uid
ON exec_snapshot(uid)
idx_gest_instId|CREATE INDEX idx_gest_instId
    ON gest(instId)
idx_gest_price_signal|CREATE INDEX idx_gest_price_signal
    ON gest(price_signal)
idx_gest_status|CREATE INDEX idx_gest_status
    ON gest(status)
idx_gest_ts_signal|CREATE INDEX idx_gest_ts_signal
    ON gest(ts_signal)
idx_gest_uid|CREATE INDEX idx_gest_uid
    ON gest(uid)
ix_gest_status|CREATE INDEX ix_gest_status
ON gest(status)
ix_gest_uid_step|CREATE INDEX ix_gest_uid_step
ON gest(uid, step)
sqlite_autoindex_exec_snapshot_1|
sqlite_autoindex_gest_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/h.db -----
-- TABLES --
h_stats    v_score_h

[TABLE: h_stats]
0|setup_hash|TEXT|0||1
1|instId|TEXT|0||0
2|side|TEXT|0||0
3|ctx|TEXT|0||0
4|regime|TEXT|0||0
5|tf_ref|TEXT|0||0
6|time_bucket|TEXT|0||0
7|score_C_bucket|TEXT|0||0
8|score_S_bucket|TEXT|0||0
9|n_trades|INTEGER|0||0
10|win_rate|REAL|0||0
11|expectancy|REAL|0||0
12|avg_pnl|REAL|0||0
13|profit_factor|REAL|0||0
14|max_dd|REAL|0||0
15|score_H|REAL|0||0
16|ts_last_update|INTEGER|0||0

[TABLE: v_score_h]
0|instId|TEXT|0||0
1|side|TEXT|0||0
2|ctx|TEXT|0||0
3|regime|TEXT|0||0
4|tf_ref|TEXT|0||0
5|time_bucket|TEXT|0||0
6|score_C_bucket|TEXT|0||0
7|score_S_bucket|TEXT|0||0
8|score_H|REAL|0||0
9|n_trades|INTEGER|0||0
10|expectancy|REAL|0||0
11|ts_last_update|INTEGER|0||0

-- VIEWS --
v_score_h|CREATE VIEW v_score_h AS
SELECT
    instId,
    side,
    ctx,
    regime,
    tf_ref,
    time_bucket,
    score_C_bucket,
    score_S_bucket,
    score_H,
    n_trades,
    expectancy,
    ts_last_update
FROM h_stats

-- INDEXES --
idx_h_lookup|CREATE INDEX idx_h_lookup
ON h_stats (
    instId, side, ctx, regime, tf_ref,
    time_bucket, score_C_bucket, score_S_bucket
)
sqlite_autoindex_h_stats_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/market.db -----
-- TABLES --
market_latest          market_volatility      v_market_score_latest
market_liquidity       v_market_flags         v_market_scored      
market_tick_stats      v_market_latest      

[TABLE: market_latest]
0|instId|TEXT|0||1
1|ticks_5s|INTEGER|1||0
2|spread_bps|REAL|1||0
3|staleness_ms|INTEGER|1||0
4|ts_update|INTEGER|1||0

[TABLE: market_volatility]
0|instId|TEXT|0||0
1|ts|INTEGER|0||0
2|range_1s|REAL|0||0
3|range_5s|REAL|0||0
4|atr|REAL|0||0
5|vol_norm|REAL|0||0

[TABLE: v_market_score_latest]
0|instId|TEXT|0||0
1|market_score||0||0
2|market_risk_factor||0||0
3|ts|INTEGER|0||0

[TABLE: market_liquidity]
0|instId|TEXT|0||0
1|ts|INTEGER|0||0
2|volume_24h|REAL|0||0
3|funding|REAL|0||0
4|spread_ok|INTEGER|0||0
5|liquidity_ok|INTEGER|0||0

[TABLE: v_market_flags]
0|instId|TEXT|0||0
1|market_fresh||0||0
2|market_active||0||0
3|market_clean||0||0

[TABLE: v_market_scored]
0|instId|TEXT|0||0
1|ts|INTEGER|0||0
2|ticks_5s|INTEGER|0||0
3|spread_bps|REAL|0||0
4|vol_norm|REAL|0||0
5|staleness_ms|INTEGER|0||0
6|spread_ok||0||0
7|liquidity_ok||0||0
8|market_ok||0||0
9|ticks_score||0||0
10|spread_score||0||0
11|vol_score||0||0
12|market_score||0||0
13|market_risk_factor||0||0

[TABLE: market_tick_stats]
0|instId|TEXT|1||0
1|ts|INTEGER|1||0
2|last|REAL|0||0
3|bid|REAL|0||0
4|ask|REAL|0||0
5|spread_abs|REAL|0||0
6|spread_bps|REAL|0||0
7|ticks_1s|INTEGER|0||0
8|ticks_5s|INTEGER|0||0
9|staleness_ms|INTEGER|0||0

[TABLE: v_market_latest]
0|instId|TEXT|0||0
1|ticks_5s|INTEGER|0||0
2|spread_bps|REAL|0||0
3|staleness_ms|INTEGER|0||0
4|spread_ok||0||0
5|liquidity_ok||0||0
6|market_ok||0||0
7|ts_update|INTEGER|0||0

-- VIEWS --
v_market_flags|CREATE VIEW v_market_flags AS
SELECT
    instId,

    CASE
        WHEN staleness_ms IS NULL OR staleness_ms > 3000 THEN 0
        ELSE 1
    END AS market_fresh,

    CASE
        WHEN ticks_5s >= 5 THEN 1
        ELSE 0
    END AS market_active,

    CASE
        WHEN spread_ok = 1 AND liquidity_ok = 1 THEN 1
        ELSE 0
    END AS market_clean

FROM v_market_latest
v_market_latest|CREATE VIEW v_market_latest AS
SELECT
  instId,

  ticks_5s,
  spread_bps,
  staleness_ms,

  -- flags normalis√©s (ATTENDUS par monitor / dec)
  CASE WHEN spread_bps <= 5.0 THEN 1 ELSE 0 END AS spread_ok,
  CASE WHEN ticks_5s >= 5 THEN 1 ELSE 0 END AS liquidity_ok,
  CASE
    WHEN ticks_5s >= 5
     AND spread_bps <= 5.0
     AND staleness_ms <= 1000
    THEN 1 ELSE 0
  END AS market_ok,

  ts_update
FROM market_latest
v_market_score_latest|CREATE VIEW v_market_score_latest AS
SELECT
  instId,
  market_score,
  market_risk_factor,
  ts
FROM v_market_scored
WHERE ts = (
  SELECT MAX(ts)
  FROM v_market_scored m2
  WHERE m2.instId = v_market_scored.instId
)
v_market_scored|CREATE VIEW v_market_scored AS
WITH vol_latest AS (
  SELECT
    v.instId,
    v.vol_norm,
    v.ts
  FROM market_volatility v
  WHERE v.ts = (
    SELECT MAX(ts)
    FROM market_volatility v2
    WHERE v2.instId = v.instId
  )
)
SELECT
  m.instId,

  -- timestamp canonique
  m.ts_update AS ts,

  -- ==========================================================
  -- RAW MARKET DATA
  -- ==========================================================
  m.ticks_5s,
  m.spread_bps,
  v.vol_norm,
  m.staleness_ms,
  m.spread_ok,
  m.liquidity_ok,
  m.market_ok,

  -- ==========================================================
  -- SCORES
  -- ==========================================================

  -- Activity (0‚Äì40)
  MIN(40, m.ticks_5s * 4) AS ticks_score,

  -- Cost (0‚Äì30)
  MAX(0, 30 - m.spread_bps * 6) AS spread_score,

  -- Volatility (0‚Äì30)
  CASE
    WHEN v.vol_norm BETWEEN 0.25 AND 0.80 THEN 30
    WHEN v.vol_norm BETWEEN 0.10 AND 0.25 THEN 20
    WHEN v.vol_norm > 0.80              THEN 20
    WHEN v.vol_norm < 0.10              THEN 10
    ELSE 0
  END AS vol_score,

  -- ==========================================================
  -- TOTAL SCORE (0‚Äì100)
  -- ==========================================================
  (
    MIN(40, m.ticks_5s * 4)
    + MAX(0, 30 - m.spread_bps * 6)
    + CASE
        WHEN v.vol_norm BETWEEN 0.25 AND 0.80 THEN 30
        WHEN v.vol_norm BETWEEN 0.10 AND 0.25 THEN 20
        WHEN v.vol_norm > 0.80              THEN 20
        WHEN v.vol_norm < 0.10              THEN 10
        ELSE 0
      END
  ) AS market_score,

  -- ==========================================================
  -- RISK FACTOR (0.30 ‚Üí 1.00)
  -- ==========================================================
  MAX(
    0.30,
    MIN(
      1.00,
      (
        (
          MIN(40, m.ticks_5s * 4)
          + MAX(0, 30 - m.spread_bps * 6)
          + CASE
              WHEN v.vol_norm BETWEEN 0.25 AND 0.80 THEN 30
              WHEN v.vol_norm BETWEEN 0.10 AND 0.25 THEN 20
              WHEN v.vol_norm > 0.80              THEN 20
              WHEN v.vol_norm < 0.10              THEN 10
              ELSE 0
            END
        ) / 100.0
      )
    )
  ) AS market_risk_factor

FROM v_market_latest m
LEFT JOIN vol_latest v
  ON v.instId = m.instId

-- INDEXES --
idx_mkt_liq_inst_ts|CREATE INDEX idx_mkt_liq_inst_ts
ON market_liquidity(instId, ts DESC)
idx_mkt_ticks_inst_ts|CREATE INDEX idx_mkt_ticks_inst_ts
ON market_tick_stats(instId, ts DESC)
idx_mkt_vol_inst_ts|CREATE INDEX idx_mkt_vol_inst_ts
ON market_volatility(instId, ts DESC)
sqlite_autoindex_market_latest_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/mfe_mae.db -----
-- TABLES --
mfe_mae        snap_gest      v_follow_mfe   v_mfe_mae_atr

[TABLE: mfe_mae]
0|uid|TEXT|0||1
1|instId|TEXT|1||0
2|side|TEXT|1||0
3|entry_price|REAL|1||0
4|ts_open|INTEGER|1||0
5|mfe|REAL|0|0|0
6|mfe_ts|INTEGER|0||0
7|mae|REAL|0|0|0
8|mae_ts|INTEGER|0||0
9|last_price|REAL|0||0
10|last_ts|INTEGER|0||0
11|ts_updated|INTEGER|1||0
12|atr|REAL|0||0

[TABLE: snap_gest]
0|uid|TEXT|0||1
1|instId|TEXT|0||0
2|side|TEXT|0||0
3|entry_price|REAL|0||0
4|atr|REAL|0||0
5|ts_open|INTEGER|0||0
6|ts_snap|INTEGER|0||0

[TABLE: v_follow_mfe]
0|uid|TEXT|0||0
1|instId|TEXT|0||0
2|side|TEXT|0||0
3|entry_price|REAL|0||0
4|ts_open|INTEGER|0||0
5|mfe|REAL|0||0
6|mfe_ts|INTEGER|0||0
7|mae|REAL|0||0
8|mae_ts|INTEGER|0||0
9|atr|REAL|0||0
10|mfe_atr||0||0
11|mae_atr||0||0
12|last_price|REAL|0||0
13|last_ts|INTEGER|0||0
14|ts_updated|INTEGER|0||0

[TABLE: v_mfe_mae_atr]
0|uid|TEXT|0||0
1|instId|TEXT|0||0
2|side|TEXT|0||0
3|entry_price|REAL|0||0
4|ts_open|INTEGER|0||0
5|mfe|REAL|0||0
6|mae|REAL|0||0
7|atr|REAL|0||0
8|mfe_atr||0||0
9|mae_atr||0||0
10|mfe_ts|INTEGER|0||0
11|mae_ts|INTEGER|0||0
12|last_price|REAL|0||0
13|last_ts|INTEGER|0||0
14|ts_updated|INTEGER|0||0

-- VIEWS --
v_follow_mfe|CREATE VIEW v_follow_mfe AS
SELECT
    uid,
    instId,
    side,

    entry_price,
    ts_open,

    mfe,
    mfe_ts,
    mae,
    mae_ts,

    atr,

    CASE
        WHEN atr > 0 THEN mfe / atr
        ELSE NULL
    END AS mfe_atr,

    CASE
        WHEN atr > 0 THEN ABS(mae) / atr
        ELSE NULL
    END AS mae_atr,

    last_price,
    last_ts,
    ts_updated
FROM mfe_mae
v_mfe_mae_atr|CREATE VIEW v_mfe_mae_atr AS
SELECT
  uid,
  instId,
  side,
  entry_price,
  ts_open,

  mfe,
  mae,
  atr,

  CASE
    WHEN atr > 0 THEN mfe / atr
    ELSE 0
  END AS mfe_atr,

  CASE
    WHEN atr > 0 THEN ABS(mae) / atr
    ELSE 0
  END AS mae_atr,

  mfe_ts,
  mae_ts,
  last_price,
  last_ts,
  ts_updated
FROM mfe_mae

-- INDEXES --
idx_mfe_mae_inst|CREATE INDEX idx_mfe_mae_inst
ON mfe_mae(instId)
idx_snap_gest_instId|CREATE INDEX idx_snap_gest_instId ON snap_gest(instId)
sqlite_autoindex_mfe_mae_1|
sqlite_autoindex_snap_gest_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/mfemae.db -----
-- TABLES --

-- VIEWS --

-- INDEXES --

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/monitor.db -----
-- TABLES --
pipeline_snapshot  snap_ctx_market    snap_dec_explain 

[TABLE: pipeline_snapshot]
0|ts|INTEGER|0||1
1|universe_total|INTEGER|0||0
2|market_ok|INTEGER|0||0
3|ctx_ok|INTEGER|0||0
4|dec_tradable|INTEGER|0||0
5|armed|INTEGER|0||0
6|fired|INTEGER|0||0
7|lost_market|INTEGER|0||0
8|lost_ctx|INTEGER|0||0
9|lost_dec|INTEGER|0||0
10|lost_armed|INTEGER|0||0

[TABLE: snap_ctx_market]
0|instId|TEXT|0||1
1|ctx|TEXT|0||0
2|score_C|REAL|0||0
3|side|TEXT|0||0
4|ctx_ok|INTEGER|0||0
5|market_ok|INTEGER|0||0
6|ts_updated|INTEGER|0||0

[TABLE: snap_dec_explain]
0|instId|TEXT|0||1
1|ctx_ok|INTEGER|0||0
2|has_range|INTEGER|0||0
3|has_atr|INTEGER|0||0
4|compression_ok|INTEGER|0||0
5|breaking_now|INTEGER|0||0

-- VIEWS --

-- INDEXES --
sqlite_autoindex_snap_ctx_market_1|
sqlite_autoindex_snap_dec_explain_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/monitor_live.db -----
-- TABLES --
position_snapshot

[TABLE: position_snapshot]
0|uid|TEXT|0||1
1|instId|TEXT|0||0
2|side|TEXT|0||0
3|entry|REAL|0||0
4|price|REAL|0||0
5|qty|REAL|0||0
6|pnl|REAL|0||0
7|pnl_pct|REAL|0||0
8|mfe|REAL|0||0
9|mae|REAL|0||0
10|atr|REAL|0||0
11|age_s|REAL|0||0
12|status|TEXT|0||0
13|ts|INTEGER|0||0

-- VIEWS --

-- INDEXES --
sqlite_autoindex_position_snapshot_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/oa.db -----
-- TABLES --
ohlcv_15m           ohlcv_5m            v_ohlcv_30m_latest
ohlcv_30m           v_ohlcv_15m_latest  v_ohlcv_5m_latest 

[TABLE: ohlcv_15m]
0|instId|TEXT|1||1
1|ts|INTEGER|1||2
2|open|REAL|0||0
3|high|REAL|0||0
4|low|REAL|0||0
5|close|REAL|0||0
6|volume|REAL|0||0

[TABLE: ohlcv_5m]
0|instId|TEXT|1||1
1|ts|INTEGER|1||2
2|open|REAL|0||0
3|high|REAL|0||0
4|low|REAL|0||0
5|close|REAL|0||0
6|volume|REAL|0||0

[TABLE: v_ohlcv_30m_latest]
0|instId|TEXT|0||0
1|ts|INTEGER|0||0
2|open|REAL|0||0
3|high|REAL|0||0
4|low|REAL|0||0
5|close|REAL|0||0
6|volume|REAL|0||0

[TABLE: ohlcv_30m]
0|instId|TEXT|1||1
1|ts|INTEGER|1||2
2|open|REAL|0||0
3|high|REAL|0||0
4|low|REAL|0||0
5|close|REAL|0||0
6|volume|REAL|0||0

[TABLE: v_ohlcv_15m_latest]
0|instId|TEXT|0||0
1|ts|INTEGER|0||0
2|open|REAL|0||0
3|high|REAL|0||0
4|low|REAL|0||0
5|close|REAL|0||0
6|volume|REAL|0||0

[TABLE: v_ohlcv_5m_latest]
0|instId|TEXT|0||0
1|ts|INTEGER|0||0
2|open|REAL|0||0
3|high|REAL|0||0
4|low|REAL|0||0
5|close|REAL|0||0
6|volume|REAL|0||0

-- VIEWS --
v_ohlcv_15m_latest|CREATE VIEW v_ohlcv_15m_latest AS
SELECT *
FROM ohlcv_15m
WHERE ts IN (
    SELECT ts FROM ohlcv_15m AS o2
    WHERE o2.instId = ohlcv_15m.instId
    ORDER BY ts DESC
    LIMIT 150
)
v_ohlcv_30m_latest|CREATE VIEW v_ohlcv_30m_latest AS
SELECT *
FROM ohlcv_30m
WHERE ts IN (
    SELECT ts FROM ohlcv_30m AS o2
    WHERE o2.instId = ohlcv_30m.instId
    ORDER BY ts DESC
    LIMIT 150
)
v_ohlcv_5m_latest|CREATE VIEW v_ohlcv_5m_latest AS
SELECT *
FROM ohlcv_5m
WHERE ts IN (
    SELECT ts FROM ohlcv_5m AS o2
    WHERE o2.instId = ohlcv_5m.instId
    ORDER BY ts DESC
    LIMIT 150
)

-- INDEXES --
idx_ohlcv_15m_ts|CREATE INDEX idx_ohlcv_15m_ts ON ohlcv_15m(ts)
idx_ohlcv_30m_ts|CREATE INDEX idx_ohlcv_30m_ts ON ohlcv_30m(ts)
idx_ohlcv_5m_ts|CREATE INDEX idx_ohlcv_5m_ts  ON ohlcv_5m(ts)
sqlite_autoindex_ohlcv_15m_1|
sqlite_autoindex_ohlcv_30m_1|
sqlite_autoindex_ohlcv_5m_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/ob.db -----
-- TABLES --
feat_1m   feat_3m   feat_5m   ohlcv_1m  ohlcv_3m  ohlcv_5m

[TABLE: feat_1m]
0|instId|TEXT|1||1
1|ts|INTEGER|1||2
2|open|REAL|0||0
3|high|REAL|0||0
4|low|REAL|0||0
5|close|REAL|0||0
6|vol|REAL|0||0

[TABLE: feat_3m]
0|instId|TEXT|1||1
1|ts|INTEGER|1||2
2|open|REAL|0||0
3|high|REAL|0||0
4|low|REAL|0||0
5|close|REAL|0||0
6|vol|REAL|0||0

[TABLE: feat_5m]
0|instId|TEXT|1||1
1|ts|INTEGER|1||2
2|open|REAL|0||0
3|high|REAL|0||0
4|low|REAL|0||0
5|close|REAL|0||0
6|vol|REAL|0||0

[TABLE: ohlcv_1m]
0|instId|TEXT|1||1
1|ts|INTEGER|1||2
2|o|REAL|0||0
3|h|REAL|0||0
4|l|REAL|0||0
5|c|REAL|0||0
6|v|REAL|0||0

[TABLE: ohlcv_3m]
0|instId|TEXT|1||1
1|ts|INTEGER|1||2
2|o|REAL|0||0
3|h|REAL|0||0
4|l|REAL|0||0
5|c|REAL|0||0
6|v|REAL|0||0

[TABLE: ohlcv_5m]
0|instId|TEXT|1||1
1|ts|INTEGER|1||2
2|o|REAL|0||0
3|h|REAL|0||0
4|l|REAL|0||0
5|c|REAL|0||0
6|v|REAL|0||0

-- VIEWS --

-- INDEXES --
sqlite_autoindex_feat_1m_1|
sqlite_autoindex_feat_3m_1|
sqlite_autoindex_feat_5m_1|
sqlite_autoindex_ohlcv_1m_1|
sqlite_autoindex_ohlcv_3m_1|
sqlite_autoindex_ohlcv_5m_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/opener.db -----
-- TABLES --
opener                    opener_backup_1768073835  v_opener                

[TABLE: opener]
0|uid|TEXT|1||1
1|instId|TEXT|1||0
2|side|TEXT|1||0
3|qty|REAL|1||0
4|lev|REAL|1||0
5|ts_open|INTEGER|0||0
6|price_exec_open|REAL|0||0
7|status|TEXT|1||0
8|exec_type|TEXT|1||2
9|step|INTEGER|1||3
10|ratio|REAL|0||0
11|qty_raw|REAL|0||0
12|qty_norm|REAL|0||0
13|reject_reason|TEXT|0||0

[TABLE: opener_backup_1768073835]
0|uid|TEXT|0||1
1|instId|TEXT|0||0
2|side|TEXT|0||0
3|qty|REAL|0||0
4|lev|REAL|0||0
5|ts_open|INTEGER|0||0
6|price_exec_open|REAL|0||0
7|status|TEXT|0||0
8|exec_type|TEXT|0||2
9|step|INTEGER|0||3
10|reason|TEXT|0||0

[TABLE: v_opener]
0|uid|TEXT|0||0
1|instId|TEXT|0||0
2|side|TEXT|0||0
3|qty|REAL|0||0
4|lev|REAL|0||0
5|ts_open|INTEGER|0||0
6|price_exec_open|REAL|0||0
7|status|TEXT|0||0
8|exec_type|TEXT|0||0
9|step|INTEGER|0||0
10|ratio|REAL|0||0
11|qty_raw|REAL|0||0
12|qty_norm|REAL|0||0
13|reject_reason|TEXT|0||0

-- VIEWS --
v_opener|CREATE VIEW v_opener AS SELECT * FROM opener

-- INDEXES --
sqlite_autoindex_opener_1|
sqlite_autoindex_opener_backup_1768073835_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/record.db -----
-- TABLES --

-- VIEWS --

-- INDEXES --

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/recorder.db -----
-- TABLES --
recorder                      v_recorder_dominant_detector
recorder_steps                v_recorder_duration         
v_edge_coin                   v_recorder_for_gest         
v_rec_exit_perf               v_recorder_score_ranges     
v_rec_golden_perf             v_recorder_stats_by_duration
v_rec_perf_exit_context       v_recorder_steps            
v_rec_perf_step_context       v_score_H_source            
v_rec_step_exit_perf          v_trade_stats               
v_rec_step_perf               v_trades_analyse            
v_recorder                  

[TABLE: recorder]
0|uid|TEXT|0||1
1|instId|TEXT|1||0
2|side|TEXT|1||0
3|ts_signal|INTEGER|1||0
4|price_signal|REAL|1||0
5|entry_reason|TEXT|0||0
6|type_signal|TEXT|0||0
7|score_C|REAL|0||0
8|score_S|REAL|0||0
9|ts_open|INTEGER|0||0
10|entry|REAL|0||0
11|qty|REAL|0||0
12|lev|REAL|0||0
13|margin|REAL|0||0
14|ts_close|INTEGER|0||0
15|price_close|REAL|0||0
16|reason_close|TEXT|0||0
17|pnl|REAL|0||0
18|pnl_pct|REAL|0||0
19|pnl_net|REAL|0||0
20|fee|REAL|0||0
21|ctx_close|TEXT|0||0
22|wt_delta_t_ms|INTEGER|0||0
23|wt_delta_price_pct|REAL|0||0
24|wt_peak_ts|INTEGER|0||0
25|wt_peak_price|REAL|0||0
26|ts_recorded|INTEGER|1||0
27|fee_total|REAL|0|0|0
28|score_of|REAL|0||0
29|score_mo|REAL|0||0
30|score_br|REAL|0||0
31|score_force|REAL|0||0
32|mfe_price|REAL|0||0
33|mfe_ts|INTEGER|0||0
34|mae_price|REAL|0||0
35|mae_ts|INTEGER|0||0
36|pnl_realized|REAL|0||0
37|close_steps|INTEGER|0||0
38|atr_signal|REAL|0||0
39|price_exec_close|REAL|0||0
40|score_H|REAL|0||0
41|score_M|REAL|0||0
42|nb_partial|INTEGER|0|0|0
43|nb_pyramide|INTEGER|0|0|0
44|mfe_atr|REAL|0|0.0|0
45|mae_atr|REAL|0|0.0|0
46|golden|INTEGER|0|0|0
47|golden_ts|INTEGER|0||0
48|last_action_ts|INTEGER|0||0
49|last_pyramide_mfe_atr|REAL|0||0
50|first_partial_mfe_atr|REAL|0||0
51|trigger_type|TEXT|0||0
52|dec_mode|TEXT|0||0
53|momentum_ok|INTEGER|0|0|0
54|prebreak_ok|INTEGER|0|0|0
55|pullback_ok|INTEGER|0|0|0
56|compression_ok|INTEGER|0|0|0
57|dec_ctx|TEXT|0||0
58|dec_score_C|REAL|0||0

[TABLE: v_recorder_dominant_detector]
0|uid|TEXT|0||0
1|instId|TEXT|0||0
2|side|TEXT|0||0
3|ts_signal|INTEGER|0||0
4|price_signal|REAL|0||0
5|entry_reason|TEXT|0||0
6|type_signal|TEXT|0||0
7|score_C|REAL|0||0
8|score_S|REAL|0||0
9|ts_open|INTEGER|0||0
10|entry|REAL|0||0
11|qty|REAL|0||0
12|lev|REAL|0||0
13|margin|REAL|0||0
14|ts_close|INTEGER|0||0
15|price_close|REAL|0||0
16|reason_close|TEXT|0||0
17|pnl|REAL|0||0
18|pnl_pct|REAL|0||0
19|pnl_net|REAL|0||0
20|fee|REAL|0||0
21|ctx_close|TEXT|0||0
22|wt_delta_t_ms|INTEGER|0||0
23|wt_delta_price_pct|REAL|0||0
24|wt_peak_ts|INTEGER|0||0
25|wt_peak_price|REAL|0||0
26|ts_recorded|INTEGER|0||0
27|fee_total|REAL|0||0
28|score_of|REAL|0||0
29|score_mo|REAL|0||0
30|score_br|REAL|0||0
31|score_force|REAL|0||0
32|mfe_price|REAL|0||0
33|mfe_ts|INTEGER|0||0
34|mae_price|REAL|0||0
35|mae_ts|INTEGER|0||0
36|pnl_realized|REAL|0||0
37|close_steps|INTEGER|0||0
38|atr_signal|REAL|0||0
39|price_exec_close|REAL|0||0
40|score_H|REAL|0||0
41|score_M|REAL|0||0
42|nb_partial|INTEGER|0||0
43|nb_pyramide|INTEGER|0||0
44|mfe_atr|REAL|0||0
45|mae_atr|REAL|0||0
46|golden|INTEGER|0||0
47|golden_ts|INTEGER|0||0
48|last_action_ts|INTEGER|0||0
49|last_pyramide_mfe_atr|REAL|0||0
50|first_partial_mfe_atr|REAL|0||0
51|trigger_type|TEXT|0||0
52|dec_mode|TEXT|0||0
53|momentum_ok|INTEGER|0||0
54|prebreak_ok|INTEGER|0||0
55|pullback_ok|INTEGER|0||0
56|compression_ok|INTEGER|0||0
57|dec_ctx|TEXT|0||0
58|dec_score_C|REAL|0||0
59|dominant_detector||0||0

[TABLE: recorder_steps]
0|uid|TEXT|1||1
1|step|INTEGER|1||2
2|exec_type|TEXT|0||0
3|reason|TEXT|0||0
4|price_exec|REAL|0||0
5|qty_exec|REAL|0||0
6|ts_exec|INTEGER|0||0
7|sl_be|REAL|0||0
8|sl_trail|REAL|0||0
9|tp_dyn|REAL|0||0
10|mfe_atr|REAL|0||0
11|mae_atr|REAL|0||0
12|golden|INTEGER|0||0

[TABLE: v_recorder_duration]
0|uid|TEXT|0||0
1|instId|TEXT|0||0
2|side|TEXT|0||0
3|entry|REAL|0||0
4|price_close|REAL|0||0
5|pnl|REAL|0||0
6|pnl_pct|REAL|0||0
7|pnl_net|REAL|0||0
8|reason_close|TEXT|0||0
9|ts_open|INTEGER|0||0
10|ts_close|INTEGER|0||0
11|dur_s||0||0
12|dur_bucket||0||0
13|is_win||0||0
14|is_loss||0||0

[TABLE: v_edge_coin]
0|instId|TEXT|0||0
1|n_trades||0||0
2|exp||0||0
3|pf||0||0
4|avg_pyramide||0||0
5|avg_partial||0||0

[TABLE: v_recorder_for_gest]

[TABLE: v_rec_exit_perf]
0|exit_type|TEXT|0||0
1|n||0||0
2|exp||0||0
3|mfe_atr||0||0
4|mae_atr||0||0
5|golden_n||0||0

[TABLE: v_recorder_score_ranges]
0|uid|TEXT|0||0
1|instId|TEXT|0||0
2|side|TEXT|0||0
3|ts_signal|INTEGER|0||0
4|price_signal|REAL|0||0
5|entry_reason|TEXT|0||0
6|type_signal|TEXT|0||0
7|score_C|REAL|0||0
8|score_S|REAL|0||0
9|ts_open|INTEGER|0||0
10|entry|REAL|0||0
11|qty|REAL|0||0
12|lev|REAL|0||0
13|margin|REAL|0||0
14|ts_close|INTEGER|0||0
15|price_close|REAL|0||0
16|reason_close|TEXT|0||0
17|pnl|REAL|0||0
18|pnl_pct|REAL|0||0
19|pnl_net|REAL|0||0
20|fee|REAL|0||0
21|ctx_close|TEXT|0||0
22|wt_delta_t_ms|INTEGER|0||0
23|wt_delta_price_pct|REAL|0||0
24|wt_peak_ts|INTEGER|0||0
25|wt_peak_price|REAL|0||0
26|ts_recorded|INTEGER|0||0
27|fee_total|REAL|0||0
28|score_of|REAL|0||0
29|score_mo|REAL|0||0
30|score_br|REAL|0||0
31|score_force|REAL|0||0
32|mfe_price|REAL|0||0
33|mfe_ts|INTEGER|0||0
34|mae_price|REAL|0||0
35|mae_ts|INTEGER|0||0
36|pnl_realized|REAL|0||0
37|close_steps|INTEGER|0||0
38|atr_signal|REAL|0||0
39|price_exec_close|REAL|0||0
40|score_H|REAL|0||0
41|score_M|REAL|0||0
42|nb_partial|INTEGER|0||0
43|nb_pyramide|INTEGER|0||0
44|mfe_atr|REAL|0||0
45|mae_atr|REAL|0||0
46|golden|INTEGER|0||0
47|golden_ts|INTEGER|0||0
48|last_action_ts|INTEGER|0||0
49|last_pyramide_mfe_atr|REAL|0||0
50|first_partial_mfe_atr|REAL|0||0
51|trigger_type|TEXT|0||0
52|dec_mode|TEXT|0||0
53|momentum_ok|INTEGER|0||0
54|prebreak_ok|INTEGER|0||0
55|pullback_ok|INTEGER|0||0
56|compression_ok|INTEGER|0||0
57|dec_ctx|TEXT|0||0
58|dec_score_C|REAL|0||0
59|force_bucket||0||0

[TABLE: v_rec_golden_perf]
0|golden|INTEGER|0||0
1|n||0||0
2|exp||0||0
3|mfe_atr||0||0
4|mae_atr||0||0

[TABLE: v_recorder_stats_by_duration]
0|dur_bucket||0||0
1|trades||0||0
2|wins||0||0
3|losses||0||0
4|winrate_pct||0||0
5|pnl_total||0||0
6|pnl_avg||0||0
7|pct_avg||0||0
8|dur_avg_s||0||0

[TABLE: v_rec_perf_exit_context]
0|exit_type|TEXT|0||0
1|n||0||0
2|exp||0||0
3|mfe||0||0
4|mae||0||0
5|golden||0||0

[TABLE: v_recorder_steps]
0|uid|TEXT|0||0
1|step|INTEGER|0||0
2|exec_type|TEXT|0||0
3|reason|TEXT|0||0
4|price_exec|REAL|0||0
5|qty_exec|REAL|0||0
6|ts_exec|INTEGER|0||0
7|sl_be|REAL|0||0
8|sl_trail|REAL|0||0
9|tp_dyn|REAL|0||0
10|mfe_atr|REAL|0||0
11|mae_atr|REAL|0||0
12|golden|INTEGER|0||0
13|type_signal|TEXT|0||0
14|dec_mode|TEXT|0||0
15|instId|TEXT|0||0
16|side|TEXT|0||0
17|entry|REAL|0||0
18|atr_signal|REAL|0||0
19|pnl_realized|REAL|0||0
20|ts_open|INTEGER|0||0
21|ts_close|INTEGER|0||0

[TABLE: v_rec_perf_step_context]
0|step|INTEGER|0||0
1|n||0||0
2|exp||0||0
3|mfe||0||0
4|mae||0||0
5|golden||0||0

[TABLE: v_score_H_source]
0|instId|TEXT|0||0
1|side|TEXT|0||0
2|entry_reason|TEXT|0||0
3|n||0||0
4|winrate||0||0
5|expectancy||0||0
6|risk||0||0
7|quality||0||0

[TABLE: v_rec_step_exit_perf]
0|step|INTEGER|0||0
1|exit_type|TEXT|0||0
2|n||0||0
3|exp||0||0
4|pf||0||0
5|mfe_atr||0||0
6|mae_atr||0||0
7|golden_n||0||0

[TABLE: v_trade_stats]
0|uid|TEXT|0||0
1|instId|TEXT|0||0
2|side|TEXT|0||0
3|entry|REAL|0||0
4|price_close|REAL|0||0
5|qty|REAL|0||0
6|pnl|REAL|0||0
7|pnl_net|REAL|0||0
8|fee_total|REAL|0||0
9|ts_open|INTEGER|0||0
10|ts_close|INTEGER|0||0
11|duration_s||0||0
12|score_C|REAL|0||0
13|score_of|REAL|0||0
14|score_mo|REAL|0||0
15|score_br|REAL|0||0
16|score_force|REAL|0||0
17|mfe_price|REAL|0||0
18|mae_price|REAL|0||0
19|mfe_pct||0||0
20|mae_pct||0||0
21|exit_efficiency||0||0
22|has_partial||0||0
23|has_pyramid||0||0
24|close_steps|INTEGER|0||0
25|entry_reason|TEXT|0||0
26|type_signal|TEXT|0||0
27|ts_recorded|INTEGER|0||0

[TABLE: v_rec_step_perf]
0|step|INTEGER|0||0
1|n||0||0
2|exp||0||0
3|mfe_atr||0||0
4|mae_atr||0||0
5|golden_n||0||0

[TABLE: v_trades_analyse]

[TABLE: v_recorder]
0|uid|TEXT|0||0
1|ts_recorded|INTEGER|0||0

-- VIEWS --
v_edge_coin|CREATE VIEW v_edge_coin AS
WITH step_final AS (
    SELECT
        uid,
        MAX(step) AS step
    FROM recorder_steps
    GROUP BY uid
)
SELECT
    r.instId,
    COUNT(*) AS n_trades,
    AVG(r.pnl_realized) AS exp,
    SUM(CASE WHEN r.pnl_realized > 0 THEN r.pnl_realized ELSE 0 END)
        / NULLIF(-SUM(CASE WHEN r.pnl_realized < 0 THEN r.pnl_realized ELSE 0 END),0)
        AS pf,
    AVG(r.nb_pyramide) AS avg_pyramide,
    AVG(r.nb_partial)  AS avg_partial
FROM recorder r
JOIN step_final sf ON sf.uid = r.uid
WHERE sf.step >= 2
GROUP BY r.instId
v_rec_exit_perf|CREATE VIEW v_rec_exit_perf AS
SELECT
  reason_close             AS exit_type,
  COUNT(*)                 AS n,
  AVG(pnl_realized)        AS exp,
  AVG(mfe_atr)             AS mfe_atr,
  AVG(mae_atr)             AS mae_atr,
  SUM(golden)              AS golden_n
FROM recorder
GROUP BY reason_close
v_rec_golden_perf|CREATE VIEW v_rec_golden_perf AS
SELECT
  golden,
  COUNT(*)          AS n,
  AVG(pnl_realized) AS exp,
  AVG(mfe_atr)      AS mfe_atr,
  AVG(mae_atr)      AS mae_atr
FROM recorder
GROUP BY golden
v_rec_perf_exit_context|CREATE VIEW v_rec_perf_exit_context AS
    SELECT
        r.reason_close         AS exit_type,
        COUNT(*)               AS n,
        AVG(r.pnl_realized)    AS exp,
        AVG(r.mfe_atr)         AS mfe,
        AVG(r.mae_atr)         AS mae,
        SUM(r.golden)          AS golden
    FROM recorder r
    GROUP BY r.reason_close
v_rec_perf_step_context|CREATE VIEW v_rec_perf_step_context AS
    SELECT
        r.close_steps          AS step,
        COUNT(*)               AS n,
        AVG(r.pnl_realized)    AS exp,
        AVG(r.mfe_atr)         AS mfe,
        AVG(r.mae_atr)         AS mae,
        SUM(r.golden)          AS golden
    FROM recorder r
    GROUP BY r.close_steps
v_rec_step_exit_perf|CREATE VIEW v_rec_step_exit_perf AS
SELECT
  close_steps              AS step,
  reason_close             AS exit_type,
  COUNT(*)                 AS n,
  AVG(pnl_realized)        AS exp,
  SUM(CASE WHEN pnl_realized > 0 THEN pnl_realized ELSE 0 END)
    / NULLIF(ABS(SUM(CASE WHEN pnl_realized < 0 THEN pnl_realized ELSE 0 END)),0) AS pf,
  AVG(mfe_atr)             AS mfe_atr,
  AVG(mae_atr)             AS mae_atr,
  SUM(golden)              AS golden_n
FROM recorder
GROUP BY close_steps, reason_close
v_rec_step_perf|CREATE VIEW v_rec_step_perf AS
SELECT
  close_steps              AS step,
  COUNT(*)                 AS n,
  AVG(pnl_realized)        AS exp,
  AVG(mfe_atr)             AS mfe_atr,
  AVG(mae_atr)             AS mae_atr,
  SUM(golden)              AS golden_n
FROM recorder
GROUP BY close_steps
v_recorder|CREATE VIEW v_recorder AS
SELECT
    uid,
    ts_recorded
FROM recorder
v_recorder_dominant_detector|CREATE VIEW v_recorder_dominant_detector AS
SELECT *,
CASE
    WHEN score_of >= score_mo AND score_of >= score_br THEN 'ORDERFLOW'
    WHEN score_mo >= score_of AND score_mo >= score_br THEN 'MOMENTUM'
    WHEN score_br >= score_of AND score_br >= score_mo THEN 'BREAKOUT'
    ELSE 'MIXED'
END AS dominant_detector
FROM recorder
v_recorder_duration|CREATE VIEW v_recorder_duration AS
SELECT
    uid,
    instId,
    side,
    entry,
    price_close,
    pnl,
    pnl_pct,
    pnl_net,
    reason_close,
    ts_open,
    ts_close,
    (ts_close - ts_open) / 1000.0 AS dur_s,

    CASE
        WHEN (ts_close - ts_open) < 500 THEN '0‚Äì0.5s'
        WHEN (ts_close - ts_open) < 1000 THEN '0.5‚Äì1s'
        WHEN (ts_close - ts_open) < 3000 THEN '1‚Äì3s'
        WHEN (ts_close - ts_open) < 5000 THEN '3‚Äì5s'
        WHEN (ts_close - ts_open) < 10000 THEN '5‚Äì10s'
        WHEN (ts_close - ts_open) < 30000 THEN '10‚Äì30s'
        WHEN (ts_close - ts_open) < 60000 THEN '30‚Äì60s'
        WHEN (ts_close - ts_open) < 120000 THEN '1‚Äì2m'
        WHEN (ts_close - ts_open) < 300000 THEN '2‚Äì5m'
        WHEN (ts_close - ts_open) < 600000 THEN '5‚Äì10m'
        WHEN (ts_close - ts_open) < 1800000 THEN '10‚Äì30m'
        ELSE '>30m'
    END AS dur_bucket,

    CASE WHEN pnl > 0 THEN 1 ELSE 0 END AS is_win,
    CASE WHEN pnl < 0 THEN 1 ELSE 0 END AS is_loss
FROM recorder
WHERE ts_open IS NOT NULL
  AND ts_close IS NOT NULL
v_recorder_for_gest|CREATE VIEW v_recorder_for_gest AS
SELECT
  uid, status, ts_record
FROM trades_record
WHERE status='recorded'
ORDER BY ts_record DESC
v_recorder_score_ranges|CREATE VIEW v_recorder_score_ranges AS
SELECT *,
CASE
    WHEN score_force < 0.6 THEN '<0.6'
    WHEN score_force < 0.7 THEN '0.6-0.7'
    WHEN score_force < 0.8 THEN '0.7-0.8'
    ELSE '>0.8'
END AS force_bucket
FROM recorder
v_recorder_stats_by_duration|CREATE VIEW v_recorder_stats_by_duration AS
SELECT
    dur_bucket,
    COUNT(*) AS trades,
    SUM(is_win) AS wins,
    SUM(is_loss) AS losses,
    ROUND(100.0 * SUM(is_win) / COUNT(*), 2) AS winrate_pct,
    ROUND(SUM(pnl), 6) AS pnl_total,
    ROUND(AVG(pnl), 6) AS pnl_avg,
    ROUND(AVG(pnl_pct), 4) AS pct_avg,
    ROUND(AVG(dur_s), 3) AS dur_avg_s
FROM v_recorder_duration
GROUP BY dur_bucket
ORDER BY dur_avg_s
v_recorder_steps|CREATE VIEW v_recorder_steps AS
SELECT
    rs.uid,
    rs.step,

    rs.exec_type,
    rs.reason,

    rs.price_exec,
    rs.qty_exec,
    rs.ts_exec,

    rs.sl_be,
    rs.sl_trail,
    rs.tp_dyn,

    rs.mfe_atr,
    rs.mae_atr,
    rs.golden,

    r.type_signal,
    r.dec_mode,
    r.instId,
    r.side,
    r.entry,
    r.atr_signal,

    r.pnl_realized,
    r.ts_open,
    r.ts_close

FROM recorder_steps rs
JOIN recorder r
  ON r.uid = rs.uid
v_score_H_source|CREATE VIEW v_score_H_source AS
SELECT
  instId,
  side,
  entry_reason,
  COUNT(*)                                   AS n,
  AVG(pnl_net > 0)                           AS winrate,
  AVG(pnl_net)                               AS expectancy,
  AVG(ABS(mae_price))                        AS risk,
  AVG(mfe_price)                             AS quality
FROM recorder
WHERE pnl_net IS NOT NULL
GROUP BY instId, side, entry_reason
v_trade_stats|CREATE VIEW v_trade_stats AS
SELECT
    r.uid,
    r.instId,
    r.side,

    r.entry,
    r.price_close,
    r.qty,

    r.pnl,
    r.pnl_net,
    r.fee_total,

    -- ------------------------------------------------------------------------
    -- Temps
    -- ------------------------------------------------------------------------
    r.ts_open,
    r.ts_close,
    (r.ts_close - r.ts_open) / 1000.0 AS duration_s,

    -- ------------------------------------------------------------------------
    -- Scores
    -- ------------------------------------------------------------------------
    r.score_C,
    r.score_of,
    r.score_mo,
    r.score_br,
    r.score_force,

    -- ------------------------------------------------------------------------
    -- MFE / MAE absolus
    -- ------------------------------------------------------------------------
    r.mfe_price,
    r.mae_price,

    -- ------------------------------------------------------------------------
    -- MFE / MAE normalis√©s en prix
    -- (ATR manquant = neutralis√©)
    -- ------------------------------------------------------------------------
    CASE
        WHEN r.entry > 0 THEN
            (r.mfe_price - r.entry) / r.entry
        ELSE NULL
    END AS mfe_pct,

    CASE
        WHEN r.entry > 0 THEN
            (r.entry - r.mae_price) / r.entry
        ELSE NULL
    END AS mae_pct,

    -- ------------------------------------------------------------------------
    -- Efficacit√© de sortie
    -- % du MFE r√©ellement captur√©
    -- ------------------------------------------------------------------------
    CASE
        WHEN r.mfe_price IS NOT NULL
         AND r.entry IS NOT NULL
         AND r.price_close IS NOT NULL
         AND ABS(r.mfe_price - r.entry) > 0
        THEN
            (r.price_close - r.entry)
            / (r.mfe_price - r.entry)
        ELSE NULL
    END AS exit_efficiency,

    -- ------------------------------------------------------------------------
    -- Flags structurels
    -- ------------------------------------------------------------------------
    CASE
        WHEN r.close_steps > 0 THEN 1 ELSE 0
    END AS has_partial,

    CASE
        WHEN r.qty IS NOT NULL
         AND r.qty > 0
         AND r.qty < (
             SELECT MAX(qty) FROM recorder r2 WHERE r2.uid = r.uid
         )
        THEN 1 ELSE 0
    END AS has_pyramid,

    r.close_steps,
    r.entry_reason,
    r.type_signal,

    r.ts_recorded

FROM recorder r
v_trades_analyse|CREATE VIEW v_trades_analyse AS
SELECT
    uid,
    instId,
    side,
    reason AS reason_signal,
    reason_close,
    price_signal,
    atr_signal,
    score_A,
    score_B,
    ts_open,
    ts_close,
    entry,
    price_close,
    sl_init,
    tp_init,
    sl_be,
    sl_trail,
    tp_dyn,
    price_to_close,
    pnl
FROM trades_record
ORDER BY ts_open ASC

-- INDEXES --
idx_recorder_ts|CREATE INDEX idx_recorder_ts
    ON recorder(ts_recorded)
idx_recorder_uid|CREATE INDEX idx_recorder_uid
    ON recorder(uid)
sqlite_autoindex_recorder_1|
sqlite_autoindex_recorder_steps_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/t.db -----
-- TABLES --
ticks                  v_exec_monitoring      v_ticks_latest       
ticks_hist             v_follower_monitoring  v_ticks_latest_spread
ticks_latest           v_gest_monitoring      v_ticks_monitoring   

[TABLE: ticks]
0|instId|TEXT|0||1
1|lastPr|REAL|1||0
2|ts_ms|INTEGER|1||0
3|bidPr|REAL|0||0
4|askPr|REAL|0||0
5|spread_bps|REAL|0||0

[TABLE: v_exec_monitoring]

[TABLE: v_ticks_latest]
0|instId|TEXT|0||0
1|bidPr|REAL|0||0
2|askPr|REAL|0||0
3|lastPr|REAL|0||0
4|ts_ms|INTEGER|0||0

[TABLE: ticks_hist]
0|id|INTEGER|0||1
1|instId|TEXT|1||0
2|lastPr|REAL|1||0
3|ts_ms|INTEGER|1||0
4|bidPr|REAL|0||0
5|askPr|REAL|0||0
6|spread_bps|REAL|0||0

[TABLE: v_follower_monitoring]

[TABLE: v_ticks_latest_spread]
0|instId|TEXT|0||0
1|lastPr|REAL|0||0
2|bidPr|REAL|0||0
3|askPr|REAL|0||0
4|spread_bps|REAL|0||0
5|ts_ms|INTEGER|0||0

[TABLE: ticks_latest]
0|instId|TEXT|0||1
1|lastPr|REAL|1||0
2|ts_ms|INTEGER|1||0

[TABLE: v_gest_monitoring]

[TABLE: v_ticks_monitoring]
0|instId|TEXT|0||0
1|lastPr|REAL|0||0

-- VIEWS --
v_exec_monitoring|CREATE VIEW v_exec_monitoring AS
SELECT
    uid,
    side,
    qty_open,
    avg_price_open,
    last_exec_type,
    last_step,
    last_price_exec,
    last_ts_exec
FROM v_exec_position
v_follower_monitoring|CREATE VIEW v_follower_monitoring AS
SELECT
    uid,
    mfe_price,
    mae_price,
    sl_trail,
    tp_dyn,
    atr_signal
FROM follower
WHERE status = 'follow'
v_gest_monitoring|CREATE VIEW v_gest_monitoring AS
SELECT
    uid,
    instId,
    side,
    entry,
    qty,
    status,
    ts_open
FROM gest
WHERE status IN (
    'open_req',
    'open_done',
    'follow',
    'partial_req',
    'partial_done',
    'pyramide_req',
    'pyramide_done',
    'close_req'
)
v_ticks_latest|CREATE VIEW v_ticks_latest AS
SELECT th.instId,
       th.bidPr,
       th.askPr,
       th.lastPr,
       th.ts_ms
FROM ticks_hist th
JOIN (
    SELECT instId, MAX(ts_ms) AS max_ts
    FROM ticks_hist
    GROUP BY instId
) m
ON th.instId = m.instId AND th.ts_ms = m.max_ts
v_ticks_latest_spread|CREATE VIEW v_ticks_latest_spread AS
SELECT
    instId,
    lastPr,
    bidPr,
    askPr,
    spread_bps,
    ts_ms
FROM ticks
v_ticks_monitoring|CREATE VIEW v_ticks_monitoring AS
SELECT
    instId,
    lastPr
FROM v_ticks_latest

-- INDEXES --
idx_ticks_hist_inst_ts|CREATE INDEX idx_ticks_hist_inst_ts
ON ticks_hist(instId, ts_ms DESC)
sqlite_autoindex_ticks_1|
sqlite_autoindex_ticks_latest_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/ticks.db -----
-- TABLES --

-- VIEWS --

-- INDEXES --

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/triggers.db -----
-- TABLES --
trig_state         v_triggers_ctx_ok  v_triggers_latest
triggers           v_triggers_fired 

[TABLE: trig_state]
0|instId|TEXT|0||1
1|last_ts|REAL|0||0
2|last_price|REAL|0||0
3|last_side|TEXT|0||0
4|last_uid|TEXT|0||0

[TABLE: v_triggers_ctx_ok]

[TABLE: v_triggers_latest]
0|uid|TEXT|0||0
1|instId|TEXT|0||0
2|side|TEXT|0||0
3|entry_reason|TEXT|0||0
4|score_of|REAL|0||0
5|score_mo|REAL|0||0
6|score_br|REAL|0||0
7|score_force|REAL|0||0
8|price|REAL|0||0
9|atr|REAL|0||0
10|ts|INTEGER|0||0
11|status|TEXT|0||0
12|ts_fire|INTEGER|0||0
13|ttl_ms|INTEGER|0||0
14|expires_at|INTEGER|0||0
15|validated|INTEGER|0||0
16|ts_validated|INTEGER|0||0
17|mfe_early|REAL|0||0
18|mae_early|REAL|0||0
19|phase|TEXT|0||0
20|fire_reason|TEXT|0||0
21|ctx|TEXT|0||0
22|score_ctx|REAL|0||0
23|pos_in_range|REAL|0||0
24|momentum_1|REAL|0||0
25|momentum_acc|REAL|0||0
26|rsi|REAL|0||0
27|adx|REAL|0||0
28|macdhist|REAL|0||0
29|bb_width|REAL|0||0
30|armed_tick_count|INTEGER|0||0
31|regime|TEXT|0||0
32|range_high|REAL|0||0
33|range_low|REAL|0||0
34|armed_ticks|INTEGER|0||0
35|pattern|TEXT|0||0
36|ts_arm|INTEGER|0||0
37|ts_expire|INTEGER|0||0
38|score_M|REAL|0||0
39|score_H|REAL|0||0
40|trigger_type|TEXT|0||0
41|momentum_ok|INTEGER|0||0
42|prebreak_ok|INTEGER|0||0
43|pullback_ok|INTEGER|0||0
44|compression_ok|INTEGER|0||0
45|dec_score_C|REAL|0||0
46|dec_mode|TEXT|0||0
47|extra_ctx||0||0
48|ts_created||0||0

[TABLE: triggers]
0|uid|TEXT|0||1
1|instId|TEXT|1||0
2|side|TEXT|1||0
3|entry_reason|TEXT|1||0
4|score_of|REAL|1||0
5|score_mo|REAL|1||0
6|score_br|REAL|1||0
7|score_force|REAL|1||0
8|price|REAL|1||0
9|atr|REAL|1||0
10|ts|INTEGER|1||0
11|status|TEXT|1||0
12|ts_fire|INTEGER|0||0
13|ttl_ms|INTEGER|0||0
14|expires_at|INTEGER|0||0
15|validated|INTEGER|0|0|0
16|ts_validated|INTEGER|0||0
17|mfe_early|REAL|0||0
18|mae_early|REAL|0||0
19|phase|TEXT|0|'armed'|0
20|fire_reason|TEXT|0||0
21|ctx|TEXT|0||0
22|score_ctx|REAL|0||0
23|pos_in_range|REAL|0||0
24|momentum_1|REAL|0||0
25|momentum_acc|REAL|0||0
26|rsi|REAL|0||0
27|adx|REAL|0||0
28|macdhist|REAL|0||0
29|bb_width|REAL|0||0
30|armed_tick_count|INTEGER|0|0|0
31|regime|TEXT|0||0
32|range_high|REAL|0||0
33|range_low|REAL|0||0
34|armed_ticks|INTEGER|0|0|0
35|pattern|TEXT|0||0
36|ts_arm|INTEGER|0||0
37|ts_expire|INTEGER|0||0
38|score_M|REAL|0||0
39|score_H|REAL|0||0
40|trigger_type|TEXT|0||0
41|momentum_ok|INTEGER|0||0
42|prebreak_ok|INTEGER|0||0
43|pullback_ok|INTEGER|0||0
44|compression_ok|INTEGER|0||0
45|dec_score_C|REAL|0||0
46|dec_mode|TEXT|0||0
47|extra_ctx||0||0
48|ts_created||0||0

[TABLE: v_triggers_fired]
0|uid|TEXT|0||0
1|instId|TEXT|0||0
2|side|TEXT|0||0
3|entry_reason|TEXT|0||0
4|score_of|REAL|0||0
5|score_mo|REAL|0||0
6|score_br|REAL|0||0
7|score_force|REAL|0||0
8|price|REAL|0||0
9|atr|REAL|0||0
10|ts|INTEGER|0||0
11|status|TEXT|0||0
12|ts_fire|INTEGER|0||0
13|ttl_ms|INTEGER|0||0
14|expires_at|INTEGER|0||0
15|validated|INTEGER|0||0
16|ts_validated|INTEGER|0||0
17|mfe_early|REAL|0||0
18|mae_early|REAL|0||0
19|phase|TEXT|0||0
20|fire_reason|TEXT|0||0
21|ctx|TEXT|0||0
22|score_ctx|REAL|0||0
23|pos_in_range|REAL|0||0
24|momentum_1|REAL|0||0
25|momentum_acc|REAL|0||0
26|rsi|REAL|0||0
27|adx|REAL|0||0
28|macdhist|REAL|0||0
29|bb_width|REAL|0||0
30|armed_tick_count|INTEGER|0||0
31|regime|TEXT|0||0
32|range_high|REAL|0||0
33|range_low|REAL|0||0
34|armed_ticks|INTEGER|0||0
35|pattern|TEXT|0||0
36|ts_arm|INTEGER|0||0
37|ts_expire|INTEGER|0||0
38|score_M|REAL|0||0
39|score_H|REAL|0||0
40|trigger_type|TEXT|0||0
41|momentum_ok|INTEGER|0||0
42|prebreak_ok|INTEGER|0||0
43|pullback_ok|INTEGER|0||0
44|compression_ok|INTEGER|0||0
45|dec_score_C|REAL|0||0
46|dec_mode|TEXT|0||0
47|extra_ctx||0||0
48|ts_created||0||0

-- VIEWS --
v_triggers_ctx_ok|CREATE VIEW v_triggers_ctx_ok AS
SELECT
    t.*
FROM triggers t
WHERE t.instId IN (
    SELECT instId
    FROM snap_ctx
    WHERE ctx_ok = 1
)
v_triggers_fired|CREATE VIEW v_triggers_fired AS
SELECT *
FROM triggers
WHERE status='fire'
v_triggers_latest|CREATE VIEW v_triggers_latest AS
SELECT t.*
FROM triggers t
JOIN (
    SELECT instId, side, MAX(ts) AS max_ts
    FROM triggers
    GROUP BY instId, side
) last
ON t.instId = last.instId
AND t.side   = last.side
AND t.ts     = last.max_ts

-- INDEXES --
idx_triggers_instId|CREATE INDEX idx_triggers_instId  ON triggers(instId)
idx_triggers_status|CREATE INDEX idx_triggers_status  ON triggers(status)
idx_triggers_ts|CREATE INDEX idx_triggers_ts      ON triggers(ts)
sqlite_autoindex_trig_state_1|
sqlite_autoindex_triggers_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/universe.db -----
-- TABLES --
universe_coin         universe_tradable     v_universe_tradable 
universe_probe_audit  v_universe_audit    
universe_seed         v_universe_enabled  

[TABLE: universe_coin]
0|instId|TEXT|0||1
1|status|TEXT|1||0
2|enabled|INTEGER|1|0|0
3|whitelisted|INTEGER|1|0|0
4|blacklisted|INTEGER|1|0|0
5|volume_24h|REAL|0||0
6|ticks_24h|INTEGER|0||0
7|spread_avg|REAL|0||0
8|spread_p95|REAL|0||0
9|data_ok|INTEGER|0||0
10|status_exchange|TEXT|0||0
11|ts_update|INTEGER|0||0

[TABLE: universe_tradable]
0|instId|TEXT|0||1
1|volume_24h|REAL|0||0
2|trades_recent|INTEGER|0||0
3|spread_proxy|REAL|0||0
4|tradable|INTEGER|1|0|0
5|reason|TEXT|0||0
6|ts_update|INTEGER|0||0

[TABLE: v_universe_tradable]
0|instId|TEXT|0||0

[TABLE: universe_probe_audit]
0|instId|TEXT|0||1
1|ohlcv_ok|INTEGER|0||0
2|candle_count|INTEGER|0||0
3|last_ts|INTEGER|0||0
4|staleness_sec|INTEGER|0||0
5|error|TEXT|0||0
6|ts_update|INTEGER|0||0

[TABLE: v_universe_audit]
0|instId|TEXT|0||0
1|status|TEXT|0||0
2|enabled|INTEGER|0||0
3|whitelisted|INTEGER|0||0
4|blacklisted|INTEGER|0||0
5|volume_24h|REAL|0||0
6|ticks_24h|INTEGER|0||0
7|spread_avg|REAL|0||0
8|spread_p95|REAL|0||0
9|data_ok|INTEGER|0||0
10|status_exchange|TEXT|0||0
11|ts_update|INTEGER|0||0

[TABLE: universe_seed]
0|instId|TEXT|0||1
1|source|TEXT|1||0
2|ts_update|INTEGER|0||0

[TABLE: v_universe_enabled]
0|instId|TEXT|0||0

-- VIEWS --
v_universe_audit|CREATE VIEW v_universe_audit AS
SELECT
    instId,
    status,
    enabled,
    whitelisted,
    blacklisted,
    volume_24h,
    ticks_24h,
    spread_avg,
    spread_p95,
    data_ok,
    status_exchange,
    ts_update
FROM universe_coin
v_universe_enabled|CREATE VIEW v_universe_enabled AS
SELECT instId
FROM universe_coin
WHERE enabled = 1
v_universe_tradable|CREATE VIEW v_universe_tradable AS
SELECT
    ut.instId
FROM universe_tradable ut
JOIN universe_coin uc
  ON uc.instId = ut.instId
WHERE
    uc.status = 'enabled'
    AND ut.tradable = 1

-- INDEXES --
idx_universe_tradable_tradable|CREATE INDEX idx_universe_tradable_tradable
ON universe_tradable(tradable)
sqlite_autoindex_universe_coin_1|
sqlite_autoindex_universe_probe_audit_1|
sqlite_autoindex_universe_seed_1|
sqlite_autoindex_universe_tradable_1|

-- TRIGGERS --


----- DATABASE: /opt/scalp/project/data/wticks.db -----
-- TABLES --
v_wticks           v_wticks_extended  wticks             wticks_extended  

[TABLE: v_wticks]
0|uid|TEXT|0||0
1|instId|TEXT|0||0
2|ts_ms|INTEGER|0||0
3|bid|REAL|0||0
4|ask|REAL|0||0
5|last|REAL|0||0
6|volume|REAL|0||0
7|window_pos|TEXT|0||0

[TABLE: v_wticks_extended]
0|uid|TEXT|0||0
1|instId_raw|TEXT|0||0
2|ts_signal|INTEGER|0||0
3|peak_ts|INTEGER|0||0
4|peak_price|REAL|0||0
5|delta_t_ms|INTEGER|0||0
6|delta_price_pct|REAL|0||0
7|window_min_price|REAL|0||0
8|window_max_price|REAL|0||0
9|window_mean_price|REAL|0||0
10|window_var_price|REAL|0||0
11|pressure_bias|REAL|0||0
12|ts_created|INTEGER|0||0
13|ts_updated|INTEGER|0||0

[TABLE: wticks]
0|uid|TEXT|1||1
1|instId|TEXT|1||0
2|ts_ms|INTEGER|1||2
3|bid|REAL|0||0
4|ask|REAL|0||0
5|last|REAL|0||0
6|volume|REAL|0||0
7|window_pos|TEXT|1||0

[TABLE: wticks_extended]
0|uid|TEXT|0||1
1|instId_raw|TEXT|0||0
2|ts_signal|INTEGER|0||0
3|peak_ts|INTEGER|0||0
4|peak_price|REAL|0||0
5|delta_t_ms|INTEGER|0||0
6|delta_price_pct|REAL|0||0
7|window_min_price|REAL|0||0
8|window_max_price|REAL|0||0
9|window_mean_price|REAL|0||0
10|window_var_price|REAL|0||0
11|pressure_bias|REAL|0||0
12|ts_created|INTEGER|0||0
13|ts_updated|INTEGER|0||0

-- VIEWS --
v_wticks|CREATE VIEW v_wticks AS
SELECT
    uid,
    instId,
    ts_ms,
    bid,
    ask,
    last,
    volume,
    window_pos
FROM wticks
ORDER BY uid, ts_ms
v_wticks_extended|CREATE VIEW v_wticks_extended AS
SELECT
    uid,
    instId_raw,
    ts_signal,
    peak_ts,
    peak_price,
    delta_t_ms,
    delta_price_pct,
    window_min_price,
    window_max_price,
    window_mean_price,
    window_var_price,
    pressure_bias,
    ts_created,
    ts_updated
FROM wticks_extended
ORDER BY ts_signal DESC

-- INDEXES --
idx_wt_uid|CREATE INDEX idx_wt_uid ON wticks_extended(uid)
idx_wticks_inst|CREATE INDEX idx_wticks_inst ON wticks(instId)
idx_wticks_uid|CREATE INDEX idx_wticks_uid ON wticks(uid)
sqlite_autoindex_wticks_1|
sqlite_autoindex_wticks_extended_1|

-- TRIGGERS --

