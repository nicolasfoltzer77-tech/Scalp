# ===== SCALP PROJECT DUMP =====
# 2025-11-01 18:30:14 UTC
# Root: /opt/scalp

========== TREE ==========
/opt/scalp/dp.sh                                                                         2503 2025-10-29 10:17:45.984721599 +0100
/opt/scalp/project/bin/a_analyse.sh                                                       110 2025-10-28 20:36:25.965060683 +0100
/opt/scalp/project/bin/b_dash.sh                                                          899 2025-10-29 12:21:39.955212633 +0100
/opt/scalp/project/bin/check_ofcr.sh                                                     2042 2025-11-01 14:04:20.321733074 +0100
/opt/scalp/project/bin/closer_clean.sh                                                    230 2025-10-31 12:42:57.348097711 +0100
/opt/scalp/project/bin/dash.sh                                                           1551 2025-10-31 13:04:23.699099491 +0100
/opt/scalp/project/bin/debug_signals.sh                                                   657 2025-11-01 15:13:23.070931192 +0100
/opt/scalp/project/bin/follower_clean.sh                                                  236 2025-10-31 12:26:25.059199562 +0100
/opt/scalp/project/bin/oa_ohlcv.sh                                                         89 2025-10-28 20:36:25.965060683 +0100
/opt/scalp/project/bin/oa_ohlcv_A.sh                                                       89 2025-10-28 20:36:25.965060683 +0100
/opt/scalp/project/bin/ob_check.sh                                                        259 2025-10-30 08:14:25.694016732 +0100
/opt/scalp/project/bin/ob_feat.sh                                                          86 2025-10-28 20:36:25.965060683 +0100
/opt/scalp/project/bin/ob_ohlcv_B.sh                                                       89 2025-10-28 20:36:25.969060690 +0100
/opt/scalp/project/bin/opener_clean.sh                                                    235 2025-10-31 12:22:06.630898758 +0100
/opt/scalp/project/bin/recorder_clean.sh                                                  237 2025-10-31 12:51:33.860668329 +0100
/opt/scalp/project/bin/reset_ofcr.sh                                                      824 2025-11-01 15:06:27.394232862 +0100
/opt/scalp/project/bin/t_ticks.sh                                                         117 2025-10-30 14:42:24.525733094 +0100
/opt/scalp/project/bin/u_universe.sh                                                       89 2025-10-28 20:36:25.969060690 +0100
/opt/scalp/project/bin/x_check_open.sh                                                   1049 2025-10-29 17:24:27.197468550 +0100
/opt/scalp/project/bin/x_check_ts_coherence.sh                                            545 2025-10-30 07:48:28.629639250 +0100
/opt/scalp/project/bin/x_close.sh                                                         102 2025-10-28 20:36:25.973060695 +0100
/opt/scalp/project/bin/x_closer.sh                                                        118 2025-10-30 18:03:08.343426202 +0100
/opt/scalp/project/bin/x_dash.sh                                                         1446 2025-10-28 20:36:25.973060695 +0100
/opt/scalp/project/bin/x_dash_close.sh                                                   1376 2025-10-29 16:48:04.843018883 +0100
/opt/scalp/project/bin/x_dash_now.sh                                                     1692 2025-10-30 09:15:42.251501164 +0100
/opt/scalp/project/bin/x_dash_open.sh                                                    1246 2025-10-29 17:22:39.233341729 +0100
/opt/scalp/project/bin/x_follow.sh                                                        103 2025-10-28 20:36:25.973060695 +0100
/opt/scalp/project/bin/x_open.sh                                                          101 2025-10-28 20:36:25.973060695 +0100
/opt/scalp/project/bin/x_reset.sh                                                         951 2025-10-29 17:19:42.773137320 +0100
/opt/scalp/project/bin/x_reset_all.sh                                                    2649 2025-10-30 08:57:45.525305862 +0100
/opt/scalp/project/bin/x_view_follow.sh                                                   368 2025-10-30 08:40:58.328083284 +0100
/opt/scalp/project/bin/xclose.sh                                                           86 2025-10-28 20:36:25.973060695 +0100
/opt/scalp/project/bin/xfollow.sh                                                          87 2025-10-28 20:36:25.973060695 +0100
/opt/scalp/project/bin/xopen.sh                                                            85 2025-10-28 20:36:25.977060702 +0100
/opt/scalp/project/config/scalp.conf                                                       18 2025-10-25 17:08:55.549075009 +0200
/opt/scalp/project/data/x_open.db.init.sql                                                136 2025-10-25 14:01:38.946514746 +0200
/opt/scalp/project/requirements.txt                                                       113 2025-10-30 08:19:30.318294376 +0100
/opt/scalp/project/scripts/A_analyse.py                                                  1601 2025-10-28 22:19:44.465383115 +0100
/opt/scalp/project/scripts/A_config.py                                                    336 2025-10-28 22:19:44.465383115 +0100
/opt/scalp/project/scripts/A_ctx.py                                                      2347 2025-10-28 22:19:44.465383115 +0100
/opt/scalp/project/scripts/A_ctx_dash.py                                                 1524 2025-10-28 22:19:44.465383115 +0100
/opt/scalp/project/scripts/B_dash.py                                                      472 2025-10-28 22:19:44.465383115 +0100
/opt/scalp/project/scripts/B_signals.py                                                  2818 2025-11-01 13:50:40.240761161 +0100
/opt/scalp/project/scripts/B_signals_loop.py                                             3025 2025-10-29 13:13:55.382735994 +0100
/opt/scalp/project/scripts/B_signals_reactive.py                                         4163 2025-10-29 13:58:37.018041574 +0100
/opt/scalp/project/scripts/H_perf.py                                                     2240 2025-10-28 22:19:44.465383115 +0100
/opt/scalp/project/scripts/H_score.py                                                     368 2025-10-28 22:19:44.465383115 +0100
/opt/scalp/project/scripts/OA_ohlcv_A.py                                                 2482 2025-10-28 22:19:44.469383119 +0100
/opt/scalp/project/scripts/OB_collect.py                                                 3304 2025-10-30 10:21:35.631301443 +0100
/opt/scalp/project/scripts/OB_feat.py                                                    1734 2025-10-28 22:19:44.469383119 +0100
/opt/scalp/project/scripts/OB_ohlcv_B.py                                                 1799 2025-10-28 22:19:44.469383119 +0100
/opt/scalp/project/scripts/S_cleanup_signals.sh                                           267 2025-10-28 09:52:03.409264353 +0100
/opt/scalp/project/scripts/S_cleanup_ticks.sh                                             147 2025-10-28 10:25:52.647287857 +0100
/opt/scalp/project/scripts/T_ticks.py                                                    6511 2025-10-30 14:42:10.193691701 +0100
/opt/scalp/project/scripts/T_ticks_debug.py                                              1378 2025-10-30 12:41:26.768642739 +0100
/opt/scalp/project/scripts/T_ticks_test_raw.py                                           1250 2025-10-30 12:43:49.868791255 +0100
/opt/scalp/project/scripts/U_universe.py                                                  572 2025-10-28 22:19:44.469383119 +0100
/opt/scalp/project/scripts/X_close.py                                                    2703 2025-10-29 16:39:24.122349039 +0100
/opt/scalp/project/scripts/X_config.py                                                    417 2025-10-28 22:19:44.469383119 +0100
/opt/scalp/project/scripts/X_dash.py                                                     1761 2025-10-28 22:19:44.469383119 +0100
/opt/scalp/project/scripts/X_follow.py                                                   1747 2025-10-29 15:19:10.783744012 +0100
/opt/scalp/project/scripts/X_open.py                                                     1851 2025-10-29 14:58:47.354246294 +0100
/opt/scalp/project/scripts/b_dash.py                                                     2112 2025-10-29 08:11:52.064666231 +0100
/opt/scalp/project/scripts/closer.py                                                     2744 2025-11-01 17:23:37.801724901 +0100
/opt/scalp/project/scripts/follower.py                                                   7549 2025-11-01 17:37:45.801663079 +0100
/opt/scalp/project/scripts/init_db.py                                                    1110 2025-10-28 22:19:44.469383119 +0100
/opt/scalp/project/scripts/opener.py                                                     3775 2025-11-01 17:23:27.389736518 +0100
/opt/scalp/project/scripts/recorder.py                                                   2257 2025-11-01 14:56:55.513301182 +0100
/opt/scalp/project/scripts/test_ws_bitget.py                                              871 2025-10-29 05:56:44.887457528 +0100
/opt/scalp/project/scripts/ticks.py                                                      3263 2025-10-29 08:32:53.050121154 +0100
/opt/scalp/project/scripts/x_close.py                                                    3442 2025-10-30 11:21:24.351950926 +0100
/opt/scalp/project/scripts/x_closer.py                                                   3298 2025-10-30 18:05:19.123568366 +0100
/opt/scalp/project/scripts/x_dash.py                                                     1689 2025-10-28 22:19:44.469383119 +0100
/opt/scalp/project/scripts/x_follow.py                                                   2740 2025-10-30 09:08:21.538751095 +0100
/opt/scalp/project/scripts/x_follow_atr_dynamic.py                                       2704 2025-10-29 19:50:45.215545972 +0100
/opt/scalp/project/scripts/x_open.py                                                     3191 2025-10-30 17:33:43.101362984 +0100
/opt/scalp/project/sql/A_ctx.sql                                                          688 2025-10-27 16:04:45.944819050 +0100
/opt/scalp/project/sql/a_ctx.sql                                                          588 2025-10-28 07:52:17.405117799 +0100
/opt/scalp/project/sql/a_ctx_fix.sql                                                      245 2025-10-28 08:04:13.109861829 +0100
/opt/scalp/project/sql/a_schema.sql                                                      1616 2025-10-28 07:59:06.705553505 +0100
/opt/scalp/project/sql/b_schema.sql                                                       611 2025-10-31 13:09:09.431638736 +0100
/opt/scalp/project/sql/b_stabilize.sql                                                    945 2025-11-01 13:48:19.756587163 +0100
/opt/scalp/project/sql/b_v_atr_latest_flat.sql                                            340 2025-10-29 21:44:39.784749681 +0100
/opt/scalp/project/sql/b_view_for_opener.sql                                              553 2025-10-31 14:09:12.247827490 +0100
/opt/scalp/project/sql/closer_schema.sql                                                  956 2025-11-01 10:07:34.368654967 +0100
/opt/scalp/project/sql/fix_oa_cols.sql                                                    775 2025-10-28 07:48:45.796892937 +0100
/opt/scalp/project/sql/follower_schema.sql                                                946 2025-11-01 09:57:19.771794349 +0100
/opt/scalp/project/sql/h_view.sql                                                         697 2025-10-27 09:02:54.311923468 +0100
/opt/scalp/project/sql/init_macd.sql                                                      696 2025-10-28 07:49:15.864924862 +0100
/opt/scalp/project/sql/oa_indicators.sql                                                 2239 2025-10-28 07:44:41.560633960 +0100
/opt/scalp/project/sql/opener_fix_ctx.sql                                                 268 2025-11-01 09:40:26.418732381 +0100
/opt/scalp/project/sql/opener_schema.sql                                                  743 2025-10-31 13:09:34.303681470 +0100
/opt/scalp/project/sql/recorder_enhance_H.sql                                            1903 2025-10-31 20:52:57.057604118 +0100
/opt/scalp/project/sql/recorder_schema.sql                                               1230 2025-11-01 10:11:37.384953995 +0100
/opt/scalp/project/sql/recorder_schema_full.sql                                          1541 2025-11-01 10:14:59.061193663 +0100
/opt/scalp/project/sql/signals.sql                                                        457 2025-10-27 06:39:43.910694224 +0100
/opt/scalp/project/sql/signals_schema.sql                                                 471 2025-10-27 19:47:22.512954270 +0100
/opt/scalp/project/sql/v_signals_last10.sql                                               375 2025-11-01 12:53:58.236334992 +0100
/opt/scalp/project/sql/x_follow.sql                                                       211 2025-10-27 06:39:43.914694229 +0100
/opt/scalp/project/sql/x_history.sql                                                      419 2025-10-27 06:39:43.914694229 +0100
/opt/scalp/project/sql/x_history_schema.sql                                               370 2025-10-27 13:00:29.340410348 +0100
/opt/scalp/project/sql/x_open.sql                                                         282 2025-10-27 06:39:43.914694229 +0100
/opt/scalp/project/sql/x_schema.sql                                                      2024 2025-10-27 12:52:14.027757222 +0100
/opt/scalp/project/tmp_a_schema.txt                                                         0 2025-11-01 10:52:10.667617232 +0100

========== FILE CONTENT ==========

----- FILE: /opt/scalp/dp.sh -----
#!/usr/bin/env bash
set -euo pipefail

# ---------- CONFIG ----------
ROOT="/opt/scalp"
DUMP_DIR="${ROOT}/dump"
mkdir -p "$DUMP_DIR"
TS="$(date +'%Y%m%d_%H%M%S')"
OUT="${DUMP_DIR}/scalp_full_${TS}.txt"
MAX_FILE_SIZE_KB="${MAX_FILE_SIZE_KB:-512}"

# ---------- GIT ENV ----------
[ -f /etc/scalp.env ] && . /etc/scalp.env
: "${GIT_USERNAME:?}"
: "${GIT_TOKEN:?}"
GIT_BRANCH="${GIT_BRANCH:-main}"
GIT_EMAIL_USE="${GIT_EMAIL:-${GIT_USERNAME}@users.noreply.github.com}"
REMOTE_URL="https://${GIT_HOST:-github.com}/${GIT_OWNER:-$GIT_USERNAME}/${GIT_REPO:-Scalp}.git"

# ---------- HEADER ----------
{
  echo "# ===== SCALP PROJECT DUMP ====="
  echo "# $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
  echo "# Root: $ROOT"
  echo
  echo "========== TREE =========="
} > "$OUT"

find "$ROOT" -type f \
  -not -path '*/.git/*' -not -path '*/venv/*' \
  -not -path '*/dump/*' -not -path '*/logs/*' \
  -size -"${MAX_FILE_SIZE_KB}"k \
  \( -name '*.py' -o -name '*.sh' -o -name '*.conf' -o -name '*.sql' -o -name '*.txt' \) |
  sort | while IFS= read -r f; do
    sz=$(stat -c%s "$f" 2>/dev/null || echo 0)
    mt=$(stat -c%y "$f" 2>/dev/null || echo unknown)
    printf "%-80s %12s %s\n" "$f" "$sz" "$mt" >> "$OUT"
done

{
  echo
  echo "========== FILE CONTENT =========="
} >> "$OUT"

find "$ROOT" -type f \
  -not -path '*/.git/*' -not -path '*/venv/*' \
  -not -path '*/dump/*' -not -path '*/logs/*' \
  -size -"${MAX_FILE_SIZE_KB}"k \
  \( -name '*.py' -o -name '*.sh' -o -name '*.conf' -o -name '*.sql' -o -name '*.txt' \) |
  sort | while IFS= read -r f; do
    echo -e "\n----- FILE: $f -----" >> "$OUT"
    cat "$f" 2>/dev/null >> "$OUT" || true
done

# ---------- DATABASES ----------
{
  echo
  echo "========== DATABASE DUMPS =========="
} >> "$OUT"

for DB_PATH in /opt/scalp/project/data/*.db; do
  [ -s "$DB_PATH" ] || continue
  echo -e "\n----- DATABASE: $DB_PATH -----" >> "$OUT"
  {
    echo "-- SCHEMA + DATA DUMP"
    sqlite3 -readonly "$DB_PATH" "PRAGMA busy_timeout=5000; .dump" 2>/dev/null || \
      echo "-- [WARN] locked or unreadable"
  } >> "$OUT"
done

# ---------- GIT PUSH ----------
cd "$ROOT"
git rev-parse --is-inside-work-tree >/dev/null 2>&1 || git init -q .
git config user.name "$GIT_USERNAME"
git config user.email "$GIT_EMAIL_USE"
git remote get-url origin >/dev/null 2>&1 || git remote add origin "$REMOTE_URL"

git add -f "$OUT"
git commit -m "dump ${TS}" || true
AUTH_URL="https://${GIT_USERNAME}:${GIT_TOKEN}@${REMOTE_URL#https://}"
git push -f "$AUTH_URL" HEAD:"$GIT_BRANCH"

----- FILE: /opt/scalp/project/bin/a_analyse.sh -----
#!/usr/bin/env bash
set -euo pipefail
cd /opt/scalp/project
source venv/bin/activate
python3 scripts/A_ctx.py

----- FILE: /opt/scalp/project/bin/b_dash.sh -----
#!/usr/bin/env bash
DB_B="/opt/scalp/project/data/b.db"
clear
echo "===== DASH B_SIGNALS ====="
echo

sqlite3 -readonly "$DB_B" <<'SQL'
.headers on
.mode column
.width 10 6 10 7 10 10 8 20
SELECT instId AS COIN,
       side AS SIDE,
       reason AS REASON,
       trigger AS TRIG,
       price AS PRICE,
       ctx AS CTX,
       score_A AS S_A,
       ts_local AS TS
FROM v_signals_latest
LIMIT 20;
SQL

echo
echo "----- SUMMARY -----"
sqlite3 -readonly "$DB_B" <<'SQL'
.headers off
.mode column
SELECT
  'BUY :'  || COUNT(*)  FILTER (WHERE side='buy')  || '   ' ||
  'SELL :' || COUNT(*)  FILTER (WHERE side='sell') AS "SIGNALS"
FROM signals;

SELECT 'LAST SIGNAL :' || instId || ' ' || side || ' ' || datetime(ts,'unixepoch','localtime')
FROM signals ORDER BY ts DESC LIMIT 1;

SELECT 'AVG AGE (s): ' || printf("%.1f",AVG((strftime('%s','now')-ts))) FROM signals;
SQL
echo "-------------------"

----- FILE: /opt/scalp/project/bin/check_ofcr.sh -----
#!/usr/bin/env bash
set -euo pipefail
DATA="/opt/scalp/project/data"

echo "===== CHECK O-F-C-R PIPELINE ====="
ts_now=$(date +%s)

check_table () {
    local db=$1
    local table=$2
    local ts_col=$3
    local label=$4
    [[ -f "$db" ]] || { echo "$label ❌ DB absente"; return; }

    local count last age_s age
    count=$(sqlite3 "$db" "SELECT COUNT(*) FROM $table;" 2>/dev/null || echo 0)
    last=$(sqlite3 "$db" "SELECT MAX($ts_col)/1000 FROM $table;" 2>/dev/null || echo 0)
    [[ -z "$last" || "$last" == "0" ]] && last=$ts_now
    age_s=$(( ts_now - ${last%.*:-0} ))
    age=$(printf "%02dh%02dm%02ds" $((age_s/3600)) $(((age_s%3600)/60)) $((age_s%60)))
    if (( age_s < 10 )); then s="✅"
    elif (( age_s < 60 )); then s="⚠️"
    else s="❌"
    fi
    echo "$(basename $db .db) → $label $s  ($count recs, last=$age ago)"
}

check_table "$DATA/opener.db"   "trades_open_init" "ts_create"  "OPENER"
check_table "$DATA/follower.db" "trades_follow"    "ts_update"  "FOLLOWER"
check_table "$DATA/closer.db"   "trades_close"     "ts_close"   "CLOSER"
check_table "$DATA/recorder.db" "trades_record"    "ts_record"  "RECORDER"

echo
echo "--- LAST OPEN ---"
sqlite3 -readonly "$DATA/opener.db" \
"SELECT instId,side,entry,sl,tp,qty,datetime(ts_create/1000,'unixepoch','localtime') FROM trades_open_init ORDER BY ts_create DESC LIMIT 5;"

echo
echo "--- LAST FOLLOW ---"
sqlite3 -readonly "$DATA/follower.db" \
"SELECT instId,sl_new,tp_new,atr_current,datetime(ts_update/1000,'unixepoch','localtime') FROM trades_follow ORDER BY ts_update DESC LIMIT 5;"

echo
echo "--- LAST CLOSE ---"
sqlite3 -readonly "$DATA/closer.db" \
"SELECT instId,side,entry,exit,pnl,reason_exit,datetime(ts_close/1000,'unixepoch','localtime') FROM trades_close ORDER BY ts_close DESC LIMIT 5;"

echo
echo "--- LAST RECORD ---"
sqlite3 -readonly "$DATA/recorder.db" \
"SELECT instId,side,entry,exit,pnl,reason_exit,datetime(ts_record/1000,'unixepoch','localtime') FROM trades_record ORDER BY ts_record DESC LIMIT 5;"

echo "===== END CHECK ====="

----- FILE: /opt/scalp/project/bin/closer_clean.sh -----
#!/usr/bin/env bash
set -euo pipefail
DB="/opt/scalp/project/data/closer.db"
sqlite3 "$DB" "DELETE FROM trades_close WHERE ts_close < (strftime('%s','now')-7200)*1000;"
sqlite3 "$DB" "VACUUM;"
echo "[CLEANER] closer.db compacted"

----- FILE: /opt/scalp/project/bin/dash.sh -----
#!/usr/bin/env bash
set -euo pipefail

DATA="/opt/scalp/project/data"
LOG="/opt/scalp/project/logs/dash.log"
now_s=$(date +%s)
ts_now="$(date '+%Y-%m-%d %H:%M:%S')"
printf "\n===== SCALP PIPE HEALTH %s =====\n" "$(date '+%H:%M:%S')" | tee -a "$LOG"

check_db() {
    local name="$1" file="$2" table="$3" ts_col="$4"
    if [[ ! -f "$file" ]]; then
        printf "%-10s ❌ no DB found\n" "$name" | tee -a "$LOG"
        return
    fi
    local count ts_last age_s h m s age_hms status
    count=$(sqlite3 "$file" "SELECT COUNT(*) FROM $table;")
    ts_last=$(sqlite3 "$file" "SELECT MAX($ts_col)/1000 FROM $table;")
    [[ -z "$ts_last" || "$ts_last" == "0" ]] && ts_last=$now_s
    age_s=$(( now_s - ${ts_last%.*:-0} ))
    h=$((age_s/3600)); m=$(( (age_s%3600)/60 )); s=$((age_s%60))
    age_hms=$(printf "%02dh%02dm%02ds" "$h" "$m" "$s")

    if (( age_s < 10 )); then status="✅"
    elif (( age_s < 60 )); then status="⚠️"
    else status="❌"
    fi

    printf "%-10s %s  %4s recs | last=%s | age=%s\n" \
        "$name" "$status" "$count" "$(date '+%H:%M:%S' -d @$ts_last 2>/dev/null || date -r "$ts_last" '+%H:%M:%S')" "$age_hms" \
        | tee -a "$LOG"
}

check_db "opener"   "$DATA/opener.db"   "trades_open_init" "ts_create"
check_db "follower" "$DATA/follower.db" "trades_follow"    "ts_update"
check_db "closer"   "$DATA/closer.db"   "trades_close"     "ts_close"
check_db "recorder" "$DATA/recorder.db" "trades_record"    "ts_record"

printf "==============================================\n" | tee -a "$LOG"
echo "" >> "$LOG"

----- FILE: /opt/scalp/project/bin/debug_signals.sh -----
#!/usr/bin/env bash
set -euo pipefail
DATA="/opt/scalp/project/data"
LOG="/opt/scalp/project/logs/debug_signals.log"

{
echo "===== DEBUG SIGNALS $(date '+%Y-%m-%d %H:%M:%S') ====="
sqlite3 -readonly "$DATA/b.db" "
SELECT instId, side, reason, ctx, price, score_B,
datetime(ts/1000,'unixepoch','localtime') AS ts_local
FROM signals_for_open
ORDER BY ts DESC LIMIT 10;
"
echo
sqlite3 -readonly "$DATA/opener.db" "
SELECT instId, side, entry, sl, tp, qty,
datetime(ts_create/1000,'unixepoch','localtime') AS ts_local
FROM trades_open_init
ORDER BY ts_create DESC LIMIT 10;
"
echo "=========================================================="
} | tee -a "$LOG"

----- FILE: /opt/scalp/project/bin/follower_clean.sh -----
#!/usr/bin/env bash
set -euo pipefail
DB="/opt/scalp/project/data/follower.db"
sqlite3 "$DB" "DELETE FROM trades_follow WHERE ts_update < (strftime('%s','now')-7200)*1000;"
sqlite3 "$DB" "VACUUM;"
echo "[CLEANER] follower.db compacted"

----- FILE: /opt/scalp/project/bin/oa_ohlcv.sh -----
#!/bin/bash
cd /opt/scalp/project
source venv/bin/activate
python3 scripts/OA_ohlcv_A.py

----- FILE: /opt/scalp/project/bin/oa_ohlcv_A.sh -----
#!/bin/bash
cd /opt/scalp/project
source venv/bin/activate
python3 scripts/OA_ohlcv_A.py

----- FILE: /opt/scalp/project/bin/ob_check.sh -----
#!/usr/bin/env bash
sqlite3 /opt/scalp/project/data/ob.db <<'SQL'
.headers on
.mode column
SELECT instId,
       COUNT(*) AS n,
       datetime(MAX(ts)/1000,'unixepoch','localtime') AS last_ts
FROM ohlcv_1m
GROUP BY instId
ORDER BY last_ts DESC
LIMIT 10;
SQL

----- FILE: /opt/scalp/project/bin/ob_feat.sh -----
#!/bin/bash
cd /opt/scalp/project
source venv/bin/activate
python3 scripts/OB_feat.py

----- FILE: /opt/scalp/project/bin/ob_ohlcv_B.sh -----
#!/bin/bash
cd /opt/scalp/project
source venv/bin/activate
python3 scripts/OB_ohlcv_B.py

----- FILE: /opt/scalp/project/bin/opener_clean.sh -----
#!/usr/bin/env bash
set -euo pipefail
DB="/opt/scalp/project/data/opener.db"
sqlite3 "$DB" "DELETE FROM trades_open_init WHERE ts_create < (strftime('%s','now')-7200)*1000;"
sqlite3 "$DB" "VACUUM;"
echo "[CLEANER] opener.db compacted"

----- FILE: /opt/scalp/project/bin/recorder_clean.sh -----
#!/usr/bin/env bash
set -euo pipefail
DB="/opt/scalp/project/data/recorder.db"
sqlite3 "$DB" "DELETE FROM trades_record WHERE ts_record < (strftime('%s','now')-86400)*1000;"
sqlite3 "$DB" "VACUUM;"
echo "[CLEANER] recorder.db compacted"

----- FILE: /opt/scalp/project/bin/reset_ofcr.sh -----
#!/usr/bin/env bash
set -euo pipefail
DATA="/opt/scalp/project/data"
DBS=(opener follower closer recorder)
echo "===== RESET O-F-C-R DATABASES (SAFE) ====="

for db in "${DBS[@]}"; do
  FILE="${DATA}/${db}.db"
  [[ -f "$FILE" ]] || continue
  echo "-- $db.db"
  tables=$(sqlite3 "$FILE" "SELECT name FROM sqlite_master WHERE type='table';")
  for t in $tables; do
    sqlite3 "$FILE" "DELETE FROM $t;" || true
  done
  sqlite3 "$FILE" "VACUUM;"
done

echo "Killing Python instances..."
pkill -f opener.py || true
pkill -f follower.py || true
pkill -f closer.py || true
pkill -f recorder.py || true

echo "Restarting services..."
systemctl restart scalp-opener.service
systemctl restart scalp-follower.service
systemctl restart scalp-closer.service
systemctl restart scalp-recorder.service

echo "===== RESET COMPLETE ====="

----- FILE: /opt/scalp/project/bin/t_ticks.sh -----
#!/usr/bin/env bash
set -euo pipefail
cd /opt/scalp/project
source venv/bin/activate
exec python3 scripts/T_ticks.py

----- FILE: /opt/scalp/project/bin/u_universe.sh -----
#!/bin/bash
cd /opt/scalp/project
source venv/bin/activate
python3 scripts/U_universe.py

----- FILE: /opt/scalp/project/bin/x_check_open.sh -----
#!/usr/bin/env bash
set -eo pipefail

DB="/opt/scalp/project/data/x_open.db"
echo "===== CHECK STRUCTURE x_open.db ====="
echo

declare -A EXPECTED
EXPECTED[positions_open]="instId side entry tp sl price_now pnl_pct age_hms ts_open"
EXPECTED[positions_closed]="instId side entry exit pnl_pct reason ts_open ts_close"
EXPECTED[capital]="balance_usdt"

for T in positions_open positions_closed capital; do
  echo "-- Table: $T --"
  if sqlite3 "$DB" ".tables" | grep -qw "$T"; then
    ACTUAL_COLS=$(sqlite3 "$DB" "PRAGMA table_info($T);" | awk -F'|' '{print $2}')
    echo "   Colonnes actuelles :"
    echo "$ACTUAL_COLS" | sed 's/^/      - /'
    echo

    MISSING=()
    for C in ${EXPECTED[$T]}; do
      if ! echo "$ACTUAL_COLS" | grep -qw "$C"; then
        MISSING+=("$C")
      fi
    done

    if [ "${#MISSING[@]}" -gt 0 ]; then
      echo "   ❌ Colonnes manquantes : ${MISSING[*]}"
    else
      echo "   ✅ Structure complète"
    fi
  else
    echo "   ⚠️ Table absente"
  fi
  echo
done

echo "===== END STRUCTURE CHECK ====="

----- FILE: /opt/scalp/project/bin/x_check_ts_coherence.sh -----
#!/usr/bin/env bash
set -e
echo "=== TS COHERENCE CHECK ==="
echo
echo "[T] ticks latest :"
sqlite3 /opt/scalp/project/data/t.db "SELECT datetime(MAX(ts)/1000,'unixepoch','localtime') FROM ticks;"

echo "[B] feat_1m latest :"
sqlite3 /opt/scalp/project/data/b.db "SELECT datetime(MAX(ts)/1000,'unixepoch','localtime') FROM feat_1m;"

echo "[X] positions_open range :"
sqlite3 /opt/scalp/project/data/x_open.db "SELECT datetime(MIN(ts_open)/1000,'unixepoch','localtime'), datetime(MAX(ts_open)/1000,'unixepoch','localtime') FROM positions_open;"

----- FILE: /opt/scalp/project/bin/x_close.sh -----
#!/bin/bash
source /opt/scalp/project/venv/bin/activate
python3 /opt/scalp/project/scripts/X_close.py

----- FILE: /opt/scalp/project/bin/x_closer.sh -----
#!/usr/bin/env bash
set -euo pipefail
cd /opt/scalp/project
source venv/bin/activate
exec python3 scripts/x_closer.py

----- FILE: /opt/scalp/project/bin/x_dash.sh -----
#!/usr/bin/env bash

DB_OPEN="/opt/scalp/project/data/x_open.db"
DB_CLOSED="/opt/scalp/project/data/x_closed.db"
DB_T="/opt/scalp/project/data/t.db"

clear
echo "===== DASH DETAIL ====="
echo
echo "--- OPEN POSITIONS ---"

sqlite3 -readonly "$DB_OPEN" <<'EOS'
.headers off
.mode list
SELECT
    o.instId || "  " ||
    o.side   || "  entry=" || printf("%.6f", o.entry) ||
    " sl="   || printf("%.6f", o.sl) ||
    " tp="   || printf("%.6f", o.tp) ||
    " qty="  || printf("%.4f", o.qty) ||
    " BE="   || o.BE ||
    " PYR="  || o.PYR ||
    " entry_reason=" || o.reason_entry ||
    " age="  || printf("%02d:%02d:%02d",
        ( (strftime('%s','now')*1000 - o.ts_open)/1000 )/3600,
        ( (strftime('%s','now')*1000 - o.ts_open)/1000 % 3600)/60,
        ( (strftime('%s','now')*1000 - o.ts_open)/1000 % 60)
    )
FROM positions_open o;
EOS

echo
echo "--- LAST CLOSED TRADES ---"

sqlite3 -readonly "$DB_CLOSED" <<'EOS'
.headers off
.mode list
SELECT
    instId || " " || side ||
    " entry=" || printf("%.6f", entry) ||
    " exit="  || printf("%.6f", exit) ||
    " pnl="   || printf("%.6f", pnl) ||
    " entry_reason=" || reason_entry ||
    " exit_reason="  || reason_exit ||
    " age=" || printf("%02d:%02d:%02d",
        ( (ts_close - ts_open)/1000 )/3600,
        ( (ts_close - ts_open)/1000 % 3600)/60,
        ( (ts_close - ts_open)/1000 % 60)
    )
FROM v_trades_history
LIMIT 20;
EOS

echo
echo "========================="

----- FILE: /opt/scalp/project/bin/x_dash_close.sh -----
#!/usr/bin/env bash
set -euo pipefail

DB="/opt/scalp/project/data/x_open.db"

echo "===== DASH CLOSED POSITIONS ====="
echo

sqlite3 -readonly "$DB" <<'SQL'
.headers off
.mode column
.width 10 6 10 10 10 6 20 10
SELECT
  instId,
  side,
  printf('%.4f', entry) AS entry,
  printf('%.4f', exit) AS exit,
  printf('%+.3f%%', pnl_pct) AS pnl,
  reason,
  datetime(ts_close,'unixepoch','localtime') AS closed_at,
  printf('%02d:%02d:%02d',
         (ts_close - ts_open)/3600,
         ((ts_close - ts_open)%3600)/60,
         (ts_close - ts_open)%60) AS age_hms
FROM positions_closed
ORDER BY ts_close DESC
LIMIT 20;
SQL

echo
echo "------ SUMMARY ------"

sqlite3 -readonly "$DB" <<'SQL'
.mode list
.separator '|'
WITH s AS (
  SELECT
    COUNT(*) AS total,
    SUM(CASE WHEN reason='TP' THEN 1 ELSE 0 END) AS tp,
    SUM(CASE WHEN reason='SL' THEN 1 ELSE 0 END) AS sl,
    ROUND(AVG(pnl_pct),3) AS avg_pnl,
    ROUND(SUM(pnl_pct),3) AS sum_pnl
  FROM positions_closed
)
SELECT
  printf('Trades=%d | TP=%d | SL=%d | TP/SL=%.2f | AvgPnL=%+.3f%% | TotalPnL=%+.3f%%',
    total,tp,sl,CAST(tp AS FLOAT)/MAX(sl,1),avg_pnl,sum_pnl)
FROM s;
SQL

# Solde actuel si dispo
BAL=$(sqlite3 -readonly "$DB" "SELECT printf('%.2f', balance_usdt) FROM v_capital LIMIT 1;" 2>/dev/null || echo "N/A")
if [ -z "\$BAL" ]; then BAL="N/A"; fi

echo "Balance USDT: \$BAL"
echo "----------------------"

----- FILE: /opt/scalp/project/bin/x_dash_now.sh -----
#!/usr/bin/env bash
set -euo pipefail

DB_FOLLOW="/opt/scalp/project/data/x_follow.db"
DB_X="/opt/scalp/project/data/x.db"

echo "===== DASH NOW ====="

# --- TOP 2 OPEN (BEST PnL) ---
echo "--- TOP 2 OPEN (BEST PnL) ---"
sqlite3 -readonly "$DB_FOLLOW" <<'SQL'
.headers off
.mode column
SELECT printf("%-10s | %-4s | entry=%.4f | now=%.4f | pnl=%+.3f%% | sl=%.4f | tp=%.4f | ATR=%.4f",
       instId, side, entry, last, pnl, sl, tp, atr)
FROM follow_state
ORDER BY pnl DESC
LIMIT 2;
SQL
echo ""

# --- WORST 2 OPEN (LOSS) ---
echo "--- WORST 2 OPEN (LOSS) ---"
sqlite3 -readonly "$DB_FOLLOW" <<'SQL'
.headers off
.mode column
SELECT printf("%-10s | %-4s | entry=%.4f | now=%.4f | pnl=%+.3f%% | sl=%.4f | tp=%.4f | ATR=%.4f",
       instId, side, entry, last, pnl, sl, tp, atr)
FROM follow_state
ORDER BY pnl ASC
LIMIT 2;
SQL
echo ""

# --- SUMMARY ---
OPEN_COUNT=$(sqlite3 -readonly "$DB_FOLLOW" "SELECT COUNT(*) FROM follow_state;")
AVG_PNL=$(sqlite3 -readonly "$DB_FOLLOW" "SELECT IFNULL(AVG(pnl),0) FROM follow_state;")
CLOSED_COUNT=$(sqlite3 -readonly "$DB_X" "SELECT IFNULL(COUNT(*),0) FROM positions_closed;")
TOTAL_PNL=$(sqlite3 -readonly "$DB_X" "SELECT IFNULL(SUM(pnl),0) FROM positions_closed;")
WIN_RATE=$(sqlite3 -readonly "$DB_X" "SELECT ROUND(100.0*SUM(CASE WHEN pnl>0 THEN 1 ELSE 0 END)/MAX(COUNT(*),1),2) FROM positions_closed;")
BALANCE=$(sqlite3 -readonly "$DB_X" "SELECT IFNULL(balance_usdt,1000.0) FROM x_budget LIMIT 1;")

printf "\n--- SUMMARY ---\n"
printf "Open=%s | AvgPnL=%+.3f%% | Closed=%s | TotalClosedPnL=%+.3f%% | WinRate=%s%% | Balance=$%.2f\n" \
       "$OPEN_COUNT" "$AVG_PNL" "$CLOSED_COUNT" "$TOTAL_PNL" "$WIN_RATE" "$BALANCE"
echo "====================="

----- FILE: /opt/scalp/project/bin/x_dash_open.sh -----
#!/usr/bin/env bash
set -euo pipefail

DB="/opt/scalp/project/data/x_open.db"
echo "===== DASH OPEN POSITIONS ====="
echo

# Vérifie les colonnes existantes
HAS_TS_OPEN=$(sqlite3 "$DB" "PRAGMA table_info(v_positions_open_detail);" | grep -c "ts_open" || true)

if [ "$HAS_TS_OPEN" -gt 0 ]; then
  COL_OPEN="datetime(ts_open,'unixepoch','localtime') AS opened_at"
else
  COL_OPEN="'-' AS opened_at"
fi

sqlite3 -readonly "$DB" <<SQL
.headers off
.mode column
.width 10 6 10 10 10 10 20
SELECT
  instId,
  side,
  printf('%.4f', entry) AS entry,
  printf('%.4f', price_now) AS price_now,
  printf('%+.3f%%', pnl_pct) AS pnl,
  age_hms,
  $COL_OPEN
FROM v_positions_open_detail
ORDER BY 1
LIMIT 30;
SQL

echo
echo "------ SUMMARY ------"

sqlite3 -readonly "$DB" <<'SQL'
.mode list
.separator '|'
WITH s AS (
  SELECT
    COUNT(*) AS total,
    ROUND(AVG(pnl_pct),3) AS avg_pnl,
    ROUND(SUM(pnl_pct),3) AS sum_pnl
  FROM v_positions_open_detail
)
SELECT printf('Open=%d | AvgPnL=%+.3f%% | TotalPnL=%+.3f%%', total, avg_pnl, sum_pnl)
FROM s;
SQL

BAL=$(sqlite3 -readonly "$DB" "SELECT printf('%.2f', balance_usdt) FROM v_capital LIMIT 1;" 2>/dev/null || echo "")
[ -z "$BAL" ] && BAL="N/A"

echo "Balance USDT: $BAL"
echo "----------------------"

----- FILE: /opt/scalp/project/bin/x_follow.sh -----
#!/bin/bash
source /opt/scalp/project/venv/bin/activate
python3 /opt/scalp/project/scripts/X_follow.py

----- FILE: /opt/scalp/project/bin/x_open.sh -----
#!/bin/bash
source /opt/scalp/project/venv/bin/activate
python3 /opt/scalp/project/scripts/X_open.py

----- FILE: /opt/scalp/project/bin/x_reset.sh -----
#!/usr/bin/env bash
set -euo pipefail

echo "=== RESET X MODULE CLEAN ==="

DBS=(
  "/opt/scalp/project/data/x_open.db"
  "/opt/scalp/project/data/x_follow.db"
  "/opt/scalp/project/data/x_close.db"
  "/opt/scalp/project/data/x.db"
)

for DB in "${DBS[@]}"; do
  if [ -f "$DB" ]; then
    echo "→ Nettoyage $DB"
    TABLES=$(sqlite3 "$DB" ".tables")
    for T in $TABLES; do
      case "$T" in
        positions_open|positions_closed|positions_follow|history|trades|signals|logs)
          echo "   - purge $T"
          sqlite3 "$DB" "DELETE FROM $T;" || true
        ;;
      esac
    done
    sqlite3 "$DB" "VACUUM;"
  fi
done

# Capital reset (dans x_open.db)
DB_MAIN="/opt/scalp/project/data/x_open.db"
sqlite3 "$DB_MAIN" <<'SQL'
CREATE TABLE IF NOT EXISTS capital (
  ts INTEGER DEFAULT (strftime('%s','now')),
  balance_usdt REAL
);
DELETE FROM capital;
INSERT INTO capital (balance_usdt) VALUES (1000.0);
SQL

echo "=== RESET COMPLETED ==="

----- FILE: /opt/scalp/project/bin/x_reset_all.sh -----
#!/usr/bin/env bash
set -euo pipefail

echo "=== RESET X MODULE (robuste) ==="

DB_X="/opt/scalp/project/data/x_open.db"
DB_F="/opt/scalp/project/data/x_follow.db"
DB_C="/opt/scalp/project/data/x_close.db"

# 1) Stopper les services pour libérer les verrous
systemctl stop scalp-x-open.service 2>/dev/null || true
systemctl stop scalp-follow.service  2>/dev/null || true
systemctl stop scalp-x-close.service 2>/dev/null || true
pkill -f x_open.py   2>/dev/null || true
pkill -f x_follow.py 2>/dev/null || true
pkill -f x_close.py  2>/dev/null || true
sleep 1

# 2) Fonction util: DELETE si la table existe
delete_if_exists () {
  local DB="$1"
  local TBL="$2"
  if [ -f "$DB" ]; then
    if sqlite3 "$DB" "SELECT 1 FROM sqlite_master WHERE type='table' AND name='$TBL';" | grep -q 1; then
      sqlite3 "$DB" "DELETE FROM $TBL;"
      echo " - $DB: $TBL vidé"
    else
      echo " - $DB: $TBL absent (ok)"
    fi
  fi
}

# 3) Vider X (open/closed) si présents
delete_if_exists "$DB_X" "positions_open"
delete_if_exists "$DB_X" "positions_closed"
# Ces tables n'existent pas toujours; on ignore si absentes:
delete_if_exists "$DB_X" "positions_history"
delete_if_exists "$DB_X" "positions_log"

# 4) Vider FOLLOW (crée les tables si absentes, puis vide)
if [ -f "$DB_F" ]; then
  sqlite3 "$DB_F" "
    CREATE TABLE IF NOT EXISTS follow_state(
      instId TEXT PRIMARY KEY,
      atr_current REAL, sl_new REAL, tp_new REAL, ts_update INTEGER, note TEXT
    );
    CREATE TABLE IF NOT EXISTS follow_log(
      ts INTEGER, instId TEXT, action TEXT, value_old REAL, value_new REAL, comment TEXT
    );
  "
  delete_if_exists "$DB_F" "follow_state"
  delete_if_exists "$DB_F" "follow_log"
else
  # créer vide pour harmoniser
  sqlite3 "$DB_F" "
    CREATE TABLE follow_state(
      instId TEXT PRIMARY KEY,
      atr_current REAL, sl_new REAL, tp_new REAL, ts_update INTEGER, note TEXT
    );
    CREATE TABLE follow_log(
      ts INTEGER, instId TEXT, action TEXT, value_old REAL, value_new REAL, comment TEXT
    );
  "
  echo " - $DB_F créé (tables follow_state, follow_log vides)"
fi

# 5) Vider CLOSE (si tu as une base dédiée; sinon ignoré)
delete_if_exists "$DB_C" "positions_closed"

# 6) VACUUM (compactage)
for DB in "$DB_X" "$DB_F" "$DB_C"; do
  [ -f "$DB" ] && sqlite3 "$DB" "VACUUM;"
done

# 7) Réinitialiser le solde à 1000 dans x_open.db
sqlite3 "$DB_X" "
  CREATE TABLE IF NOT EXISTS account_balance(ts INTEGER, balance_usdt REAL);
  DELETE FROM account_balance;
  INSERT INTO account_balance VALUES (strftime('%s','now')*1000, 1000.0);
"
echo "💰 Solde initial défini à 1000 USDT dans $DB_X"

echo "✅ RESET terminé"

----- FILE: /opt/scalp/project/bin/x_view_follow.sh -----
#!/usr/bin/env bash
sqlite3 /opt/scalp/project/data/x_open.db <<'SQL'
ATTACH DATABASE '/opt/scalp/project/data/x_follow.db' AS follow;

SELECT 
    p.instId,
    p.side,
    p.entry,
    p.sl,
    p.tp,
    f.sl_new  AS sl_follow,
    f.tp_new  AS tp_follow,
    f.atr_current
FROM positions_open p
LEFT JOIN follow.follow_state f ON f.instId = p.instId
LIMIT 10;
SQL

----- FILE: /opt/scalp/project/bin/xclose.sh -----
#!/bin/bash
cd /opt/scalp/project
source venv/bin/activate
python3 scripts/X_close.py

----- FILE: /opt/scalp/project/bin/xfollow.sh -----
#!/bin/bash
cd /opt/scalp/project
source venv/bin/activate
python3 scripts/X_follow.py

----- FILE: /opt/scalp/project/bin/xopen.sh -----
#!/bin/bash
cd /opt/scalp/project
source venv/bin/activate
python3 scripts/X_open.py

----- FILE: /opt/scalp/project/config/scalp.conf -----
UNIVERSE_LIMIT=20

----- FILE: /opt/scalp/project/data/x_open.db.init.sql -----
CREATE TABLE IF NOT EXISTS positions_open (
    instId TEXT PRIMARY KEY,
    side TEXT,
    entry REAL,
    qty REAL,
    ts INTEGER
);

----- FILE: /opt/scalp/project/requirements.txt -----
ccxt>=4.2.0
pandas>=2.0.0
numpy>=1.24.0
requests>=2.31.0
python-dateutil>=2.8.2
aiohttp>=3.9.0
matplotlib>=3.8.0

----- FILE: /opt/scalp/project/scripts/A_analyse.py -----
#!/usr/bin/env python3
import sqlite3, math, time

DB_A = "/opt/scalp/project/data/a.db"
DB_U = "/opt/scalp/project/data/u.db"
DB_OB = "/opt/scalp/project/data/ob.db"
TF = "5m"

def softmax(x):
    e = [math.exp(i) for i in x]
    s = sum(e)
    return [v/s for v in e]

def get_universe():
    con = sqlite3.connect(DB_U)
    rows = con.execute("SELECT instId FROM universe ORDER BY instId").fetchall()
    con.close()
    return [r[0] for r in rows]

def load_ob(inst):
    con = sqlite3.connect(DB_OB)
    row = con.execute(f"SELECT rsi FROM ob_{TF} WHERE instId=? ORDER BY ts DESC LIMIT 1", (inst,)).fetchone()
    con.close()
    return row[0] if row else None

def compute_ctx(rsi):
    if rsi < 30: return "bullish"
    if rsi > 70: return "bearish"
    if 45 <= rsi <= 55: return "range"
    return "none"

def compute_score_A(ctx):
    if ctx == "bullish": return 0.8
    if ctx == "bearish": return -0.8
    if ctx == "range": return 0.0
    return 0.0

def run():
    insts = get_universe()
    now = int(time.time()*1000)
    out = []

    for inst in insts:
        rsi = load_ob(inst)
        if rsi is None:
            continue
        ctx = compute_ctx(rsi)
        score_A = compute_score_A(ctx)
        p_buy, p_sell = softmax([score_A, -score_A])
        out.append((inst, now, 0.0, score_A, p_buy, p_sell, ctx))

    con = sqlite3.connect(DB_A)
    con.execute("DELETE FROM ctx_a_latest")
    con.executemany("INSERT INTO ctx_a_latest(instId,ts,score_U,score_A,p_buy,p_sell,ctx) VALUES (?,?,?,?,?,?,?)", out)
    con.commit()
    con.close()

if __name__ == "__main__":
    run()

----- FILE: /opt/scalp/project/scripts/A_config.py -----
#!/usr/bin/env python3

# DB paths
DB_A  = "/opt/scalp/project/data/a.db"
DB_OB = "/opt/scalp/project/data/ob.db"
DB_OA = "/opt/scalp/project/data/oa.db"
DB_U  = "/opt/scalp/project/data/u.db"

# TF used
TF_SHORT = "5m"
TF_MED   = "15m"
TF_LONG  = "30m"

# Weights for score (softmax later)
W_SHORT = 0.50
W_MED   = 0.30
W_LONG  = 0.20

----- FILE: /opt/scalp/project/scripts/A_ctx.py -----
#!/usr/bin/env python3
import sqlite3, time, numpy as np

DB_A  = "/opt/scalp/project/data/a.db"
DB_OA = "/opt/scalp/project/data/oa.db"
DB_U  = "/opt/scalp/project/data/u.db"

def macd(vals):
    def ema(v, p):
        if len(v) < p: return None
        a = 2/(p+1)
        e = v[0]
        for x in v[1:]:
            e = a*x + (1-a)*e
        return e
    e12, e26 = ema(vals,12), ema(vals,26)
    if e12 is None or e26 is None:
        return 0
    return e12 - e26

def run():
    con = sqlite3.connect(DB_A)
    con.execute("ATTACH DATABASE ? AS oa",(DB_OA,))
    con.execute("ATTACH DATABASE ? AS u",(DB_U,))
    cur = con.cursor()

    insts = [r[0] for r in cur.execute("SELECT instId FROM u.universe")]
    ts_now = int(time.time()*1000)
    rows_out = []

    for inst in insts:
        d5  = cur.execute("SELECT close FROM oa.ohlcv_5m  WHERE instId=? ORDER BY ts DESC LIMIT 150",(inst,)).fetchall()
        d15 = cur.execute("SELECT close FROM oa.ohlcv_15m WHERE instId=? ORDER BY ts DESC LIMIT 150",(inst,)).fetchall()
        d30 = cur.execute("SELECT close FROM oa.ohlcv_30m WHERE instId=? ORDER BY ts DESC LIMIT 150",(inst,)).fetchall()

        if not d5 or not d15 or not d30:
            continue

        close5  = np.array([x[0] for x in d5][::-1])
        close15 = np.array([x[0] for x in d15][::-1])
        close30 = np.array([x[0] for x in d30][::-1])

        macd5  = macd(close5.tolist())
        macd15 = macd(close15.tolist())
        macd30 = macd(close30.tolist())

        # === U NEUTRE ===
        score_U = 0.0

        # A = force contextuelle via MACD multi-TF
        score_A = np.nanmean([abs(macd5), abs(macd15), abs(macd30)])

        if macd5 > 0 and macd15 > 0 and macd30 > 0:
            ctx = "bullish"; p_buy, p_sell = 0.9, 0.1
        elif macd5 < 0 and macd15 < 0 and macd30 < 0:
            ctx = "bearish"; p_buy, p_sell = 0.1, 0.9
        else:
            ctx = "range"; p_buy, p_sell = 0.5, 0.5

        rows_out.append((inst, ts_now, score_U, score_A, p_buy, p_sell, ctx))

    cur.execute("DELETE FROM ctx_a_latest")
    cur.executemany("""
        INSERT INTO ctx_a_latest(instId,ts,score_U,score_A,p_buy,p_sell,ctx)
        VALUES (?,?,?,?,?,?,?)
    """, rows_out)
    con.commit()
    con.close()
    print("[A] ✓ ctx_A updated (U neutral)")
    
if __name__ == "__main__":
    run()

----- FILE: /opt/scalp/project/scripts/A_ctx_dash.py -----
#!/usr/bin/env python3
import sqlite3, time

DB_A = "/opt/scalp/project/data/a.db"

def hms(ts):
    if ts > 10_000_000_000: 
        ts = ts/1000
    return time.strftime("%H:%M:%S", time.localtime(ts))

def run():
    con = sqlite3.connect(DB_A)
    rows = con.execute("""
    SELECT instId, ctx, score_A, ts
    FROM ctx_a_latest
    ORDER BY ABS(score_A) DESC, instId
    """).fetchall()
    con.close()

    # remove duplicates by instId (keep first occurrence only)
    seen = set()
    clean_rows = []
    for r in rows:
        if r[0] not in seen:
            seen.add(r[0])
            clean_rows.append(r)

    # categories
    bull  = [r for r in clean_rows if r[1]=="bullish"]
    bear  = [r for r in clean_rows if r[1]=="bearish"]
    rang  = [r for r in clean_rows if r[1]=="range"]
    other = [r for r in clean_rows if r[1] not in ("bullish","bearish","range")]

    total = len(clean_rows)
    ts = clean_rows[0][3] if clean_rows else int(time.time())

    print("===== CTX SUMMARY (A) =====")
    print(f"bullish | {len(bull):<2} | {' '.join([r[0] for r in bull[:5]])} | {hms(ts)}")
    print(f"bearish | {len(bear):<2} | {' '.join([r[0] for r in bear[:5]])} | {hms(ts)}")
    print(f"range   | {len(rang):<2} | {' '.join([r[0] for r in rang[:5]])} | {hms(ts)}")
    print(f"other   | {len(other):<2} | {' '.join([r[0] for r in other[:5]])} | {hms(ts)}")
    print("---------------------------")
    print(f"TOTAL   | {total}")
    print("===========================")

if __name__=="__main__":
    run()

----- FILE: /opt/scalp/project/scripts/B_dash.py -----
import sqlite3
DB="/opt/scalp/project/data/signals.db"

con=sqlite3.connect(DB)
rows=con.execute("""
SELECT ts_signal,instId,side,reason,ctx,score_A,score_B,price
FROM signals
ORDER BY ts_signal DESC LIMIT 12
""").fetchall()
con.close()

print("\n===== LAST SIGNALS (B) =====")
for r in rows:
    ts,inst,side,reason,ctx,sA,sB,price = r
    print(f"{inst:10} | {side:4} | {reason:12} | {ctx:7} | A={sA:.3f} | B={sB:.3f} | {price}")
print("============================\n")

----- FILE: /opt/scalp/project/scripts/B_signals.py -----
#!/usr/bin/env python3
import sqlite3, time, logging

DB_B = "/opt/scalp/project/data/b.db"
DB_A = "/opt/scalp/project/data/a.db"

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s B %(levelname)s %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)

# === Lecture des contextes ===
def get_ctx_scores():
    with sqlite3.connect(DB_A) as con:
        con.row_factory = sqlite3.Row
        rows = con.execute("SELECT REPLACE(instId,'/','') AS instId, ctx, score_A FROM ctx_A_latest").fetchall()
        return {r["instId"]: (r["ctx"], r["score_A"]) for r in rows}

# === Lecture des features ===
def get_features():
    with sqlite3.connect(DB_B) as con:
        con.row_factory = sqlite3.Row
        rows = con.execute("SELECT instId, rsi, ema_fast, ema_slow, atr FROM feat_1m").fetchall()
        return rows

# === Détermination du signal ===
def compute_signal(ctx, feat):
    rsi, ema_fast, ema_slow, atr = feat["rsi"], feat["ema_fast"], feat["ema_slow"], feat["atr"]
    # Force de tendance EMA
    ema_diff = (ema_fast - ema_slow) / ema_slow * 100 if ema_slow else 0
    # RSI zones
    if rsi > 65 and ema_diff > 0.05:
        side, reason = "sell", "BO"         # breakout haut
    elif rsi < 35 and ema_diff < -0.05:
        side, reason = "buy", "MR"          # mean reversion bas
    elif abs(ema_diff) < 0.02:
        side, reason = "hold", "RANGE"      # pas de tendance
    else:
        side, reason = ("buy", "REV") if rsi < 50 else ("sell", "REV")

    # Score technique (force du signal)
    trend_strength = min(abs(ema_diff) * 1000, 100)
    momentum = abs(rsi - 50) / 50 * 100
    score_B = round(0.6 * momentum + 0.4 * trend_strength, 2)
    return side, reason, score_B

def main():
    logging.info("Starting continuous SIGNAL ENGINE B ...")

    while True:
        try:
            ctx_map = get_ctx_scores()
            feats = get_features()
            now = int(time.time())

            with sqlite3.connect(DB_B) as con:
                for f in feats:
                    inst = f["instId"]
                    ctx, score_A = ctx_map.get(inst, ("neutral", 0))
                    side, reason, score_B = compute_signal(ctx, f)
                    if side == "hold":
                        continue  # pas de signal à enregistrer
                    con.execute("""
                        INSERT INTO signals_B(instId, side, reason, price, ctx, score_A, score_B, ts, ts_hms)
                        VALUES (?,?,?,?,?,?,?,?, time('now','localtime'))
                    """, (inst, side, reason, f["ema_fast"], ctx, score_A, score_B, now))
                con.commit()
            logging.info(f"Signals updated ({len(feats)})")
        except Exception as e:
            logging.error(f"Loop error: {e}")
        time.sleep(5)

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/B_signals_loop.py -----
#!/usr/bin/env python3
"""
SCALP - B_SIGNALS (daemon loop)
Relit A + ticks, met à jour les signaux toutes les 60 s.
"""

import os, time, logging, sqlite3, sys
from datetime import datetime

DB_A = "/opt/scalp/project/data/a.db"
DB_T = "/opt/scalp/project/data/t.db"
DB_B = "/opt/scalp/project/data/b.db"
LOG_FILE = "/opt/scalp/project/logs/b_signals.log"

def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s B_SIGNALS %(levelname)s %(message)s",
        handlers=[logging.FileHandler(LOG_FILE), logging.StreamHandler(sys.stdout)],
        force=True,
    )

def connect_db(path):
    con = sqlite3.connect(path, timeout=10)
    con.execute("PRAGMA journal_mode=WAL;")
    return con

def get_ctx():
    con = connect_db(DB_A)
    rows = con.execute("SELECT instId, ctx, score_A FROM v_ctx_latest;").fetchall()
    con.close()
    return {r[0]: (r[1], r[2]) for r in rows}

def get_price(instId):
    con = connect_db(DB_T)
    row = con.execute("SELECT lastPr FROM v_ticks_latest WHERE instId=? LIMIT 1;", (instId,)).fetchone()
    con.close()
    return row[0] if row else None

def store_signal(inst, side, reason, trigger, price, ctx, score_A):
    con = connect_db(DB_B)
    ts = int(time.time())
    con.execute("""
        INSERT INTO signals(instId, side, reason, trigger, price, ctx, score_A, ts)
        VALUES (?,?,?,?,?,?,?,?);
    """, (inst, side, reason, trigger, price, ctx, score_A, ts))
    con.commit()
    con.close()

def main():
    setup_logging()
    logging.info("B_SIGNALS LOOP started.")
    while True:
        ctxs = get_ctx()
        n = 0
        for inst, (ctx, score_A) in ctxs.items():
            price = get_price(inst)
            if not price:
                continue
            if ctx == "bullish":
                store_signal(inst, "buy", "CTX_BULL", "BO", price, ctx, score_A)
                n += 1
            elif ctx == "bearish":
                store_signal(inst, "sell", "CTX_BEAR", "MR", price, ctx, score_A)
                n += 1
        logging.info(f"Cycle done → {n} signals @ {datetime.now().strftime('%H:%M:%S')}")
        time.sleep(60)

if __name__ == "__main__":
    main()
def store_signal(inst, side, reason, trigger, price, ctx, score_A):
    con = connect_db(DB_B)
    ts_now = int(time.time())
    # vérifie s’il existe déjà un signal identique sur 2 dernières minutes
    exists = con.execute("""
        SELECT 1 FROM signals
        WHERE instId=? AND side=? AND reason=? AND trigger=? 
          AND ts > strftime('%s','now','-120 seconds')
        LIMIT 1;
    """, (inst, side, reason, trigger)).fetchone()
    if not exists:
        con.execute("""
            INSERT INTO signals(instId, side, reason, trigger, price, ctx, score_A, ts)
            VALUES (?,?,?,?,?,?,?,?);
        """, (inst, side, reason, trigger, price, ctx, score_A, ts_now))
        con.commit()
        logging.info(f"NEW {inst} {side} {reason} {trigger} ctx={ctx} price={price:.4f} sA={score_A:.3f}")
    con.close()

----- FILE: /opt/scalp/project/scripts/B_signals_reactive.py -----
#!/usr/bin/env python3
"""
SCALP - B_SIGNALS (reactive, fixed mapping T<->A)
- Déclenche sur ticks frais (<3s)
- Normalise instId: T = ADAUSDT  / A = ADA/USDT
- Anti-duplication 5s (pas de flood, pas de gel)
"""

import time, sqlite3, logging, sys

DB_A = "/opt/scalp/project/data/a.db"
DB_T = "/opt/scalp/project/data/t.db"
DB_B = "/opt/scalp/project/data/b.db"
LOG_FILE = "/opt/scalp/project/logs/b_signals.log"

# ---------- LOG ----------
def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s B_SIGNALS %(levelname)s %(message)s",
        handlers=[logging.FileHandler(LOG_FILE), logging.StreamHandler(sys.stdout)],
        force=True,
    )

# ---------- DB ----------
def connect_db(path):
    con = sqlite3.connect(path, timeout=10)
    con.execute("PRAGMA journal_mode=WAL;")
    con.execute("PRAGMA busy_timeout=5000;")
    return con

# ---------- instId mapping ----------
QUOTES = ("USDT","USDC","BTC","ETH")

def to_a_inst(inst_no_slash: str) -> str:
    # "ADAUSDT" -> "ADA/USDT" ; gère USDT/USDC/BTC/ETH
    for q in QUOTES:
        if inst_no_slash.endswith(q):
            base = inst_no_slash[:-len(q)]
            return f"{base}/{q}"
    return inst_no_slash  # fallback

# ---------- FETCH ----------
def get_fresh_ticks(max_age_s=3):
    con = connect_db(DB_T)
    rows = con.execute("""
        SELECT instId
        FROM v_ticks_latest
        WHERE (strftime('%s','now') - ts_ms/1000.0) < ?
    """, (max_age_s,)).fetchall()
    con.close()
    return [r[0] for r in rows]

def get_ctx_for_t_inst(t_inst: str):
    a_inst = to_a_inst(t_inst)
    con = connect_db(DB_A)
    row = con.execute("SELECT ctx, score_A FROM v_ctx_latest WHERE instId=?;", (a_inst,)).fetchone()
    con.close()
    return row if row else (None, None)

def get_price(t_inst: str):
    con = connect_db(DB_T)
    row = con.execute("SELECT lastPr FROM v_ticks_latest WHERE instId=?;", (t_inst,)).fetchone()
    con.close()
    return float(row[0]) if row else None

# ---------- INSERT ----------
def store_signal(inst_t, side, reason, trigger, price, ctx, score_A):
    con = connect_db(DB_B)
    # anti-dup 5s sur combinaison sémantique
    exists = con.execute("""
        SELECT 1 FROM signals
        WHERE instId=? AND side=? AND reason=? AND trigger=?
          AND ts > strftime('%s','now','-5 seconds')
        LIMIT 1;
    """, (inst_t, side, reason, trigger)).fetchone()
    if not exists:
        ts_now = int(time.time())
        con.execute("""
            INSERT INTO signals(instId, side, reason, trigger, price, ctx, score_A, ts)
            VALUES (?,?,?,?,?,?,?,?);
        """, (inst_t, side, reason, trigger, price, ctx, score_A, ts_now))
        con.commit()
        logging.info(f"NEW {inst_t} {side} {reason} {trigger} ctx={ctx} price={price:.4f} sA={score_A:.3f}")
    con.close()

# ---------- MAIN ----------
def main():
    setup_logging()
    logging.info("B_SIGNALS reactive running (anti-dup 5s)")
    last_tick_emit = {}  # throttle <1s par paire

    while True:
        try:
            for inst_t in get_fresh_ticks(max_age_s=3):
                ctx, sA = get_ctx_for_t_inst(inst_t)
                if not ctx:  # pas de contexte exploitable
                    continue
                ctx = ctx.strip().lower()
                if ctx not in ("bullish","bearish"):
                    continue

                # throttle 1s par paire pour éviter le spam intra-burst
                lt = last_tick_emit.get(inst_t)
                now = time.time()
                if lt and now - lt < 1.0:
                    continue
                last_tick_emit[inst_t] = now

                price = get_price(inst_t)
                if price is None:
                    continue

                side   = "buy" if ctx=="bullish" else "sell"
                reason = f"CTX_{ctx.upper()[:4]}"
                trigger= "BO" if side=="buy" else "MR"

                store_signal(inst_t, side, reason, trigger, price, ctx, sA)

            time.sleep(0.5)
        except Exception as e:
            logging.error(f"ERR {e}")
            time.sleep(2)

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/H_perf.py -----
#!/usr/bin/env python3
import sqlite3, time, statistics, logging, sys
from pathlib import Path

LOG = "/opt/scalp/project/logs/H_perf.log"
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(message)s",
    handlers=[logging.FileHandler(LOG), logging.StreamHandler(sys.stdout)]
)

DB_CLOSED = "/opt/scalp/project/data/x_closed.db"
DB_H = "/opt/scalp/project/data/h.db"

def connect_db(path):
    con = sqlite3.connect(path, timeout=30, isolation_level=None)
    con.execute("PRAGMA journal_mode=WAL;")
    con.execute("PRAGMA synchronous=NORMAL;")
    con.execute("PRAGMA busy_timeout=5000;")
    return con

def ensure_closed_schema():
    con = connect_db(DB_CLOSED)
    con.execute("""
        CREATE TABLE IF NOT EXISTS positions_closed(
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            instId TEXT, side TEXT, entry REAL, exit REAL,
            sl REAL, tp REAL, pnl REAL, reason TEXT,
            ts_open INTEGER, ts_close INTEGER
        )
    """)
    con.close()

def migrate_h():
    con = connect_db(DB_H)
    con.execute("""
        CREATE TABLE IF NOT EXISTS score_H(
            instId TEXT PRIMARY KEY,
            avg_pnl REAL,
            winrate REAL,
            trades INTEGER,
            last_update INTEGER
        )
    """)
    con.close()

def compute_score():
    ensure_closed_schema()
    con_c = connect_db(DB_CLOSED)
    rows = con_c.execute("SELECT instId, pnl FROM positions_closed").fetchall()
    con_c.close()
    if not rows:
        logging.info("Aucun trade clos, pas de calcul.")
        return
    data = {}
    for inst,pnl in rows:
        data.setdefault(inst,[]).append(pnl)
    con_h = connect_db(DB_H)
    for inst,vals in data.items():
        avg = statistics.mean(vals)
        winrate = sum(1 for v in vals if v>0)/len(vals)
        con_h.execute("""
            INSERT OR REPLACE INTO score_H(instId,avg_pnl,winrate,trades,last_update)
            VALUES(?,?,?,?,?)
        """,(inst,avg,winrate,len(vals),int(time.time()*1000)))
    con_h.close()
    logging.info(f"Scores H mis à jour pour {len(data)} instruments.")

def main(argv):
    migrate_h()
    compute_score()

if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))

----- FILE: /opt/scalp/project/scripts/H_score.py -----
#!/usr/bin/env python3
import sqlite3, time

DB_H="/opt/scalp/project/data/x_history.db"

def latest_H():
    con=sqlite3.connect(DB_H)
    row=con.execute("SELECT score_H FROM v_H_latest").fetchone()
    con.close()
    return float(row[0]) if row and row[0] else 0.0

def run():
    h=latest_H()
    print(f"[H] score_H={h:.3f}")

if __name__=="__main__":
    run()

----- FILE: /opt/scalp/project/scripts/OA_ohlcv_A.py -----
#!/usr/bin/env python3
import sqlite3, time, ccxt

DBU = "/opt/scalp/project/data/u.db"
DBO = "/opt/scalp/project/data/oa.db"
TF_LIST = ["5m","15m","30m"]
INIT = 150
MAX_ROWS = 300

ex = ccxt.bitget()

def to_bitget_symbol(inst: str) -> str:
    return inst if ":" in inst else f"{inst}:USDT"

def ensure_schema():
    con = sqlite3.connect(DBO, timeout=5)
    cur = con.cursor()
    for tf in TF_LIST:
        cur.execute(f"DROP TABLE IF EXISTS ohlcv_{tf}")
        cur.execute(f"""
        CREATE TABLE IF NOT EXISTS ohlcv_{tf}(
          instId TEXT,
          ts INTEGER,
          open REAL, high REAL, low REAL, close REAL, volume REAL,
          PRIMARY KEY(instId, ts)
        )
        """)
    con.commit()
    con.close()

def load_universe():
    con = sqlite3.connect(DBU, timeout=5)
    rows = [r[0] for r in con.execute("SELECT instId FROM universe")]
    con.close()
    return rows

def last_ts(con, tf, inst):
    row = con.execute(f"SELECT MAX(ts) FROM ohlcv_{tf} WHERE instId=?", (inst,)).fetchone()
    return row[0] if row and row[0] is not None else None

def upsert_batch(tf, inst, batch):
    if not batch:
        return
    con = sqlite3.connect(DBO, timeout=5)
    cur = con.cursor()
    cur.executemany(
        f"INSERT OR REPLACE INTO ohlcv_{tf}(instId,ts,open,high,low,close,volume) VALUES (?,?,?,?,?,?,?)",
        [(inst, o[0], o[1], o[2], o[3], o[4], o[5]) for o in batch]
    )
    cur.execute(f"""
        DELETE FROM ohlcv_{tf}
        WHERE instId=?
          AND ts NOT IN (
            SELECT ts FROM ohlcv_{tf}
            WHERE instId=?
            ORDER BY ts DESC
            LIMIT {MAX_ROWS}
          )
    """, (inst, inst))
    con.commit()
    con.close()

def sync_inst_tf(inst, tf):
    inst_ccxt = to_bitget_symbol(inst)
    con = sqlite3.connect(DBO, timeout=5)
    ts_last = last_ts(con, tf, inst)
    con.close()

    if ts_last is None:
        data = ex.fetch_ohlcv(inst_ccxt, tf, limit=INIT)
        upsert_batch(tf, inst, data)
        return

    data = ex.fetch_ohlcv(inst_ccxt, tf, since=ts_last + 1, limit=150)
    upsert_batch(tf, inst, data)

def main():
    ensure_schema()
    insts = load_universe()
    for inst in insts:
        for tf in TF_LIST:
            try:
                sync_inst_tf(inst, tf)
                time.sleep(0.25)
            except Exception as e:
                print(f"[OA][{inst}][{tf}] WARN: {e}")
    print("[OA] ✅ Multi-TF sync to oa.db")

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/OB_collect.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OB_collect.py
→ Récupère les bougies 1m Bitget pour les instruments du universe + positions ouvertes
→ Ne fetch que les bougies manquantes
"""

import ccxt
import sqlite3
import time
import datetime
import os

DB_OB = "/opt/scalp/project/data/ob.db"
DB_U = "/opt/scalp/project/data/u.db"
DB_X = "/opt/scalp/project/data/x_open.db"
LOG_PREFIX = "OB_COLLECT"


def log(msg: str):
    print(f"{datetime.datetime.now():%Y-%m-%d %H:%M:%S} {LOG_PREFIX} {msg}", flush=True)


def get_watchlist():
    """Fusionne universe actif + positions ouvertes"""
    watch = set()

    # 1. Universe actif
    try:
        conn_u = sqlite3.connect(DB_U)
        for (instId,) in conn_u.execute("SELECT DISTINCT instId FROM universe WHERE active=1;"):
            watch.add(instId)
        conn_u.close()
    except Exception as e:
        log(f"ERR universe: {e}")

    # 2. Coins avec positions ouvertes
    try:
        conn_x = sqlite3.connect(DB_X)
        for (instId,) in conn_x.execute("SELECT DISTINCT instId FROM positions_open;"):
            watch.add(instId)
        conn_x.close()
    except Exception as e:
        log(f"ERR x_open: {e}")

    return sorted(list(watch))


def init_db():
    """Création table si manquante"""
    conn = sqlite3.connect(DB_OB)
    conn.execute("""
        CREATE TABLE IF NOT EXISTS ohlcv_1m (
            instId TEXT,
            ts INTEGER,
            o REAL, h REAL, l REAL, c REAL, v REAL,
            PRIMARY KEY (instId, ts)
        );
    """)
    conn.commit()
    return conn


def fetch_and_store(instId: str, conn: sqlite3.Connection, limit: int = 200):
    """Récupère uniquement les bougies manquantes"""
    ex = ccxt.bitget()
    symbol = instId.replace("USDT", "/USDT")

    # dernière bougie connue
    cur = conn.cursor()
    cur.execute("SELECT MAX(ts) FROM ohlcv_1m WHERE instId=?;", (instId,))
    last_ts = cur.fetchone()[0]

    if last_ts is None:
        # première synchro : on prend 200 bougies
        since = int(time.time() * 1000) - limit * 60 * 1000
        log(f"{instId}: initial sync, fetching last {limit} bars")
    else:
        # on continue juste après la dernière
        since = int(last_ts + 60_000)
        log(f"{instId}: fetching new data since {datetime.datetime.fromtimestamp(last_ts/1000)}")

    try:
        candles = ex.fetch_ohlcv(symbol, timeframe="1m", since=since, limit=limit)
        if not candles:
            log(f"{instId}: no new candles")
            return

        cur = conn.cursor()
        for ts, o, h, l, c, v in candles:
            cur.execute(
                "INSERT OR REPLACE INTO ohlcv_1m VALUES (?,?,?,?,?,?,?)",
                (instId, ts, o, h, l, c, v)
            )
        conn.commit()

        last_dt = datetime.datetime.fromtimestamp(candles[-1][0] / 1000)
        log(f"{instId}: added {len(candles)} new bars → {last_dt:%Y-%m-%d %H:%M:%S}")
    except Exception as e:
        log(f"ERR fetch {instId}: {e}")


def main():
    conn = init_db()
    watchlist = get_watchlist()
    if not watchlist:
        log("No instruments to collect → exit")
        return

    for instId in watchlist:
        fetch_and_store(instId, conn)

    conn.close()
    log("Sync complete ✅")


if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/OB_feat.py -----
#!/usr/bin/env python3
import sqlite3, time

DB_OB = "/opt/scalp/project/data/ob.db"
DB_B  = "/opt/scalp/project/data/b.db"

def ensure_schema():
    con = sqlite3.connect(DB_B, timeout=30, isolation_level=None)
    con.execute("PRAGMA journal_mode=WAL;")
    con.execute("""CREATE TABLE IF NOT EXISTS feat_1m(
        instId TEXT,
        ts INTEGER,
        atr REAL,
        PRIMARY KEY(instId, ts)
    )""")
    con.execute("""CREATE TABLE IF NOT EXISTS feat_3m(
        instId TEXT,
        ts INTEGER,
        atr REAL,
        PRIMARY KEY(instId, ts)
    )""")
    con.close()

def atr14(rows):
    # rows = [(ts,o,h,l,c,v)] triés ASC
    if len(rows) < 15:
        return None
    trs=[]
    prev_close = rows[0][4]
    for (_,o,h,l,c,v) in rows[1:]:
        trs.append(max(h-l, abs(h-prev_close), abs(l-prev_close)))
        prev_close=c
    return sum(trs[-14:]) / 14.0

def process(tf):
    tbl_k = f"kline_{tf}"
    tbl_f = f"feat_{tf}"
    con_ob = sqlite3.connect(DB_OB)
    con_b  = sqlite3.connect(DB_B)

    insts = [r[0] for r in con_ob.execute(f"SELECT DISTINCT instId FROM {tbl_k}")]
    for inst in insts:
        rows = con_ob.execute(
            f"SELECT ts,o,h,l,c,v FROM {tbl_k} WHERE instId=? ORDER BY ts ASC",
            (inst,)
        ).fetchall()
        a = atr14(rows)
        if a is None:
            continue
        ts = rows[-1][0]
        con_b.execute(
            f"INSERT OR REPLACE INTO {tbl_f}(instId,ts,atr) VALUES(?,?,?)",
            (inst,ts,a)
        )
    con_b.commit()
    con_ob.close()
    con_b.close()

def main():
    ensure_schema()
    while True:
        process("1m")
        process("3m")
        time.sleep(20)  # toutes les 20s

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/OB_ohlcv_B.py -----
#!/usr/bin/env python3
import ccxt, sqlite3, time

DBu = "/opt/scalp/project/data/u.db"
DBo = "/opt/scalp/project/data/ob.db"
ex = ccxt.bitget()

def to_bitget_symbol(inst: str) -> str:
    return inst if ":USDT" in inst else f"{inst}:USDT"

def init_db():
    con = sqlite3.connect(DBo, timeout=30, isolation_level=None)
    con.execute("PRAGMA journal_mode=WAL;")
    con.execute("""CREATE TABLE IF NOT EXISTS kline_1m(
        instId TEXT, ts INTEGER, o REAL, h REAL, l REAL, c REAL, v REAL,
        PRIMARY KEY(instId, ts)
    )""")
    con.execute("""CREATE TABLE IF NOT EXISTS kline_3m(
        instId TEXT, ts INTEGER, o REAL, h REAL, l REAL, c REAL, v REAL,
        PRIMARY KEY(instId, ts)
    )""")
    con.close()

def get_universe():
    con = sqlite3.connect(DBu, timeout=30, isolation_level=None)
    rows = con.execute("SELECT instId FROM universe").fetchall()
    con.close()
    return [r[0] for r in rows]

def upsert(tf, inst, ohlcv):
    tbl = "kline_1m" if tf == "1m" else "kline_3m"
    con = sqlite3.connect(DBo, timeout=30, isolation_level=None)
    con.execute(f"INSERT OR REPLACE INTO {tbl}(instId,ts,o,h,l,c,v) VALUES(?,?,?,?,?,?,?)",
                (inst, ohlcv[0], ohlcv[1], ohlcv[2], ohlcv[3], ohlcv[4], ohlcv[5]))
    con.close()

def fetch_tf(inst, tf):
    sym = to_bitget_symbol(inst)
    ohlc = ex.fetch_ohlcv(sym, tf, limit=150)
    for o in ohlc:
        upsert(tf, inst, o)
    print(f"[OB] {inst} {tf} stored ({len(ohlc)} candles)")

def main():
    init_db()
    while True:
        try:
            for inst in get_universe():
                fetch_tf(inst, "1m")
                fetch_tf(inst, "3m")
            time.sleep(5)
        except Exception as e:
            print("[OB ERROR]", e)
            time.sleep(2)

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/S_cleanup_signals.sh -----
#!/usr/bin/env bash
set -euo pipefail
sqlite3 /opt/scalp/project/data/signals.db "
WITH ranked AS (
  SELECT rowid,
         ROW_NUMBER() OVER (PARTITION BY instId ORDER BY ts_signal DESC) AS rn
  FROM signals_for_open
)
DELETE FROM signals_for_open WHERE rn > 10;
"

----- FILE: /opt/scalp/project/scripts/S_cleanup_ticks.sh -----
#!/usr/bin/env bash
set -euo pipefail
sqlite3 /opt/scalp/project/data/t.db "
DELETE FROM ticks
WHERE ts < strftime('%s','now','-1 hour') * 1000;
"

----- FILE: /opt/scalp/project/scripts/T_ticks.py -----
#!/usr/bin/env python3
# --- SCALP - TICKS COLLECTOR (Bitget Futures v2 WS) ---
# Inputs:  u.db (universe active=1)
# Outputs: t.db (ticks, ticks_hist, v_ticks_latest)
#
# WebSocket public Futures v2: wss://ws.bitget.com/v2/ws/public
# Maintient ticks temps réel, reconnecte automatiquement,
# logue tout, idempotent, conforme guide IA.

from __future__ import annotations
import argparse, asyncio, json, logging, sqlite3, sys, time
from pathlib import Path
from typing import Any, List

DB_T = "/opt/scalp/project/data/t.db"
DB_U = "/opt/scalp/project/data/u.db"
LOGF = "/opt/scalp/project/logs/t_ticks.log"
WS_URL = "wss://ws.bitget.com/v2/ws/public"

# --- LOGGING ---------------------------------------------------
def setup_logging() -> None:
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s T_TICKS %(levelname)s %(message)s",
        handlers=[
            logging.FileHandler(LOGF),
            logging.StreamHandler(sys.stdout),
        ],
        force=True,
    )

# --- SQLITE ----------------------------------------------------
def connect_db(path: str) -> sqlite3.Connection:
    con = sqlite3.connect(path, timeout=30, isolation_level=None)
    con.execute("PRAGMA journal_mode=WAL;")
    con.execute("PRAGMA synchronous=NORMAL;")
    con.execute("PRAGMA busy_timeout=5000;")
    return con

SCHEMA_SQL = """
CREATE TABLE IF NOT EXISTS ticks(
  instId TEXT PRIMARY KEY,
  lastPr REAL,
  ts_ms INTEGER
);
CREATE TABLE IF NOT EXISTS ticks_hist(
  instId TEXT,
  lastPr REAL,
  ts_ms INTEGER,
  PRIMARY KEY(instId, ts_ms)
);
CREATE VIEW IF NOT EXISTS v_ticks_latest AS
SELECT
  t.instId,
  t.lastPr,
  t.ts_ms,
  strftime('%H:%M:%S', t.ts_ms/1000, 'unixepoch','localtime') AS hms,
  printf('%02d:%02d:%02d',
     ((strftime('%s','now')*1000 - t.ts_ms)/1000)/3600,
     (((strftime('%s','now')*1000 - t.ts_ms)/1000)%3600)/60,
     ((strftime('%s','now')*1000 - t.ts_ms)/1000)%60) AS age_hms
FROM ticks t
ORDER BY t.instId;
"""

def migrate(conn: sqlite3.Connection) -> None:
    conn.executescript(SCHEMA_SQL)

def upsert_tick(db_t: str, instId: str, price: float, ts_ms: int) -> None:
    con = connect_db(db_t)
    cur = con.cursor()
    cur.execute(
        "INSERT INTO ticks_hist(instId,lastPr,ts_ms) VALUES(?,?,?) "
        "ON CONFLICT(instId,ts_ms) DO NOTHING;",
        (instId, price, ts_ms),
    )
    cur.execute(
        "INSERT INTO ticks(instId,lastPr,ts_ms) VALUES(?,?,?) "
        "ON CONFLICT(instId) DO UPDATE SET lastPr=excluded.lastPr, ts_ms=excluded.ts_ms;",
        (instId, price, ts_ms),
    )
    con.commit()
    con.close()

# --- UNIVERSE --------------------------------------------------
def load_universe(db_u: str) -> List[str]:
    con = connect_db(db_u)
    cur = con.cursor()
    try:
        insts = [r[0] for r in cur.execute(
            "SELECT instId FROM universe WHERE active=1 ORDER BY instId;"
        ).fetchall()]
        if not insts:
            raise Exception
    except Exception:
        insts = [r[0] for r in cur.execute(
            "SELECT DISTINCT instId FROM universe ORDER BY instId;"
        ).fetchall()]
    con.close()
    return [s.replace("/", "").upper() for s in insts]

# --- SELF TEST -------------------------------------------------
def smoke_test() -> None:
    tmp = Path("/tmp/t_ticks_ws_test.db")
    if tmp.exists():
        tmp.unlink()
    con = connect_db(str(tmp))
    migrate(con)
    now_ms = int(time.time() * 1000)
    con.execute("INSERT INTO ticks VALUES(?,?,?)", ("TESTUSDT", 1.2345, now_ms))
    row = con.execute("SELECT instId FROM v_ticks_latest WHERE instId='TESTUSDT'").fetchone()
    assert row and row[0] == "TESTUSDT", "self-test failed"
    con.close()
    tmp.unlink(missing_ok=True)
    logging.info("SELF-TEST OK")

# --- WEBSOCKET HANDLER ----------------------------------------
async def run_ws(db_t: str, db_u: str) -> None:
    import websockets

    while True:
        insts = load_universe(db_u)
        if not insts:
            logging.warning("Aucun instrument actif → attente 5s")
            await asyncio.sleep(5)
            continue

        try:
            async with websockets.connect(WS_URL, ping_interval=None) as ws:
                subs = [
                    {"instType":"USDT-FUTURES","channel":"ticker","instId":inst}
                    for inst in insts
                ]
                msg_sub = {"op":"subscribe","args":subs}
                await ws.send(json.dumps(msg_sub))
                logging.info(f"Abonnement envoyé ({len(subs)} paires)")

                last_ping = time.time()

                while True:
                    try:
                        raw = await asyncio.wait_for(ws.recv(), timeout=25)
                    except asyncio.TimeoutError:
                        # heartbeat toutes 20s
                        await ws.send(json.dumps({"op":"ping"}))
                        last_ping = time.time()
                        continue

                    msg = json.loads(raw)
                    if "action" not in msg:
                        continue
                    if msg["action"] not in ("snapshot","update"):
                        continue
                    data = msg.get("data", [])
                    for d in data:
                        inst = d.get("instId")
                        pr = d.get("lastPr") or d.get("last") or d.get("markPrice")
                        ts_ms = int(d.get("ts") or int(time.time()*1000))
                        if not inst or not pr:
                            continue
                        upsert_tick(db_t, inst, float(pr), ts_ms)
                    await asyncio.sleep(0)  # yield event loop

        except Exception as e:
            logging.error(f"WS error: {e} → reconnect dans 3s")
            await asyncio.sleep(3)

# --- MAIN ------------------------------------------------------
def parse(argv: List[str]) -> argparse.Namespace:
    p = argparse.ArgumentParser(description="SCALP - Ticks collector (Bitget Futures WS)")
    p.add_argument("--db-t", default=DB_T)
    p.add_argument("--db-u", default=DB_U)
    p.add_argument("--self-test", action="store_true")
    return p.parse_args(argv)

def main(argv: List[str]) -> int:
    setup_logging()
    args = parse(argv)
    if args.self_test:
        smoke_test()
        return 0

    con = connect_db(args.db_t)
    migrate(con)
    con.close()

    asyncio.run(run_ws(args.db_t, args.db_u))
    return 0

if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))

----- FILE: /opt/scalp/project/scripts/T_ticks_debug.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import asyncio, json, websockets, datetime, re

WS_URL = "wss://ws.bitget.com/mix/v1/stream"

# liste restreinte pour test
INSTRUMENTS = ["BTCUSDT", "ETHUSDT", "BNBUSDT"]

async def listen():
    async with websockets.connect(WS_URL, ping_interval=20) as ws:
        subs = []
        for inst in INSTRUMENTS:
            subs.append({
                "op": "subscribe",
                "args": [f"ticker:{inst}_UMCBL"]
            })
        for s in subs:
            await ws.send(json.dumps(s))
        print("Subscriptions sent:", subs)

        count = 0
        while True:
            msg = await ws.recv()
            ts = datetime.datetime.now().strftime("%H:%M:%S")
            print(f"\n[{ts}] RAW:", msg[:200])  # tronqué si long

            # test parsing brut
            try:
                clean = re.search(r'\{.*\}', msg)
                obj = json.loads(clean.group(0)) if clean else None
                if obj:
                    ticker = obj.get("data", [{}])[0]
                    inst = ticker.get("symbol", "?")
                    last = ticker.get("last", "?")
                    print(f"→ Parsed {inst} = {last}")
            except Exception as e:
                print("⚠️ Parse error:", e)

            count += 1
            if count >= 5:
                break

asyncio.run(listen())

----- FILE: /opt/scalp/project/scripts/T_ticks_test_raw.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import asyncio, json, time, websockets

WS_URL = "wss://ws.bitget.com/v2/ws/public"
INSTRUMENTS = ["BTCUSDT", "ETHUSDT", "BNBUSDT"]

async def test():
    async with websockets.connect(WS_URL, ping_interval=None) as ws:
        subs = [{"instType": "USDT-FUTURES", "channel": "ticker", "instId": i} for i in INSTRUMENTS]
        msg = {"op": "subscribe", "args": subs}
        await ws.send(json.dumps(msg))
        print("✅ Sent:", msg)

        async def pinger():
            while True:
                await asyncio.sleep(10)
                await ws.send('{"op":"ping"}')
        asyncio.create_task(pinger())

        while True:
            raw = await ws.recv()
            ts = time.strftime("%H:%M:%S")
            print(f"\n[{ts}] RAW →", raw[:250])

            try:
                data = json.loads(raw)
                if "data" in data:
                    for d in data["data"]:
                        inst = d.get("instId")
                        pr   = d.get("lastPr")
                        if inst and pr:
                            print(f"→ Parsed {inst} = {pr}")
            except Exception as e:
                print("⚠️ Parse error:", e)

asyncio.run(test())

----- FILE: /opt/scalp/project/scripts/U_universe.py -----
import ccxt, sqlite3

DBU = "/opt/scalp/project/data/u.db"
TOP = 20

exchange = ccxt.bitget()
markets = exchange.load_markets()

perps = []
for s,info in markets.items():
    if info.get('swap',False) and info['quote'] == 'USDT':
        inst = s.replace(":USDT","")  # -> BTC/USDT:USDT → BTC/USDT
        perps.append(inst)

perps = perps[:TOP]

con = sqlite3.connect(DBU, timeout=5)
con.execute("DELETE FROM universe;")
for inst in perps:
    con.execute("INSERT OR IGNORE INTO universe(instId) VALUES (?)", (inst,))
con.commit()
con.close()

print("[U] OK :", perps)

----- FILE: /opt/scalp/project/scripts/X_close.py -----
#!/usr/bin/env python3
import sqlite3
import time
import logging

DB = "/opt/scalp/project/data/x_open.db"
LOG = "/opt/scalp/project/logs/x_close.log"

logging.basicConfig(
    filename=LOG,
    level=logging.INFO,
    format="%(asctime)s X_CLOSE %(levelname)s %(message)s"
)

def compute_pnl(side, entry, exit):
    try:
        if side == "buy":
            return ((exit - entry) / entry) * 100
        elif side == "sell":
            return ((entry - exit) / entry) * 100
    except Exception:
        return 0.0
    return 0.0

def close_position(inst, side, entry, exit_price, reason):
    pnl = compute_pnl(side, entry, exit_price)
    ts_close = int(time.time())
    try:
        con = sqlite3.connect(DB)
        cur = con.cursor()

        # Historisation complète
        cur.execute("""
            INSERT INTO positions_closed (
                instId, side, entry, exit, pnl_pct, reason, ts_open, ts_close
            )
            SELECT instId, side, entry, ?, ?, ?, ts_open, ?
            FROM positions_open
            WHERE instId=?;
        """, (exit_price, pnl, reason, ts_close, inst))

        # Suppression position ouverte
        cur.execute("DELETE FROM positions_open WHERE instId=?;", (inst,))
        con.commit()
        con.close()

        logging.info(f"CLOSE {inst} {reason} exit={exit_price:.4f} pnl={pnl:.3f}%")
    except Exception as e:
        logging.error(f"ERR close_position {inst} {e}")

def check_positions():
    try:
        con = sqlite3.connect(DB)
        cur = con.cursor()
        cur.execute("""
            SELECT instId, side, entry, tp, sl, price_now
            FROM positions_open;
        """)
        rows = cur.fetchall()
        con.close()
    except Exception as e:
        logging.error(f"ERR reading positions_open: {e}")
        return

    for inst, side, entry, tp, sl, price_now in rows:
        if price_now == 0 or price_now is None:
            continue

        if side == "buy":
            if tp and price_now >= tp:
                close_position(inst, side, entry, price_now, "TP")
            elif sl and price_now <= sl:
                close_position(inst, side, entry, price_now, "SL")
        elif side == "sell":
            if tp and price_now <= tp:
                close_position(inst, side, entry, price_now, "TP")
            elif sl and price_now >= sl:
                close_position(inst, side, entry, price_now, "SL")

def run():
    logging.info("CLOSE service started.")
    while True:
        try:
            check_positions()
            logging.info("READY")
        except Exception as e:
            logging.error(f"ERR main loop {e}")
        time.sleep(5)

if __name__ == "__main__":
    run()

----- FILE: /opt/scalp/project/scripts/X_config.py -----
DB_SIG="/opt/scalp/project/data/signals.db"
DB_T="/opt/scalp/project/data/t.db"
DB_A="/opt/scalp/project/data/a.db"
DB_XOPEN="/opt/scalp/project/data/x_open.db"
DB_XCLOSED="/opt/scalp/project/data/x_closed.db"   # <-- ajouté
DB_XFOLLOW="/opt/scalp/project/data/x_follow.db"
DB_H="/opt/scalp/project/data/h.db"

COOLDOWN_OPEN = 0        # tu pourras remonter plus tard (ex 45-120)
ATR_SL_MULT = 2.0
ATR_TP_MULT = 3.0

----- FILE: /opt/scalp/project/scripts/X_dash.py -----
#!/usr/bin/env python3
import sqlite3, time

DB_O = "/opt/scalp/project/data/x_open.db"
DB_H = "/opt/scalp/project/data/x_history.db"
DB_T = "/opt/scalp/project/data/t.db"

def h(ts): 
    return time.strftime("%H:%M:%S", time.localtime(ts/1000))

def price(inst):
    con = sqlite3.connect(DB_T)
    r = con.execute("SELECT price FROM ticks WHERE instId=? ORDER BY ts DESC LIMIT 1",(inst,)).fetchone()
    con.close()
    return float(r[0]) if r else None

# ===== OPEN POSITIONS =====
print("===== OPEN POSITIONS =====")
con = sqlite3.connect(DB_O)
rows = con.execute("SELECT instId,side,entry,sl,tp,qty,score_U,score_A,score_B,ts_open FROM positions_open").fetchall()
con.close()

if not rows:
    print("No open positions")
else:
    for r in rows:
        inst,side,e,sl,tp,qty,u,a,b,ts = r
        p = price(inst)
        pnl = (p-e)*qty if side=="buy" else (e-p)*qty
        print(f"{inst} | {side} | entry={e:.6f} | sl={sl:.6f} | tp={tp:.6f} | pnl={pnl:.4f} | {h(ts)}")
print("==========================\n")

# ===== LAST CLOSED =====
print("===== LAST CLOSED =====")
con = sqlite3.connect(DB_H)
hist = con.execute("""
SELECT instId,side,entry,exit,qty,pnl,ts_close,reason
FROM x_history ORDER BY ts_close DESC LIMIT 5
""").fetchall()
con.close()

if not hist:
    print("No closed positions")
else:
    for inst,side,e,x,qty,pnl,tsc,reason in hist:
        print(f"{inst} | {side} | {e:.4f}->{x:.4f} | pnl={pnl:.4f} | {h(tsc)} | {reason}")
print("==========================\n")

print("===== ACCOUNT =====")
BAL = 1000.0
total_pnl = sum([h[5] for h in hist]) if hist else 0
print(f"Balance paper  : {BAL:.2f} USDT")
print(f"Equity paper   : {BAL+total_pnl:.2f} USDT")
print(f"Closed PnL     : {total_pnl:.4f} USDT")
print("==========================")

----- FILE: /opt/scalp/project/scripts/X_follow.py -----
#!/usr/bin/env python3
import sqlite3
import time
import logging
from datetime import datetime

DB_OPEN = "/opt/scalp/project/data/x_open.db"
DB_TICKS = "/opt/scalp/project/data/t.db"

logging.basicConfig(
    filename="/opt/scalp/project/logs/x_follow.log",
    level=logging.INFO,
    format="%(asctime)s X_FOLLOW %(levelname)s %(message)s"
)

def get_ticks():
    """Lit les derniers prix depuis t.db"""
    con = sqlite3.connect(DB_TICKS)
    cur = con.cursor()
    cur.execute("SELECT instId,lastPr FROM v_ticks_latest;")
    rows = dict(cur.fetchall())
    con.close()
    return rows

def update_positions(ticks):
    """Met à jour les positions ouvertes avec le prix actuel et le PnL"""
    con = sqlite3.connect(DB_OPEN)
    cur = con.cursor()
    cur.execute("SELECT instId,side,entry FROM positions_open;")
    rows = cur.fetchall()

    n = 0
    for inst, side, entry in rows:
        if inst not in ticks:
            continue
        price_now = ticks[inst]
        if side == "buy":
            pnl = ((price_now - entry) / entry) * 100
        else:
            pnl = ((entry - price_now) / entry) * 100

        cur.execute("""
            UPDATE positions_open
            SET price_now=?, pnl_pct=?, age_hms=strftime('%H:%M:%S','now','localtime')
            WHERE instId=?;
        """, (price_now, pnl, inst))
        n += 1

    con.commit()
    con.close()
    return n

def run():
    logging.info("FOLLOW service started.")
    while True:
        try:
            ticks = get_ticks()
            count = update_positions(ticks)
            logging.info(f"FOLLOW {count} positions updated")
        except Exception as e:
            logging.error(f"ERR {e}")
        time.sleep(5)

if __name__ == "__main__":
    run()

----- FILE: /opt/scalp/project/scripts/X_open.py -----
#!/usr/bin/env python3
import sqlite3, time, logging

DB_B = "/opt/scalp/project/data/b.db"
DB_X = "/opt/scalp/project/data/x_open.db"
LOG = "/opt/scalp/project/logs/x_open.log"

logging.basicConfig(filename=LOG, level=logging.INFO,
                    format="%(asctime)s X_OPEN %(levelname)s %(message)s")

def get_new_signals():
    with sqlite3.connect(DB_B) as con:
        con.row_factory = sqlite3.Row
        return [dict(r) for r in con.execute("""
            SELECT instId, side, trigger, price, ts_local
            FROM v_signals_for_open
            ORDER BY ts_local DESC
            LIMIT 50;
        """)]

def can_open(inst):
    """Refuse si déjà en position ou si ouvert il y a <30s"""
    with sqlite3.connect(DB_X) as con:
        cur = con.cursor()
        row = cur.execute("""
            SELECT ts_open FROM positions_open
            WHERE instId=? ORDER BY ts_open DESC LIMIT 1;
        """, (inst,)).fetchone()
        if not row:
            return True
        last = int(row[0]) / 1000
        return (time.time() - last) > 30  # 30s mini

def insert_open(sig):
    with sqlite3.connect(DB_X) as con:
        if not can_open(sig["instId"]):
            logging.debug(f"SKIP {sig['instId']} recent or active")
            return
        con.execute("""
            INSERT OR IGNORE INTO positions_open (instId, side, entry, ts_open)
            VALUES (?, ?, ?, strftime('%s','now')*1000);
        """, (sig["instId"], sig["side"], sig["price"]))
        con.commit()
        logging.info(f"NEW OPEN {sig['instId']} {sig['side']} @ {sig['price']}")

def main():
    logging.info("READY")
    while True:
        try:
            for s in get_new_signals():
                insert_open(s)
        except Exception as e:
            logging.error(f"ERR {e}")
        time.sleep(5)

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/b_dash.py -----
#!/usr/bin/env python3
import sqlite3, time
from datetime import datetime

DB_A = "/opt/scalp/project/data/a.db"
DB_B = "/opt/scalp/project/data/b.db"
DB_T = "/opt/scalp/project/data/t.db"

def get_ctx():
    with sqlite3.connect(DB_A) as con:
        cur = con.cursor()
        cur.execute("SELECT instId, ctx FROM v_ctx_latest WHERE ctx IN ('bullish','bearish','range');")
        return cur.fetchall()

def get_last_tick(inst):
    with sqlite3.connect(DB_T) as con:
        cur = con.cursor()
        cur.execute("SELECT lastPr, ts_ms FROM v_ticks_latest WHERE instId=? LIMIT 1;", (inst,))
        r = cur.fetchone()
    if not r:
        return None, None, None, None
    pr, ts_ms = r
    ts_s = ts_ms / 1000
    hms = datetime.fromtimestamp(ts_s).strftime("%H:%M:%S")
    delta = round(time.time() - ts_s, 1)
    return pr, ts_s, hms, delta

def get_last_signal(inst):
    with sqlite3.connect(DB_B) as con:
        cur = con.cursor()
        cur.execute("SELECT ts FROM signals WHERE instId=? ORDER BY ts DESC LIMIT 1;", (inst,))
        r = cur.fetchone()
    if not r:
        return None, None, None
    ts = float(r[0])
    hms = datetime.fromtimestamp(ts).strftime("%H:%M:%S")
    delta = round(time.time() - ts, 1)
    return ts, hms, delta

def dash():
    print(f"===== DASH {datetime.now().strftime('%H:%M:%S')} =====")
    for inst, ctx in get_ctx():
        pr, ts_tick, hms_tick, delta_tick = get_last_tick(inst)
        ts_sig, hms_sig, delta_sig = get_last_signal(inst)

        delta = "-"
        if ts_tick and ts_sig:
            delta = round(ts_tick - ts_sig, 1)

        flag = "⚠️" if delta_tick and delta_tick > 5 else "✅"
        print(f"{inst:<10} | ctx={ctx:<8} | price={pr or '-':<10} | "
              f"tick={hms_tick or '-':>8} | sig={hms_sig or '-':>8} | "
              f"Δ={delta:<6} | {flag}")
    print("=" * 90)

if __name__ == "__main__":
    while True:
        try:
            dash()
            time.sleep(3)
        except KeyboardInterrupt:
            break
        except Exception as e:
            print("B_DASH ERROR:", e)
            time.sleep(5)

----- FILE: /opt/scalp/project/scripts/closer.py -----
#!/usr/bin/env python3
import sqlite3, time, logging, sys
from pathlib import Path

DB_F = Path("/opt/scalp/project/data/follower.db")
DB_C = Path("/opt/scalp/project/data/closer.db")
DB_O = Path("/opt/scalp/project/data/opener.db")
LOG_PATH = "/opt/scalp/project/logs/closer.log"

def setup_log():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s %(levelname)s %(message)s",
        handlers=[logging.FileHandler(LOG_PATH), logging.StreamHandler(sys.stdout)],
    )

def connect(path: Path):
    con = sqlite3.connect(path, timeout=30, isolation_level=None)
    con.execute("PRAGMA journal_mode=WAL;")
    return con

def migrate(con):
    con.executescript("""
    CREATE TABLE IF NOT EXISTS trades_close (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        instId TEXT, side TEXT,
        entry REAL, exit REAL, pnl REAL,
        sl REAL, tp REAL, reason_exit TEXT,
        ctx TEXT, score_U REAL, score_A REAL, score_B REAL,
        ts_open INTEGER, ts_close INTEGER,
        status TEXT DEFAULT 'recorded'
    );
    """)

def fetch_to_close(conF):
    q = """
    SELECT instId, side, entry, last, sl_new, tp_new, reason_close, ts_update, ctx, score_U, score_A, score_B
    FROM trades_follow
    WHERE reason_close IS NOT NULL
    ORDER BY ts_update DESC LIMIT 50;
    """
    return conF.execute(q).fetchall()

def update_virtual_balance(pnl_usd: float):
    conO = connect(DB_O)
    conO.execute("UPDATE balance_virtual SET balance = balance + ?, ts_update=? WHERE id=1",
                 (pnl_usd, int(time.time()*1000)))
    conO.commit()
    conO.close()

def main():
    setup_log()
    conF = connect(DB_F)
    conC = connect(DB_C)
    migrate(conC)

    rows = fetch_to_close(conF)
    if not rows:
        logging.info("[CLOSER] aucun signal de clôture reçu")
        return

    now = int(time.time()*1000)
    closed = 0

    for instId, side, entry, last, sl, tp, reason, ts_follow, ctx, su, sa, sb in rows:
        pnl = (last - entry) / entry
        if side == "sell":
            pnl *= -1
        pnl_usd = pnl * entry
        conC.execute("""
            INSERT INTO trades_close(instId,side,entry,exit,pnl,sl,tp,reason_exit,ctx,score_U,score_A,score_B,ts_open,ts_close,status)
            VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)
        """, (instId, side, entry, last, pnl, sl, tp, reason, ctx, su, sa, sb, ts_follow, now, 'recorded'))
        update_virtual_balance(pnl_usd)
        closed += 1

    conC.commit()
    conC.close(); conF.close()
    logging.info(f"[CLOSER] {closed} positions fermées et solde ajusté")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logging.error("Erreur CLOSER: %s", e, exc_info=True)
        sys.exit(1)

----- FILE: /opt/scalp/project/scripts/follower.py -----
#!/usr/bin/env python3
# ============================================================
# SCALP - FOLLOWER MODULE  (ATR, BE, TRAIL, PYR, TIMEOUT)
# ============================================================

import sqlite3, time, logging, sys, math
from pathlib import Path

DB_T = Path("/opt/scalp/project/data/t.db")
DB_O = Path("/opt/scalp/project/data/opener.db")
DB_F = Path("/opt/scalp/project/data/follower.db")
LOG_PATH = "/opt/scalp/project/logs/follower.log"

ATR_PERIOD = 14
ATR_FACTOR_SL = 1.5
ATR_FACTOR_TP = 2.5
BE_TRIGGER_ATR = 1.0
TRAIL_DISTANCE_ATR = 1.0
PYR_TRIGGER_ATR = 1.5
MAX_PYRAMIDE = 2
TIMEOUT_MS = 15 * 60 * 1000  # 15 minutes

# ------------------------------------------------------------
def setup_log():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s %(levelname)s %(message)s",
        handlers=[logging.FileHandler(LOG_PATH), logging.StreamHandler(sys.stdout)],
    )

def connect(path: Path):
    con = sqlite3.connect(path, timeout=30, isolation_level=None)
    con.execute("PRAGMA journal_mode=WAL;")
    con.execute("PRAGMA synchronous=NORMAL;")
    con.execute("PRAGMA busy_timeout=5000;")
    return con

# ------------------------------------------------------------
def migrate(con):
    con.executescript("""
    CREATE TABLE IF NOT EXISTS trades_follow (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        instId TEXT,
        side TEXT,
        entry REAL,
        last REAL,
        sl_new REAL,
        tp_new REAL,
        atr_current REAL,
        ts_update INTEGER,
        ctx TEXT DEFAULT '',
        score_U REAL DEFAULT 0,
        score_A REAL DEFAULT 0,
        score_B REAL DEFAULT 0,
        be_active INTEGER DEFAULT 0,
        trail_active INTEGER DEFAULT 0,
        pyr_level INTEGER DEFAULT 0,
        reason_close TEXT DEFAULT NULL
    );

    DROP VIEW IF EXISTS v_for_close_ready;
    CREATE VIEW v_for_close_ready AS
    SELECT instId AS Instrument, side AS Side,
           printf('%.6f', entry) AS Entry,
           printf('%.6f', last)  AS Last,
           printf('%.6f', sl_new) AS SL,
           printf('%.6f', tp_new) AS TP,
           reason_close AS Reason,
           ctx AS Context,
           printf('%.2f', score_U) AS Score_U,
           printf('%.2f', score_A) AS Score_A,
           printf('%.2f', score_B) AS Score_B,
           datetime(ts_update/1000,'unixepoch','localtime') AS Time_Update
    FROM trades_follow
    WHERE reason_close IS NOT NULL
    ORDER BY ts_update DESC;
    """)

# ------------------------------------------------------------
def get_latest_ticks(conT):
    q = "SELECT instId,lastPr FROM v_ticks_latest;"
    try:
        return {r[0]: r[1] for r in conT.execute(q).fetchall()}
    except Exception:
        return {}

def load_open_positions(conO):
    q = "SELECT instId,side,entry,sl,tp,qty,ts_create FROM trades_open_init WHERE status='open';"
    return conO.execute(q).fetchall()

def get_atr(conT, instId: str) -> float:
    try:
        q = f"SELECT atr14 FROM v_atr WHERE instId='{instId}'"
        r = conT.execute(q).fetchone()
        if r and r[0]:
            return float(r[0])
    except Exception:
        pass
    return 0.0

# ------------------------------------------------------------
def update_positions(conF, conT, open_positions):
    now = int(time.time() * 1000)
    for instId, side, entry, sl, tp, qty, ts_open in open_positions:
        last = get_latest_ticks(conT).get(instId)
        if not last:
            continue

        atr = get_atr(conT, instId)
        if atr == 0:
            atr = abs(tp - sl)

        # calculs SL/TP dynamiques
        if side == "buy":
            sl_new = max(sl, entry - ATR_FACTOR_SL * atr)
            tp_new = max(tp, entry + ATR_FACTOR_TP * atr)
        else:
            sl_new = min(sl, entry + ATR_FACTOR_SL * atr)
            tp_new = min(tp, entry - ATR_FACTOR_TP * atr)

        conF.execute("""
            INSERT INTO trades_follow(instId,side,entry,last,sl_new,tp_new,atr_current,ts_update)
            VALUES (?,?,?,?,?,?,?,?)
        """, (instId, side, entry, last, sl_new, tp_new, atr, now))
    conF.commit()

# ------------------------------------------------------------
def evolve_positions(conF):
    """Break-even, trailing, pyramide, timeout & clôture."""
    rows = conF.execute("""
        SELECT id, instId, side, entry, last, sl_new, tp_new,
               atr_current, be_active, trail_active, pyr_level, ts_update
        FROM trades_follow
        WHERE reason_close IS NULL;
    """).fetchall()
    now = int(time.time() * 1000)

    for r in rows:
        (id_, instId, side, entry, last, sl, tp,
         atr, be_active, trail_active, pyr_level, ts_update) = r

        reason = None
        # --- Break-even ---
        if not be_active:
            gain = (last - entry) if side == "buy" else (entry - last)
            if gain >= BE_TRIGGER_ATR * atr:
                new_sl = entry
                conF.execute(
                    "UPDATE trades_follow SET sl_new=?, be_active=1 WHERE id=?",
                    (new_sl, id_)
                )
                be_active = 1
                logging.info(f"[FOLLOWER] {instId} BE activé à {new_sl:.4f}")

        # --- Trailing stop ---
        if be_active and not trail_active:
            conF.execute("UPDATE trades_follow SET trail_active=1 WHERE id=?", (id_,))
            trail_active = 1
        if trail_active:
            if side == "buy":
                target_sl = last - TRAIL_DISTANCE_ATR * atr
                if target_sl > sl:
                    conF.execute("UPDATE trades_follow SET sl_new=? WHERE id=?", (target_sl, id_))
            else:
                target_sl = last + TRAIL_DISTANCE_ATR * atr
                if target_sl < sl:
                    conF.execute("UPDATE trades_follow SET sl_new=? WHERE id=?", (target_sl, id_))

        # --- Pyramiding ---
        if pyr_level < MAX_PYRAMIDE:
            distance = (last - entry) if side == "buy" else (entry - last)
            if distance >= PYR_TRIGGER_ATR * atr:
                conF.execute("UPDATE trades_follow SET pyr_level=pyr_level+1 WHERE id=?", (id_,))
                logging.info(f"[FOLLOWER] {instId} pyramide +1 (niveau {pyr_level+1})")

        # --- Clôture conditions ---
        if side == "buy" and last >= tp:
            reason = "takeprofit"
        elif side == "buy" and last <= sl:
            reason = "stoploss"
        elif side == "sell" and last <= tp:
            reason = "takeprofit"
        elif side == "sell" and last >= sl:
            reason = "stoploss"
        elif now - ts_update > TIMEOUT_MS:
            reason = "timeout"

        if reason:
            conF.execute(
                "UPDATE trades_follow SET reason_close=?, ts_update=? WHERE id=?",
                (reason, now, id_)
            )
            logging.info(f"[FOLLOWER] {instId} clôture signal: {reason}")

    conF.commit()

# ------------------------------------------------------------
def main():
    setup_log()
    conT, conO, conF = connect(DB_T), connect(DB_O), connect(DB_F)
    migrate(conF)
    open_positions = load_open_positions(conO)
    if not open_positions:
        logging.info("[FOLLOWER] aucune position ouverte à suivre")
    else:
        update_positions(conF, conT, open_positions)
        evolve_positions(conF)

    conT.close(); conO.close(); conF.close()

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logging.error("Erreur FOLLOWER: %s", e, exc_info=True)
        sys.exit(1)

----- FILE: /opt/scalp/project/scripts/init_db.py -----
import sqlite3

DB_A = "/opt/scalp/project/data/a.db"

def init_db():
    con = sqlite3.connect(DB_A, timeout=5)
    cur = con.cursor()

    cur.execute("""
    CREATE TABLE IF NOT EXISTS ohlcv_5m (
        instId TEXT,
        ts INTEGER,
        open REAL,
        high REAL,
        low REAL,
        close REAL,
        vol REAL
    );
    """)

    cur.execute("""
    CREATE TABLE IF NOT EXISTS ohlcv_15m (
        instId TEXT,
        ts INTEGER,
        open REAL,
        high REAL,
        low REAL,
        close REAL,
        vol REAL
    );
    """)

    cur.execute("""
    CREATE TABLE IF NOT EXISTS ohlcv_30m (
        instId TEXT,
        ts INTEGER,
        open REAL,
        high REAL,
        low REAL,
        close REAL,
        vol REAL
    );
    """)

    cur.execute("""
    CREATE TABLE IF NOT EXISTS ctx_a (
        instId TEXT,
        ts INTEGER,
        p_buy REAL,
        p_hold REAL,
        p_sell REAL,
        score REAL,
        ctx TEXT
    );
    """)

    con.commit()
    con.close()
    print("[INIT_DB] OK – A DB ready")

if __name__ == "__main__":
    init_db()

----- FILE: /opt/scalp/project/scripts/opener.py -----
#!/usr/bin/env python3
import sqlite3, time, logging, sys
from pathlib import Path

DB_B = Path("/opt/scalp/project/data/b.db")
DB_O = Path("/opt/scalp/project/data/opener.db")
LOG_PATH = "/opt/scalp/project/logs/opener.log"

MAX_TRADE_RISK = 0.02  # 2 % du solde actuel

def setup_log():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s %(levelname)s %(message)s",
        handlers=[logging.FileHandler(LOG_PATH), logging.StreamHandler(sys.stdout)],
    )

def connect(path: Path):
    con = sqlite3.connect(path, timeout=30, isolation_level=None)
    con.execute("PRAGMA journal_mode=WAL;")
    return con

def migrate(con):
    con.executescript("""
    CREATE TABLE IF NOT EXISTS trades_open_init (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        instId TEXT,
        side TEXT,
        entry REAL,
        sl REAL,
        tp REAL,
        qty REAL,
        ts_create INTEGER,
        status TEXT DEFAULT 'open'
    );
    CREATE UNIQUE INDEX IF NOT EXISTS idx_open_inst ON trades_open_init(instId);

    CREATE TABLE IF NOT EXISTS balance_virtual (
        id INTEGER PRIMARY KEY CHECK (id=1),
        balance REAL DEFAULT 1000.0,
        ts_update INTEGER
    );
    INSERT OR IGNORE INTO balance_virtual(id,balance,ts_update)
    VALUES (1,1000.0,strftime('%s','now')*1000);
    """)

def get_balance(con):
    r = con.execute("SELECT balance FROM balance_virtual WHERE id=1").fetchone()
    return r[0] if r else 1000.0

def update_balance(con, delta):
    con.execute(
        "UPDATE balance_virtual SET balance = balance + ?, ts_update = ? WHERE id=1",
        (delta, int(time.time()*1000))
    )

def fetch_signals(conB):
    # robust fallback on timestamp column
    cols = [r[1] for r in conB.execute("PRAGMA table_info(v_signals_last10);").fetchall()]
    ts_col = "ts_ms" if "ts_ms" in cols else ("ts_hms" if "ts_hms" in cols else None)

    q = f"""
    SELECT instId, side, price, score_B
    FROM v_signals_last10
    WHERE score_B > 60
    ORDER BY {ts_col or 'ROWID'} DESC LIMIT 10;
    """
    try:
        return conB.execute(q).fetchall()
    except Exception as e:
        logging.error("fetch_signals: %s", e)
        return []

def already_open(conO, instId: str) -> bool:
    r = conO.execute("SELECT 1 FROM trades_open_init WHERE instId=? AND status='open'", (instId,)).fetchone()
    return bool(r)

def size_from_balance(balance: float, price: float) -> float:
    usd_alloc = balance * MAX_TRADE_RISK
    return round(usd_alloc / price, 6)

def main():
    setup_log()
    conB, conO = connect(DB_B), connect(DB_O)
    migrate(conO)

    balance = get_balance(conO)
    signals = fetch_signals(conB)
    if not signals:
        logging.info(f"[OPENER] aucun signal éligible | balance={balance:.2f}")
        return

    now = int(time.time()*1000)
    created = 0

    for instId, side, price, score in signals:
        if already_open(conO, instId):
            continue
        qty = size_from_balance(balance, price)
        cost = qty * price
        if cost > balance:
            continue  # capital insuffisant
        sl = price * (0.99 if side == "buy" else 1.01)
        tp = price * (1.01 if side == "buy" else 0.99)
        conO.execute("""
            INSERT INTO trades_open_init(instId,side,entry,sl,tp,qty,ts_create)
            VALUES (?,?,?,?,?,?,?)
        """, (instId, side, price, sl, tp, qty, now))
        update_balance(conO, -cost)
        balance -= cost
        created += 1

    conO.commit()
    conO.close(); conB.close()
    logging.info(f"[OPENER] {created} positions ouvertes | solde restant={balance:.2f}")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logging.error("Erreur OPENER: %s", e, exc_info=True)
        sys.exit(1)

----- FILE: /opt/scalp/project/scripts/recorder.py -----
#!/usr/bin/env python3
from __future__ import annotations
import logging, sqlite3, sys, time
from pathlib import Path

DB_CLOSER = Path("/opt/scalp/project/data/closer.db")
DB_RECORDER = Path("/opt/scalp/project/data/recorder.db")
LOG_PATH = "/opt/scalp/project/logs/recorder.log"

def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s %(levelname)s %(message)s",
        handlers=[
            logging.FileHandler(LOG_PATH),
            logging.StreamHandler(sys.stdout),
        ],
    )

def connect_db(path: Path) -> sqlite3.Connection:
    con = sqlite3.connect(path, timeout=30, isolation_level=None)
    con.execute("PRAGMA journal_mode=WAL;")
    con.execute("PRAGMA synchronous=NORMAL;")
    con.execute("PRAGMA busy_timeout=5000;")
    return con

def migrate(con: sqlite3.Connection):
    con.executescript("""
    CREATE TABLE IF NOT EXISTS trades_record (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        instId TEXT,
        side TEXT,
        entry REAL,
        exit REAL,
        pnl REAL,
        sl REAL,
        tp REAL,
        reason_exit TEXT,
        ts_open INTEGER,
        ts_close INTEGER,
        ts_record INTEGER DEFAULT (strftime('%s','now')*1000)
    );
    CREATE INDEX IF NOT EXISTS idx_record_ts ON trades_record(ts_record);
    """)

def record_from_closer():
    con_c = connect_db(DB_CLOSER)
    con_r = connect_db(DB_RECORDER)
    migrate(con_r)
    rows = con_c.execute("""
        SELECT instId, side, entry, exit, pnl, sl, tp, reason_exit, ts_open, ts_close
        FROM trades_close
        WHERE ts_close > IFNULL((SELECT MAX(ts_close) FROM trades_record),0)
        ORDER BY ts_close;
    """).fetchall()
    if not rows:
        con_c.close(); con_r.close(); return 0
    con_r.executemany("""
        INSERT INTO trades_record(instId,side,entry,exit,pnl,sl,tp,reason_exit,ts_open,ts_close,ts_record)
        VALUES (?,?,?,?,?,?,?,?,?,?,strftime('%s','now')*1000);
    """, rows)
    con_r.commit(); con_c.close(); con_r.close()
    logging.info("[RECORDER] %d lignes archivées", len(rows))
    return len(rows)

def main(argv):
    setup_logging()
    record_from_closer()
    return 0

if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))

----- FILE: /opt/scalp/project/scripts/test_ws_bitget.py -----
#!/usr/bin/env python3
import asyncio, json, websockets, time

async def main():
    url = "wss://ws.bitget.com/v2/ws/public"
    payload = {
        "op": "subscribe",
        "args": [{
            "instType": "USDT-FUTURES",
            "channel": "ticker",
            "instId": "BTCUSDT"
        }]
    }

    print("Connecting to Bitget WS...")
    async with websockets.connect(url, ping_interval=20) as ws:
        await ws.send(json.dumps(payload))
        print("Subscribed to BTCUSDT ticker (USDT-FUTURES)\n")

        async for msg in ws:
            data = json.loads(msg)
            if "data" in data:
                tick = data["data"][0]
                price = tick.get("lastPr")
                ts = tick.get("ts")
                if price:
                    print(f"[{time.strftime('%H:%M:%S')}] BTCUSDT -> {price} (ts={ts})")

asyncio.run(main())

----- FILE: /opt/scalp/project/scripts/ticks.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import asyncio
import json
import sqlite3
import threading
import time
from queue import Queue
import websockets

DB_PATH = "/opt/scalp/project/data/t.db"
DB_A_PATH = "/opt/scalp/project/data/a.db"
WS_URL = "wss://ws.bitget.com/mix/v1/stream"
FLUSH_INTERVAL = 0.5  # secondes
QUEUE_MAX = 5000

q = Queue(maxsize=QUEUE_MAX)
lock = threading.Lock()
stop_event = threading.Event()

# --- Connexion SQLite optimisée ---
def init_db():
    conn = sqlite3.connect(DB_PATH, check_same_thread=False, timeout=10)
    cur = conn.cursor()
    cur.executescript("""
        PRAGMA journal_mode=WAL;
        PRAGMA synchronous=OFF;
        CREATE TABLE IF NOT EXISTS ticks(
            instId TEXT PRIMARY KEY,
            price REAL,
            ts_ms INTEGER
        );
        CREATE INDEX IF NOT EXISTS idx_ticks_ts ON ticks(ts_ms);
    """)
    conn.commit()
    return conn

# --- Récupération des symboles depuis le contexte A ---
def get_symbols():
    conn = sqlite3.connect(DB_A_PATH)
    cur = conn.cursor()
    cur.execute("SELECT instId FROM v_ctx_latest;")
    symbols = [r[0].replace("/", "") for r in cur.fetchall()]
    conn.close()
    return symbols

# --- Thread d'écriture SQLite ---
def writer_thread():
    conn = init_db()
    cur = conn.cursor()
    last_flush = 0
    buffer = []
    while not stop_event.is_set():
        try:
            tick = q.get(timeout=FLUSH_INTERVAL)
            buffer.append(tick)
        except:
            pass

        now = time.time()
        if now - last_flush >= FLUSH_INTERVAL and buffer:
            with lock:
                cur.executemany(
                    "INSERT INTO ticks (instId, price, ts_ms) VALUES (?, ?, ?) "
                    "ON CONFLICT(instId) DO UPDATE SET price=excluded.price, ts_ms=excluded.ts_ms;",
                    buffer,
                )
                conn.commit()
                buffer.clear()
                last_flush = now

    conn.commit()
    conn.close()

# --- Fonction WS principale ---
async def ws_consumer():
    symbols = get_symbols()
    args = [
        {"instType": "USDT-FUTURES", "channel": "ticker", "instId": s}
        for s in symbols
    ]
    sub_msg = json.dumps({"op": "subscribe", "args": args})
    print(f"[ticks] Subscribing to {len(symbols)} symbols...")

    async with websockets.connect(WS_URL, ping_interval=15, ping_timeout=10) as ws:
        await ws.send(sub_msg)
        print("[ticks] Connected & subscribed.")
        async for msg in ws:
            data = json.loads(msg)
            if "data" not in data:
                continue
            for d in data["data"]:
                try:
                    instId = d["instId"]
                    price = float(d["lastPr"])
                    ts_ms = int(d["ts"])
                    if not q.full():
                        q.put((instId, price, ts_ms))
                except Exception as e:
                    pass

# --- Main ---
def main():
    wt = threading.Thread(target=writer_thread, daemon=True)
    wt.start()

    try:
        asyncio.run(ws_consumer())
    except KeyboardInterrupt:
        print("Stopping...")
    finally:
        stop_event.set()
        wt.join()

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/x_close.py -----
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
X_CLOSE
→ Ferme les positions lorsque TP / SL / conditions de perte ATR sont atteintes.
→ Archive les positions fermées dans x_open.db.positions_closed
"""

import sqlite3, datetime, time

DB_FOLLOW = "/opt/scalp/project/data/x_follow.db"
DB_X = "/opt/scalp/project/data/x_open.db"
DB_T = "/opt/scalp/project/data/t.db"
LOG_PREFIX = "X_CLOSE"

def log(msg):
    print(f"{datetime.datetime.now():%Y-%m-%d %H:%M:%S} {LOG_PREFIX} {msg}", flush=True)

def fetch_last_price(instId):
    conn_t = sqlite3.connect(DB_T)
    cur = conn_t.cursor()
    cur.execute("SELECT lastPr FROM v_ticks_latest WHERE instId=?;", (instId,))
    row = cur.fetchone()
    conn_t.close()
    return float(row[0]) if row else None

def close_position(row, reason):
    """Déplace la position vers positions_closed et supprime de follow_state"""
    conn_x = sqlite3.connect(DB_X)
    conn_f = sqlite3.connect(DB_FOLLOW)
    try:
        instId, side, entry, sl, tp, last, atr, pnl, ts_open = row
        ts_close = int(time.time())
        pnl_pct = round((pnl or 0.0), 4)
        conn_x.execute("""
            INSERT INTO positions_closed(instId, side, entry, sl, tp, last, atr, pnl, ts_open, ts_close, reason)
            VALUES (?,?,?,?,?,?,?,?,?,?,?);
        """, (instId, side, entry, sl, tp, last, atr, pnl_pct, ts_open, ts_close, reason))
        conn_x.commit()
        conn_f.execute("DELETE FROM follow_state WHERE instId=?;", (instId,))
        conn_f.commit()
        log(f"{instId} CLOSED ({reason}) PnL={pnl_pct:.3f}%")
    except Exception as e:
        log(f"ERR close_position {instId}: {e}")
    finally:
        conn_x.close()
        conn_f.close()

def check_and_close():
    conn_f = sqlite3.connect(DB_FOLLOW)
    cur = conn_f.cursor()
    cur.execute("SELECT instId, side, entry, sl, tp, last, atr, pnl, ts FROM follow_state;")
    rows = cur.fetchall()
    conn_f.close()

    if not rows:
        log("No positions to check.")
        return

    for row in rows:
        instId, side, entry, sl, tp, last, atr, pnl, ts_open = row
        price = fetch_last_price(instId)
        if price is None:
            continue

        if side == "buy" and price <= sl:
            close_position(row, "SL")
        elif side == "buy" and price >= tp:
            close_position(row, "TP")
        elif side == "sell" and price >= sl:
            close_position(row, "SL")
        elif side == "sell" and price <= tp:
            close_position(row, "TP")
        # optionnel: protection ATR extrême
        elif atr > 0 and abs(price - entry) > 5 * atr:
            close_position(row, "ATR_FAILSAFE")

def init_closed_table():
    conn_x = sqlite3.connect(DB_X)
    conn_x.execute("""
        CREATE TABLE IF NOT EXISTS positions_closed (
            instId TEXT,
            side TEXT,
            entry REAL,
            sl REAL,
            tp REAL,
            last REAL,
            atr REAL,
            pnl REAL,
            ts_open INTEGER,
            ts_close INTEGER,
            reason TEXT
        );
    """)
    conn_x.commit()
    conn_x.close()

def main():
    init_closed_table()
    log("READY")
    while True:
        try:
            check_and_close()
            time.sleep(5)
        except KeyboardInterrupt:
            break
        except Exception as e:
            log(f"ERR main loop: {e}")
            time.sleep(3)

if __name__ == "__main__":
    main()

----- FILE: /opt/scalp/project/scripts/x_closer.py -----
#!/usr/bin/env python3
# --- SCALP - X CLOSER ---
# Ferme les positions selon conditions simples (PnL, SL, TP, etc.)
# Mise à jour dans x_close.db / x_open.db
#
from __future__ import annotations
import argparse, logging, sqlite3, sys, time
from pathlib import Path
from typing import List

DB_X_OPEN  = "/opt/scalp/project/data/x_open.db"
DB_X_CLOSE = "/opt/scalp/project/data/x_close.db"
LOGF       = "/opt/scalp/project/logs/x_closer.log"

# --- Logging ---
def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s X_CLOSER %(levelname)s %(message)s",
        handlers=[
            logging.FileHandler(LOGF),
            logging.StreamHandler(sys.stdout),
        ],
        force=True,
    )

# --- Connexion SQLite ---
def connect_db(path: str) -> sqlite3.Connection:
    c = sqlite3.connect(path, timeout=30, isolation_level=None)
    c.execute("PRAGMA journal_mode=WAL;")
    c.execute("PRAGMA synchronous=NORMAL;")
    c.execute("PRAGMA busy_timeout=5000;")
    return c

def migrate(conn: sqlite3.Connection):
    conn.executescript("""
    CREATE TABLE IF NOT EXISTS positions_closed (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        instId TEXT NOT NULL,
        side TEXT NOT NULL,
        entry REAL,
        exit REAL,
        pnl REAL,
        ts_open INTEGER,
        ts_close INTEGER,
        status TEXT DEFAULT 'closed'
    );
    CREATE INDEX IF NOT EXISTS idx_closed_instId ON positions_closed(instId);
    """)

# --- Lecture des positions ouvertes ---
def fetch_open(conn: sqlite3.Connection):
    return conn.execute("SELECT id, instId, side, entry, ts_open FROM positions_open WHERE status='open';").fetchall()

# --- Simulation de clôture ---
def should_close(instId: str, side: str, entry: float) -> bool:
    # ici tu placeras ta logique (ATR, TP, SL, trailing, etc.)
    # pour test on ferme aléatoirement après quelques secondes
    return time.time() % 60 < 1  # ferme environ une fois par minute

def close_position(conn_open: sqlite3.Connection, conn_close: sqlite3.Connection, row):
    id_, instId, side, entry, ts_open = row
    ts_close = int(time.time() * 1000)
    exit_price = entry  # simulé
    pnl = 0.0
    conn_close.execute(
        "INSERT INTO positions_closed(instId,side,entry,exit,pnl,ts_open,ts_close,status) VALUES(?,?,?,?,?,?,?,?)",
        (instId, side, entry, exit_price, pnl, ts_open, ts_close, 'closed'),
    )
    conn_open.execute("UPDATE positions_open SET status='closed' WHERE id=?", (id_,))
    conn_close.commit()
    conn_open.commit()
    logging.info(f"CLOSE {instId} {side} @ {exit_price}")

def process():
    conn_open = connect_db(DB_X_OPEN)
    conn_close = connect_db(DB_X_CLOSE)
    migrate(conn_close)
    rows = fetch_open(conn_open)
    for r in rows:
        if should_close(r[1], r[2], r[3]):
            close_position(conn_open, conn_close, r)
    conn_open.close()
    conn_close.close()

def main(argv: List[str]) -> int:
    setup_logging()
    while True:
        try:
            process()
            time.sleep(2)
        except KeyboardInterrupt:
            break
        except Exception as e:
            logging.error(f"Loop error: {e}")
            time.sleep(2)
    return 0

if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))

----- FILE: /opt/scalp/project/scripts/x_dash.py -----
#!/usr/bin/env python3
import sqlite3, time
from datetime import datetime

DBP="/opt/scalp/project/data/x_open.db"
DBF="/opt/scalp/project/data/x_follow.db"
DBH="/opt/scalp/project/data/x_history.db"

def h(ts):return datetime.fromtimestamp(ts/1000).strftime("%H:%M:%S")

def get_H(inst):
    con=sqlite3.connect(DBH)
    r=con.execute("""
    WITH last20 AS (
        SELECT pnl FROM history WHERE instId=?
        ORDER BY ts_close DESC LIMIT 20
    ),
    stats AS (
        SELECT 
            (SELECT COUNT(*) FROM last20 WHERE pnl>0)*1.0/(SELECT COUNT(*) FROM last20) AS winrate,
            (SELECT SUM(pnl) FROM last20 WHERE pnl>0) AS sum_win,
            (SELECT SUM(ABS(pnl)) FROM last20 WHERE pnl<0) AS sum_loss
    )
    SELECT 
        CASE WHEN sum_loss IS NULL OR sum_loss=0 THEN 1.0 
        ELSE (0.50*winrate + 0.50*MIN(1.0, (sum_win/sum_loss)/2.0))
        END AS H
    FROM stats
    """,(inst,)).fetchone()
    con.close()
    return float(r[0]) if r and r[0] else 0.0

print("===== X DASH =====")

# OPEN
con=sqlite3.connect(DBP)
rows=con.execute("SELECT instId,side,entry,qty,lev,risk,score_G,ts_open FROM positions_open").fetchall()
con.close()
if not rows:
    print("No open position")
else:
    for r in rows:
        inst,side,e,qty,lev,risk,sg,ts=r
        Hs=get_H(inst)
        print(f"{inst} | {side} | entry={e} | lev={lev:.2f} | risk={risk:.3f} | G={sg:.3f} | H={Hs:.3f} | {h(ts)}")

# FOLLOW
con=sqlite3.connect(DBF)
rows=con.execute("SELECT instId,current,upnl,stage,ts_update FROM follow").fetchall()
con.close()
for r in rows:
    inst,cur,u,st,ts=r
    print(f"FOLLOW -> {inst} | {cur} | upnl={u:.4f} | {st} | {h(ts)}")

print("===================")

----- FILE: /opt/scalp/project/scripts/x_follow.py -----
#!/usr/bin/env python3
import sqlite3, time, datetime, logging, os, math

DB_X_OPEN = "/opt/scalp/project/data/x_open.db"
DB_OB = "/opt/scalp/project/data/ob.db"
DB_T = "/opt/scalp/project/data/t.db"
DB_FOLLOW = "/opt/scalp/project/data/x_follow.db"
LOG_FILE = "/opt/scalp/project/logs/x_follow.log"

os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)
logging.basicConfig(filename=LOG_FILE, level=logging.INFO,
                    format="%(asctime)s X_FOLLOW %(levelname)s %(message)s")

def get_conn(db):
    return sqlite3.connect(db, timeout=2, isolation_level=None)

def get_positions():
    with get_conn(DB_X_OPEN) as c:
        return c.execute("""
            SELECT instId, side, entry, ts_open FROM positions_open
        """).fetchall()

def get_atr():
    with get_conn(DB_OB) as c:
        return dict(c.execute("SELECT instId, atr FROM v_atr_1m_latest"))

def get_ticks():
    with get_conn(DB_T) as c:
        return dict(c.execute("SELECT instId, lastPr FROM v_ticks_latest"))

def ensure_tables():
    with get_conn(DB_FOLLOW) as c:
        c.executescript("""
        CREATE TABLE IF NOT EXISTS follow_state (
            instId TEXT PRIMARY KEY,
            side TEXT,
            entry REAL,
            sl REAL,
            tp REAL,
            last REAL,
            atr REAL,
            pnl REAL,
            ts INTEGER
        );
        """)

def update_follow_state(rows):
    with get_conn(DB_FOLLOW) as c:
        for r in rows:
            c.execute("""
            INSERT OR REPLACE INTO follow_state
            (instId, side, entry, sl, tp, last, atr, pnl, ts)
            VALUES (?,?,?,?,?,?,?,?,?)
            """, r)

def calc_pnl(side, entry, now):
    if side == "buy":
        return (now - entry) / entry * 100
    elif side == "sell":
        return (entry - now) / entry * 100
    return 0

def run_follow():
    ensure_tables()
    positions = get_positions()
    atrs = get_atr()
    ticks = get_ticks()

    updated = []
    for instId, side, entry, ts_open in positions:
        atr = atrs.get(instId, 0.0)
        now = ticks.get(instId, 0.0)
        if now == 0.0:
            continue

        # SL / TP dynamiques = 1×ATR
        sl = entry - atr if side == "buy" else entry + atr
        tp = entry + atr if side == "buy" else entry - atr
        pnl = calc_pnl(side, entry, now)

        updated.append((instId, side, entry, sl, tp, now, atr, pnl, int(time.time()*1000)))

    update_follow_state(updated)
    logging.info("FOLLOW update %d positions.", len(updated))

if __name__ == "__main__":
    while True:
        try:
            run_follow()
            time.sleep(5)
        except Exception as e:
            logging.error("FOLLOW ERROR: %s", e)
            time.sleep(10)

----- FILE: /opt/scalp/project/scripts/x_follow_atr_dynamic.py -----
#!/usr/bin/env python3
import sqlite3, time, logging

DB_X = "/opt/scalp/project/data/x_open.db"
DB_B = "/opt/scalp/project/data/b.db"
SLEEP = 5  # secondes entre chaque cycle

logging.basicConfig(
    filename="/opt/scalp/project/logs/x_follow.log",
    level=logging.INFO,
    format="%(asctime)s X_FOLLOW INFO %(message)s"
)

def get_latest_atr():
    """Récupère l’ATR le plus récent pour chaque instId depuis b.db"""
    with sqlite3.connect(f"file:{DB_B}?mode=ro", uri=True) as cb:
        cb.row_factory = sqlite3.Row
        cur = cb.cursor()
        cur.execute("""
            SELECT f1.instId, f1.atr
            FROM feat_1m f1
            WHERE f1.ts = (SELECT MAX(f2.ts) FROM feat_1m f2 WHERE f2.instId=f1.instId)
        """)
        return {r['instId']: r['atr'] for r in cur.fetchall()}

def follow_cycle():
    with sqlite3.connect(f"file:{DB_X}?mode=rw", uri=True) as cx:
        cx.row_factory = sqlite3.Row
        cur = cx.cursor()

        atrs = get_latest_atr()
        cur.execute("SELECT * FROM positions_open")
        rows = cur.fetchall()
        updates = 0

        for r in rows:
            inst, side, entry, sl, tp, price_now = (
                r['instId'], r['side'], r['entry'], r['sl'], r['tp'], r['price_now']
            )
            atr = atrs.get(inst)
            if atr is None or atr <= 0:
                continue

            # initialisation si vide
            if sl == 0 or tp == 0 or r['atr_open'] == 0:
                new_sl = entry - atr * 1.5 if side == 'buy' else entry + atr * 1.5
                new_tp = entry + atr * 3 if side == 'buy' else entry - atr * 3
                cur.execute("""
                    UPDATE positions_open
                    SET sl=?, tp=?, atr_open=?
                    WHERE instId=?
                """, (new_sl, new_tp, atr, inst))
                updates += 1
                continue

            # suivi dynamique du SL (ATR trailing)
            if side == 'buy':
                new_sl = max(sl, price_now - atr * 1.5)
            else:
                new_sl = min(sl, price_now + atr * 1.5)

            if abs(new_sl - sl) > 1e-9:  # évite les écritures inutiles
                cur.execute("UPDATE positions_open SET sl=? WHERE instId=?", (new_sl, inst))
                updates += 1

        cx.commit()
        if updates:
            logging.info(f"FOLLOW ATR dynamic update: {updates} positions ajustées")
        else:
            logging.info("FOLLOW ATR dynamic: aucune mise à jour")

if __name__ == "__main__":
    while True:
        try:
            follow_cycle()
        except Exception as e:
            logging.error(f"FOLLOW ATR dynamic error: {e}")
        time.sleep(SLEEP)

----- FILE: /opt/scalp/project/scripts/x_open.py -----
#!/usr/bin/env python3
# --- SCALP - X OPEN (positions creation) ---
# Lit les signaux prêts dans b.db / v_signals_for_open
# et crée les positions dans x_open.db
#
from __future__ import annotations
import argparse, logging, sqlite3, sys, time
from pathlib import Path
from typing import List, Tuple

DB_B = "/opt/scalp/project/data/b.db"
DB_X = "/opt/scalp/project/data/x_open.db"
LOGF = "/opt/scalp/project/logs/x_open.log"

def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s X_OPEN %(levelname)s %(message)s",
        handlers=[
            logging.FileHandler(LOGF),
            logging.StreamHandler(sys.stdout),
        ],
        force=True,
    )

def connect_db(path: str) -> sqlite3.Connection:
    conn = sqlite3.connect(path, timeout=30, isolation_level=None)
    conn.execute("PRAGMA journal_mode=WAL;")
    conn.execute("PRAGMA synchronous=NORMAL;")
    conn.execute("PRAGMA busy_timeout=5000;")
    return conn

def migrate(conn: sqlite3.Connection) -> None:
    conn.executescript("""
    CREATE TABLE IF NOT EXISTS positions_open(
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        instId TEXT NOT NULL,
        side TEXT NOT NULL,
        entry REAL,
        ts_open INTEGER,
        status TEXT DEFAULT 'open'
    );
    CREATE INDEX IF NOT EXISTS idx_open_instId ON positions_open(instId);
    """)

def fetch_signals(conn_b: sqlite3.Connection) -> List[Tuple[str,str,float,int]]:
    # On ne suppose plus l'existence de ts_hms : on prend ts_signal si dispo
    cols = [c[1] for c in conn_b.execute("PRAGMA table_info(signals_B);")]
    ts_col = "ts_signal" if "ts_signal" in cols else "ts"
    q = f"SELECT instId,side,price,{ts_col} FROM v_signals_for_open ORDER BY {ts_col} DESC LIMIT 50;"
    try:
        return conn_b.execute(q).fetchall()
    except Exception as e:
        logging.error(f"Impossible de lire v_signals_for_open: {e}")
        return []

def already_open(conn_x: sqlite3.Connection, instId: str) -> bool:
    row = conn_x.execute(
        "SELECT 1 FROM positions_open WHERE instId=? AND status='open' LIMIT 1;", (instId,)
    ).fetchone()
    return bool(row)

def insert_open(conn_x: sqlite3.Connection, instId: str, side: str, price: float, ts: int):
    conn_x.execute(
        "INSERT INTO positions_open(instId,side,entry,ts_open,status) VALUES(?,?,?,?,?)",
        (instId, side, price, ts, "open"),
    )
    conn_x.commit()

def process():
    conn_b = connect_db(DB_B)
    conn_x = connect_db(DB_X)
    migrate(conn_x)
    signals = fetch_signals(conn_b)
    for instId, side, price, ts in signals:
        if already_open(conn_x, instId):
            continue
        insert_open(conn_x, instId, side, price, ts)
        logging.info(f"NEW OPEN {instId} {side} @ {price}")
    conn_b.close()
    conn_x.close()

def main(argv: List[str]) -> int:
    setup_logging()
    while True:
        try:
            process()
            time.sleep(1)
        except KeyboardInterrupt:
            break
        except Exception as e:
            logging.error(f"Loop error: {e}")
            time.sleep(2)
    return 0

if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))

----- FILE: /opt/scalp/project/sql/A_ctx.sql -----
DROP VIEW IF EXISTS v_A_latest;
DROP VIEW IF EXISTS v_A_features;
DROP TABLE IF EXISTS ctx_a_latest;

CREATE TABLE IF NOT EXISTS ctx_a_latest (
    instId TEXT PRIMARY KEY,
    ts INTEGER,
    score_U REAL,
    score_A REAL,
    p_buy REAL,
    p_hold REAL,
    p_sell REAL,
    ctx TEXT
);

-- vue features multi-TF (inputs pour le modèle NEUTRAL)
CREATE VIEW v_A_features AS
SELECT
    m5.instId AS instId,
    m5.close AS close_5m,
    m15.close AS close_15m,
    m30.close AS close_30m,
    m5.ts AS ts
FROM ohlcv_5m m5
JOIN ohlcv_15m m15 ON m15.instId=m5.instId
JOIN ohlcv_30m m30 ON m30.instId=m5.instId;

-- vue sortie finale
CREATE VIEW v_A_latest AS
SELECT *
FROM ctx_a_latest;

----- FILE: /opt/scalp/project/sql/a_ctx.sql -----
DROP VIEW IF EXISTS ctx_a_latest;

CREATE VIEW ctx_a_latest AS
SELECT 
    f30.instId,
    f30.ts,
    COALESCE((ABS(f5.macd) + ABS(f15.macd) + ABS(f30.macd)) / 3.0, 0) AS score_A,
    CASE
        WHEN f5.macd > 0 AND f15.macd > 0 AND f30.macd > 0 THEN 'bullish'
        WHEN f5.macd < 0 AND f15.macd < 0 AND f30.macd < 0 THEN 'bearish'
        ELSE 'range'
    END AS ctx
FROM ohlcv_30m f30
LEFT JOIN ohlcv_15m f15 ON f15.instId=f30.instId
LEFT JOIN ohlcv_5m  f5  ON f5.instId=f30.instId
WHERE f30.ts = (SELECT MAX(ts) FROM ohlcv_30m f3 WHERE f3.instId=f30.instId)
GROUP BY f30.instId;

----- FILE: /opt/scalp/project/sql/a_ctx_fix.sql -----
DROP VIEW IF EXISTS ctx_a_latest;

CREATE VIEW ctx_a_latest AS
SELECT a1.instId, a1.ts, a1.score_U, a1.score_A, a1.p_buy, a1.p_sell, a1.ctx
FROM ctx_A a1
WHERE a1.ts = (
    SELECT MAX(a2.ts)
    FROM ctx_A a2
    WHERE a2.instId = a1.instId
);

----- FILE: /opt/scalp/project/sql/a_schema.sql -----
-- =========================================================
-- SCHEMA A : contextes multi-TF
-- =========================================================

-- --- tables brutes importées depuis OA ---
DROP TABLE IF EXISTS feat_5m;
DROP TABLE IF EXISTS feat_15m;
DROP TABLE IF EXISTS feat_30m;

CREATE TABLE feat_5m AS
SELECT instId, ts, open, high, low, close, vol FROM main.ohlcv_5m;

CREATE TABLE feat_15m AS
SELECT instId, ts, open, high, low, close, vol FROM main.ohlcv_15m;

CREATE TABLE feat_30m AS
SELECT instId, ts, open, high, low, close, vol FROM main.ohlcv_30m;

-- --- Ajout colonnes d'indicateurs ---
ALTER TABLE feat_5m  ADD COLUMN ema12 REAL;
ALTER TABLE feat_5m  ADD COLUMN ema26 REAL;
ALTER TABLE feat_5m  ADD COLUMN macd  REAL;
ALTER TABLE feat_5m  ADD COLUMN rsi14 REAL;

ALTER TABLE feat_15m ADD COLUMN ema12 REAL;
ALTER TABLE feat_15m ADD COLUMN ema26 REAL;
ALTER TABLE feat_15m ADD COLUMN macd  REAL;
ALTER TABLE feat_15m ADD COLUMN rsi14 REAL;

ALTER TABLE feat_30m ADD COLUMN ema12 REAL;
ALTER TABLE feat_30m ADD COLUMN ema26 REAL;
ALTER TABLE feat_30m ADD COLUMN macd  REAL;
ALTER TABLE feat_30m ADD COLUMN rsi14 REAL;

-- --- Table des contextes ---
DROP TABLE IF EXISTS ctx_A;
CREATE TABLE ctx_A (
    instId   TEXT,
    ts       INTEGER,
    score_U  REAL,
    score_A  REAL,
    p_buy    REAL,
    p_sell   REAL,
    ctx      TEXT
);

-- --- Vue simplifiée du dernier contexte ---
DROP VIEW IF EXISTS ctx_a_latest;
CREATE VIEW ctx_a_latest AS
SELECT instId, ts, score_U, score_A, p_buy, p_sell, ctx
FROM ctx_A
WHERE ts = (SELECT MAX(ts2) FROM ctx_A t2 WHERE t2.instId = ctx_A.instId);

----- FILE: /opt/scalp/project/sql/b_schema.sql -----
CREATE TABLE IF NOT EXISTS signals_B (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    instId TEXT NOT NULL,
    side TEXT NOT NULL,
    reason TEXT,
    score REAL,
    ts_signal INTEGER,
    status TEXT DEFAULT 'new'
);

-- Vue exposée pour opener (signaux non traités)
CREATE VIEW IF NOT EXISTS v_for_opener AS
SELECT id, instId, side, reason, score, ts_signal
FROM signals_B
WHERE status='new';

-- Accusé de réception venant d'opener
CREATE TABLE IF NOT EXISTS b_ack (
    signal_id INTEGER PRIMARY KEY,
    ts_ack INTEGER
);

CREATE VIEW IF NOT EXISTS v_to_B_ack AS
SELECT signal_id, ts_ack FROM b_ack;

----- FILE: /opt/scalp/project/sql/b_stabilize.sql -----
-- === TABLE SIGNALS_B ===
CREATE TABLE IF NOT EXISTS signals_B (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    instId TEXT,
    side TEXT,
    reason TEXT,
    price REAL,
    ctx TEXT,
    score_A REAL DEFAULT 0,
    score_B REAL DEFAULT 0,
    ts INTEGER,
    ts_hms TEXT
);

-- === VIEW v_signals_latest ===
DROP VIEW IF EXISTS v_signals_latest;
CREATE VIEW v_signals_latest AS
SELECT
    instId,
    side,
    reason,
    price,
    ctx,
    score_A,
    score_B,
    datetime(ts, 'unixepoch', 'localtime') AS ts_hms,
    printf('%02d:%02d', (strftime('%s','now') - ts)/60, (strftime('%s','now') - ts)%60) AS age_hms
FROM signals_B
ORDER BY ts DESC;

-- === VIEW v_for_opener ===
DROP VIEW IF EXISTS v_for_opener;
CREATE VIEW v_for_opener AS
SELECT
    instId,
    side,
    reason AS entry_reason,
    price AS price_signal,
    ctx,
    score_A,
    score_B,
    ts,
    ts_hms
FROM v_signals_latest
WHERE score_B >= 70
ORDER BY ts DESC;

----- FILE: /opt/scalp/project/sql/b_v_atr_latest_flat.sql -----
-- Vue: v_atr_latest_flat (instId sans '/'), ts, atr
DROP VIEW IF EXISTS v_atr_latest_flat;
CREATE VIEW v_atr_latest_flat AS
WITH latest AS (
  SELECT instId, MAX(ts) AS ts
  FROM feat_1m
  GROUP BY instId
)
SELECT
  REPLACE(f.instId,'/','') AS instId,
  f.ts,
  f.atr
FROM feat_1m f
JOIN latest l
  ON f.instId = l.instId AND f.ts = l.ts;

----- FILE: /opt/scalp/project/sql/b_view_for_opener.sql -----
-- Vue de production pour opener, compatible avec version actuelle de B
DROP VIEW IF EXISTS v_for_opener;
CREATE VIEW v_for_opener AS
SELECT
    ROW_NUMBER() OVER () AS id,
    instId,
    side,
    reason AS entry_reason,    -- MR, BO, PB, REV, CONT, RNG
    NULL AS score_U,           -- réservé pour score univers
    score_A,                   -- score actuel émis par B
    NULL AS score_B,           -- réservé pour score signal B
    price,
    ts * 1000 AS ts_signal     -- alignement ms
FROM v_signals_latest
WHERE side IN ('buy','sell');

----- FILE: /opt/scalp/project/sql/closer_schema.sql -----
PRAGMA foreign_keys=OFF;

DROP VIEW  IF EXISTS v_for_recorder;
DROP VIEW  IF EXISTS v_to_follower_ack;
DROP TABLE IF EXISTS trades_close;
DROP TABLE IF EXISTS close_ack;

CREATE TABLE trades_close (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    follow_id INTEGER,
    instId TEXT,
    side TEXT,
    entry REAL,
    exit REAL,
    qty REAL,
    pnl REAL,
    sl REAL,
    tp REAL,
    ts_open INTEGER,
    ts_close INTEGER,
    reason_exit TEXT,
    entry_reason TEXT,
    ctx TEXT,
    score_U REAL,
    score_A REAL,
    score_B REAL,
    status TEXT DEFAULT 'recorded'
);

CREATE TABLE close_ack (
    follow_id INTEGER,
    ts_ack INTEGER
);

CREATE VIEW v_for_recorder AS
SELECT
    id AS close_id,
    instId, side, entry, exit, qty, pnl, sl, tp,
    ts_open, ts_close, reason_exit, entry_reason,
    ctx, score_U, score_A, score_B
FROM trades_close
WHERE status='recorded';

CREATE VIEW v_to_follower_ack AS
SELECT follow_id, ts_ack FROM close_ack;

----- FILE: /opt/scalp/project/sql/fix_oa_cols.sql -----
-- =========================================================
-- Force la présence des colonnes EMA / MACD / RSI
-- =========================================================

-- 5m
BEGIN;
ALTER TABLE ohlcv_5m ADD COLUMN ema12 REAL;
ALTER TABLE ohlcv_5m ADD COLUMN ema26 REAL;
ALTER TABLE ohlcv_5m ADD COLUMN macd REAL;
ALTER TABLE ohlcv_5m ADD COLUMN rsi14 REAL;
COMMIT;

-- 15m
BEGIN;
ALTER TABLE ohlcv_15m ADD COLUMN ema12 REAL;
ALTER TABLE ohlcv_15m ADD COLUMN ema26 REAL;
ALTER TABLE ohlcv_15m ADD COLUMN macd REAL;
ALTER TABLE ohlcv_15m ADD COLUMN rsi14 REAL;
COMMIT;

-- 30m
BEGIN;
ALTER TABLE ohlcv_30m ADD COLUMN ema12 REAL;
ALTER TABLE ohlcv_30m ADD COLUMN ema26 REAL;
ALTER TABLE ohlcv_30m ADD COLUMN macd REAL;
ALTER TABLE ohlcv_30m ADD COLUMN rsi14 REAL;
COMMIT;

----- FILE: /opt/scalp/project/sql/follower_schema.sql -----
PRAGMA foreign_keys=OFF;

DROP VIEW  IF EXISTS v_for_closer;
DROP TABLE IF EXISTS trades_follow;

CREATE TABLE trades_follow (
    id            INTEGER PRIMARY KEY AUTOINCREMENT,
    instId        TEXT,
    side          TEXT,
    entry         REAL,
    qty           REAL,
    sl            REAL,
    tp            REAL,
    atr           REAL,
    be            INTEGER DEFAULT 0,
    pyr           INTEGER DEFAULT 0,
    pnl           REAL DEFAULT 0,
    entry_reason  TEXT,
    ctx           TEXT,
    score_U       REAL,
    score_A       REAL,
    score_B       REAL,
    ts_open       INTEGER,
    ts_update     INTEGER,
    status        TEXT DEFAULT 'active',
    exit_reason   TEXT DEFAULT ''
);

CREATE VIEW v_for_closer AS
SELECT
    id AS follow_id,
    instId, side, entry, qty, sl, tp, pnl,
    ts_open, ts_update, exit_reason, status,
    entry_reason, ctx, score_U, score_A, score_B
FROM trades_follow
WHERE status='to_close';

----- FILE: /opt/scalp/project/sql/h_view.sql -----
DROP VIEW IF EXISTS v_H_latest;
CREATE VIEW v_H_latest AS
WITH last20 AS (
    SELECT pnl, pnl_pct
    FROM history
    ORDER BY ts_close DESC
    LIMIT 20
),
stats AS (
    SELECT 
        (SELECT COUNT(*) FROM last20 WHERE pnl > 0) * 1.0 / (SELECT COUNT(*) FROM last20) AS winrate,
        (SELECT SUM(pnl) FROM last20 WHERE pnl > 0) AS sum_win,
        (SELECT SUM(ABS(pnl)) FROM last20 WHERE pnl < 0) AS sum_loss
)
SELECT 
    winrate,
    CASE WHEN sum_loss IS NULL OR sum_loss=0 THEN 1.0 ELSE MIN(1.0, (sum_win / sum_loss) / 2.0) END AS pf_norm,
    (0.50*winrate + 0.50*CASE WHEN sum_loss IS NULL OR sum_loss=0 THEN 1.0 ELSE MIN(1.0, (sum_win / sum_loss) / 2.0) END) AS score_H
FROM stats;

----- FILE: /opt/scalp/project/sql/init_macd.sql -----
-- =========================================================
-- Calcule basique MACD sur les trois TF
-- =========================================================

UPDATE ohlcv_5m
SET macd = (SELECT close - AVG(close) FROM (SELECT close FROM ohlcv_5m o2 WHERE o2.instId=ohlcv_5m.instId AND o2.ts<=ohlcv_5m.ts ORDER BY ts DESC LIMIT 26));

UPDATE ohlcv_15m
SET macd = (SELECT close - AVG(close) FROM (SELECT close FROM ohlcv_15m o2 WHERE o2.instId=ohlcv_15m.instId AND o2.ts<=ohlcv_15m.ts ORDER BY ts DESC LIMIT 26));

UPDATE ohlcv_30m
SET macd = (SELECT close - AVG(close) FROM (SELECT close FROM ohlcv_30m o2 WHERE o2.instId=ohlcv_30m.instId AND o2.ts<=ohlcv_30m.ts ORDER BY ts DESC LIMIT 26));

----- FILE: /opt/scalp/project/sql/oa_indicators.sql -----
-- =========================================================
-- OA INDICATORS (EMA, RSI, MACD, STOCH, ATR)
-- Corrigé pour tables: ohlcv_5m / ohlcv_15m / ohlcv_30m
-- =========================================================

-- Ajout des colonnes (si manquantes)
ALTER TABLE ohlcv_5m  ADD COLUMN ema12 REAL;
ALTER TABLE ohlcv_5m  ADD COLUMN ema26 REAL;
ALTER TABLE ohlcv_5m  ADD COLUMN macd REAL;
ALTER TABLE ohlcv_5m  ADD COLUMN macd_signal REAL;
ALTER TABLE ohlcv_5m  ADD COLUMN macd_hist REAL;
ALTER TABLE ohlcv_5m  ADD COLUMN rsi14 REAL;

ALTER TABLE ohlcv_15m ADD COLUMN ema12 REAL;
ALTER TABLE ohlcv_15m ADD COLUMN ema26 REAL;
ALTER TABLE ohlcv_15m ADD COLUMN macd REAL;
ALTER TABLE ohlcv_15m ADD COLUMN macd_signal REAL;
ALTER TABLE ohlcv_15m ADD COLUMN macd_hist REAL;
ALTER TABLE ohlcv_15m ADD COLUMN rsi14 REAL;

ALTER TABLE ohlcv_30m ADD COLUMN ema12 REAL;
ALTER TABLE ohlcv_30m ADD COLUMN ema26 REAL;
ALTER TABLE ohlcv_30m ADD COLUMN macd REAL;
ALTER TABLE ohlcv_30m ADD COLUMN macd_signal REAL;
ALTER TABLE ohlcv_30m ADD COLUMN macd_hist REAL;
ALTER TABLE ohlcv_30m ADD COLUMN rsi14 REAL;

-- EMA simple proxy (SMA initiale)
UPDATE ohlcv_5m
SET ema12 = (SELECT AVG(close) FROM (SELECT close FROM ohlcv_5m o2 WHERE o2.instId=ohlcv_5m.instId AND o2.ts<=ohlcv_5m.ts ORDER BY ts DESC LIMIT 12)),
    ema26 = (SELECT AVG(close) FROM (SELECT close FROM ohlcv_5m o2 WHERE o2.instId=ohlcv_5m.instId AND o2.ts<=ohlcv_5m.ts ORDER BY ts DESC LIMIT 26));
UPDATE ohlcv_5m SET macd = ema12 - ema26;

UPDATE ohlcv_15m
SET ema12 = (SELECT AVG(close) FROM (SELECT close FROM ohlcv_15m o2 WHERE o2.instId=ohlcv_15m.instId AND o2.ts<=ohlcv_15m.ts ORDER BY ts DESC LIMIT 12)),
    ema26 = (SELECT AVG(close) FROM (SELECT close FROM ohlcv_15m o2 WHERE o2.instId=ohlcv_15m.instId AND o2.ts<=ohlcv_15m.ts ORDER BY ts DESC LIMIT 26));
UPDATE ohlcv_15m SET macd = ema12 - ema26;

UPDATE ohlcv_30m
SET ema12 = (SELECT AVG(close) FROM (SELECT close FROM ohlcv_30m o2 WHERE o2.instId=ohlcv_30m.instId AND o2.ts<=ohlcv_30m.ts ORDER BY ts DESC LIMIT 12)),
    ema26 = (SELECT AVG(close) FROM (SELECT close FROM ohlcv_30m o2 WHERE o2.instId=ohlcv_30m.instId AND o2.ts<=ohlcv_30m.ts ORDER BY ts DESC LIMIT 26));
UPDATE ohlcv_30m SET macd = ema12 - ema26;


----- FILE: /opt/scalp/project/sql/opener_fix_ctx.sql -----
DROP VIEW IF EXISTS v_for_follower;

CREATE VIEW v_for_follower AS
SELECT
    id,
    instId,
    side,
    entry,
    qty,
    sl,
    tp,
    entry_reason,
    ctx,
    score_U,
    score_A,
    score_B,
    ts_create
FROM trades_open_init
WHERE status = 'pending';

----- FILE: /opt/scalp/project/sql/opener_schema.sql -----
CREATE TABLE IF NOT EXISTS trades_open_init (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    instId TEXT NOT NULL,
    side TEXT NOT NULL,
    entry REAL,
    qty REAL,
    leverage INTEGER DEFAULT 5,
    margin REAL,
    sl REAL,
    tp REAL,
    reason TEXT,
    ts_create INTEGER,
    status TEXT DEFAULT 'pending'
);

-- Vue exposée pour follower
CREATE VIEW IF NOT EXISTS v_for_follower AS
SELECT id, instId, side, entry, qty, leverage, margin, sl, tp, reason, ts_create
FROM trades_open_init
WHERE status='pending';

-- Accusé de réception pour B_signals
CREATE TABLE IF NOT EXISTS opener_ack (
    signal_id INTEGER PRIMARY KEY,
    ts_ack INTEGER
);

CREATE VIEW IF NOT EXISTS v_to_B_ack AS
SELECT signal_id, ts_ack FROM opener_ack;

----- FILE: /opt/scalp/project/sql/recorder_enhance_H.sql -----
-- ======================================================
-- RECORDER H PERFORMANCE ENHANCEMENT
-- ======================================================

-- Nettoyage préalable
DROP VIEW IF EXISTS v_H_coin;
DROP VIEW IF EXISTS v_H_setup;
DROP VIEW IF EXISTS v_H_coin_setup;

-- === SCORE H COIN (EMA par actif) ===
CREATE VIEW v_H_coin AS
WITH ranked AS (
    SELECT
        instId,
        score_H,
        ROW_NUMBER() OVER (PARTITION BY instId ORDER BY ts_record DESC) AS n
    FROM trades_record
)
SELECT
    instId,
    ROUND(SUM(score_H * POWER(0.9, n-1)) / SUM(POWER(0.9, n-1)), 4) AS score_H_coin,
    COUNT(*) AS trades_count,
    ROUND(SUM(CASE WHEN score_H > 0 THEN 1 ELSE 0 END)*100.0/COUNT(*),1) AS winrate
FROM ranked
GROUP BY instId
ORDER BY score_H_coin DESC;

-- === SCORE H SETUP (EMA par setup/entry_reason) ===
CREATE VIEW v_H_setup AS
WITH ranked AS (
    SELECT
        entry_reason,
        score_H,
        ROW_NUMBER() OVER (PARTITION BY entry_reason ORDER BY ts_record DESC) AS n
    FROM trades_record
)
SELECT
    entry_reason,
    ROUND(SUM(score_H * POWER(0.9, n-1)) / SUM(POWER(0.9, n-1)), 4) AS score_H_setup,
    COUNT(*) AS trades_count,
    ROUND(SUM(CASE WHEN score_H > 0 THEN 1 ELSE 0 END)*100.0/COUNT(*),1) AS winrate
FROM ranked
GROUP BY entry_reason
ORDER BY score_H_setup DESC;

-- === SCORE H COIN x SETUP (EMA croisé) ===
CREATE VIEW v_H_coin_setup AS
WITH ranked AS (
    SELECT
        instId,
        entry_reason,
        score_H,
        ROW_NUMBER() OVER (PARTITION BY instId, entry_reason ORDER BY ts_record DESC) AS n
    FROM trades_record
)
SELECT
    instId,
    entry_reason,
    ROUND(SUM(score_H * POWER(0.9, n-1)) / SUM(POWER(0.9, n-1)), 4) AS score_H_pair,
    COUNT(*) AS trades_count,
    ROUND(SUM(CASE WHEN score_H > 0 THEN 1 ELSE 0 END)*100.0/COUNT(*),1) AS winrate
FROM ranked
GROUP BY instId, entry_reason
ORDER BY score_H_pair DESC;

----- FILE: /opt/scalp/project/sql/recorder_schema.sql -----
PRAGMA foreign_keys=OFF;

DROP VIEW  IF EXISTS v_perf_summary;
DROP VIEW  IF EXISTS v_H_coin;
DROP VIEW  IF EXISTS v_H_setup;
DROP VIEW  IF EXISTS v_H_coin_setup;
DROP TABLE IF EXISTS trades_record;

CREATE TABLE trades_record (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    instId TEXT,
    side TEXT,
    pnl REAL,
    score_H REAL,
    reason_exit TEXT,
    entry_reason TEXT,
    ctx TEXT,
    ts_close INTEGER
);

CREATE VIEW v_perf_summary AS
SELECT
    COUNT(*) AS total,
    SUM(CASE WHEN pnl>0 THEN 1 ELSE 0 END) AS wins,
    SUM(CASE WHEN pnl<=0 THEN 1 ELSE 0 END) AS losses,
    ROUND(AVG(pnl),6) AS avg_pnl,
    ROUND(AVG(score_H),6) AS avg_H
FROM trades_record;

CREATE VIEW v_H_coin AS
SELECT
    instId,
    ROUND(AVG(score_H),6) AS avg_H,
    COUNT(*) AS n,
    ROUND(SUM(pnl),6) AS sum_pnl
FROM trades_record
GROUP BY instId;

CREATE VIEW v_H_setup AS
SELECT
    entry_reason,
    ROUND(AVG(score_H),6) AS avg_H,
    COUNT(*) AS n,
    ROUND(SUM(pnl),6) AS sum_pnl
FROM trades_record
GROUP BY entry_reason;

CREATE VIEW v_H_coin_setup AS
SELECT
    instId,
    entry_reason,
    ROUND(AVG(score_H),6) AS avg_H,
    COUNT(*) AS n,
    ROUND(SUM(pnl),6) AS sum_pnl
FROM trades_record
GROUP BY instId, entry_reason;

----- FILE: /opt/scalp/project/sql/recorder_schema_full.sql -----
PRAGMA foreign_keys=OFF;
DROP VIEW IF EXISTS v_perf_summary;
DROP VIEW IF EXISTS v_H_coin;
DROP VIEW IF EXISTS v_H_setup;
DROP VIEW IF EXISTS v_H_coin_setup;
DROP TABLE IF EXISTS trades_record;

CREATE TABLE trades_record (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    instId TEXT,
    side TEXT,
    pnl_raw REAL,
    pnl_net REAL,
    score_U REAL,
    score_A REAL,
    score_B REAL,
    score_H REAL,
    reason_exit TEXT,
    entry_reason TEXT,
    ctx TEXT,
    be_active INTEGER DEFAULT 0,
    trail_active INTEGER DEFAULT 0,
    pyr_level INTEGER DEFAULT 0,
    ts_open INTEGER,
    ts_close INTEGER,
    duration_s REAL,
    ts_record INTEGER DEFAULT (strftime('%s','now'))
);

CREATE VIEW v_perf_summary AS
SELECT
    COUNT(*) AS total,
    SUM(CASE WHEN pnl_net>0 THEN 1 ELSE 0 END) AS wins,
    SUM(CASE WHEN pnl_net<=0 THEN 1 ELSE 0 END) AS losses,
    ROUND(AVG(pnl_net),6) AS avg_pnl,
    ROUND(AVG(score_H),6) AS avg_H
FROM trades_record;

CREATE VIEW v_H_coin AS
SELECT instId,
       ROUND(AVG(score_H),6) AS avg_H,
       COUNT(*) AS n,
       ROUND(SUM(pnl_net),6) AS sum_pnl
FROM trades_record
GROUP BY instId;

CREATE VIEW v_H_setup AS
SELECT entry_reason,
       ROUND(AVG(score_H),6) AS avg_H,
       COUNT(*) AS n,
       ROUND(SUM(pnl_net),6) AS sum_pnl
FROM trades_record
GROUP BY entry_reason;

CREATE VIEW v_H_coin_setup AS
SELECT instId,
       entry_reason,
       ROUND(AVG(score_H),6) AS avg_H,
       COUNT(*) AS n,
       ROUND(SUM(pnl_net),6) AS sum_pnl
FROM trades_record
GROUP BY instId, entry_reason;

----- FILE: /opt/scalp/project/sql/signals.sql -----
DROP TABLE IF EXISTS signals;
CREATE TABLE signals (
    instId TEXT,
    side TEXT,
    ctx TEXT,
    score_U REAL,
    score_A REAL,
    score_B REAL,
    reason TEXT,
    ts_signal INTEGER
);
CREATE INDEX IF NOT EXISTS idx_signals_inst_ts ON signals(instId, ts_signal DESC);
DROP VIEW IF EXISTS signals_for_open;
CREATE VIEW signals_for_open AS
SELECT instId, side, ctx, score_U, score_A, score_B, reason, ts_signal
FROM signals
ORDER BY ts_signal DESC;

----- FILE: /opt/scalp/project/sql/signals_schema.sql -----
DROP TABLE IF EXISTS signals;
CREATE TABLE signals(
    instId     TEXT,
    ts_signal  INTEGER,
    side       TEXT,
    ctx        TEXT,
    score_U    REAL,
    score_A    REAL,
    score_B    REAL,
    reason     TEXT
);
CREATE INDEX IF NOT EXISTS idx_sig_inst ON signals(instId);
CREATE INDEX IF NOT EXISTS idx_sig_ts   ON signals(ts_signal DESC);

DROP VIEW IF EXISTS signals_for_open;
CREATE VIEW signals_for_open AS
SELECT *
FROM signals
ORDER BY ts_signal DESC;

----- FILE: /opt/scalp/project/sql/v_signals_last10.sql -----
CREATE VIEW IF NOT EXISTS v_signals_last10 AS
SELECT
    instId,
    side,
    reason,
    ctx,
    ROUND(price,6) AS price,
    ROUND(score_B,2) AS score_B,
    strftime('%Y-%m-%d %H:%M:%S', ts, 'unixepoch','localtime') AS ts_local,
    printf('%02d:%02d', (strftime('%s','now') - ts)/60, (strftime('%s','now') - ts)%60) AS age_hms
FROM signals_B
ORDER BY ts DESC
LIMIT 10;

----- FILE: /opt/scalp/project/sql/x_follow.sql -----
DROP TABLE IF EXISTS follow;
CREATE TABLE follow (
    instId TEXT PRIMARY KEY,
    entry REAL,
    current REAL,
    upnl REAL,
    sl REAL,
    tp1 REAL,
    tp2 REAL,
    stage TEXT,
    ts_update INTEGER
);

----- FILE: /opt/scalp/project/sql/x_history.sql -----
DROP TABLE IF EXISTS history;
CREATE TABLE history (
    instId TEXT,
    side TEXT,
    entry REAL,
    exit REAL,
    qty REAL,
    pnl REAL,
    pnl_pct REAL,
    lev REAL,
    risk REAL,
    score_U REAL,
    score_A REAL,
    score_B REAL,
    score_G REAL,
    reason_entry TEXT,
    reason_exit TEXT,
    ts_open INTEGER,
    ts_close INTEGER
);
CREATE INDEX IF NOT EXISTS idx_hist_ts ON history(ts_close DESC);

----- FILE: /opt/scalp/project/sql/x_history_schema.sql -----
CREATE TABLE IF NOT EXISTS x_history (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    instId TEXT NOT NULL,
    side TEXT NOT NULL,
    entry REAL NOT NULL,
    exit REAL NOT NULL,
    qty REAL NOT NULL,
    pnl REAL NOT NULL,
    score_U REAL NOT NULL,
    score_A REAL NOT NULL,
    score_B REAL NOT NULL,
    ts_open INTEGER NOT NULL,
    ts_close INTEGER NOT NULL
);

----- FILE: /opt/scalp/project/sql/x_open.sql -----
DROP TABLE IF EXISTS positions_open;
CREATE TABLE positions_open (
    instId TEXT PRIMARY KEY,
    side TEXT,
    entry REAL,
    qty REAL,
    lev REAL,
    risk REAL,
    score_U REAL,
    score_A REAL,
    score_B REAL,
    score_G REAL,
    reason TEXT,
    ts_open INTEGER
);

----- FILE: /opt/scalp/project/sql/x_schema.sql -----
-- =====================================================
-- X.DB  (Open, Follow, History, Views, Indexes)
-- =====================================================

-- POSITIONS OUVERTES
CREATE TABLE IF NOT EXISTS positions_open (
    instId      TEXT PRIMARY KEY,
    side        TEXT,
    entry       REAL,
    sl          REAL,
    tp          REAL,
    qty         REAL,
    score_U     REAL,
    score_A     REAL,
    score_B     REAL,
    ts_open     INTEGER
);

-- POSITIONS SUIVIES (SL/TP/BE/TRAIL)
CREATE TABLE IF NOT EXISTS follow (
    instId      TEXT PRIMARY KEY,
    side        TEXT,
    entry       REAL,
    sl          REAL,
    tp          REAL,
    be_active   INTEGER DEFAULT 0,
    trail_active INTEGER DEFAULT 0,
    atr         REAL,
    ts_update   INTEGER
);

-- HISTORIQUE
CREATE TABLE IF NOT EXISTS x_history (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    instId      TEXT,
    side        TEXT,
    entry       REAL,
    exit        REAL,
    pnl         REAL,
    score_U     REAL,
    score_A     REAL,
    score_B     REAL,
    ts_open     INTEGER,
    ts_close    INTEGER
);

-- ===== VUES =====

-- Dernière ATR 1m
CREATE VIEW IF NOT EXISTS v_atr1m AS
SELECT instId, atr, ts
FROM ob_atr_1m
WHERE ts = (SELECT MAX(ts) FROM ob_atr_1m AS t2 WHERE t2.instId = ob_atr_1m.instId);

-- Dernier signal B pour X
CREATE VIEW IF NOT EXISTS signals_for_open AS
SELECT instId, side, ctx, score_U, score_A, score_B, ts_signal
FROM signals
WHERE ts_signal = (SELECT MAX(ts_signal) FROM signals s2 WHERE s2.instId = signals.instId);

-- Suivi des positions (open + ATR)
CREATE VIEW IF NOT EXISTS v_positions_follow AS
SELECT p.instId, p.side, p.entry, f.sl, f.tp, f.atr, f.be_active, f.trail_active
FROM positions_open p
LEFT JOIN follow f ON p.instId = f.instId;

-- ===== INDEXES =====
CREATE INDEX IF NOT EXISTS idx_positions_open_inst ON positions_open(instId);
CREATE INDEX IF NOT EXISTS idx_follow_inst ON follow(instId);
CREATE INDEX IF NOT EXISTS idx_x_history_inst ON x_history(instId);

----- FILE: /opt/scalp/project/tmp_a_schema.txt -----

========== DATABASE DUMPS ==========

----- DATABASE: /opt/scalp/project/data/a.db -----
-- SCHEMA + DATA DUMP
5000
-- [WARN] locked or unreadable

----- DATABASE: /opt/scalp/project/data/b.db -----
-- SCHEMA + DATA DUMP
5000
-- [WARN] locked or unreadable

----- DATABASE: /opt/scalp/project/data/closer.db -----
-- SCHEMA + DATA DUMP
5000
-- [WARN] locked or unreadable

----- DATABASE: /opt/scalp/project/data/follower.db -----
-- SCHEMA + DATA DUMP
5000
-- [WARN] locked or unreadable

----- DATABASE: /opt/scalp/project/data/h.db -----
-- SCHEMA + DATA DUMP
5000
-- [WARN] locked or unreadable

----- DATABASE: /opt/scalp/project/data/oa.db -----
-- SCHEMA + DATA DUMP
5000
-- [WARN] locked or unreadable

----- DATABASE: /opt/scalp/project/data/ob.db -----
-- SCHEMA + DATA DUMP
5000
-- [WARN] locked or unreadable

----- DATABASE: /opt/scalp/project/data/opener.db -----
-- SCHEMA + DATA DUMP
5000
-- [WARN] locked or unreadable

----- DATABASE: /opt/scalp/project/data/recorder.db -----
-- SCHEMA + DATA DUMP
5000
-- [WARN] locked or unreadable

----- DATABASE: /opt/scalp/project/data/signals.db -----
-- SCHEMA + DATA DUMP
5000
-- [WARN] locked or unreadable

----- DATABASE: /opt/scalp/project/data/t.db -----
-- SCHEMA + DATA DUMP
5000
-- [WARN] locked or unreadable

----- DATABASE: /opt/scalp/project/data/u.db -----
-- SCHEMA + DATA DUMP
5000
-- [WARN] locked or unreadable

----- DATABASE: /opt/scalp/project/data/x.db -----
-- SCHEMA + DATA DUMP
5000
-- [WARN] locked or unreadable

----- DATABASE: /opt/scalp/project/data/x_account.db -----
-- SCHEMA + DATA DUMP
5000
-- [WARN] locked or unreadable

----- DATABASE: /opt/scalp/project/data/x_close.db -----
-- SCHEMA + DATA DUMP
5000
-- [WARN] locked or unreadable

----- DATABASE: /opt/scalp/project/data/x_closed.db -----
-- SCHEMA + DATA DUMP
5000
-- [WARN] locked or unreadable

----- DATABASE: /opt/scalp/project/data/x_follow.db -----
-- SCHEMA + DATA DUMP
5000
-- [WARN] locked or unreadable

----- DATABASE: /opt/scalp/project/data/x_history.db -----
-- SCHEMA + DATA DUMP
5000
-- [WARN] locked or unreadable

----- DATABASE: /opt/scalp/project/data/x_open.db -----
-- SCHEMA + DATA DUMP
5000
-- [WARN] locked or unreadable
